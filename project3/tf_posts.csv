,approved_at_utc,subreddit,selftext,author_fullname,saved,mod_reason_title,gilded,clicked,title,link_flair_richtext,subreddit_name_prefixed,hidden,pwls,link_flair_css_class,downs,thumbnail_height,top_awarded_type,hide_score,name,quarantine,link_flair_text_color,upvote_ratio,author_flair_background_color,subreddit_type,ups,total_awards_received,media_embed,thumbnail_width,author_flair_template_id,is_original_content,user_reports,secure_media,is_reddit_media_domain,is_meta,category,secure_media_embed,link_flair_text,can_mod_post,score,approved_by,author_premium,thumbnail,edited,author_flair_css_class,author_flair_richtext,gildings,content_categories,is_self,mod_note,created,link_flair_type,wls,removed_by_category,banned_by,author_flair_type,domain,allow_live_comments,selftext_html,likes,suggested_sort,banned_at_utc,view_count,archived,no_follow,is_crosspostable,pinned,over_18,all_awardings,awarders,media_only,link_flair_template_id,can_gild,spoiler,locked,author_flair_text,treatment_tags,visited,removed_by,num_reports,distinguished,subreddit_id,mod_reason_by,removal_reason,link_flair_background_color,id,is_robot_indexable,report_reasons,author,discussion_type,num_comments,send_replies,whitelist_status,contest_mode,mod_reports,author_patreon_flair,author_flair_text_color,permalink,parent_whitelist_status,stickied,url,subreddit_subscribers,created_utc,num_crossposts,media,is_video,post_hint,url_overridden_by_dest,preview,is_gallery,media_metadata,gallery_data,crosspost_parent_list,crosspost_parent,author_cakeday
0,,tensorflow,You can discuss anything here that doesn't require it's own post,t2_yr9xa,False,,0,False,The Official Feedback and Discussion Thread,[],r/tensorflow,False,6,,0,,,False,t3_fxzwdq,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,self,False,,[],{},,True,,1586492549.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;You can discuss anything here that doesn&amp;#39;t require it&amp;#39;s own post&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,moderator,t5_3alkk,,,,fxzwdq,True,,AkashMishra,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/fxzwdq/the_official_feedback_and_discussion_thread/,all_ads,True,https://www.reddit.com/r/tensorflow/comments/fxzwdq/the_official_feedback_and_discussion_thread/,22217,1586463749.0,0,,False,,,,,,,,,
1,,tensorflow,"A while back I made a post requesting the admins of this sub to make a mega thread about the certification exam, but unfortunately, they didn't do it so I decided I would make one myself, you can find my original request [here](https://www.reddit.com/r/tensorflow/comments/hhl4co/suggestion_lets_make_a_mega_thread_about_the/).

# Can the exam be taken the second you pay?

Yes, after you paid for the exam and your ID has been verified you are eligible to start whenever you want, it can be at that moment, a week later, or even a month.

# Where do you take the exam?

The exam can be taken from your home computer and is administered via a PyCharm plugin, an explanation on how to set it up can be found [here](https://utility.trueability.com/google/tensor-flow/Instructions_for_taking_the_TensorFlow_Certificate_exam.pdf) (on page 4).

# What is the process of the exam?

The exam is divided into 5 questions, each is harder and worth more points than the previous one, each question requires you to build and train a different model. **After you finish each question you are required to submit your answer otherwise it wouldn't count!** you can find an explanation on how to do it [here](https://utility.trueability.com/google/tensor-flow/Instructions_for_taking_the_TensorFlow_Certificate_exam.pdf) (on page 15).

After submitting an answer you receive a score between 1-5, you can resubmit your answer but note that **ONLY YOUR LAST SUBMISSION IS TAKEN INTO ACCOUNT**.

# What if my computer is not strong enough?

If you can’t train models in a reasonable amount of time (I.e. hours to train a single model) then you should consider using google Colab for the training part, the exam only requires you to have a trained model, it doesn’t matter where it has been trained.

# How much time does it take to get your results?

Google's official response is ""up to 2 weeks"" but I personally received my results immediately after finishing the exam.

# Can I take the exam again if I fail?

Google's official statement is:

* If you don't pass on your first attempt, you must wait 14 days before purchasing and taking the exam again.
* If you don't pass on your second attempt, you can purchase and retake the exam after a two month waiting period.
* If after three attempts you still have not passed the exam, you must wait one year.

# How do I study for the exam?

1. [TensorFlow in Practice specialization](https://www.coursera.org/specializations/tensorflow-in-practice) \- Highly recommended, should teach you everything you need.

Got more questions? think I forgot something? comment below and I would add it to this thread!",t2_6ec7nliq,False,,0,False,[Megathread] TensorFlow certification exam,[],r/tensorflow,False,6,,0,,,False,t3_hqd0qd,False,dark,0.99,,public,80,4,{},,,False,[],,False,False,,{},,False,80,,True,self,1594660064.0,,[],{},,True,,1594665566.0,text,6,,,text,self.tensorflow,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A while back I made a post requesting the admins of this sub to make a mega thread about the certification exam, but unfortunately, they didn&amp;#39;t do it so I decided I would make one myself, you can find my original request &lt;a href=""https://www.reddit.com/r/tensorflow/comments/hhl4co/suggestion_lets_make_a_mega_thread_about_the/""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;Can the exam be taken the second you pay?&lt;/h1&gt;

&lt;p&gt;Yes, after you paid for the exam and your ID has been verified you are eligible to start whenever you want, it can be at that moment, a week later, or even a month.&lt;/p&gt;

&lt;h1&gt;Where do you take the exam?&lt;/h1&gt;

&lt;p&gt;The exam can be taken from your home computer and is administered via a PyCharm plugin, an explanation on how to set it up can be found &lt;a href=""https://utility.trueability.com/google/tensor-flow/Instructions_for_taking_the_TensorFlow_Certificate_exam.pdf""&gt;here&lt;/a&gt; (on page 4).&lt;/p&gt;

&lt;h1&gt;What is the process of the exam?&lt;/h1&gt;

&lt;p&gt;The exam is divided into 5 questions, each is harder and worth more points than the previous one, each question requires you to build and train a different model. &lt;strong&gt;After you finish each question you are required to submit your answer otherwise it wouldn&amp;#39;t count!&lt;/strong&gt; you can find an explanation on how to do it &lt;a href=""https://utility.trueability.com/google/tensor-flow/Instructions_for_taking_the_TensorFlow_Certificate_exam.pdf""&gt;here&lt;/a&gt; (on page 15).&lt;/p&gt;

&lt;p&gt;After submitting an answer you receive a score between 1-5, you can resubmit your answer but note that &lt;strong&gt;ONLY YOUR LAST SUBMISSION IS TAKEN INTO ACCOUNT&lt;/strong&gt;.&lt;/p&gt;

&lt;h1&gt;What if my computer is not strong enough?&lt;/h1&gt;

&lt;p&gt;If you can’t train models in a reasonable amount of time (I.e. hours to train a single model) then you should consider using google Colab for the training part, the exam only requires you to have a trained model, it doesn’t matter where it has been trained.&lt;/p&gt;

&lt;h1&gt;How much time does it take to get your results?&lt;/h1&gt;

&lt;p&gt;Google&amp;#39;s official response is &amp;quot;up to 2 weeks&amp;quot; but I personally received my results immediately after finishing the exam.&lt;/p&gt;

&lt;h1&gt;Can I take the exam again if I fail?&lt;/h1&gt;

&lt;p&gt;Google&amp;#39;s official statement is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you don&amp;#39;t pass on your first attempt, you must wait 14 days before purchasing and taking the exam again.&lt;/li&gt;
&lt;li&gt;If you don&amp;#39;t pass on your second attempt, you can purchase and retake the exam after a two month waiting period.&lt;/li&gt;
&lt;li&gt;If after three attempts you still have not passed the exam, you must wait one year.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;How do I study for the exam?&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=""https://www.coursera.org/specializations/tensorflow-in-practice""&gt;TensorFlow in Practice specialization&lt;/a&gt; - Highly recommended, should teach you everything you need.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Got more questions? think I forgot something? comment below and I would add it to this thread!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 500, 'id': 'award_2ae56630-cfe0-424e-b810-4945b9145358', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 100, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/Animated_Helpful_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/Animated_Helpful_512.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/Animated_Helpful_512.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/Animated_Helpful_512.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/Animated_Helpful_512.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/Animated_Helpful_512.png', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Gives %{coin_symbol}100 Coins to both the author and the community.', 'end_date': None, 'subreddit_coin_reward': 100, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful (Pro)', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/zkc9cw88c8361_ChristmasHelpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=57278b329d19fd1d345888bfff68a51528777538', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/zkc9cw88c8361_ChristmasHelpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=db7b3f20402a8a6820a4ffebf35160d2557986e2', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/zkc9cw88c8361_ChristmasHelpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=0100d8da8f4dae0dc81d430733aa622d752c268c', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/zkc9cw88c8361_ChristmasHelpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=1029c080a179f45b6d83a51ed79dfd57997ae266', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/zkc9cw88c8361_ChristmasHelpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=50e7f8a870f79df7bc38bedb8a12e01137df5a77', 'width': 128, 'height': 128}], 'icon_format': 'APNG', 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/zkc9cw88c8361_ChristmasHelpful.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 50, 'id': 'award_02d9ab2c-162e-4c01-8438-317a016ed3d9', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""I'm in this with you."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Take My Energy', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 50, 'id': 'award_69c94eb4-d6a3-48e7-9cf2-0f39fed8b87c', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=16&amp;height=16&amp;auto=webp&amp;s=bb033b3352b6ece0954d279a56f99e16c67abe14', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=32&amp;height=32&amp;auto=webp&amp;s=a8e1d0c2994e6e0b254fab1611d539a4fb94e38a', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=48&amp;height=48&amp;auto=webp&amp;s=723e4e932c9692ac61cf5b7509424c6ae1b5d220', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=64&amp;height=64&amp;auto=webp&amp;s=b7f0640e403ac0ef31236a4a0b7f3dc25de6046c', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=128&amp;height=128&amp;auto=webp&amp;s=ac954bb1a06af66bf9295bbfee4550443fb6f21d', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Listen, get educated, and get involved.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Ally', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=16&amp;height=16&amp;auto=webp&amp;s=bb033b3352b6ece0954d279a56f99e16c67abe14', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=32&amp;height=32&amp;auto=webp&amp;s=a8e1d0c2994e6e0b254fab1611d539a4fb94e38a', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=48&amp;height=48&amp;auto=webp&amp;s=723e4e932c9692ac61cf5b7509424c6ae1b5d220', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=64&amp;height=64&amp;auto=webp&amp;s=b7f0640e403ac0ef31236a4a0b7f3dc25de6046c', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png?width=128&amp;height=128&amp;auto=webp&amp;s=ac954bb1a06af66bf9295bbfee4550443fb6f21d', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5nswjpyy44551_Ally.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,hqd0qd,True,,TomerHorowitz,,57,True,all_ads,False,[],False,,/r/tensorflow/comments/hqd0qd/megathread_tensorflow_certification_exam/,all_ads,True,https://www.reddit.com/r/tensorflow/comments/hqd0qd/megathread_tensorflow_certification_exam/,22217,1594636766.0,0,,False,,,,,,,,,
2,,tensorflow,,t2_40d0zt4s,False,,0,False,Guide To TensorLy: A Python Library For Tensor Learning,[],r/tensorflow,False,6,,0,78.0,,False,t3_m1vp41,False,dark,0.97,,public,29,0,{},140.0,,False,[],,False,False,,{},Discussion,False,29,,False,https://b.thumbs.redditmedia.com/vIgcLfK6oQb1os6iap-I5XWBOycS_voQYHwpnX9PcgI.jpg,False,,[],{},,False,,1615405407.0,text,6,,,text,analyticsindiamag.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,m1vp41,True,,analyticsindiam,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/m1vp41/guide_to_tensorly_a_python_library_for_tensor/,all_ads,False,https://analyticsindiamag.com/guide-to-tensorly-a-python-library-for-tensor-learning/,22217,1615376607.0,0,,False,link,https://analyticsindiamag.com/guide-to-tensorly-a-python-library-for-tensor-learning/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?auto=webp&amp;s=a1709956bd1529d2f44aee0e553c543cff0d76fb', 'width': 1600, 'height': 900}, 'resolutions': [{'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0799d6530237daa26050b0e0c29d0383d45e12ab', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9886b6c93e3c58183c458ce4ba76c5d8823a6d0', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=699b346be409fd1f571fee28dd07191eafc792a8', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fc74715aeb7644323ddff0d93fbc7cc175414eb', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9640274b183d5ec1f4066c189ef24bb5012544c', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/VIqxecvf8I8F1iTbo91NncRY2Q_sdIDBxVAVawGbtIo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d6b7586eccea0d4c3e5d371ac85aa9c733d9c1db', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'EdnC3kuu_N5yzf9jlpwjhyyJcLxhdyoy_bkf71jeWWQ'}], 'enabled': False}",,,,,,
3,,tensorflow,,t2_2e4fra5g,False,,0,False,Few experiments with neuro networks and sin(x) function. How NN fails in extrapolating,[],r/tensorflow,False,6,,0,105.0,,False,t3_m140zy,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pv0kgcO26JQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Why your neural network fails to predict a market price.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pv0kgcO26JQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'CloseToAlgoTrading', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pv0kgcO26JQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/CloseToAlgoTrading'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pv0kgcO26JQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/m140zy', 'height': 200}",,False,0,,False,https://b.thumbs.redditmedia.com/dobF1PIjE3_RNpc7ulO6THTyBWhpt2T9RexCE9wW62Q.jpg,False,,[],{},,False,,1615315934.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,m140zy,True,,Denis_Vo,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/m140zy/few_experiments_with_neuro_networks_and_sinx/,all_ads,False,https://youtu.be/pv0kgcO26JQ,22217,1615287134.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Why your neural network fails to predict a market price.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pv0kgcO26JQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'CloseToAlgoTrading', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pv0kgcO26JQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/CloseToAlgoTrading'}}",False,rich:video,https://youtu.be/pv0kgcO26JQ,"{'images': [{'source': {'url': 'https://external-preview.redd.it/8ggd1LuRmg0n4a-gjbyFrSx1Cs8dZ5mhWHElrE1KDaU.jpg?auto=webp&amp;s=6f7bd0025cce52ad6f893d03fd1abe3837e7d9a1', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/8ggd1LuRmg0n4a-gjbyFrSx1Cs8dZ5mhWHElrE1KDaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe5a798cdd93aca1bd1fb2156ba59c11b3692142', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/8ggd1LuRmg0n4a-gjbyFrSx1Cs8dZ5mhWHElrE1KDaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1b1d0956eda89eeedc4fff5182a285087e2d045', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/8ggd1LuRmg0n4a-gjbyFrSx1Cs8dZ5mhWHElrE1KDaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa2eb721f7670d2b3b9a9b17716716b3dad2d3f3', 'width': 320, 'height': 240}], 'variants': {}, 'id': '6aoZGfTVubGR8sO_5u9AoqrHtCcOhIY4Hhe3y0SN1hM'}], 'enabled': False}",,,,,,
4,,tensorflow,"Open Neural Network Exchange (ONNX) is a powerful and open format built to represent machine learning models. The final outcome of training any machine learning or deep learning algorithm is a model file that represents the mapping of input data to output predictions in an efficient manner.

Read more: [https://analyticsindiamag.com/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx/](https://analyticsindiamag.com/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx/)",t2_40d0zt4s,False,,0,False,Converting a model from Pytorch to Tensorflow: Guide to ONNX,[],r/tensorflow,False,6,,0,,,False,t3_m0ed3t,False,dark,0.92,,public,19,0,{},,,False,[],,False,False,,{},Discussion,False,19,,False,self,False,,[],{},,True,,1615234126.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Open Neural Network Exchange (ONNX) is a powerful and open format built to represent machine learning models. The final outcome of training any machine learning or deep learning algorithm is a model file that represents the mapping of input data to output predictions in an efficient manner.&lt;/p&gt;

&lt;p&gt;Read more: &lt;a href=""https://analyticsindiamag.com/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx/""&gt;https://analyticsindiamag.com/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,m0ed3t,True,,analyticsindiam,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/m0ed3t/converting_a_model_from_pytorch_to_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/m0ed3t/converting_a_model_from_pytorch_to_tensorflow/,22217,1615205326.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?auto=webp&amp;s=b6b9662774296c1ace6c21c71d74d18d6ec9f1bd', 'width': 1640, 'height': 924}, 'resolutions': [{'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=90766cbc4b97732d9ff2f50bf4d4de72c205f577', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=387fbd04ec08391130d43cd3ffd4d2ef1d7a1554', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f34d211dc68dd2f0b4cc8f2be4dab0c5c7221be', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1aa36311e3326aa1e972a76c3fa1d7c7fe32d336', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=effe39e93ee877daada6b97f1b0aad20a97c4592', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/b3wcHCh1vyuDOJ2ZhnicD8BRGJl4-ggXE3nlWNQhAAk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8046adbfafb368d868af71534e2e51991107ae44', 'width': 1080, 'height': 608}], 'variants': {}, 'id': 'n3T4I4dtOOPcNVA3EUHygJmlq7D5L3W3_vt08SvphxQ'}], 'enabled': False}",,,,,,
5,,tensorflow,,t2_3sxzs6ia,False,,0,False,Deep Learning With TensorFlow &amp; Keras - One of the best tutorial for beginners,[],r/tensorflow,False,6,,0,105.0,,False,t3_lzxjbr,False,dark,0.9,,public,14,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eK0tvVRMDgw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'TensorFlow And Keras Tutorial | Deep Learning With TensorFlow &amp; Keras  | Deep Learning | Simplilearn', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eK0tvVRMDgw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Simplilearn', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/eK0tvVRMDgw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/Simplilearn'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eK0tvVRMDgw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lzxjbr', 'height': 200}",Tutorial,False,14,,False,https://b.thumbs.redditmedia.com/gyQsR6NKgGG6_nwHVvXQTGslz-7hcJ6ZNwa7sxAT3hU.jpg,False,,[],{},,False,,1615173643.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lzxjbr,True,,Public_Conflict,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lzxjbr/deep_learning_with_tensorflow_keras_one_of_the/,all_ads,False,https://www.youtube.com/watch?v=eK0tvVRMDgw,22217,1615144843.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'TensorFlow And Keras Tutorial | Deep Learning With TensorFlow &amp; Keras  | Deep Learning | Simplilearn', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eK0tvVRMDgw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Simplilearn', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/eK0tvVRMDgw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/Simplilearn'}}",False,rich:video,https://www.youtube.com/watch?v=eK0tvVRMDgw,"{'images': [{'source': {'url': 'https://external-preview.redd.it/SVAI3dQ7V1f8V-Fqdu_Y1ZQoIHhw8NS3VFzYFtFFX_0.jpg?auto=webp&amp;s=7174a216a8867ebd74ce180cd991a851ae156061', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/SVAI3dQ7V1f8V-Fqdu_Y1ZQoIHhw8NS3VFzYFtFFX_0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ab85962945de8be3c9cd7b71ef470346cc1ff80', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/SVAI3dQ7V1f8V-Fqdu_Y1ZQoIHhw8NS3VFzYFtFFX_0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a81ce88e2e1641aa7c6d656a7f767cbfeab636d3', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/SVAI3dQ7V1f8V-Fqdu_Y1ZQoIHhw8NS3VFzYFtFFX_0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3315e46057aa0a866081e2b961c85466f9656e9', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Z7aUKab5WPgscGDA5zXjxEVKWZ-e0wHPm8EqB-r7-X8'}], 'enabled': False}",,,,,,
6,,tensorflow,,t2_2o7eaff,False,,0,False,How we used AI to Create Complete Band’s Visual Identity,[],r/tensorflow,False,6,,0,78.0,,False,t3_m0ag0x,False,dark,0.6,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/X9F9tosJgd4Y6_FGH_GkYjjrh21IK5_qTOb46ypkDaM.jpg,False,,[],{},,False,,1615217072.0,text,6,,,text,rubikscode.net,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,m0ag0x,True,,RubiksCodeNMZ,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/m0ag0x/how_we_used_ai_to_create_complete_bands_visual/,all_ads,False,https://rubikscode.net/2021/03/07/how-we-used-ai-to-create-complete-bands-visual-identity/,22217,1615188272.0,0,,False,link,https://rubikscode.net/2021/03/07/how-we-used-ai-to-create-complete-bands-visual-identity/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?auto=webp&amp;s=4f650fdde15ce2cdce303e107a405ddee2f1f4f0', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f654c84e03b5f74da74052ebf0ea462b156a8b1', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff0bff763ad656bde058d318a472e9f60e53a8cb', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ad956028b65f8643b289f4a032b9223f942db9e', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=680b5f3101f5354bcc0effd5cb5404f39a72b10b', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b96d3c93872cd170f984e56d4903ec92c46c8031', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/NmHJOA0NtZbRVbafjlQdE74PFEgnJ2QZ-Ygqzqb31pI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ebe6c8614d5cbc7454b371f6ffc543f4733592f4', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'guG4XvezJ3j1pb4oRv1rwwACEhpDTOVhZpiKTsBZ3sk'}], 'enabled': False}",,,,,,
7,,tensorflow,,t2_68tp0yii,False,,0,False,Looking for feedback on my project built with Tensorflow Lite. It's a social app for creating image classifiers called Palapa.,[],r/tensorflow,False,6,,0,105.0,,False,t3_lzfzye,False,dark,0.92,,public,20,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/IMcfixRK6D8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Automation Stories - Audio Alerts', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/IMcfixRK6D8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Palapa', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IMcfixRK6D8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_Kber2ZFb4fR0NSqABKh_g'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/IMcfixRK6D8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lzfzye', 'height': 200}",Project,False,20,,False,https://b.thumbs.redditmedia.com/YEY5QhVlbFmzMRNUHU0ZKn7lLZcnspjGs-T4yRi4JjY.jpg,False,,[],{},,False,,1615108895.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lzfzye,True,,saad2xi,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lzfzye/looking_for_feedback_on_my_project_built_with/,all_ads,False,https://youtu.be/IMcfixRK6D8,22217,1615080095.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Automation Stories - Audio Alerts', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/IMcfixRK6D8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Palapa', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IMcfixRK6D8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_Kber2ZFb4fR0NSqABKh_g'}}",False,rich:video,https://youtu.be/IMcfixRK6D8,"{'images': [{'source': {'url': 'https://external-preview.redd.it/N51AVApq4SGAo0NK_rNJZm7ULYw-QfXtiRWUo6xKpAk.jpg?auto=webp&amp;s=5b535210b4033fc72906d919705c99b4df4f56fb', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/N51AVApq4SGAo0NK_rNJZm7ULYw-QfXtiRWUo6xKpAk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ea4e0b114ec01adab9fafeb3c415f937495178a', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/N51AVApq4SGAo0NK_rNJZm7ULYw-QfXtiRWUo6xKpAk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8aeb6c929e2f1aea0d52efc6a72aacacd34ad3c', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/N51AVApq4SGAo0NK_rNJZm7ULYw-QfXtiRWUo6xKpAk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7920bddf02cdbf7f63b53f98d79beea2184b4234', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'B6uS26-wZTzt8pE7M1COsrgRDzSM5EeqwRVPeGJaLZ0'}], 'enabled': False}",,,,,,
8,,tensorflow,"TL/DR: Developing stock prediction model. It's predicting Coca Cola closes at $42.56 on 3/12/2021. I expect this be VERY inaccurate.

Disclaimer: Don't use this for financial advice. I'm brand new to tensorflow/python and the stock market. I own no KO shares. 

So for background, I'm teaching myself about investing and tensorflow all in a single project. I know nothing about either topic. I hope to provide weekly updates here to keep my honest, and on track.

My goal is to have a prediction for the Friday closing price of a stock before the market opens on Monday. Scope wise, I'm starting with Coca Cola only, and eventually plan to include tickers in DJIA and then scale up all tickers in the SP500. 

To evaluate the ""goodness"" of my models, I plan to compare against ""Assume it stays the same."" 

On 2021-03-05 KO closed at $50.79. My baseline comparison will be to compare the % error of my model prediction of $42.56 vs the % error of assuming the closing price next week remains $50.79.

Long term, I plan to use Root Mean Square of the percent error of my model vs. ""Assume it stays the same.""

On the technical side, I'm using Alphavantage for my data source. For the last week, I use:

1. Monday's open price in USD
2. Monday's high price in USD
3. Monday's low price in USD
4. Monday's closing price in USD
5. Monday's volume in shares

These 5 features are collected for all 5 days. 

My neural network has 2 layers:

1. 20 nodes LSTM
2. 10 nodes LSTM

The output is the predicted closing price of Friday.

I've used the last 10 years of Coca Cola's daily trading information using Alphabantage's TIME\_SERIES\_DAILY. 

For the LSTM, I include 10 weeks of lookback to include in training and I'm using a randomly selected 70/30 training/validation split. Though due to the nature of LSTM, I have a fair share of rolling overlap.

I have not included scaling yet. I plan on changing the pricing features from USD to % change from last week's close, though I have not yet implemented that.

I also plan on changing volume to not be in shares, by rather percentage of shares outstanding, though I might end up using percentage of float. Still seeking a data source to easily integrate this, but I might need to do it by hand. 

My LSTM prediction also back predicted Coca Cola to be closing pretty consistently around $42.56 for the last 10 weeks, and this clearly is NOT true. So I'll check back in a week to see how bad I've performed.",t2_ari9vkm7,False,,0,False,Silly Prediction: Coca Cola Stock closing price $42.56 for 3/12/2021,[],r/tensorflow,False,6,,0,,,False,t3_lzv277,False,dark,0.17,,public,0,0,{},,,False,[],,False,False,,{},Project,False,0,,False,self,False,,[],{},,True,,1615166288.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TL/DR: Developing stock prediction model. It&amp;#39;s predicting Coca Cola closes at $42.56 on 3/12/2021. I expect this be VERY inaccurate.&lt;/p&gt;

&lt;p&gt;Disclaimer: Don&amp;#39;t use this for financial advice. I&amp;#39;m brand new to tensorflow/python and the stock market. I own no KO shares. &lt;/p&gt;

&lt;p&gt;So for background, I&amp;#39;m teaching myself about investing and tensorflow all in a single project. I know nothing about either topic. I hope to provide weekly updates here to keep my honest, and on track.&lt;/p&gt;

&lt;p&gt;My goal is to have a prediction for the Friday closing price of a stock before the market opens on Monday. Scope wise, I&amp;#39;m starting with Coca Cola only, and eventually plan to include tickers in DJIA and then scale up all tickers in the SP500. &lt;/p&gt;

&lt;p&gt;To evaluate the &amp;quot;goodness&amp;quot; of my models, I plan to compare against &amp;quot;Assume it stays the same.&amp;quot; &lt;/p&gt;

&lt;p&gt;On 2021-03-05 KO closed at $50.79. My baseline comparison will be to compare the % error of my model prediction of $42.56 vs the % error of assuming the closing price next week remains $50.79.&lt;/p&gt;

&lt;p&gt;Long term, I plan to use Root Mean Square of the percent error of my model vs. &amp;quot;Assume it stays the same.&amp;quot;&lt;/p&gt;

&lt;p&gt;On the technical side, I&amp;#39;m using Alphavantage for my data source. For the last week, I use:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Monday&amp;#39;s open price in USD&lt;/li&gt;
&lt;li&gt;Monday&amp;#39;s high price in USD&lt;/li&gt;
&lt;li&gt;Monday&amp;#39;s low price in USD&lt;/li&gt;
&lt;li&gt;Monday&amp;#39;s closing price in USD&lt;/li&gt;
&lt;li&gt;Monday&amp;#39;s volume in shares&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These 5 features are collected for all 5 days. &lt;/p&gt;

&lt;p&gt;My neural network has 2 layers:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;20 nodes LSTM&lt;/li&gt;
&lt;li&gt;10 nodes LSTM&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The output is the predicted closing price of Friday.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve used the last 10 years of Coca Cola&amp;#39;s daily trading information using Alphabantage&amp;#39;s TIME_SERIES_DAILY. &lt;/p&gt;

&lt;p&gt;For the LSTM, I include 10 weeks of lookback to include in training and I&amp;#39;m using a randomly selected 70/30 training/validation split. Though due to the nature of LSTM, I have a fair share of rolling overlap.&lt;/p&gt;

&lt;p&gt;I have not included scaling yet. I plan on changing the pricing features from USD to % change from last week&amp;#39;s close, though I have not yet implemented that.&lt;/p&gt;

&lt;p&gt;I also plan on changing volume to not be in shares, by rather percentage of shares outstanding, though I might end up using percentage of float. Still seeking a data source to easily integrate this, but I might need to do it by hand. &lt;/p&gt;

&lt;p&gt;My LSTM prediction also back predicted Coca Cola to be closing pretty consistently around $42.56 for the last 10 weeks, and this clearly is NOT true. So I&amp;#39;ll check back in a week to see how bad I&amp;#39;ve performed.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lzv277,True,,squirrelaway4all,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lzv277/silly_prediction_coca_cola_stock_closing_price/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lzv277/silly_prediction_coca_cola_stock_closing_price/,22217,1615137488.0,0,,False,,,,,,,,,
9,,tensorflow,,t2_a9ckctu2,False,,0,False,Save models as tflite,[],r/tensorflow,False,6,,0,60.0,,False,t3_lzbuhy,False,dark,1.0,,public,7,0,{},140.0,,False,[],,False,False,,{},Question,False,7,,False,https://b.thumbs.redditmedia.com/Vca_hs7hgToIDrteBgctX7pinu44O9O4cUyei69L-kM.jpg,False,,[],{},,False,,1615095702.0,text,6,,,text,reddit.com,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lzbuhy,True,,Rama_AI,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/lzbuhy/save_models_as_tflite/,all_ads,False,https://www.reddit.com/gallery/lzbuhy,22217,1615066902.0,0,,False,,https://www.reddit.com/gallery/lzbuhy,,True,"{'p4gxpu9r8hl61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 40, 'x': 108, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b7b074c8e9a1051e3ad627a551677ebd4a2140e'}, {'y': 80, 'x': 216, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=04bcf28fa6bcf3892bfcd7ea2793931bf241cccc'}, {'y': 118, 'x': 320, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=deb300165e9834f3bfacbe5dd924c4540908aee3'}, {'y': 237, 'x': 640, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=83e770a0636f308d85a7da31adafa19b0b6111e1'}, {'y': 356, 'x': 960, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d5a2242cf28c2b642ebeab2767bbc972af855fd5'}, {'y': 401, 'x': 1080, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d1e00052218f0da9fdb6aa0d5e9b6f161a64958b'}], 's': {'y': 667, 'x': 1795, 'u': 'https://preview.redd.it/p4gxpu9r8hl61.png?width=1795&amp;format=png&amp;auto=webp&amp;s=d0c8e1d5a59b77e6d82801bdac4017d4da89ece2'}, 'id': 'p4gxpu9r8hl61'}, '833gqt9r8hl61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 46, 'x': 108, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fcb8ef745127449c1c8b64d9dabfc7877add2e33'}, {'y': 93, 'x': 216, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20c6992343e54d5a1fc6a5b5bb03187c5f2e73b9'}, {'y': 138, 'x': 320, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f56efeac7432b0e782a434ce6d2ac6a6db94947a'}, {'y': 276, 'x': 640, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a71ab49a87d86494fa72d68ca355ddc11319f775'}, {'y': 415, 'x': 960, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c6d7fbda7b038195eee5d2e20ae1d5eef26d3b1f'}, {'y': 467, 'x': 1080, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c09cbfe9bd3e4713e4e253769178a7342cb31d99'}], 's': {'y': 652, 'x': 1507, 'u': 'https://preview.redd.it/833gqt9r8hl61.png?width=1507&amp;format=png&amp;auto=webp&amp;s=20ffb324b84ae43fb59356b4a73420b065a16076'}, 'id': '833gqt9r8hl61'}}","{'items': [{'caption': 'Hello,  I am working on an image caption model but I faced a problem with saving the model as tflite or HDF5. I tried a lot of things but does not work.  May anyone help me?', 'media_id': '833gqt9r8hl61', 'id': 31615477}, {'media_id': 'p4gxpu9r8hl61', 'id': 31615478}]}",,,
10,,tensorflow,,t2_2ywvy0k,False,,0,False,"Anyone has link for code to this? Just to label some old photos and animate (still a beginner, dunno if you can animate or teach TF to do facial expressions)",[],r/tensorflow,False,6,,0,140.0,,False,t3_lyq33s,False,dark,0.92,,public,44,0,{},140.0,,False,[],"{'reddit_video': {'bitrate_kbps': 2400, 'fallback_url': 'https://v.redd.it/8pyx7d9tzal61/DASH_720.mp4?source=fallback', 'height': 720, 'width': 405, 'scrubber_media_url': 'https://v.redd.it/8pyx7d9tzal61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/8pyx7d9tzal61/DASHPlaylist.mpd?a=1618044636%2CZTMwM2RkMzQzNmExOWMzYjBkN2JkZTlmOTllOTJhMTNhNzFiN2Y2NzVjODlkZTc5NjYwMDc1YWU1ODRjM2E5OA%3D%3D&amp;v=1&amp;f=sd', 'duration': 44, 'hls_url': 'https://v.redd.it/8pyx7d9tzal61/HLSPlaylist.m3u8?a=1618044636%2CYTdhNjNjMGMzNzA4ODhlYmRjNGQyZTBjYjQ0MGI3YTE3OGExNmUwOWIxNmMzMzhhYzM2YmJmY2E0NDJlMjI5Zg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},Question,False,44,,False,https://b.thumbs.redditmedia.com/rfOKTgnCvYY1qx3rxudcwIeAjI_X3K_DvlCYONOwSks.jpg,False,,[],{},,False,,1615020033.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lyq33s,True,,karball,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/lyq33s/anyone_has_link_for_code_to_this_just_to_label/,all_ads,False,https://v.redd.it/8pyx7d9tzal61,22217,1614991233.0,0,"{'reddit_video': {'bitrate_kbps': 2400, 'fallback_url': 'https://v.redd.it/8pyx7d9tzal61/DASH_720.mp4?source=fallback', 'height': 720, 'width': 405, 'scrubber_media_url': 'https://v.redd.it/8pyx7d9tzal61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/8pyx7d9tzal61/DASHPlaylist.mpd?a=1618044636%2CZTMwM2RkMzQzNmExOWMzYjBkN2JkZTlmOTllOTJhMTNhNzFiN2Y2NzVjODlkZTc5NjYwMDc1YWU1ODRjM2E5OA%3D%3D&amp;v=1&amp;f=sd', 'duration': 44, 'hls_url': 'https://v.redd.it/8pyx7d9tzal61/HLSPlaylist.m3u8?a=1618044636%2CYTdhNjNjMGMzNzA4ODhlYmRjNGQyZTBjYjQ0MGI3YTE3OGExNmUwOWIxNmMzMzhhYzM2YmJmY2E0NDJlMjI5Zg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/8pyx7d9tzal61,"{'images': [{'source': {'url': 'https://external-preview.redd.it/lYxIXsJ16Q4UtPrcbxyc2e2TsvDACl2IDfOQoztpCkY.png?format=pjpg&amp;auto=webp&amp;s=f43e0063fdfae93a94fd740d18b8642fdf80ab71', 'width': 576, 'height': 1024}, 'resolutions': [{'url': 'https://external-preview.redd.it/lYxIXsJ16Q4UtPrcbxyc2e2TsvDACl2IDfOQoztpCkY.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f0459e7320decb5820925382340b4ddd724c1475', 'width': 108, 'height': 192}, {'url': 'https://external-preview.redd.it/lYxIXsJ16Q4UtPrcbxyc2e2TsvDACl2IDfOQoztpCkY.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=365681b073fd7b364e74ff895db6b9bb731c22a4', 'width': 216, 'height': 384}, {'url': 'https://external-preview.redd.it/lYxIXsJ16Q4UtPrcbxyc2e2TsvDACl2IDfOQoztpCkY.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8951fa65606946f2a064c05b37d01c7a8470d90e', 'width': 320, 'height': 568}], 'variants': {}, 'id': 'RgLmkV-tEb6xEseC-j8D2dUY8L5MKOKJf4QyzJBJH18'}], 'enabled': False}",,,,,,
11,,tensorflow,,t2_40d0zt4s,False,,0,False,Guide to Abstract Meaning Representation(AMR) to text with TensorFlow - Analytics India Magazine,[],r/tensorflow,False,6,,0,105.0,,False,t3_lxga0e,False,dark,1.0,,public,10,0,{},140.0,,False,[],,False,False,,{},Discussion,False,10,,False,https://b.thumbs.redditmedia.com/H1hUH1-E1eB5r-wzALIDZv9CfZnbVtwbNEsgf6xJOuA.jpg,False,,[],{},,False,,1614876629.0,text,6,,,text,analyticsindiamag.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lxga0e,True,,analyticsindiam,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lxga0e/guide_to_abstract_meaning_representationamr_to/,all_ads,False,https://analyticsindiamag.com/guide-to-abstract-meaning-representationamr-to-text-with-tensorflow/,22217,1614847829.0,0,,False,link,https://analyticsindiamag.com/guide-to-abstract-meaning-representationamr-to-text-with-tensorflow/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?auto=webp&amp;s=a741c1afa926ed72746ddea3021141b96774536d', 'width': 2560, 'height': 1920}, 'resolutions': [{'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da71c4f22b2c96ae49fc35cafa7eebcf70a38bae', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=007b64237eeccdda8f636cc735a69e8becf85b3a', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a06efe4a76f71b980c74e00d068aa2b41842a978', 'width': 320, 'height': 240}, {'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c3f188eaa66babfadddadecbd3c2ba5e4d727ea', 'width': 640, 'height': 480}, {'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93f5cb8db6c94f68f1bea411684ee47db7abe8b1', 'width': 960, 'height': 720}, {'url': 'https://external-preview.redd.it/rrBPIqWF6I6D5_-sG0pNoAgpwXCi6olyLmM0EnTPy_E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e73a38cdb03961565cbdc16929e0d8afdc400f08', 'width': 1080, 'height': 810}], 'variants': {}, 'id': 'cRORc2AHllMDNy2LjFC8oxPE9oX-DrHNy5dRShGazlk'}], 'enabled': False}",,,,,,
12,,tensorflow,"Hello,

I am working on an image caption model but I faced a problem with saving the model as tflite or HDF5. I tried a lot of things but does not work. 

My model is a subclass model and similar to this work : 

[https://tensorflow.google.cn/tutorials/text/image\_captioning?hl=en](https://www.freelancer.com/users/l.php?url=https:%2F%2Ftensorflow.google.cn%2Ftutorials%2Ftext%2Fimage_captioning%3Fhl%3Den&amp;sig=0e2a00e1399e0f8c575476e0d728aebcd41fbb3e1d3497a6ec140f54e0375860)

&amp;#x200B;

 Can anyone help me?",t2_a9ckctu2,False,,0,False,Save TensorFlow subclass model,[],r/tensorflow,False,6,,0,,,False,t3_lxn6mi,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614900855.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I am working on an image caption model but I faced a problem with saving the model as tflite or HDF5. I tried a lot of things but does not work. &lt;/p&gt;

&lt;p&gt;My model is a subclass model and similar to this work : &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.freelancer.com/users/l.php?url=https:%2F%2Ftensorflow.google.cn%2Ftutorials%2Ftext%2Fimage_captioning%3Fhl%3Den&amp;amp;sig=0e2a00e1399e0f8c575476e0d728aebcd41fbb3e1d3497a6ec140f54e0375860""&gt;https://tensorflow.google.cn/tutorials/text/image_captioning?hl=en&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can anyone help me?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lxn6mi,True,,Rama_AI,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lxn6mi/save_tensorflow_subclass_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lxn6mi/save_tensorflow_subclass_model/,22217,1614872055.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?auto=webp&amp;s=d6a56eb9f1938d80b2f8e37de4de7fbbe84b2526', 'width': 1200, 'height': 1200}, 'resolutions': [{'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=76b41cb3d1bee81e6053f9b0e52bdb57096d1d50', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=badb7597681cb024f67ae067719c132d4f2ae4a0', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c53f9348e7a18697d6b5d26e81e2cb69386e102', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3227057b2519eab3ae75b86cc48aee958486bbcc', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b4a7a668a9d3cccae4c7db958a2af297160dd9f8', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/F3jijM5sHRPFeJkGMwpaeKPoMHx3GU96mT46QJPoOJI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=40ca8cf5b8d02ebc01ed1e5d808e4a89f0f8f3ad', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': '5kiHQ8zBqCJTAIVzQS4ZE0tWPcZl5xwpr-2S0fpzwgc'}], 'enabled': False}",,,,,,
13,,tensorflow,,t2_na9ca,False,,0,False,"TF Beginner, i made a little TFJS Web App",[],r/tensorflow,False,6,,0,89.0,,False,t3_lw30qm,False,dark,1.0,,public,13,1,{},140.0,,False,[],,False,False,,{},Project,False,13,,False,https://b.thumbs.redditmedia.com/jHxoDwLUAkTN-IIXYkQFjfyfrWbs6JI_z6EwqeUpiow.jpg,False,,[],{},,False,,1614723626.0,text,6,,,text,wnderlvst.com,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lw30qm,True,,DonRedditor,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lw30qm/tf_beginner_i_made_a_little_tfjs_web_app/,all_ads,False,https://wnderlvst.com/projects/object-detection,22217,1614694826.0,0,,False,link,https://wnderlvst.com/projects/object-detection,"{'images': [{'source': {'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?auto=webp&amp;s=1e85549798072bdbaec69af2221bc1dd04c66525', 'width': 1165, 'height': 741}, 'resolutions': [{'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e935971764bf06dc062441ddef9beee322347994', 'width': 108, 'height': 68}, {'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b539e4cd809886fdeaf1abdf7e51f4f52e31ce3b', 'width': 216, 'height': 137}, {'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa16e140427a2c5613220f89153ee1a7c8dc6342', 'width': 320, 'height': 203}, {'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e8b150e85d2237e468985a04a7297b3e28f99059', 'width': 640, 'height': 407}, {'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a28d9a42bebead6d10e8df76001c09ab5779f59f', 'width': 960, 'height': 610}, {'url': 'https://external-preview.redd.it/7MsqqDnleBe-P-8vjoYJz-IqrsyUursn4mS6VXv2IBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=76b423dbad55ce06cd341bece9c31ae48399da35', 'width': 1080, 'height': 686}], 'variants': {}, 'id': '6TnDUaDmjFabZd4ajSfawvPnr1Gce5bAUit_j-solv8'}], 'enabled': False}",,,,,,
14,,tensorflow,"Hi guys,

need help setting up pycocotools for my training. I have installed through git, pip and even conda. Been stuck on it for the past three days. When i run my main python file, i keep getting this error:

I am using 

windows 10 64bits, python 3.7 Anaconda,tensorflow  2.4.1, CUDA 11.0.2 and Cudnn 8.0.2.

&amp;#x200B;

python model\_main\_tf2.py --model\_dir=models/ssd\_mobilenet\_v2\_fpnlite --pipeline\_config\_path=models/ssd\_mobilenet\_v2\_fpnlite/pipeline.config

&amp;#x200B;

Any help on this??

&amp;#x200B;

https://preview.redd.it/ri0w25ojpkk61.png?width=1441&amp;format=png&amp;auto=webp&amp;s=1cb0b8ddacd815a5d823de92f738dd267c30fd7a",t2_1kh79sw8,False,,0,False,Tensorflow Object Detection API pycocotools Error,[],r/tensorflow,False,6,,0,25.0,,False,t3_lvx420,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/dUOuZg-zmPD3-7uFndoFd8JA_GOku2zajWYi0lPsBMA.jpg,False,,[],{},,True,,1614701669.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;need help setting up pycocotools for my training. I have installed through git, pip and even conda. Been stuck on it for the past three days. When i run my main python file, i keep getting this error:&lt;/p&gt;

&lt;p&gt;I am using &lt;/p&gt;

&lt;p&gt;windows 10 64bits, python 3.7 Anaconda,tensorflow  2.4.1, CUDA 11.0.2 and Cudnn 8.0.2.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;python model_main_tf2.py --model_dir=models/ssd_mobilenet_v2_fpnlite --pipeline_config_path=models/ssd_mobilenet_v2_fpnlite/pipeline.config&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any help on this??&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ri0w25ojpkk61.png?width=1441&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1cb0b8ddacd815a5d823de92f738dd267c30fd7a""&gt;https://preview.redd.it/ri0w25ojpkk61.png?width=1441&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1cb0b8ddacd815a5d823de92f738dd267c30fd7a&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lvx420,True,,jason_rims,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/lvx420/tensorflow_object_detection_api_pycocotools_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lvx420/tensorflow_object_detection_api_pycocotools_error/,22217,1614672869.0,0,,False,,,,,"{'ri0w25ojpkk61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 19, 'x': 108, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cc87c8498ec8007f081064d43a7b7134984ef29'}, {'y': 38, 'x': 216, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=49ee095877158eef3f16e1b5e75e743f547c2fa1'}, {'y': 57, 'x': 320, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d986b18098bc0deedbbd10fd4d68d4546ecde254'}, {'y': 115, 'x': 640, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab5dcc0ded01fadade1e91089e7e98322e9d1019'}, {'y': 172, 'x': 960, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a9d5a167088d85ff9dd0fe75fc15135ac56191ac'}, {'y': 194, 'x': 1080, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0670511fd5f42ded8b22e2a81f326ba617c53a79'}], 's': {'y': 259, 'x': 1441, 'u': 'https://preview.redd.it/ri0w25ojpkk61.png?width=1441&amp;format=png&amp;auto=webp&amp;s=1cb0b8ddacd815a5d823de92f738dd267c30fd7a'}, 'id': 'ri0w25ojpkk61'}}",,,,
15,,tensorflow,"I have a dataset of posts on a website (which I have downloaded in file format data/category1 and data/category2) all are png, or jpg format files. All with unique dimensions. Is there a way to train the neural network without resizing the images? I already know I would have to train them in separate batches, but I cannot for the life of me figure out how to get them all into individual batches to be trained. Thank you in advance for your help :D",t2_32zhu7m3,False,,0,False,Image classification FCN training,[],r/tensorflow,False,6,,0,,,False,t3_lvqsxn,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1614677988.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset of posts on a website (which I have downloaded in file format data/category1 and data/category2) all are png, or jpg format files. All with unique dimensions. Is there a way to train the neural network without resizing the images? I already know I would have to train them in separate batches, but I cannot for the life of me figure out how to get them all into individual batches to be trained. Thank you in advance for your help :D&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lvqsxn,True,,Yo1up,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/lvqsxn/image_classification_fcn_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lvqsxn/image_classification_fcn_training/,22217,1614649188.0,0,,False,,,,,,,,,
16,,tensorflow,"Hi everybody,

&amp;#x200B;

I am attempting to create a tf.data.Dataset object for image classification. My idea is to ""cut"" it in two parts in order to make it more maintenable and then to create a ""pipeline"" object later.

&amp;#x200B;

I have multiple ways of loading data:

\- From a CSV file (image names + labels)

\- From a directory (labels are the folder names)

\- etc.

&amp;#x200B;

I made an Interface, ""IDatasource"" which is implemented by CSVLoader and DirectoryLoader for example.

&amp;#x200B;

I also want to make another object, DatasetPreparer, which takes as input the output of CSVLoader and DirectoryLoader, so a IDatasource. The goal is to make it prepare the Dataset: set the batch size, prepare it for performance, and, **ideally load the images** (i.e. map the image paths to the actual images).

&amp;#x200B;

Here is my question: **what should I output from IDatasource to still be able to load the images from DatasetPreparer?** I want only to implement the less things possible in IDatasource, as I just want to code the part that actually changes between the multiple data sources.

&amp;#x200B;

Thanks so much in advance!",t2_x5e5qpq,False,,0,False,An object-oriented tf.data.Dataset creation,[],r/tensorflow,False,6,,0,,,False,t3_lv9n03,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1614635309.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am attempting to create a tf.data.Dataset object for image classification. My idea is to &amp;quot;cut&amp;quot; it in two parts in order to make it more maintenable and then to create a &amp;quot;pipeline&amp;quot; object later.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have multiple ways of loading data:&lt;/p&gt;

&lt;p&gt;- From a CSV file (image names + labels)&lt;/p&gt;

&lt;p&gt;- From a directory (labels are the folder names)&lt;/p&gt;

&lt;p&gt;- etc.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I made an Interface, &amp;quot;IDatasource&amp;quot; which is implemented by CSVLoader and DirectoryLoader for example.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I also want to make another object, DatasetPreparer, which takes as input the output of CSVLoader and DirectoryLoader, so a IDatasource. The goal is to make it prepare the Dataset: set the batch size, prepare it for performance, and, &lt;strong&gt;ideally load the images&lt;/strong&gt; (i.e. map the image paths to the actual images).&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Here is my question: &lt;strong&gt;what should I output from IDatasource to still be able to load the images from DatasetPreparer?&lt;/strong&gt; I want only to implement the less things possible in IDatasource, as I just want to code the part that actually changes between the multiple data sources.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks so much in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lv9n03,True,,BlueskyFR,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lv9n03/an_objectoriented_tfdatadataset_creation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lv9n03/an_objectoriented_tfdatadataset_creation/,22217,1614606509.0,0,,False,,,,,,,,,
17,,tensorflow,"Hello. I have a question regarding tensorflow. I was working on a Deep Q Network problem using Tensorflow. The code is as follows:

```

g = tf.Graph()
with g.as_default():
    w_1 = tf.Variable(tf.truncated_normal([n_input, n_hidden_1], stddev=0.1))
    w_1_p = tf.Variable(tf.truncated_normal([n_input, n_hidden_1], stddev=0.1))
    ## There are other parameters too but they are excluded for simplicity

def update_target_q_network(sess):
    """""" Update target q network once in a while """"""
    sess.run(w_1_p.assign(sess.run(w_1)))

for i_episode in range(n_episode):
    ........ #Code removed for simplicity
    if i_episode%10 == 0:
        update_target_q_network(centralsess)
    ........

```

Basically after every specific number of n_episodes (10 in this case), the parameter w_1 is copied to w_1_p. 

The issue with the code is that the time it takes to run the function update_target_q_network keeps on increasing as the n_episodes increase. So for example it takes 0-1 second for 100th episode however the time increase to 220 seconds for 7500th episode. 
Can anyone kindly tell how can the running time of the code can be improved? I tried reading the reason (the graph keeps on becoming larger) but I am not sure about that or how or change code to reduce time. Thank you for your help.",t2_6g1ackmz,False,,0,False,Tensorflow DQN execution time keeps on increasing,[],r/tensorflow,False,6,,0,,,False,t3_lva0th,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1614636336.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello. I have a question regarding tensorflow. I was working on a Deep Q Network problem using Tensorflow. The code is as follows:&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;g = tf.Graph()
with g.as_default():
    w_1 = tf.Variable(tf.truncated_normal([n_input, n_hidden_1], stddev=0.1))
    w_1_p = tf.Variable(tf.truncated_normal([n_input, n_hidden_1], stddev=0.1))
    ## There are other parameters too but they are excluded for simplicity&lt;/p&gt;

&lt;p&gt;def update_target_q_network(sess):
    &amp;quot;&amp;quot;&amp;quot; Update target q network once in a while &amp;quot;&amp;quot;&amp;quot;
    sess.run(w_1_p.assign(sess.run(w_1)))&lt;/p&gt;

&lt;p&gt;for i_episode in range(n_episode):
    ........ #Code removed for simplicity
    if i_episode%10 == 0:
        update_target_q_network(centralsess)
    ........&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Basically after every specific number of n_episodes (10 in this case), the parameter w_1 is copied to w_1_p. &lt;/p&gt;

&lt;p&gt;The issue with the code is that the time it takes to run the function update_target_q_network keeps on increasing as the n_episodes increase. So for example it takes 0-1 second for 100th episode however the time increase to 220 seconds for 7500th episode. 
Can anyone kindly tell how can the running time of the code can be improved? I tried reading the reason (the graph keeps on becoming larger) but I am not sure about that or how or change code to reduce time. Thank you for your help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lva0th,True,,FarzanUllah,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lva0th/tensorflow_dqn_execution_time_keeps_on_increasing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lva0th/tensorflow_dqn_execution_time_keeps_on_increasing/,22217,1614607536.0,0,,False,,,,,,,,,
18,,tensorflow,"I want to create a python program for neural style transfer based on this tutorial: https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398. They used tensorflow 1.* for this but I use tensorflow 2.* (gpu), so I had to change a few things. Both my version and the original version of the program raised a ValueError when I tried to return a vgg19 model. Can someone explain this error or tell me how to fix it?

```def get_model():
    vgg = tf.keras.applications.vgg19.VGG19(include_top = False, weights = 'imagenet')
    vgg.trainable = False
    style_outputs = [vgg.get_layer(name) for name in style_layers]
    content_outputs = [vgg.get_layer(name) for name in content_layers]
    model_outputs = style_outputs + content_outputs
    return tf.keras.Model(vgg.input, model_outputs)

=========================================================

Traceback (most recent call last):
  File ""NST_V2.py"", line 155, in &lt;module&gt;
    main()
  File ""NST_V2.py"", line 152, in main
    best, best_loss = run_style_transfer(args['content'], args['style'])
  File ""NST_V2.py"", line 101, in run_style_transfer
    model = get_model()
  File ""NST_V2.py"", line 48, in get_model
    return tf.keras.Model(vgg.input, model_outputs)
  File ""C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\training\tracking\base.py"", line 517, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\functional.py"", line 120, in __init__
    self._init_graph_network(inputs, outputs)
  File ""C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\training\tracking\base.py"", line 517, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\functional.py"", line 157, in _init_graph_network
    self._validate_graph_inputs_and_outputs()
  File ""C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\functional.py"", line 727, in _validate_graph_inputs_and_outputs
    raise ValueError('Output tensors of a ' + cls_name + ' model must be '
ValueError: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A05C2F9D60&gt;```",t2_8llrf5kg,False,,0,False,Error when returning tf.keras.Model,[],r/tensorflow,False,6,,0,,,False,t3_lv9t0b,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614635779.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to create a python program for neural style transfer based on this tutorial: &lt;a href=""https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398""&gt;https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398&lt;/a&gt;. They used tensorflow 1.* for this but I use tensorflow 2.* (gpu), so I had to change a few things. Both my version and the original version of the program raised a ValueError when I tried to return a vgg19 model. Can someone explain this error or tell me how to fix it?&lt;/p&gt;

&lt;p&gt;```def get_model():
    vgg = tf.keras.applications.vgg19.VGG19(include_top = False, weights = &amp;#39;imagenet&amp;#39;)
    vgg.trainable = False
    style_outputs = [vgg.get_layer(name) for name in style_layers]
    content_outputs = [vgg.get_layer(name) for name in content_layers]
    model_outputs = style_outputs + content_outputs
    return tf.keras.Model(vgg.input, model_outputs)&lt;/p&gt;

&lt;h1&gt;&lt;/h1&gt;

&lt;p&gt;Traceback (most recent call last):
  File &amp;quot;NST&lt;em&gt;V2.py&amp;quot;, line 155, in &amp;lt;module&amp;gt;
    main()
  File &amp;quot;NST_V2.py&amp;quot;, line 152, in main
    best, best_loss = run_style_transfer(args[&amp;#39;content&amp;#39;], args[&amp;#39;style&amp;#39;])
  File &amp;quot;NST_V2.py&amp;quot;, line 101, in run_style_transfer
    model = get_model()
  File &amp;quot;NST_V2.py&amp;quot;, line 48, in get_model
    return tf.keras.Model(vgg.input, model_outputs)
  File &amp;quot;C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\training\tracking\base.py&amp;quot;, line 517, in _method_wrapper
    result = method(self, &lt;em&gt;args, *&lt;/em&gt;kwargs)
  File &amp;quot;C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\functional.py&amp;quot;, line 120, in __init&lt;/em&gt;_
    self._init_graph_network(inputs, outputs)
  File &amp;quot;C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\training\tracking\base.py&amp;quot;, line 517, in _method_wrapper
    result = method(self, &lt;em&gt;args, *&lt;/em&gt;kwargs)
  File &amp;quot;C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\functional.py&amp;quot;, line 157, in _init_graph_network
    self._validate_graph_inputs_and_outputs()
  File &amp;quot;C:\Users\fredd\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\functional.py&amp;quot;, line 727, in _validate_graph_inputs_and_outputs
    raise ValueError(&amp;#39;Output tensors of a &amp;#39; + cls_name + &amp;#39; model must be &amp;#39;
ValueError: Output tensors of a Functional model must be the output of a TensorFlow &lt;code&gt;Layer&lt;/code&gt; (thus holding past layer metadata). Found: &amp;lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A05C2F9D60&amp;gt;```&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lv9t0b,True,,Jirne_VR,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lv9t0b/error_when_returning_tfkerasmodel/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lv9t0b/error_when_returning_tfkerasmodel/,22217,1614606979.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yP66qmtp5xt-W_xMX0BrQzrRPb09kwo6EZTCT-edCs8.jpg?auto=webp&amp;s=109fc505d3ecaabc12f71630a11dfc6d0d060a35', 'width': 624, 'height': 339}, 'resolutions': [{'url': 'https://external-preview.redd.it/yP66qmtp5xt-W_xMX0BrQzrRPb09kwo6EZTCT-edCs8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba9460b4075d70bf08691577fbdc0c8ea0c5dee1', 'width': 108, 'height': 58}, {'url': 'https://external-preview.redd.it/yP66qmtp5xt-W_xMX0BrQzrRPb09kwo6EZTCT-edCs8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e1acc190c393555ce3cc09f5872dc72639b0c519', 'width': 216, 'height': 117}, {'url': 'https://external-preview.redd.it/yP66qmtp5xt-W_xMX0BrQzrRPb09kwo6EZTCT-edCs8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b50341cc2008de14b8c6c96209764c43de7e2b8b', 'width': 320, 'height': 173}], 'variants': {}, 'id': 'rFqGWogZhHyZt1ZmQzfo3WptCOHICzh9uLpkVKKrDrk'}], 'enabled': False}",,,,,,
19,,tensorflow,"I am trying to print a list of objects, some of which are constants and some and some are variables. When i print the list, only the constant tensors are shown, while Variables are are represented by empty space. They are present in the calculation, and that is going through without a hitch. But somehow in this print issue, they are absent.",t2_2nvdpdl,False,,0,False,Unable to print tf.Variable objects,[],r/tensorflow,False,6,,0,,,False,t3_lv5g1p,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614621851.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to print a list of objects, some of which are constants and some and some are variables. When i print the list, only the constant tensors are shown, while Variables are are represented by empty space. They are present in the calculation, and that is going through without a hitch. But somehow in this print issue, they are absent.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lv5g1p,True,,curtlytalks,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/lv5g1p/unable_to_print_tfvariable_objects/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lv5g1p/unable_to_print_tfvariable_objects/,22217,1614593051.0,0,,False,,,,,,,,,
20,,tensorflow,"Check out my [question](https://stackoverflow.com/questions/66416196/pre-processing-images-for-pre-trained-models-in-tensorflow-js) on stackoverflow for specifics, but I’m wondering about general strategies for pre-processing inputs into Tensorflow.js....do I need to use a convolutional network? Can I use the model to pre-process input? There’s some commands in python that are missing in js for doing this",t2_keuor,False,,0,False,Pre-Processing Images for Pre-Trained Models in Tensorflow.js,[],r/tensorflow,False,6,,0,,,False,t3_luza4v,False,dark,0.72,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1614599572.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Check out my &lt;a href=""https://stackoverflow.com/questions/66416196/pre-processing-images-for-pre-trained-models-in-tensorflow-js""&gt;question&lt;/a&gt; on stackoverflow for specifics, but I’m wondering about general strategies for pre-processing inputs into Tensorflow.js....do I need to use a convolutional network? Can I use the model to pre-process input? There’s some commands in python that are missing in js for doing this&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,luza4v,True,,areddy831,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/luza4v/preprocessing_images_for_pretrained_models_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/luza4v/preprocessing_images_for_pretrained_models_in/,22217,1614570772.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
21,,tensorflow,"Hello r/tensorflow!

I have my own images that I need to label and make ready so I can train my own AI. What would the best way be to do this? Thanks!",t2_cxdvt,False,,0,False,Labelling my own images,[],r/tensorflow,False,6,,0,,,False,t3_luobgz,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1614569635.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello &lt;a href=""/r/tensorflow""&gt;r/tensorflow&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;I have my own images that I need to label and make ready so I can train my own AI. What would the best way be to do this? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,luobgz,True,,turtlewithdowns,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/luobgz/labelling_my_own_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/luobgz/labelling_my_own_images/,22217,1614540835.0,0,,False,,,,,,,,,
22,,tensorflow,Can someone tell me which version of tensorflow uses random_normal instead of random.normal?,t2_882yao80,False,,0,False,Tensorflow version using random_normal()?,[],r/tensorflow,False,6,,0,,,False,t3_lujqjn,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614557939.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone tell me which version of tensorflow uses random_normal instead of random.normal?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lujqjn,True,,greenmantis43,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lujqjn/tensorflow_version_using_random_normal/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lujqjn/tensorflow_version_using_random_normal/,22217,1614529139.0,0,,False,,,,,,,,,
23,,tensorflow,"I need to convert the following model to TF2:

    ema = tf.train.ExponentialMovingAverage(alpha)
    ema_apply_op = ema.apply(params)  # params are the model trainable variables
    
    
    def custom_getter(getter, *args, **kwargs):
        return ema.average(getter(*args, **kwargs))
    
    
    with tf.variable_scope('my_model', custom_getter=custom_getter, reuse=True):
        polyak_model = create_polyak(*args, **kwargs)  # model of identical architecture as the main model 

In TF1 this line results in a `tf.Operation 'ExponentialMovingAverage' type=NoOp&gt;` to be run in a TF1 session. 

    ema_apply_op = ema.apply(params)  # params are the model trainable variables

In TF2, this results in None which is confusing, I'm not sure what `ema.apply()` actually does in TF2. The result I'm expecting is another model holding the moving average of the weights. Assuming there are 2 models `model1`, `model2` I need `model2` to keep a moving average of `model1`'s weights.",t2_4jbcsgd0,False,,0,False,What is th equivalent of tf.variable_scope with custom getter in TF2,[],r/tensorflow,False,6,,0,,,False,t3_lugdgd,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614548569.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need to convert the following model to TF2:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ema = tf.train.ExponentialMovingAverage(alpha)
ema_apply_op = ema.apply(params)  # params are the model trainable variables


def custom_getter(getter, *args, **kwargs):
    return ema.average(getter(*args, **kwargs))


with tf.variable_scope(&amp;#39;my_model&amp;#39;, custom_getter=custom_getter, reuse=True):
    polyak_model = create_polyak(*args, **kwargs)  # model of identical architecture as the main model 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In TF1 this line results in a &lt;code&gt;tf.Operation &amp;#39;ExponentialMovingAverage&amp;#39; type=NoOp&amp;gt;&lt;/code&gt; to be run in a TF1 session. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ema_apply_op = ema.apply(params)  # params are the model trainable variables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In TF2, this results in None which is confusing, I&amp;#39;m not sure what &lt;code&gt;ema.apply()&lt;/code&gt; actually does in TF2. The result I&amp;#39;m expecting is another model holding the moving average of the weights. Assuming there are 2 models &lt;code&gt;model1&lt;/code&gt;, &lt;code&gt;model2&lt;/code&gt; I need &lt;code&gt;model2&lt;/code&gt; to keep a moving average of &lt;code&gt;model1&lt;/code&gt;&amp;#39;s weights.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lugdgd,True,,emadboctor,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lugdgd/what_is_th_equivalent_of_tfvariable_scope_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lugdgd/what_is_th_equivalent_of_tfvariable_scope_with/,22217,1614519769.0,0,,False,,,,,,,,,
24,,tensorflow,"I dumped pixel arrays with their labels to a pickle file, but it will take up too much memory to load and use Keras at the same time.

How can I load this large array into a CNN without it overloading memory?

Thanks!",t2_5xwgd1f8,False,,0,False,Loading Array too large for Memory?,[],r/tensorflow,False,6,,0,,,False,t3_ltzs7i,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1614496455.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I dumped pixel arrays with their labels to a pickle file, but it will take up too much memory to load and use Keras at the same time.&lt;/p&gt;

&lt;p&gt;How can I load this large array into a CNN without it overloading memory?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ltzs7i,True,,llub888,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/ltzs7i/loading_array_too_large_for_memory/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ltzs7i/loading_array_too_large_for_memory/,22217,1614467655.0,0,,False,,,,,,,,,
25,,tensorflow,"Hey,

Tensorflow broke in my conda environment and I cant seem to get it working again. I'm having differnt issues with getting tensorflow-gpu==2.3.0 and 2.4.1 working.

**GTX 1070 GPU drivers:**

-CUDA 11.0.3

-CUDNN 8.0.5.77

installed with $`conda install cudatoolkit=11.0 cudnn=8.0 -c=conda-forge`

-Python 3.8.8

--------------
**Tensorflow 2.4.1:**

    tensorflow                2.3.0           mkl_py38h8557ec7_0
    tensorflow-base           2.3.0           eigen_py38h75a453f_0
    tensorflow-estimator      2.4.0              pyh9656e83_0    conda-forge
    tensorflow-gpu            2.3.0                he13fc11_0

installed with pip install --upgrade tensorflow-gpu==2.4.1

I have set all the environment variables correctly.
Checking with `print(tf.config.list_physical_devices('GPU'))`  gives: `[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]`



So tensorflow seems to be installed and recognises my gpu. I've been working on a LSTM model, when training with $ `model.fit()` , it runs for 6 epochs and then gives this error 


    Epoch 1/50
    2021-02-27 14:50:38.552734: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
    2021-02-27 14:50:38.882403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
    2021-02-27 14:50:39.546250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
    2021-02-27 14:50:39.794953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
    37/37 [==============================] - 7s 55ms/step - loss: 7.0684 - accuracy: 0.1270
    Epoch 2/50
    37/37 [==============================] - 2s 54ms/step - loss: 4.8889 - accuracy: 0.1828
    Epoch 3/50
    37/37 [==============================] - 2s 54ms/step - loss: 4.7884 - accuracy: 0.1666
    Epoch 4/50
    37/37 [==============================] - 2s 54ms/step - loss: 4.6866 - accuracy: 0.1480
    Epoch 5/50
    37/37 [==============================] - 2s 55ms/step - loss: 4.5179 - accuracy: 0.1630
    Epoch 6/50
    17/37 [============&gt;.................] - ETA: 1s - loss: 4.2505 - accuracy: 0.14842021-02-27 14:50:55.955000: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR
    in tensorflow/stream_executor/cuda/cuda_dnn.cc(2004): 'cudnnRNNBackwardWeights( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), output_desc.handles(), output_data.opaque(), workspace.opaque(), workspace.size(), rnn_desc.params_handle(), params_backprop_data-&gt;opaque(), reserve_space_data-&gt;opaque(), reserve_space_data-&gt;size())'
    2021-02-27 14:50:55.955194: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1926 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 100, 64, 256]
    2021-02-27 14:50:55,957 : MainThread : INFO : Saving model history to model_history.csv
    2021-02-27 14:50:55,961 : MainThread : INFO : Saving model to D:\project\project_engine\fftest_checkpoints\batch_0\synthetic
    Traceback (most recent call last):
      File ""runTrain.py"", line 65, in &lt;module&gt;
        model.train()
      ...
      ... 
      ...
      File ""D:\project\project_engine\runTrain.py"", line 201, in train_rnn
        model.fit(dataset, epochs=store.epochs, callbacks=_callbacks)
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1100, in fit
        tmp_logs = self.train_function(iterator)
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
        result = self._call(*args, **kwds)
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\def_function.py"", line 855, in _call
        return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 2942, in __call__
        return graph_function._call_flat(
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 1918, in _call_flat
        return self._build_call_outputs(self._inference_function.call(
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\function.py"", line 555, in call
        outputs = execute.execute(
      File ""C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
        tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
    tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.
             [[{{node gradient_tape/sequential/embedding/embedding_lookup/Reshape/_20}}]] [Op:__inference_train_function_4800]
    
    Function call stack:
    train_function
    
Tensorflow forums with similar issues mention memory or driver issues but this isn't the case as the model wouldn't start training at all. Also I know the code is fine because I trained on the same code with no issue in an old environment I was using 2 months ago. It also runs fine in a CPU only tensorflow environment. 

Does anyone have any suggestions on how to fix this? 

---------------------------------
**Tensorflow 2.3.0:**

Secondly, I cant even try another version of tensorflow gpu in a different environment.

    conda install -c anaconda tensorflow-gpu

Tensorflow GPU succesfully installs but doesn't run on my GPU for reasons stated here - https://www.reddit.com/r/tensorflow/comments/jtwcth/how_to_enable_tensorflow_code_to_run_on_a_gpu/gp0b3mf/

------------

I've now lost 2 days and a lot of will to leave, any help with either issues would be massively appreciated.",t2_72rwe,False,,0,False,[_Derived_]RecvAsync is cancelled - LSTM,[],r/tensorflow,False,6,,0,,,False,t3_ltq8qt,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1614448488.0,,[],{},,True,,1614468002.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey,&lt;/p&gt;

&lt;p&gt;Tensorflow broke in my conda environment and I cant seem to get it working again. I&amp;#39;m having differnt issues with getting tensorflow-gpu==2.3.0 and 2.4.1 working.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GTX 1070 GPU drivers:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;-CUDA 11.0.3&lt;/p&gt;

&lt;p&gt;-CUDNN 8.0.5.77&lt;/p&gt;

&lt;p&gt;installed with $&lt;code&gt;conda install cudatoolkit=11.0 cudnn=8.0 -c=conda-forge&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;-Python 3.8.8&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;&lt;strong&gt;Tensorflow 2.4.1:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow                2.3.0           mkl_py38h8557ec7_0
tensorflow-base           2.3.0           eigen_py38h75a453f_0
tensorflow-estimator      2.4.0              pyh9656e83_0    conda-forge
tensorflow-gpu            2.3.0                he13fc11_0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;installed with pip install --upgrade tensorflow-gpu==2.4.1&lt;/p&gt;

&lt;p&gt;I have set all the environment variables correctly.
Checking with &lt;code&gt;print(tf.config.list_physical_devices(&amp;#39;GPU&amp;#39;))&lt;/code&gt;  gives: &lt;code&gt;[PhysicalDevice(name=&amp;#39;/physical_device:GPU:0&amp;#39;, device_type=&amp;#39;GPU&amp;#39;)]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So tensorflow seems to be installed and recognises my gpu. I&amp;#39;ve been working on a LSTM model, when training with $ &lt;code&gt;model.fit()&lt;/code&gt; , it runs for 6 epochs and then gives this error &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Epoch 1/50
2021-02-27 14:50:38.552734: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-27 14:50:38.882403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-27 14:50:39.546250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-27 14:50:39.794953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
37/37 [==============================] - 7s 55ms/step - loss: 7.0684 - accuracy: 0.1270
Epoch 2/50
37/37 [==============================] - 2s 54ms/step - loss: 4.8889 - accuracy: 0.1828
Epoch 3/50
37/37 [==============================] - 2s 54ms/step - loss: 4.7884 - accuracy: 0.1666
Epoch 4/50
37/37 [==============================] - 2s 54ms/step - loss: 4.6866 - accuracy: 0.1480
Epoch 5/50
37/37 [==============================] - 2s 55ms/step - loss: 4.5179 - accuracy: 0.1630
Epoch 6/50
17/37 [============&amp;gt;.................] - ETA: 1s - loss: 4.2505 - accuracy: 0.14842021-02-27 14:50:55.955000: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(2004): &amp;#39;cudnnRNNBackwardWeights( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), output_desc.handles(), output_data.opaque(), workspace.opaque(), workspace.size(), rnn_desc.params_handle(), params_backprop_data-&amp;gt;opaque(), reserve_space_data-&amp;gt;opaque(), reserve_space_data-&amp;gt;size())&amp;#39;
2021-02-27 14:50:55.955194: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1926 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 100, 64, 256]
2021-02-27 14:50:55,957 : MainThread : INFO : Saving model history to model_history.csv
2021-02-27 14:50:55,961 : MainThread : INFO : Saving model to D:\project\project_engine\fftest_checkpoints\batch_0\synthetic
Traceback (most recent call last):
  File &amp;quot;runTrain.py&amp;quot;, line 65, in &amp;lt;module&amp;gt;
    model.train()
  ...
  ... 
  ...
  File &amp;quot;D:\project\project_engine\runTrain.py&amp;quot;, line 201, in train_rnn
    model.fit(dataset, epochs=store.epochs, callbacks=_callbacks)
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\keras\engine\training.py&amp;quot;, line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\def_function.py&amp;quot;, line 828, in __call__
    result = self._call(*args, **kwds)
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\def_function.py&amp;quot;, line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\function.py&amp;quot;, line 2942, in __call__
    return graph_function._call_flat(
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\function.py&amp;quot;, line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\function.py&amp;quot;, line 555, in call
    outputs = execute.execute(
  File &amp;quot;C:\Users\Me\anaconda3\envs\tf_gpu\lib\site-packages\tensorflow\python\eager\execute.py&amp;quot;, line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.
         [[{{node gradient_tape/sequential/embedding/embedding_lookup/Reshape/_20}}]] [Op:__inference_train_function_4800]

Function call stack:
train_function
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tensorflow forums with similar issues mention memory or driver issues but this isn&amp;#39;t the case as the model wouldn&amp;#39;t start training at all. Also I know the code is fine because I trained on the same code with no issue in an old environment I was using 2 months ago. It also runs fine in a CPU only tensorflow environment. &lt;/p&gt;

&lt;p&gt;Does anyone have any suggestions on how to fix this? &lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;&lt;strong&gt;Tensorflow 2.3.0:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Secondly, I cant even try another version of tensorflow gpu in a different environment.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c anaconda tensorflow-gpu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tensorflow GPU succesfully installs but doesn&amp;#39;t run on my GPU for reasons stated here - &lt;a href=""https://www.reddit.com/r/tensorflow/comments/jtwcth/how_to_enable_tensorflow_code_to_run_on_a_gpu/gp0b3mf/""&gt;https://www.reddit.com/r/tensorflow/comments/jtwcth/how_to_enable_tensorflow_code_to_run_on_a_gpu/gp0b3mf/&lt;/a&gt;&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;I&amp;#39;ve now lost 2 days and a lot of will to leave, any help with either issues would be massively appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ltq8qt,True,,nuusain,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/ltq8qt/derived_recvasync_is_cancelled_lstm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ltq8qt/derived_recvasync_is_cancelled_lstm/,22217,1614439202.0,0,,False,,,,,,,,,
26,,tensorflow,"Hi, guys, I am working on a project relating to image segmentation, and I  met a trouble when I tried to train a model.

I used the code from [https://keras.io/examples/vision/oxford\_pets\_image\_segmentation/](https://keras.io/examples/vision/oxford_pets_image_segmentation/) and I used use my own dataset for training. Everything was fine until running '[model.fit](https://model.fit)()'

The complete warning is:  InvalidArgumentError:  logits and labels must have the same first dimension, got logits shape \[32,92160\] and labels shape \[247808\] 	 \[\[node sparse\_categorical\_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at &lt;ipython-input-48-dac0e73a3d3d&gt;:11) \]\] \[Op:\_\_inference\_train\_function\_27962\] 

My code block is shown below:

`from google.colab import drive`  
`drive.mount('/content/drive')`

`!unzip /content/drive/MyDrive/data/train_image.zip`  
`!unzip /content/drive/MyDrive/data/train_mask.zip`

 

`import os`  
`input_dir = ""image/""`  
`target_dir = ""mask/""`  
`img_size = (88,88)`  
`num_classes = 10`  
`batch_size = 32`  
`input_img_paths = sorted(`  
    `[`  
        `os.path.join(input_dir, fname)`  
 `for fname in os.listdir(input_dir)`  
 `if fname.endswith("".jpg"")`  
    `]`  
`)`  
`target_img_paths = sorted(`  
    `[`  
     `os.path.join(target_dir,fname)`  
 `for fname in os.listdir(target_dir)`  
 `if fname.endswith("".jpg"")`  
    `]`  
`)`  
 

`from tensorflow import keras`  
`import numpy as np`  
`from tensorflow.keras.preprocessing.image import load_img`  
`class SAR(keras.utils.Sequence):`  
 `def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):`  
 `self.batch_size = batch_size`  
 `self.img_size = img_size`  
 `self.input_img_paths = input_img_paths`  
 `self.target_img_paths = target_img_paths`  
 `def __len__(self):`  
 `return len(self.target_img_paths) // self.batch_size`  
 `def __getitem__(self, idx):`  
 `""""""Returns tuple (input, target) correspond to batch #idx.""""""`  
        `i = idx * self.batch_size`  
        `batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]`  
        `batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]`  
        `x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=""float32"")`  
 `for j, path in enumerate(batch_input_img_paths):`  
            `img = load_img(path, target_size=self.img_size)`  
            `x[j] = img`  
        `y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=""uint8"")`  
 `for j, path in enumerate(batch_target_img_paths):`  
            `img = load_img(path, target_size=self.img_size, color_mode=""grayscale"")`  
            `y[j] = np.expand_dims(img, 2)`  
   
            `y[j] -= 1`  
 `return x, y`

 

`from tensorflow.keras import layers`  
`import tensorflow as tf`  


`def get_model(img_size, num_classes):`  
    `inputs = keras.Input(shape=img_size + (3,))`  
 `### [First half of the network: downsampling inputs] ###`  
 `# Entry block`  
 `#x = layers.Flatten()(inputs) #additional`  
    `x = layers.Conv2D(32, 3, strides=2, padding=""same"")(inputs)`  
    `x = layers.BatchNormalization()(x)`  
    `x = layers.Activation(""relu"")(x)`  
    `previous_block_activation = x  # Set aside residual`  
   
 `for filters in [64, 128, 256]:`  
        `x = layers.Activation(""relu"")(x)`  
        `x = layers.SeparableConv2D(filters, 3, padding=""same"")(x)`  
        `x = layers.BatchNormalization()(x)`  
        `x = layers.Activation(""relu"")(x)`  
        `x = layers.SeparableConv2D(filters, 3, padding=""same"")(x)`  
        `x = layers.BatchNormalization()(x)`  
        `x = layers.MaxPooling2D(3, strides=2, padding=""same"")(x)`  
 `# Project residual`  
        `residual = layers.Conv2D(filters, 1, strides=2, padding=""same"")(`  
            `previous_block_activation`  
        `)`  
        `x = layers.add([x, residual])  # Add back residual`  
        `previous_block_activation = x  # Set aside next residual`  
 `### [Second half of the network: upsampling inputs] ###`  
 `for filters in [256, 128, 64, 32]:`  
        `x = layers.Activation(""relu"")(x)`  
        `x = layers.Conv2DTranspose(filters, 3, padding=""same"")(x)`  
        `x = layers.BatchNormalization()(x)`  
        `x = layers.Activation(""relu"")(x)`  
        `x = layers.Conv2DTranspose(filters, 3, padding=""same"")(x)`  
        `x = layers.BatchNormalization()(x)`  
        `x = layers.UpSampling2D(2)(x)`  
 `# Project residual`  
        `residual = layers.UpSampling2D(2)(previous_block_activation)`  
        `residual = layers.Conv2D(filters, 1, padding=""same"")(residual)`  
        `x = layers.add([x, residual])  # Add back residual`  
        `previous_block_activation = x  # Set aside next residual`  
 `# Add a per-pixel classification layer`  
    `outputs = layers.Conv2D(num_classes, 3, activation=""softmax"", padding=""same"")(x)`  
 `# Define the model`  
    `model = keras.Model(inputs, outputs)`  
 `return model`  


`# Free up RAM in case the model definition cells were run multiple times`  
`keras.backend.clear_session()`  
`# Build model`  
`model = get_model(img_size, num_classes)`  
`model.summary()`

 

`import random`  
`# Split our img paths into a training and a validation set`  
`val_samples = 1000`  
`random.Random(1337).shuffle(input_img_paths)`  
`random.Random(1337).shuffle(target_img_paths)`  
`train_input_img_paths = input_img_paths[:-val_samples]`  
`train_target_img_paths = target_img_paths[:-val_samples]`  
`val_input_img_paths = input_img_paths[-val_samples:]`  
`val_target_img_paths = target_img_paths[-val_samples:]`  
`# Instantiate data Sequences for each split`  
`train_gen = SAR(`  
    `batch_size, img_size, train_input_img_paths, train_target_img_paths`  
`)`  
`val_gen = SAR(batch_size, img_size, val_input_img_paths, val_target_img_paths)`

&amp;#x200B;

`model.compile(optimizer=""adam"", loss=""sparse_categorical_crossentropy"")`

`epochs = 15`  
[`model.fit`](https://model.fit)`(train_gen, epochs=epochs, validation_data=val_gen)`  


I would be grateful if you guys could help me deal with this problem.",t2_7ih8klh3,False,,0,False,InvalidArgumentError: logits and labels must have the same first dimension,[],r/tensorflow,False,6,,0,,,False,t3_ltjrol,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1614443425.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, guys, I am working on a project relating to image segmentation, and I  met a trouble when I tried to train a model.&lt;/p&gt;

&lt;p&gt;I used the code from &lt;a href=""https://keras.io/examples/vision/oxford_pets_image_segmentation/""&gt;https://keras.io/examples/vision/oxford_pets_image_segmentation/&lt;/a&gt; and I used use my own dataset for training. Everything was fine until running &amp;#39;&lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;()&amp;#39;&lt;/p&gt;

&lt;p&gt;The complete warning is:  InvalidArgumentError:  logits and labels must have the same first dimension, got logits shape [32,92160] and labels shape [247808]     [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at &amp;lt;ipython-input-48-dac0e73a3d3d&amp;gt;:11) ]] [Op:__inference_train_function_27962] &lt;/p&gt;

&lt;p&gt;My code block is shown below:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from google.colab import drive&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;drive.mount(&amp;#39;/content/drive&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;!unzip /content/drive/MyDrive/data/train_image.zip&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;!unzip /content/drive/MyDrive/data/train_mask.zip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import os&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;input_dir = &amp;quot;image/&amp;quot;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;target_dir = &amp;quot;mask/&amp;quot;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;img_size = (88,88)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;num_classes = 10&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;batch_size = 32&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;input_img_paths = sorted(&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;[&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;os.path.join(input_dir, fname)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for fname in os.listdir(input_dir)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;if fname.endswith(&amp;quot;.jpg&amp;quot;)&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;target_img_paths = sorted(&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;[&lt;/code&gt;&lt;br/&gt;
     &lt;code&gt;os.path.join(target_dir,fname)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for fname in os.listdir(target_dir)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;if fname.endswith(&amp;quot;.jpg&amp;quot;)&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;from tensorflow import keras&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import numpy as np&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;from tensorflow.keras.preprocessing.image import load_img&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;class SAR(keras.utils.Sequence):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;self.batch_size = batch_size&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;self.img_size = img_size&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;self.input_img_paths = input_img_paths&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;self.target_img_paths = target_img_paths&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;def __len__(self):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return len(self.target_img_paths) // self.batch_size&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;def __getitem__(self, idx):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Returns tuple (input, target) correspond to batch #idx.&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;i = idx * self.batch_size&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=&amp;quot;float32&amp;quot;)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for j, path in enumerate(batch_input_img_paths):&lt;/code&gt;&lt;br/&gt;
            &lt;code&gt;img = load_img(path, target_size=self.img_size)&lt;/code&gt;&lt;br/&gt;
            &lt;code&gt;x[j] = img&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=&amp;quot;uint8&amp;quot;)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for j, path in enumerate(batch_target_img_paths):&lt;/code&gt;&lt;br/&gt;
            &lt;code&gt;img = load_img(path, target_size=self.img_size, color_mode=&amp;quot;grayscale&amp;quot;)&lt;/code&gt;&lt;br/&gt;
            &lt;code&gt;y[j] = np.expand_dims(img, 2)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;            &lt;code&gt;y[j] -= 1&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return x, y&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from tensorflow.keras import layers&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import tensorflow as tf&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def get_model(img_size, num_classes):&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;inputs = keras.Input(shape=img_size + (3,))&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;### [First half of the network: downsampling inputs] ###&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Entry block&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#x = layers.Flatten()(inputs) #additional&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;x = layers.Conv2D(32, 3, strides=2, padding=&amp;quot;same&amp;quot;)(inputs)&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;x = layers.Activation(&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;previous_block_activation = x  # Set aside residual&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;for filters in [64, 128, 256]:&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.Activation(&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.SeparableConv2D(filters, 3, padding=&amp;quot;same&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.Activation(&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.SeparableConv2D(filters, 3, padding=&amp;quot;same&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.MaxPooling2D(3, strides=2, padding=&amp;quot;same&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Project residual&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;residual = layers.Conv2D(filters, 1, strides=2, padding=&amp;quot;same&amp;quot;)(&lt;/code&gt;&lt;br/&gt;
            &lt;code&gt;previous_block_activation&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.add([x, residual])  # Add back residual&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;previous_block_activation = x  # Set aside next residual&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;### [Second half of the network: upsampling inputs] ###&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for filters in [256, 128, 64, 32]:&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.Activation(&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.Conv2DTranspose(filters, 3, padding=&amp;quot;same&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.Activation(&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.Conv2DTranspose(filters, 3, padding=&amp;quot;same&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.UpSampling2D(2)(x)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Project residual&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;residual = layers.UpSampling2D(2)(previous_block_activation)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;residual = layers.Conv2D(filters, 1, padding=&amp;quot;same&amp;quot;)(residual)&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;x = layers.add([x, residual])  # Add back residual&lt;/code&gt;&lt;br/&gt;
        &lt;code&gt;previous_block_activation = x  # Set aside next residual&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Add a per-pixel classification layer&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;outputs = layers.Conv2D(num_classes, 3, activation=&amp;quot;softmax&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Define the model&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;model = keras.Model(inputs, outputs)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return model&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Free up RAM in case the model definition cells were run multiple times&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;keras.backend.clear_session()&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;# Build model&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model = get_model(img_size, num_classes)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.summary()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import random&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;# Split our img paths into a training and a validation set&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;val_samples = 1000&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;random.Random(1337).shuffle(input_img_paths)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;random.Random(1337).shuffle(target_img_paths)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;train_input_img_paths = input_img_paths[:-val_samples]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;train_target_img_paths = target_img_paths[:-val_samples]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;val_input_img_paths = input_img_paths[-val_samples:]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;val_target_img_paths = target_img_paths[-val_samples:]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;# Instantiate data Sequences for each split&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;train_gen = SAR(&lt;/code&gt;&lt;br/&gt;
    &lt;code&gt;batch_size, img_size, train_input_img_paths, train_target_img_paths&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;val_gen = SAR(batch_size, img_size, val_input_img_paths, val_target_img_paths)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.compile(optimizer=&amp;quot;adam&amp;quot;, loss=&amp;quot;sparse_categorical_crossentropy&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;epochs = 15&lt;/code&gt;&lt;br/&gt;
&lt;a href=""https://model.fit""&gt;&lt;code&gt;model.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(train_gen, epochs=epochs, validation_data=val_gen)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;I would be grateful if you guys could help me deal with this problem.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ltjrol,True,,Apprehensive_Ad_6830,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ltjrol/invalidargumenterror_logits_and_labels_must_have/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ltjrol/invalidargumenterror_logits_and_labels_must_have/,22217,1614414625.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&amp;s=0c3f0b8af92c3a962f569a389e9673597e12f8ec', 'width': 774, 'height': 269}, 'resolutions': [{'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9985b1dc92701ea8c38c4bb72a28d50198fb54ab', 'width': 108, 'height': 37}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a7452ccf0826692f35ac78457de9275d52f5935', 'width': 216, 'height': 75}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ae2ffe955b207d1da9c058b01c62aff9e80110d7', 'width': 320, 'height': 111}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff31c7e26d2e15f6faa6e4bedc2a41dfe0eab9ab', 'width': 640, 'height': 222}], 'variants': {}, 'id': 'qsh7aKFxRPo6CaMu10A7nekvx_ez8hkySyb6h9YVvHI'}], 'enabled': False}",,,,,,
27,,tensorflow,,t2_wxzqp,False,,0,False,"[solved]: No Reddit, tensorflow is about cooking",[],r/tensorflow,False,6,,0,35.0,,False,t3_lswnph,False,dark,0.85,,public,69,1,{},140.0,,False,[],,True,False,,{},Discussion,False,69,,True,https://b.thumbs.redditmedia.com/KQIu0PxZZGIsQh_kocyTYjj11Qyou4SYorib5epxywE.jpg,False,,[],{},,False,,1614370955.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lswnph,True,,TimeVendor,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lswnph/solved_no_reddit_tensorflow_is_about_cooking/,all_ads,False,https://i.redd.it/3a3uu3cjetj61.jpg,22217,1614342155.0,0,,False,image,https://i.redd.it/3a3uu3cjetj61.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?auto=webp&amp;s=f220eb5fd422ea08d982032f75ef139465ea8f7e', 'width': 1124, 'height': 289}, 'resolutions': [{'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b98a2fba1c7f2d467a9249055c88d7a3dd00261', 'width': 108, 'height': 27}, {'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d0796c097b1b55ef6f498fada275d22fcf59ace0', 'width': 216, 'height': 55}, {'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b0a89f62eae23807bca19fb9a32aa5ed668d8f2c', 'width': 320, 'height': 82}, {'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=41e4d80f343b62b0c2719fbbc332ff42c3e885e9', 'width': 640, 'height': 164}, {'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2f8fed4fe65169350fa315bd0d90a6971f69ee12', 'width': 960, 'height': 246}, {'url': 'https://preview.redd.it/3a3uu3cjetj61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da7a950ecdfc073113dbb2d3ac66db043f394359', 'width': 1080, 'height': 277}], 'variants': {}, 'id': '3Z3kCNbksbF5M4WBo-mAm_pUdFzsl4W7_LryOJhar6w'}], 'enabled': True}",,,,,,
28,,tensorflow,,t2_44mbtmjy,False,,0,False,Tom Cruise deepfake videos are all over the internet and passing the best deepfake detectors!,[],r/tensorflow,False,6,,0,42.0,,False,t3_lt9jqq,False,dark,1.0,,public,4,0,{},140.0,,False,[],,False,False,,{},,False,4,,False,https://b.thumbs.redditmedia.com/wznT7cB7SlM6Ye_sJWF4lFYsuKvrDl6bXUgnWrY3qSI.jpg,False,,[],{},,False,,1614407182.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lt9jqq,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lt9jqq/tom_cruise_deepfake_videos_are_all_over_the/,all_ads,False,/r/LatestInML/comments/lt94cb/tom_cruise_deepfake_videos_are_all_over_the/,22217,1614378382.0,0,,False,link,/r/LatestInML/comments/lt94cb/tom_cruise_deepfake_videos_are_all_over_the/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?auto=webp&amp;s=4f24997ef2c142e60dc77448de49d1dc4b1eee89', 'width': 816, 'height': 246}, 'resolutions': [{'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb18b9ff11a399264b6b501fe2d796f1842cf531', 'width': 108, 'height': 32}, {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=da2566eef17424fd29022c2bd0acf057bdb46a0e', 'width': 216, 'height': 65}, {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf85a599b289c4ca5c54a1bdb5cfe86f9639add4', 'width': 320, 'height': 96}, {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=acdd3d63aa80dcd914b7db35e68df4a506b56cb0', 'width': 640, 'height': 192}], 'variants': {}, 'id': 'Oy9XQnD0kbZKV8MluszAr5rc5pkygj6xIhZeXeFGkRs'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""Learn more about how this works: [link to paper and code](https://catalyzex.com/paper/arxiv:2005.05535)\n\nhttps://reddit.com/link/lt94cb/video/u5sfu79nawj61/player\n\n👇 Free extension to get code for ML papers (❤️' by Andrew Ng)  \nChrome: https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Tom Cruise deepfake videos are all over the internet and passing the best deepfake detectors!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 42, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'u5sfu79nawj61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/lt94cb/asset/u5sfu79nawj61/DASHPlaylist.mpd?a=1618044644%2CZmIyODQxZDA0NTczNzJlYjFmZWY0ZWY0Yzk2YzA1YzI4NWI3MGNmNTkwZDAyZmYzOThiNmUxMTY1YTc4MmU1YQ%3D%3D&amp;v=1&amp;f=sd', 'x': 405, 'y': 720, 'hlsUrl': 'https://v.redd.it/link/lt94cb/asset/u5sfu79nawj61/HLSPlaylist.m3u8?a=1618044644%2CNWM1MDA3NGQ0MzJhM2U2NDBiMzY1MTkzODA5NDRkZGNkN2VjYTk4OGNlZmJmZjE3YmZhYjY5MzIwZDM5YTNmOQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'u5sfu79nawj61', 'isGif': False}}, 'name': 't3_lt94cb', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.87, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 48, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 48, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/wznT7cB7SlM6Ye_sJWF4lFYsuKvrDl6bXUgnWrY3qSI.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1614405976.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Learn more about how this works: &lt;a href=""https://catalyzex.com/paper/arxiv:2005.05535""&gt;link to paper and code&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/lt94cb/video/u5sfu79nawj61/player""&gt;https://reddit.com/link/lt94cb/video/u5sfu79nawj61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39; by Andrew Ng)&lt;br/&gt;\nChrome: &lt;a href=""https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?auto=webp&amp;s=4f24997ef2c142e60dc77448de49d1dc4b1eee89', 'width': 816, 'height': 246}, 'resolutions': [{'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb18b9ff11a399264b6b501fe2d796f1842cf531', 'width': 108, 'height': 32}, {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=da2566eef17424fd29022c2bd0acf057bdb46a0e', 'width': 216, 'height': 65}, {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf85a599b289c4ca5c54a1bdb5cfe86f9639add4', 'width': 320, 'height': 96}, {'url': 'https://external-preview.redd.it/CZcLat1G57HQ2laiL1yZp8HQry2k4Aveg6d2zUecVss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=acdd3d63aa80dcd914b7db35e68df4a506b56cb0', 'width': 640, 'height': 192}], 'variants': {}, 'id': 'Oy9XQnD0kbZKV8MluszAr5rc5pkygj6xIhZeXeFGkRs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lt94cb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/lt94cb/tom_cruise_deepfake_videos_are_all_over_the/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/lt94cb/tom_cruise_deepfake_videos_are_all_over_the/', 'subreddit_subscribers': 6676, 'created_utc': 1614377176.0, 'num_crossposts': 12, 'media': None, 'is_video': False}]",t3_lt94cb,
29,,tensorflow,"This series covers a complete guide to TensorFlow and Keras, starting off with TensorFlow. This tutorial will cover:

* An introduction to TensorFlow and Keras (brief history and background)
* Different accelerators, including CPUs, GPUs, and TPUs
* Quick starter guide for beginners
* Tensors, constants, and variables
* Backpropagation, graphs, layers, and models
* Gradient clipping, gradient reversal, and gradient tape

Article link: [https://blog.paperspace.com/absolute-guide-to-tensorflow/](https://blog.paperspace.com/absolute-guide-to-tensorflow/)

Stay tuned for Part 2, covering a complete guide to Keras.",t2_15en0l,False,,0,False,[Tutorial] The Guide to TensorFlow,[],r/tensorflow,False,6,,0,,,False,t3_lt3ou9,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},Tutorial,False,7,,False,self,False,,[],{},,True,,1614391347.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This series covers a complete guide to TensorFlow and Keras, starting off with TensorFlow. This tutorial will cover:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An introduction to TensorFlow and Keras (brief history and background)&lt;/li&gt;
&lt;li&gt;Different accelerators, including CPUs, GPUs, and TPUs&lt;/li&gt;
&lt;li&gt;Quick starter guide for beginners&lt;/li&gt;
&lt;li&gt;Tensors, constants, and variables&lt;/li&gt;
&lt;li&gt;Backpropagation, graphs, layers, and models&lt;/li&gt;
&lt;li&gt;Gradient clipping, gradient reversal, and gradient tape&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/absolute-guide-to-tensorflow/""&gt;https://blog.paperspace.com/absolute-guide-to-tensorflow/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stay tuned for Part 2, covering a complete guide to Keras.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lt3ou9,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lt3ou9/tutorial_the_guide_to_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lt3ou9/tutorial_the_guide_to_tensorflow/,22217,1614362547.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?auto=webp&amp;s=97e6708de5796ea0d32d22ae7d6b278b271924a5', 'width': 1120, 'height': 900}, 'resolutions': [{'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4272e3ca78b60e5577eb769722e912d61cc359e', 'width': 108, 'height': 86}, {'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4438b7d476a09627036d72a97f05176c2dc09cdb', 'width': 216, 'height': 173}, {'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ff14475a16db406af136537f9b770587620d44d', 'width': 320, 'height': 257}, {'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afd45eca978ec89116b64167942cb7e72856bc04', 'width': 640, 'height': 514}, {'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f933556e681b4398d78e641d99987e744f320896', 'width': 960, 'height': 771}, {'url': 'https://external-preview.redd.it/4mXXEuu9GuRxCIBt0lS7yr99e7i-8Scfdy5Ae74vbHc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7a9405fc3d33a9d9dd43100c1bdd8dbdc2a00eaf', 'width': 1080, 'height': 867}], 'variants': {}, 'id': 'eId_TSntnzZBqQ4Or1g5TM9boBzCiuJRlg64M0kKSvw'}], 'enabled': False}",,,,,,
30,,tensorflow,"If you’re a programmer, you want to explore deep learning, and need a platform to help you do it - this tutorial is exactly for you.

In this tutorial you will learn:
- Getting around in Google Colab
- Installing python libraries in Colab
- Downloading large datasets in Colab 
- Training a Deep learning model in Colab
- Using TensorBoard in Colab

[Google Colab for Deep Learning](https://neptune.ai/blog/how-to-use-google-colab-for-deep-learning-complete-tutorial?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-how-to-use-google-colab-for-deep-learning-complete-tutorial&amp;utm_content=tensorflow)",t2_5hfacnnv,False,,0,False,[Beginners Tutorial] How to Use Google Colab for Deep Learning,[],r/tensorflow,False,6,,0,,,False,t3_lt5v98,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,self,False,,[],{},,True,,1614397039.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you’re a programmer, you want to explore deep learning, and need a platform to help you do it - this tutorial is exactly for you.&lt;/p&gt;

&lt;p&gt;In this tutorial you will learn:
- Getting around in Google Colab
- Installing python libraries in Colab
- Downloading large datasets in Colab 
- Training a Deep learning model in Colab
- Using TensorBoard in Colab&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/how-to-use-google-colab-for-deep-learning-complete-tutorial?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-how-to-use-google-colab-for-deep-learning-complete-tutorial&amp;amp;utm_content=tensorflow""&gt;Google Colab for Deep Learning&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lt5v98,True,,kk_ai,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lt5v98/beginners_tutorial_how_to_use_google_colab_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lt5v98/beginners_tutorial_how_to_use_google_colab_for/,22217,1614368239.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?auto=webp&amp;s=c0595816e83606cee7639819c508d0a835fd7cda', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6e7d2ddcf90e7895aa3201ad39c9e03698df83a', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff333757367818988052e0088ac32726956582d3', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da75aa309e3ceb2105c3b039a8dc37b2fbd57de6', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df57b4aca5ce1f8cc188807ce2d6cb15bd61323a', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3fc3d5b3e60826010376bf95c263eb7b53d7aad0', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/7nYD6gv0wQZyCJbd_AqwQEEuDame1YCo03tU40hVFFU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=67a765275e002fc976bbf962ba1eb38cd109cace', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'T2WD4O1kjTc9M-uYfQjMqI7KkTHrJ16EpZbCCKu1kxY'}], 'enabled': False}",,,,,,
31,,tensorflow,,t2_tunuoy8,False,,0,False,It's forming layers,[],r/tensorflow,False,6,,0,130.0,,False,t3_lt1ctn,False,dark,0.6,,public,1,0,{},140.0,,False,[],,True,False,,{},,False,1,,False,https://a.thumbs.redditmedia.com/mJTKAqCPYSJxlFsv6F026C56XKW9iXhWPuiPg9sEhG4.jpg,False,,[],{},,False,,1614385876.0,text,6,,,text,i.redd.it,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lt1ctn,True,,I-_-DuNn0,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lt1ctn/its_forming_layers/,all_ads,False,https://i.redd.it/uxkh2tgwmuj61.jpg,22217,1614357076.0,0,,False,image,https://i.redd.it/uxkh2tgwmuj61.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?auto=webp&amp;s=64089b15cc4101ed7e8a991c83735119b649fb92', 'width': 1080, 'height': 1006}, 'resolutions': [{'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85379a332263ff6c0740440c406c81b8c32df247', 'width': 108, 'height': 100}, {'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7005bbd229a2e3dd2b7bd45d2b9b77486cc8454', 'width': 216, 'height': 201}, {'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d09bb616a9a63e5b6f2eafe7e59fd9011e559fa', 'width': 320, 'height': 298}, {'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1485731af9d3ebbf03b61ad9e98755f25a4bb6d7', 'width': 640, 'height': 596}, {'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7ad1e292400b3a3739440421361a6c051d85f04e', 'width': 960, 'height': 894}, {'url': 'https://preview.redd.it/uxkh2tgwmuj61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f8a96956bdbb39276203a3c8775f401dd40b80cc', 'width': 1080, 'height': 1006}], 'variants': {}, 'id': 'IV6NyeA6pKhE7K38Iv6eVR1id-nuZXCqzEmqtLHbgnY'}], 'enabled': True}",,,,,,
32,,tensorflow,,t2_1krqyfrs,False,,0,False,5 TIPS on How to WIN the OpenCV Spatial AI Competition,[],r/tensorflow,False,6,,0,105.0,,False,t3_lsyliu,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Xp8xCX36Hns?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '5 TIPS on How to WIN the OpenCV Spatial AI Competition', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Xp8xCX36Hns?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Augmented Startups', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Xp8xCX36Hns/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/augmentedstartups'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Xp8xCX36Hns?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lsyliu', 'height': 200}",Discussion,False,1,,False,https://b.thumbs.redditmedia.com/Yg7eNS9Rq98YSkbWVr4OQf7SqPHAyoN_8JygDuMmhVc.jpg,False,,[],{},,False,,1614377964.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lsyliu,True,,AugmentedStartups,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lsyliu/5_tips_on_how_to_win_the_opencv_spatial_ai/,all_ads,False,https://youtu.be/Xp8xCX36Hns,22217,1614349164.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '5 TIPS on How to WIN the OpenCV Spatial AI Competition', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Xp8xCX36Hns?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Augmented Startups', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Xp8xCX36Hns/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/augmentedstartups'}}",False,rich:video,https://youtu.be/Xp8xCX36Hns,"{'images': [{'source': {'url': 'https://external-preview.redd.it/_PK9I-QqGrCm8k73grHDMgJYamiyckdloBhXsIDmzHM.jpg?auto=webp&amp;s=1bc2f9a58f65d25696df84d65a473a2520aa3434', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/_PK9I-QqGrCm8k73grHDMgJYamiyckdloBhXsIDmzHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab91d1df7cffbdd84b052b21e68e69bd3342c4bb', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/_PK9I-QqGrCm8k73grHDMgJYamiyckdloBhXsIDmzHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a92c88fca2bda4bfa94a50282451aea56f5dfa70', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/_PK9I-QqGrCm8k73grHDMgJYamiyckdloBhXsIDmzHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78e50db143487c340c84a41b61141b821cb863e0', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'dSxDrtViUpkCqNDnygECOCtgsjaOcXNHTrevFtVAU5M'}], 'enabled': False}",,,,,,
33,,tensorflow,,t2_abc93ry0,False,,0,False,Tensorflow Installation,[],r/tensorflow,False,6,,0,,,False,t3_lswaz0,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,default,False,,[],{},,False,,1614369523.0,text,6,,,text,self.cpp_questions,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lswaz0,True,,mugeshk_97,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lswaz0/tensorflow_installation/,all_ads,False,/r/cpp_questions/comments/lstfe4/tensorflow_installation/,22217,1614340723.0,0,,False,,/r/cpp_questions/comments/lstfe4/tensorflow_installation/,,,,,"[{'approved_at_utc': None, 'subreddit': 'cpp_questions', 'selftext': '\nCan anyone help me to install tensorflow c++ in ubuntu 20.04 I struck on this for more than 2 days', 'author_fullname': 't2_abc93ry0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Tensorflow Installation', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/cpp_questions', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'open', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lstfe4', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'OPEN', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1614357436.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.cpp_questions', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can anyone help me to install tensorflow c++ in ubuntu 20.04 I struck on this for more than 2 days&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'a98f883e-a327-11e3-900a-12313d27e9a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2tdbd', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lstfe4', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'mugeshk_97', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/cpp_questions/comments/lstfe4/tensorflow_installation/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/cpp_questions/comments/lstfe4/tensorflow_installation/', 'subreddit_subscribers': 42182, 'created_utc': 1614328636.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_lstfe4,
34,,tensorflow,"In the latest update of VS Code last week, they added support for TensorBoard integration in VS Code. It’s on the latest Python extension for VS code. Just wanted to share with everyone!

&amp;#x200B;

https://preview.redd.it/lg64jrhqhij61.png?width=2556&amp;format=png&amp;auto=webp&amp;s=1afe8944a278356a3eafbc98039424b62069c505

To launch tensorboard, just open the command palette in VS Code and search for the command ""Launch TensorBoard""

&amp;#x200B;

https://preview.redd.it/g96z1lxxhij61.png?width=1064&amp;format=png&amp;auto=webp&amp;s=cc1f0bc16bd9141796e88b6fea4878141bbe74c2

It looks like VS Code will automatically look for your TensorBoard log files within your directory.",t2_d2hk7,False,,0,False,New TensorBoard Integration in VS Code,[],r/tensorflow,False,6,,0,73.0,,False,t3_lrqkzk,False,dark,0.97,,public,37,0,{},140.0,,False,[],,False,False,,{},,False,37,,False,https://b.thumbs.redditmedia.com/GdfDdpLIaoONkTmWEk7WwcRlZvOQuZnhYlgTM67aLIs.jpg,1614239821.0,,[],{},,True,,1614238949.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In the latest update of VS Code last week, they added support for TensorBoard integration in VS Code. It’s on the latest Python extension for VS code. Just wanted to share with everyone!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/lg64jrhqhij61.png?width=2556&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1afe8944a278356a3eafbc98039424b62069c505""&gt;https://preview.redd.it/lg64jrhqhij61.png?width=2556&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1afe8944a278356a3eafbc98039424b62069c505&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To launch tensorboard, just open the command palette in VS Code and search for the command &amp;quot;Launch TensorBoard&amp;quot;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/g96z1lxxhij61.png?width=1064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc1f0bc16bd9141796e88b6fea4878141bbe74c2""&gt;https://preview.redd.it/g96z1lxxhij61.png?width=1064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc1f0bc16bd9141796e88b6fea4878141bbe74c2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It looks like VS Code will automatically look for your TensorBoard log files within your directory.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lrqkzk,True,,evilcubed,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lrqkzk/new_tensorboard_integration_in_vs_code/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lrqkzk/new_tensorboard_integration_in_vs_code/,22217,1614210149.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?auto=webp&amp;s=4f47ec50f2da0ac9292cfb6c9a79976490490f5e', 'width': 2556, 'height': 1339}, 'resolutions': [{'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5097bb86c8e0a99d258047acf4fa5b7afdd3bc17', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=25c43877debca84d93b31ed1aa923c566aff36d8', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a965b62707c32ee00cba2db38ae5dc3bfd5dfcb7', 'width': 320, 'height': 167}, {'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0326f2a5d5727b0e2aaaf0a29a4d54e0c6e31b05', 'width': 640, 'height': 335}, {'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bb4ef29783128bafdf79252e45b61dbc757bbb8f', 'width': 960, 'height': 502}, {'url': 'https://external-preview.redd.it/KgXGmLn4PC1d2LTPdlwuIfedkpavuTJntMeiT9lI2Mo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ac0de2e78a0165d70c21a798377354b286aa7fe4', 'width': 1080, 'height': 565}], 'variants': {}, 'id': 'JhwH31CPme6co9Spj4tOj--BHimD_R0THnN9Hw8B98k'}], 'enabled': False}",,"{'g96z1lxxhij61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 17, 'x': 108, 'u': 'https://preview.redd.it/g96z1lxxhij61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8772614f4088845b97d76c01316e4328b81cd600'}, {'y': 35, 'x': 216, 'u': 'https://preview.redd.it/g96z1lxxhij61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5be7ae2fdbb2fb55c80578b52bd53b9f97615a80'}, {'y': 52, 'x': 320, 'u': 'https://preview.redd.it/g96z1lxxhij61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=be7b29d7bddbb0b0b87f7bee11b72ae3f51d9dd0'}, {'y': 105, 'x': 640, 'u': 'https://preview.redd.it/g96z1lxxhij61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a7198fa30e9cb52930b508f5c0d3b07196a3aa4'}, {'y': 158, 'x': 960, 'u': 'https://preview.redd.it/g96z1lxxhij61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea6abcd1aa9acb5f84d67a85ebfd786426c93490'}], 's': {'y': 176, 'x': 1064, 'u': 'https://preview.redd.it/g96z1lxxhij61.png?width=1064&amp;format=png&amp;auto=webp&amp;s=cc1f0bc16bd9141796e88b6fea4878141bbe74c2'}, 'id': 'g96z1lxxhij61'}, 'lg64jrhqhij61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 56, 'x': 108, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=929ff382e8380f87e3dad4e78cf74a00aba4b175'}, {'y': 113, 'x': 216, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=303810e7d48a9a92f918614f04a7639b22dbcebd'}, {'y': 167, 'x': 320, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6dffcb0cda09c4a2caa66b14877144fee87d8c4d'}, {'y': 335, 'x': 640, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc668cab25264749e3341047ceea4af5ba9abc96'}, {'y': 502, 'x': 960, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e60f9fd3fd3eeea3c32d23c82ee514d205cbb56b'}, {'y': 565, 'x': 1080, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18a70afcd218cf74499888842fcd7bdc2c5b36b7'}], 's': {'y': 1339, 'x': 2556, 'u': 'https://preview.redd.it/lg64jrhqhij61.png?width=2556&amp;format=png&amp;auto=webp&amp;s=1afe8944a278356a3eafbc98039424b62069c505'}, 'id': 'lg64jrhqhij61'}}",,,,
35,,tensorflow,"Hey guys,   


Currently working on a tensorflow python script which I plan to use on a server with multiple cores .   


The problem is that if I try to run the script in separate ssh sessions it will always default to the same core, and I need it to run in a different core each time so I can take advantage of all of the cores available .   


Using tensorflow 2.2 so tf session is no longer available .   


Can anyone please tell me how to achieve this ?  


Thanks",t2_k4t6mbz,False,,0,False,Running tensorflow for python in multiple cores ?,[],r/tensorflow,False,6,,0,,,False,t3_ls907f,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614295523.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys,   &lt;/p&gt;

&lt;p&gt;Currently working on a tensorflow python script which I plan to use on a server with multiple cores .   &lt;/p&gt;

&lt;p&gt;The problem is that if I try to run the script in separate ssh sessions it will always default to the same core, and I need it to run in a different core each time so I can take advantage of all of the cores available .   &lt;/p&gt;

&lt;p&gt;Using tensorflow 2.2 so tf session is no longer available .   &lt;/p&gt;

&lt;p&gt;Can anyone please tell me how to achieve this ?  &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ls907f,True,,Triptonpt,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ls907f/running_tensorflow_for_python_in_multiple_cores/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ls907f/running_tensorflow_for_python_in_multiple_cores/,22217,1614266723.0,0,,False,,,,,,,,,
36,,tensorflow,"I am trying to solve 2nd order ODE which is 

y''+100y=0, y(0)=0, y'(0)=10 on \[0, 1\] interval

using neural network. Here is the code: [https://colab.research.google.com/gist/rprtr258/717c07b72f2263ca0dc401c83e9179e5/2nd-order-ode.ipynb#scrollTo=zeub0DBC9pkr](https://colab.research.google.com/gist/rprtr258/717c07b72f2263ca0dc401c83e9179e5/2nd-order-ode.ipynb#scrollTo=zeub0DBC9pkr)

But I have two problems:

1. I guess tf recompiles(retraces) some function during learning which slows learning proccess significantly. Putting whole learning process into function doesn't help.
2. NN doesn't fit at all. I guess it might be because of gradient size on last layer or something. Anyway it is difficult to test during 1.

Any help with problem 1 and maybe problem 2 will be appreciated.",t2_13av1p,False,,0,False,Couldn't train nn for solving 2nd order ODE,[],r/tensorflow,False,6,,0,,,False,t3_ls6r7e,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614289071.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to solve 2nd order ODE which is &lt;/p&gt;

&lt;p&gt;y&amp;#39;&amp;#39;+100y=0, y(0)=0, y&amp;#39;(0)=10 on [0, 1] interval&lt;/p&gt;

&lt;p&gt;using neural network. Here is the code: &lt;a href=""https://colab.research.google.com/gist/rprtr258/717c07b72f2263ca0dc401c83e9179e5/2nd-order-ode.ipynb#scrollTo=zeub0DBC9pkr""&gt;https://colab.research.google.com/gist/rprtr258/717c07b72f2263ca0dc401c83e9179e5/2nd-order-ode.ipynb#scrollTo=zeub0DBC9pkr&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But I have two problems:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I guess tf recompiles(retraces) some function during learning which slows learning proccess significantly. Putting whole learning process into function doesn&amp;#39;t help.&lt;/li&gt;
&lt;li&gt;NN doesn&amp;#39;t fit at all. I guess it might be because of gradient size on last layer or something. Anyway it is difficult to test during 1.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Any help with problem 1 and maybe problem 2 will be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ls6r7e,True,,rprtr258,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ls6r7e/couldnt_train_nn_for_solving_2nd_order_ode/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ls6r7e/couldnt_train_nn_for_solving_2nd_order_ode/,22217,1614260271.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&amp;s=73eb91ea5a5347f216c0f0c4d6796396826aae49', 'width': 260, 'height': 260}, 'resolutions': [{'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b647239f77bf713f4a6209cfa4867351c055fd9', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f4234ff3f4f4ebd7f77236dedb03a2faee3e04a', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nkhh65ujo5BznFJFojoMPaKjGuLSpPj6KGhRov-ykOg'}], 'enabled': False}",,,,,,
37,,tensorflow,[https://stackoverflow.com/questions/66363862/why-my-model-has-a-low-mae-and-low-r2-score-at-the-same-time](https://stackoverflow.com/questions/66363862/why-my-model-has-a-low-mae-and-low-r2-score-at-the-same-time),t2_8l1rudmf,False,,0,False,Why my Model has a low MAE and low R2 score at the same time?,[],r/tensorflow,False,6,,0,,,False,t3_ls0tx8,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1614266399.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://stackoverflow.com/questions/66363862/why-my-model-has-a-low-mae-and-low-r2-score-at-the-same-time""&gt;https://stackoverflow.com/questions/66363862/why-my-model-has-a-low-mae-and-low-r2-score-at-the-same-time&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ls0tx8,True,,notm3llo,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ls0tx8/why_my_model_has_a_low_mae_and_low_r2_score_at/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ls0tx8/why_my_model_has_a_low_mae_and_low_r2_score_at/,22217,1614237599.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
38,,tensorflow,"How can I take two feature vectors as outputs from two inputs, store them, and compare a feature vector from a third input to the first feature vectors within one model? End result is dataset C is 80% similar to dataset A 20% to dataset B, etc.",t2_7nkszese,False,,0,False,Model within a model?,[],r/tensorflow,False,6,,0,,,False,t3_lryskt,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1614258432.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How can I take two feature vectors as outputs from two inputs, store them, and compare a feature vector from a third input to the first feature vectors within one model? End result is dataset C is 80% similar to dataset A 20% to dataset B, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lryskt,True,,BestUCanIsGoodEnough,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lryskt/model_within_a_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lryskt/model_within_a_model/,22217,1614229632.0,0,,False,,,,,,,,,
39,,tensorflow,"Hi,I am trying to run tflite model on browser. It would run client side, I have converted the model to wasm format and am able to run it successfully on browser.

Since, It would be client side, The tflite model would be accessible to everyone. Is it possible to encrypt the model in anyway, So not everyone has access to the model?

The application is built using mediapipe framework, Not sure if it would change the solution.

Thanks!",t2_7wbpzask,False,,0,False,How to encrypt a tflite model,[],r/tensorflow,False,6,,0,,,False,t3_lrfj5q,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1614209449.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,I am trying to run tflite model on browser. It would run client side, I have converted the model to wasm format and am able to run it successfully on browser.&lt;/p&gt;

&lt;p&gt;Since, It would be client side, The tflite model would be accessible to everyone. Is it possible to encrypt the model in anyway, So not everyone has access to the model?&lt;/p&gt;

&lt;p&gt;The application is built using mediapipe framework, Not sure if it would change the solution.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lrfj5q,True,,cvmldlengineer,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lrfj5q/how_to_encrypt_a_tflite_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lrfj5q/how_to_encrypt_a_tflite_model/,22217,1614180649.0,0,,False,,,,,,,,,
40,,tensorflow,,t2_42kliopx,False,,0,False,Help with debugging,[],r/tensorflow,False,6,,0,105.0,,False,t3_lrqf4v,False,dark,0.5,,public,0,0,{},140.0,,False,[],,True,False,,{},Question,False,0,,False,https://a.thumbs.redditmedia.com/Ul_pDGDt2Z0x4t7p5qcOSsUW13iVwPu6s_-PG5QWB64.jpg,False,,[],{},,False,,1614238507.0,text,6,,,text,i.redd.it,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lrqf4v,True,,iWatchBlack,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lrqf4v/help_with_debugging/,all_ads,False,https://i.redd.it/nbw6k9rogij61.jpg,22217,1614209707.0,0,,False,image,https://i.redd.it/nbw6k9rogij61.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?auto=webp&amp;s=d32ed7d1c0f9273279f29af8b65c55128e0835ed', 'width': 4032, 'height': 3024}, 'resolutions': [{'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=534ffaa648c77a5139379b63575f4d5403f255f9', 'width': 108, 'height': 81}, {'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb5d11bf57e5aec30c2ecd0a62fbeea30b2f7f5d', 'width': 216, 'height': 162}, {'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8261cc614d43fbaa499202a13b176d9c4b59326', 'width': 320, 'height': 240}, {'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6975056a408816c5b0fd477676af65c2303c0e1f', 'width': 640, 'height': 480}, {'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eff43f9b2f3d84a59d650c3e802a5d56ea6d2f53', 'width': 960, 'height': 720}, {'url': 'https://preview.redd.it/nbw6k9rogij61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=92b3f869814726149dd4c2fdbc290b2776113d64', 'width': 1080, 'height': 810}], 'variants': {}, 'id': 'uyOlvanxObuOuu3LyB9-Iy_srvaa39GtWhPxi4M2B0E'}], 'enabled': True}",,,,,,
41,,tensorflow,"So I found out that a tesla M40 has the same amount of cuda cores as a 2080S but 2080S has tensor cores and is a lot more expensive but M40 is a lot cheaper so which would be the best bang for buck?

Price 2080S: 700$ specs: cuda cores 3072 core clock 1815MHz ram
8GB mem clock 2000 (15.5 GB effective) tensor cores: 384



Price M40: 140$(used) specs: cuda cores 3072 core clock 1110MHz ram: 12GB mem clock 1502 (6GBs effective)

Comparing price I would think for coding rendering and AI M40 would be better if you got 2 but tell me what you guys think",t2_aacniabq,False,,0,False,M40 vs 2080S which is better?,[],r/tensorflow,False,6,,0,,,False,t3_lrgkxa,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614212258.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I found out that a tesla M40 has the same amount of cuda cores as a 2080S but 2080S has tensor cores and is a lot more expensive but M40 is a lot cheaper so which would be the best bang for buck?&lt;/p&gt;

&lt;p&gt;Price 2080S: 700$ specs: cuda cores 3072 core clock 1815MHz ram
8GB mem clock 2000 (15.5 GB effective) tensor cores: 384&lt;/p&gt;

&lt;p&gt;Price M40: 140$(used) specs: cuda cores 3072 core clock 1110MHz ram: 12GB mem clock 1502 (6GBs effective)&lt;/p&gt;

&lt;p&gt;Comparing price I would think for coding rendering and AI M40 would be better if you got 2 but tell me what you guys think&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lrgkxa,True,,isaiahii10,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/lrgkxa/m40_vs_2080s_which_is_better/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lrgkxa/m40_vs_2080s_which_is_better/,22217,1614183458.0,0,,False,,,,,,,,,
42,,tensorflow,,t2_57d7z400,False,,0,False,Help,[],r/tensorflow,False,6,,0,,,False,t3_lrcz1r,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,default,False,,[],{},,False,,1614202367.0,text,6,,,text,self.learnmachinelearning,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lrcz1r,True,,waqasmarri,,2,False,all_ads,False,[],False,,/r/tensorflow/comments/lrcz1r/help/,all_ads,False,/r/learnmachinelearning/comments/lrcvzh/deploying_ml_model/,22217,1614173567.0,0,,False,,/r/learnmachinelearning/comments/lrcvzh/deploying_ml_model/,,,,,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': 'I have all the code in jupyter notebook. I have .pkl and .h5 files.\nHow can i deploy it? So that i dont have to wait for so long each time code runs, prediction is actually in seconds. How can i achieve this?\nTell me both ways, the automated GUI and the customized GUI with html css. Help needed!!', 'author_fullname': 't2_57d7z400', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Deploying ML model', 'link_flair_richtext': [{'e': 'text', 't': 'Help'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lrcvzh', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1614202116.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have all the code in jupyter notebook. I have .pkl and .h5 files.\nHow can i deploy it? So that i dont have to wait for so long each time code runs, prediction is actually in seconds. How can i achieve this?\nTell me both ways, the automated GUI and the customized GUI with html css. Help needed!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'af5dfa18-accf-11e9-9669-0ec668ea0cbc', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': 'lrcvzh', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'waqasmarri', 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/lrcvzh/deploying_ml_model/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/lrcvzh/deploying_ml_model/', 'subreddit_subscribers': 217921, 'created_utc': 1614173316.0, 'num_crossposts': 5, 'media': None, 'is_video': False}]",t3_lrcvzh,
43,,tensorflow,,t2_825dsgq6,False,,0,False,[D] : Any good resources for object detection using TensorFlow? Stuck on it!,[],r/tensorflow,False,6,,0,,,False,t3_lr3t35,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,True,default,False,,[],{},,False,,1614170209.0,text,6,,,text,self.MachineLearning,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lr3t35,True,,anotsohypocritesoul,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lr3t35/d_any_good_resources_for_object_detection_using/,all_ads,False,/r/MachineLearning/comments/lr3n2y/d_any_good_resources_for_object_detection_using/,22217,1614141409.0,0,,False,,/r/MachineLearning/comments/lr3n2y/d_any_good_resources_for_object_detection_using/,,,,,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '[removed]', 'author_fullname': 't2_825dsgq6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] : Any good resources for object detection using TensorFlow? Stuck on it!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lr3n2y', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'author_premium': True, 'thumbnail': 'default', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1614169662.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': 'moderator', 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lr3n2y', 'is_robot_indexable': False, 'report_reasons': None, 'author': 'anotsohypocritesoul', 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/lr3n2y/d_any_good_resources_for_object_detection_using/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/lr3n2y/d_any_good_resources_for_object_detection_using/', 'subreddit_subscribers': 1740787, 'created_utc': 1614140862.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_lr3n2y,
44,,tensorflow,,t2_wxzqp,False,,0,False,So does r/tensorflow have ________ in its name. ... oh! Come on Reddit!,[],r/tensorflow,False,6,,0,38.0,,False,t3_lqg2i8,False,dark,0.87,,public,54,0,{},140.0,,False,[],,True,False,,{},Question,False,54,,True,https://b.thumbs.redditmedia.com/P_V-phecR53nEUW6FOLVqkF-JgO3R7ny4AO6s4RaTQU.jpg,False,,[],{},,False,,1614107895.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lqg2i8,True,,TimeVendor,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/lqg2i8/so_does_rtensorflow_have_in_its_name_oh_come_on/,all_ads,False,https://i.redd.it/wqsydjqbo7j61.jpg,22217,1614079095.0,0,,False,image,https://i.redd.it/wqsydjqbo7j61.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?auto=webp&amp;s=2c1b2c28c92b092fd834bc46c2a8d0c489cfd6dc', 'width': 1124, 'height': 313}, 'resolutions': [{'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8c8e86d136b2f95935322e7bd489e788e9e681b9', 'width': 108, 'height': 30}, {'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f838cfbb5fc80d85939565faa9336b2f66113629', 'width': 216, 'height': 60}, {'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80c544c8ad380c77dcd64cffef5697cf0bb960e1', 'width': 320, 'height': 89}, {'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fcf442ef8685776878b1da0dad05dd57eec57e25', 'width': 640, 'height': 178}, {'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=316ca9814422ac25af5122ae66ea4786a496f1a7', 'width': 960, 'height': 267}, {'url': 'https://preview.redd.it/wqsydjqbo7j61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d19c08e15475d8d1d98d216f3eec35e33e9e17f1', 'width': 1080, 'height': 300}], 'variants': {}, 'id': 'EKrHe1NKuh29c7yDIT3pSOEtHGF7isE4nvn272d1oG4'}], 'enabled': True}",,,,,,
45,,tensorflow,"I am using Keras for boundary/contour detection using a Unet. When I use binary cross-entropy as the loss, the losses decrease over time as expected the predicted boundaries look reasonable

However, I have tried custom loss for Dice with varying LRs, none of them are working well. 

	
	smooth = 1e-6
	def dice_coef(y_true, y_pred):
	    y_true_f = K.flatten(y_true)
	    y_pred_f = K.flatten(y_pred)
	    intersection = K.sum(y_true_f * y_pred_f)
	    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


	def dice(y_true, y_pred):
	    return 1-dice_coef(y_true, y_pred)

the loss values don't improve. That is, it will show something like

    loss: nan - dice: .9607 - val_loss: nan - val_dice: .9631

I get NaNs for the losses and values for `dice` and `val_dice` that barely change as the epochs iterate. This is regardless of what I use for the LR, whether it be .01 to 1e-6

The dimensions of the train images/labels looks like N x H x W x 1, where N is the number of images, H/W are the height/width of each image

can anyone help?",t2_tpult,False,,0,False,Why getting NaN values for custom Dice loss in Keras?,[],r/tensorflow,False,6,,0,,,False,t3_lqznlv,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614159345.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using Keras for boundary/contour detection using a Unet. When I use binary cross-entropy as the loss, the losses decrease over time as expected the predicted boundaries look reasonable&lt;/p&gt;

&lt;p&gt;However, I have tried custom loss for Dice with varying LRs, none of them are working well. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;smooth = 1e-6
def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dice(y_true, y_pred):
    return 1-dice_coef(y_true, y_pred)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the loss values don&amp;#39;t improve. That is, it will show something like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;loss: nan - dice: .9607 - val_loss: nan - val_dice: .9631
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I get NaNs for the losses and values for &lt;code&gt;dice&lt;/code&gt; and &lt;code&gt;val_dice&lt;/code&gt; that barely change as the epochs iterate. This is regardless of what I use for the LR, whether it be .01 to 1e-6&lt;/p&gt;

&lt;p&gt;The dimensions of the train images/labels looks like N x H x W x 1, where N is the number of images, H/W are the height/width of each image&lt;/p&gt;

&lt;p&gt;can anyone help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lqznlv,True,,74throwaway,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lqznlv/why_getting_nan_values_for_custom_dice_loss_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lqznlv/why_getting_nan_values_for_custom_dice_loss_in/,22217,1614130545.0,2,,False,,,,,,,,,
46,,tensorflow,"Hello Guys, 

I'm challenging myself to create simple 1 dimension tensor that consist of integers, range from 1-10 using the linespace function and with a shape of 6. However I haven't been successful doing that. How do I fix this ?

My code: 

\[1,2,3,4,5,6,7,8,9,10\]

 torch.linspace(1, 1, 10)",t2_409owhnf,False,,0,False,Creating a tensor using linspace function,[],r/tensorflow,False,6,,0,,,False,t3_lquyzu,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614148291.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello Guys, &lt;/p&gt;

&lt;p&gt;I&amp;#39;m challenging myself to create simple 1 dimension tensor that consist of integers, range from 1-10 using the linespace function and with a shape of 6. However I haven&amp;#39;t been successful doing that. How do I fix this ?&lt;/p&gt;

&lt;p&gt;My code: &lt;/p&gt;

&lt;p&gt;[1,2,3,4,5,6,7,8,9,10]&lt;/p&gt;

&lt;p&gt;torch.linspace(1, 1, 10)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lquyzu,True,,destin95,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lquyzu/creating_a_tensor_using_linspace_function/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lquyzu/creating_a_tensor_using_linspace_function/,22217,1614119491.0,0,,False,,,,,,,,,
47,,tensorflow,"I'm learning about pose estimation and found out that Tensorflow only have a [Tensorflow Lite Model](https://www.tensorflow.org/lite/examples/pose_estimation/overview?hl=en) and a [JS Web Application](https://github.com/tensorflow/tfjs-models/tree/master/posenet),

I've been experimenting with the Lite model but it is not very accurate since it only handles an input image of 257x257. 

Where can I find more Tensorflow models for pose estimation?",t2_fpx0f,False,,0,False,Pose Estimation with Python,[],r/tensorflow,False,6,,0,,,False,t3_lqu9wu,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614146398.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m learning about pose estimation and found out that Tensorflow only have a &lt;a href=""https://www.tensorflow.org/lite/examples/pose_estimation/overview?hl=en""&gt;Tensorflow Lite Model&lt;/a&gt; and a &lt;a href=""https://github.com/tensorflow/tfjs-models/tree/master/posenet""&gt;JS Web Application&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been experimenting with the Lite model but it is not very accurate since it only handles an input image of 257x257. &lt;/p&gt;

&lt;p&gt;Where can I find more Tensorflow models for pose estimation?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lqu9wu,True,,darkrubiks,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lqu9wu/pose_estimation_with_python/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lqu9wu/pose_estimation_with_python/,22217,1614117598.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?auto=webp&amp;s=2572596fe2183c02bb87888fad10698003d1766c', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f38f154b31bbc61f967552a73eae2d908d46ae03', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=800ed1265a325e2ebbd4bac73e5a0a9f87375fc4', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef1d21237970b3962ea11427b5fb4a133b573f95', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd75fe122929cebeb28f32cabc416c0d34746e81', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e61b7e8ded8e04296fb02cef535a2339569b52b', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fce2149c6d3aad062f85426dd46ad50c64a82b2e', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'X-wKcTKmnQRaY7Q0VF7Fv5E2VV8HI6yDgaH8MhXzwMA'}], 'enabled': False}",,,,,,
48,,tensorflow,"We implemented a VAE (Variation Autoencoder), in different flavours/variants:

\- standard 

\- hierachical 

\- vampprior (based on [https://arxiv.org/abs/1705.07120](https://arxiv.org/abs/1705.07120))

This is a good project both if you want to get started with different models such as VAE and also if you want to get a grasp of different implementations. 

The implementation is at the following GitHub repository [https://github.com/morpheusthewhite/vae-vampprior](https://github.com/morpheusthewhite/vae-vampprior)",t2_2dyvbb1d,False,,0,False,A simple and ready to use VAE (+hierarchical and vampprior variants),[],r/tensorflow,False,6,,0,,,False,t3_lqmg4c,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Project,False,2,,False,self,False,,[],{},,True,,1614126560.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We implemented a VAE (Variation Autoencoder), in different flavours/variants:&lt;/p&gt;

&lt;p&gt;- standard &lt;/p&gt;

&lt;p&gt;- hierachical &lt;/p&gt;

&lt;p&gt;- vampprior (based on &lt;a href=""https://arxiv.org/abs/1705.07120""&gt;https://arxiv.org/abs/1705.07120&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;This is a good project both if you want to get started with different models such as VAE and also if you want to get a grasp of different implementations. &lt;/p&gt;

&lt;p&gt;The implementation is at the following GitHub repository &lt;a href=""https://github.com/morpheusthewhite/vae-vampprior""&gt;https://github.com/morpheusthewhite/vae-vampprior&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lqmg4c,True,,morpheusthewhite,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lqmg4c/a_simple_and_ready_to_use_vae_hierarchical_and/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lqmg4c/a_simple_and_ready_to_use_vae_hierarchical_and/,22217,1614097760.0,0,,False,,,,,,,,,
49,,tensorflow,"I'm trying to create a data pipeline like this:

&amp;#x200B;

https://preview.redd.it/gedmeuy9j7j61.png?width=762&amp;format=png&amp;auto=webp&amp;s=7dddd34f9f202c2238e54e35814dc5f315d3c6ee

The raw inputs are a bunch of videos. For each video, I need some frames, and the audio on corresponding time being extracted as well. Both will be the input to the model.

I've looked into TFRecord and related articles but still can't figure out good steps to do it. Can somebody give me some advice? I only need information like steps in high level, for example: 

1. Make TFRecords using tf.data.Dataset (this doesn't seem right, but just an example)
2. ...

&amp;#x200B;

Thank you.",t2_1y6a3u8h,False,,0,False,Questions of creating a data pipeline,[],r/tensorflow,False,6,,0,87.0,,False,t3_lqfohr,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},Question,False,3,,False,https://a.thumbs.redditmedia.com/w7shfwf7vDX04R-GX6XVxLaF62F99C642leIlddpTZ4.jpg,False,,[],{},,True,,1614106516.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to create a data pipeline like this:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gedmeuy9j7j61.png?width=762&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7dddd34f9f202c2238e54e35814dc5f315d3c6ee""&gt;https://preview.redd.it/gedmeuy9j7j61.png?width=762&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7dddd34f9f202c2238e54e35814dc5f315d3c6ee&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The raw inputs are a bunch of videos. For each video, I need some frames, and the audio on corresponding time being extracted as well. Both will be the input to the model.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve looked into TFRecord and related articles but still can&amp;#39;t figure out good steps to do it. Can somebody give me some advice? I only need information like steps in high level, for example: &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Make TFRecords using tf.data.Dataset (this doesn&amp;#39;t seem right, but just an example)&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lqfohr,True,,pavlovseal,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lqfohr/questions_of_creating_a_data_pipeline/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lqfohr/questions_of_creating_a_data_pipeline/,22217,1614077716.0,0,,False,,,,,"{'gedmeuy9j7j61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/gedmeuy9j7j61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b7d3ee823a7f64ba5b70dc3b992d2cc497229c8'}, {'y': 135, 'x': 216, 'u': 'https://preview.redd.it/gedmeuy9j7j61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e2044923ffe1a41b0ede7293877e9277ce66247'}, {'y': 200, 'x': 320, 'u': 'https://preview.redd.it/gedmeuy9j7j61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7ec175e184817fe29ee3493336341e017ff683e'}, {'y': 401, 'x': 640, 'u': 'https://preview.redd.it/gedmeuy9j7j61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5fb7e967e05acba35dcbb85c927b650eb06ef3c9'}], 's': {'y': 478, 'x': 762, 'u': 'https://preview.redd.it/gedmeuy9j7j61.png?width=762&amp;format=png&amp;auto=webp&amp;s=7dddd34f9f202c2238e54e35814dc5f315d3c6ee'}, 'id': 'gedmeuy9j7j61'}}",,,,
50,,tensorflow,"Hi, so I’m quite new to machine learning and I’m currently making a CGAN. I’ve ran into a problem as the input of my discriminator is going to be (None, 41, 4) but I’ve got output from my generator to be (None, 44, 4). How do I resolve this?

TL;DR : how do I go from (None, 44, 4) to (None, 41, 4)?",t2_4wzmvm1l,False,,0,False,Reshaping my output layer,[],r/tensorflow,False,6,,0,,,False,t3_lql8lj,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614123544.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, so I’m quite new to machine learning and I’m currently making a CGAN. I’ve ran into a problem as the input of my discriminator is going to be (None, 41, 4) but I’ve got output from my generator to be (None, 44, 4). How do I resolve this?&lt;/p&gt;

&lt;p&gt;TL;DR : how do I go from (None, 44, 4) to (None, 41, 4)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lql8lj,True,,georgigotsauce,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lql8lj/reshaping_my_output_layer/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lql8lj/reshaping_my_output_layer/,22217,1614094744.0,0,,False,,,,,,,,,
51,,tensorflow,"Hello everyone!

I'm working on a global forecasting problem for some products at a marketplace. I currently have a data frame that contains daily sales for each product, which I can differentiate by the product id. I've been working in the pre-processing step (normalizing, one hot encoding, ...). In addition, I have constructed a code for the sliding window BUT I haven't conditioned it over the id. I don't want the window to combine time series of different products (e.g. having some time steps of product 1 and some for product 2 in the same window because they were adjacent). 

Do you know a way I can do this? I don't want to split the dataframe into different files because I have around 5k different identifiers. 

Thanks in advance. :)",t2_11ggjx7,False,,0,False,How to create a sliding window per id,[],r/tensorflow,False,6,,0,,,False,t3_lql0os,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1614122986.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on a global forecasting problem for some products at a marketplace. I currently have a data frame that contains daily sales for each product, which I can differentiate by the product id. I&amp;#39;ve been working in the pre-processing step (normalizing, one hot encoding, ...). In addition, I have constructed a code for the sliding window BUT I haven&amp;#39;t conditioned it over the id. I don&amp;#39;t want the window to combine time series of different products (e.g. having some time steps of product 1 and some for product 2 in the same window because they were adjacent). &lt;/p&gt;

&lt;p&gt;Do you know a way I can do this? I don&amp;#39;t want to split the dataframe into different files because I have around 5k different identifiers. &lt;/p&gt;

&lt;p&gt;Thanks in advance. :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lql0os,True,,saikjuan,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lql0os/how_to_create_a_sliding_window_per_id/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lql0os/how_to_create_a_sliding_window_per_id/,22217,1614094186.0,0,,False,,,,,,,,,
52,,tensorflow,"I need to do this very same calculation in TF2 which ends up by calculating `v1` and `v2` which are softmax output and the same softmax output but calculated using a `tf.train.ExponentialMovingAverage` `average()` method. The original example can be found [here](https://github.com/openai/baselines/blob/master/baselines/acer/acer.py) at line 88. The example below is a simplified version.

**TF1 code:**

    import tensorflow as tf
    
    
    with tf.variable_scope('my_model', reuse=tf.AUTO_REUSE):
        step_model = StepModel(step_param)  # step_param is a placeholder
        train_model = TrainModel(train_param)  # train_param is a placeholder
    
    params = tf.trainable_variables('my_model')
    ema = tf.train.ExponentialMovingAverage(0.99)
    ema_apply_op = ema.apply(params)
    
    def custom_getter(getter, *args, **kwargs):
        return ema.average(getter(*args, **kwargs))
    
    with tf.variable_scope(""my_model"", custom_getter=custom_getter, reuse=True):
        avg_model = AveragingModel(avg_param)  # avg_param is a placeholder
    
    train_model_p = tf.nn.softmax(train_model.pi)
    avg_model_p = tf.nn.softmax(avg_model.pi)
    common_param = some_param
    with tf.get_default_session() as sess:
        feed_dict = {
            train_model.train_param: common_param,
            avg_model.avg_param: common_param,
        }
        ops = [train_model_p, avg_model_p]
        v1, v2 = sess.run(ops, feed_dict)[1:]

If I want to keep a moving average of the trainable variables in TF2 without worrying about `v1` and `v2`, I'd do:

    from tensorflow.keras.optimizers import Adam
    from tensorflow_addons.optimizers import MovingAverage
    from tensorflow.keras.models import Model

and then I'd wrap the `tf.keras.optimizers.Optimizer()` being used:

    model = Model(...)
    optim = MovingAverage(Adam())
    model.compile(optimizer=optim)
    model.fit(...)

But I need to get the values of `v1` and `v2` for further calculations.",t2_4jbcsgd0,False,,0,False,How to convert TF1 model with custom getter to TF2,[],r/tensorflow,False,6,,0,,,False,t3_lqjvjc,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1614119979.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need to do this very same calculation in TF2 which ends up by calculating &lt;code&gt;v1&lt;/code&gt; and &lt;code&gt;v2&lt;/code&gt; which are softmax output and the same softmax output but calculated using a &lt;code&gt;tf.train.ExponentialMovingAverage&lt;/code&gt; &lt;code&gt;average()&lt;/code&gt; method. The original example can be found &lt;a href=""https://github.com/openai/baselines/blob/master/baselines/acer/acer.py""&gt;here&lt;/a&gt; at line 88. The example below is a simplified version.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TF1 code:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf


with tf.variable_scope(&amp;#39;my_model&amp;#39;, reuse=tf.AUTO_REUSE):
    step_model = StepModel(step_param)  # step_param is a placeholder
    train_model = TrainModel(train_param)  # train_param is a placeholder

params = tf.trainable_variables(&amp;#39;my_model&amp;#39;)
ema = tf.train.ExponentialMovingAverage(0.99)
ema_apply_op = ema.apply(params)

def custom_getter(getter, *args, **kwargs):
    return ema.average(getter(*args, **kwargs))

with tf.variable_scope(&amp;quot;my_model&amp;quot;, custom_getter=custom_getter, reuse=True):
    avg_model = AveragingModel(avg_param)  # avg_param is a placeholder

train_model_p = tf.nn.softmax(train_model.pi)
avg_model_p = tf.nn.softmax(avg_model.pi)
common_param = some_param
with tf.get_default_session() as sess:
    feed_dict = {
        train_model.train_param: common_param,
        avg_model.avg_param: common_param,
    }
    ops = [train_model_p, avg_model_p]
    v1, v2 = sess.run(ops, feed_dict)[1:]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If I want to keep a moving average of the trainable variables in TF2 without worrying about &lt;code&gt;v1&lt;/code&gt; and &lt;code&gt;v2&lt;/code&gt;, I&amp;#39;d do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.keras.optimizers import Adam
from tensorflow_addons.optimizers import MovingAverage
from tensorflow.keras.models import Model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and then I&amp;#39;d wrap the &lt;code&gt;tf.keras.optimizers.Optimizer()&lt;/code&gt; being used:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = Model(...)
optim = MovingAverage(Adam())
model.compile(optimizer=optim)
model.fit(...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But I need to get the values of &lt;code&gt;v1&lt;/code&gt; and &lt;code&gt;v2&lt;/code&gt; for further calculations.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lqjvjc,True,,emadboctor,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lqjvjc/how_to_convert_tf1_model_with_custom_getter_to_tf2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lqjvjc/how_to_convert_tf1_model_with_custom_getter_to_tf2/,22217,1614091179.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/DZ7Hqtu8pacE0RH3j35lvbGP5nfugXvx4BZYutIgkUQ.jpg?auto=webp&amp;s=e790dfd22ddf29a4faf92d7bd2985bac28e32e28', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/DZ7Hqtu8pacE0RH3j35lvbGP5nfugXvx4BZYutIgkUQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cddfafccceb971dceea8e590068a6b05daf3cd6a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/DZ7Hqtu8pacE0RH3j35lvbGP5nfugXvx4BZYutIgkUQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=820112006878142f35d7fdf09ed6aadb0f609aa6', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/DZ7Hqtu8pacE0RH3j35lvbGP5nfugXvx4BZYutIgkUQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a819b7dfd1139f626c559dddadd25b9aedc5953', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'rmkuBneBGTGepgZx-zZwrobffFPKaUKQxumwWo3FGHQ'}], 'enabled': False}",,,,,,
53,,tensorflow,"Price:140$
Specs 

Cuda cores: 4,992

Core speed: 562-875 per card

RAM 24GB

RAM speed: 480GB/s

This is a 2 pci slot card basically 2 cards in 1 
No cooling included (I got a plan for that)

Display card will be my old gtx 950",t2_aacniabq,False,,0,False,I saw some tesla k80 graphics acceleration cards they have no display port there for helping workloads are these any good for tensorflow AI building,[],r/tensorflow,False,6,,0,,,False,t3_lq16l3,False,dark,1.0,,public,11,0,{},,,False,[],,False,False,,{},Question,False,11,,False,self,1614031348.0,,[],{},,True,,1614059902.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Price:140$
Specs &lt;/p&gt;

&lt;p&gt;Cuda cores: 4,992&lt;/p&gt;

&lt;p&gt;Core speed: 562-875 per card&lt;/p&gt;

&lt;p&gt;RAM 24GB&lt;/p&gt;

&lt;p&gt;RAM speed: 480GB/s&lt;/p&gt;

&lt;p&gt;This is a 2 pci slot card basically 2 cards in 1 
No cooling included (I got a plan for that)&lt;/p&gt;

&lt;p&gt;Display card will be my old gtx 950&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lq16l3,True,,isaiahii10,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/lq16l3/i_saw_some_tesla_k80_graphics_acceleration_cards/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lq16l3/i_saw_some_tesla_k80_graphics_acceleration_cards/,22217,1614031102.0,0,,False,,,,,,,,,
54,,tensorflow,,t2_89lfl2lx,False,,0,False,I've been working on an real time object detection project and I've been face with an error while trying to capture image to label and train.. please help,[],r/tensorflow,False,6,,0,140.0,,False,t3_lqbqn1,False,dark,0.5,,public,0,0,{},140.0,,False,[],,True,False,,{},Question,False,0,,False,https://b.thumbs.redditmedia.com/taTdgc1NKDIKEhURQARkTniAoN7Wf58LpPTZCj7lZ8g.jpg,False,,[],{},,False,,1614091761.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lqbqn1,True,,Field_Great,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lqbqn1/ive_been_working_on_an_real_time_object_detection/,all_ads,False,https://i.redd.it/7zff2dxbc6j61.jpg,22217,1614062961.0,0,,False,image,https://i.redd.it/7zff2dxbc6j61.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?auto=webp&amp;s=71117fbf7d9b37c874e32944c0f54f605d7efe01', 'width': 3120, 'height': 4160}, 'resolutions': [{'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bfdf0d9fcdffe1d1475b853e027b67c157bd6737', 'width': 108, 'height': 144}, {'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=21783252aca3246d2a72596986c58a19ac4cb69c', 'width': 216, 'height': 288}, {'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd2856d1ab576cb74f31e52840b26cec11c3e5a0', 'width': 320, 'height': 426}, {'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9fdfc2708a6e3d7c5495669bf877895b4bfd4f02', 'width': 640, 'height': 853}, {'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e2d132f77668b5e00a8aca4c9aa18f2f4db0327b', 'width': 960, 'height': 1280}, {'url': 'https://preview.redd.it/7zff2dxbc6j61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d433b15104c754880143ea5db46f7b2dc2c3f2f2', 'width': 1080, 'height': 1440}], 'variants': {}, 'id': '0FpdHg8Grbm4HXDesQnTEN_TfzeJ-wuWheJUdBchQbk'}], 'enabled': True}",,,,,,
55,,tensorflow,"whenever I run 'pip3 install tensorflow' it has this error: 
```
    ERROR: Could not find a version that satisfies the requirement tensorflow
    ERROR: No matching distribution found for tensorflow
```",t2_51d36gja,False,,0,False,Help with install TensorFlow on python,[],r/tensorflow,False,6,,0,,,False,t3_lpyrm4,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1614054091.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;whenever I run &amp;#39;pip3 install tensorflow&amp;#39; it has this error: 
&lt;code&gt;
    ERROR: Could not find a version that satisfies the requirement tensorflow
    ERROR: No matching distribution found for tensorflow
&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lpyrm4,True,,-SpamCauldron-,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lpyrm4/help_with_install_tensorflow_on_python/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lpyrm4/help_with_install_tensorflow_on_python/,22217,1614025291.0,0,,False,,,,,,,,,
56,,tensorflow,"Hi

I wanted to implement  a neural network for student admission dataset and output of the model and also loss doesn't change much

    n_features = X_train.shape[1]
    n_labels = y_train.shape[1]
    
    features = tf.placeholder(tf.float32, [None, n_features])
    labels = tf.placeholder(tf.float32, [None, n_labels])
    
    w = [
        tf.Variable(tf.random_normal((n_features, 16), stddev=0.01), name='Weights_layer_0'),
        tf.Variable(tf.random_normal((16, 4), stddev=0.01), name='Weights_layer_1'),
        tf.Variable(tf.random_normal((4, n_labels), stddev=0.01), name='Weights_layer_2'),
    ]
    
    n_layers = len(w)
    b = [
        tf.Variable(tf.zeros(16), name='Bias_layer_0'),
        tf.Variable(tf.zeros(4), name='Bias_layer_1'),
        tf.Variable(tf.zeros(n_labels), name='Bias_layer_2'),
    ]
    
    
    def neural_network(input, weights, biases):
        for i in range(n_layers-1):
            layer = tf.add(tf.matmul(input if i==0 else layer, weights[i]),biases[i])
            layer = tf.nn.relu(layer)
            # layer = tf.nn.dropout(layer, keep_prob=0.6)
        out_layer = tf.add(tf.matmul(layer, weights[-1]),biases[-1])
        # layer1 = tf.add(tf.matmul(input , weights[0]),biases[0])
        # layer1 = tf.nn.relu(layer1)
        # layer1 = tf.nn.dropout(layer1, keep_prob=0.5)
        #
        # layer2 = tf.add(tf.matmul(layer1 , weights[1]),biases[1])
        # layer2 = tf.nn.relu(layer2)
        # layer2 = tf.nn.dropout(layer2, keep_prob=0.5)
        #
        # out_layer = tf.add(tf.matmul(layer2 , weights[2]),biases[2])
        return out_layer
    
    loss_ = []
    res = []
    prediction = neural_network(features, w, b)
    # loss = tf.reduce_mean(-tf.reduce_sum(labels*tf.log(prediction), reduction_indices=1))
    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction, labels=labels))
    optim = tf.train.AdadeltaOptimizer(0.001).minimize(loss)
    # correct_prediction = tf.equal(tf.round(prediction), labels)
    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    with tf.device('/dml:0'):
        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            for i in range(20):
                for m,n in zip(X_train_batches, y_train_batches):
                    _, l = sess.run([optim, loss],feed_dict={features: m, labels: n})
                loss_.append(l)
                    # pprint(sess.run(w))
                    # pprint(sess.run(b))
    
                acc = sess.run([accuracy], feed_dict={features: X_train, labels: y_train})
                print(i, acc)
            test_accuracy = sess.run(accuracy,feed_dict={features: X_test, labels: y_test})
            print(test_accuracy)
            res = sess.run(neural_network(features,w,b),feed_dict={features: X})

[link to full code](https://pastebin.com/HiShJ8a5)

Do you see any thing wrong in my implementation? What is missing?",t2_69i5g4ss,False,,0,False,Help my neural network accuracy and loss does not change,[],r/tensorflow,False,6,,0,,,False,t3_lpueps,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1614043974.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I wanted to implement  a neural network for student admission dataset and output of the model and also loss doesn&amp;#39;t change much&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;n_features = X_train.shape[1]
n_labels = y_train.shape[1]

features = tf.placeholder(tf.float32, [None, n_features])
labels = tf.placeholder(tf.float32, [None, n_labels])

w = [
    tf.Variable(tf.random_normal((n_features, 16), stddev=0.01), name=&amp;#39;Weights_layer_0&amp;#39;),
    tf.Variable(tf.random_normal((16, 4), stddev=0.01), name=&amp;#39;Weights_layer_1&amp;#39;),
    tf.Variable(tf.random_normal((4, n_labels), stddev=0.01), name=&amp;#39;Weights_layer_2&amp;#39;),
]

n_layers = len(w)
b = [
    tf.Variable(tf.zeros(16), name=&amp;#39;Bias_layer_0&amp;#39;),
    tf.Variable(tf.zeros(4), name=&amp;#39;Bias_layer_1&amp;#39;),
    tf.Variable(tf.zeros(n_labels), name=&amp;#39;Bias_layer_2&amp;#39;),
]


def neural_network(input, weights, biases):
    for i in range(n_layers-1):
        layer = tf.add(tf.matmul(input if i==0 else layer, weights[i]),biases[i])
        layer = tf.nn.relu(layer)
        # layer = tf.nn.dropout(layer, keep_prob=0.6)
    out_layer = tf.add(tf.matmul(layer, weights[-1]),biases[-1])
    # layer1 = tf.add(tf.matmul(input , weights[0]),biases[0])
    # layer1 = tf.nn.relu(layer1)
    # layer1 = tf.nn.dropout(layer1, keep_prob=0.5)
    #
    # layer2 = tf.add(tf.matmul(layer1 , weights[1]),biases[1])
    # layer2 = tf.nn.relu(layer2)
    # layer2 = tf.nn.dropout(layer2, keep_prob=0.5)
    #
    # out_layer = tf.add(tf.matmul(layer2 , weights[2]),biases[2])
    return out_layer

loss_ = []
res = []
prediction = neural_network(features, w, b)
# loss = tf.reduce_mean(-tf.reduce_sum(labels*tf.log(prediction), reduction_indices=1))
loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction, labels=labels))
optim = tf.train.AdadeltaOptimizer(0.001).minimize(loss)
# correct_prediction = tf.equal(tf.round(prediction), labels)
correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
with tf.device(&amp;#39;/dml:0&amp;#39;):
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(20):
            for m,n in zip(X_train_batches, y_train_batches):
                _, l = sess.run([optim, loss],feed_dict={features: m, labels: n})
            loss_.append(l)
                # pprint(sess.run(w))
                # pprint(sess.run(b))

            acc = sess.run([accuracy], feed_dict={features: X_train, labels: y_train})
            print(i, acc)
        test_accuracy = sess.run(accuracy,feed_dict={features: X_test, labels: y_test})
        print(test_accuracy)
        res = sess.run(neural_network(features,w,b),feed_dict={features: X})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=""https://pastebin.com/HiShJ8a5""&gt;link to full code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do you see any thing wrong in my implementation? What is missing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lpueps,True,,s_arme,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/lpueps/help_my_neural_network_accuracy_and_loss_does_not/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lpueps/help_my_neural_network_accuracy_and_loss_does_not/,22217,1614015174.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;s=07c121a0180003f7373863af66192b6ff6a937da', 'width': 150, 'height': 150}, 'resolutions': [{'url': 'https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9c6a296446d05d873c629a30253398c4d29c1b', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs'}], 'enabled': False}",,,,,,
57,,tensorflow,"I'm reusing old code that was origionally written for TF-1 but I keep getting the following error:\`\`\`

    TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.

\`\`\`

Whenever I run \`model.fit\`. I believe its an issue in reusing old code but it has been implemented in the same way just using TF 2

(Model code)

\`\`\`

    _input = keras.layers.Input(             
                                shape=(self.statesize,), name='input_state')          
    _input_context = keras.layers.Input(             
                                shape=(self.num_intruders, 7), name='input_context')
    empty = keras.layers.Input(shape=(HIDDEN_SIZE,), name='empty')          
    advantage = keras.layers.Input(shape=(1,), name=""advantage"")          
    old_prediction = keras.layers.Input(shape=(self.actionsize,), name='old_predictions')         
    
    flatten_context = keras.layers.Flatten()(_input_context)           
    h1 = keras.layers.Dense(HIDDEN_SIZE, activation='relu')(flatten_context)
    combine = keras.layers.concatenate([_input, h1], axis=1)          
    h2 = keras.layers.Dense(256, activation='relu')(combine)         
    h3 = keras.layers.Dense(256, activation='relu')(h2)          
    out = keras.layers.Dense(self.actionsize+1, activation=None)(h3)          
    policy = keras.layers.Lambda(lambda x: x[:, :self.actionsize], output_shape=(self.actionsize,))(out)         
    value = keras.layers.Lambda(lambda x: x[:, self.actionsize:], output_shape=(self.valuesize,))(out)          
    policy_out = keras.layers.Activation('softmax', name='policy_out')(policy)         
    value_out = keras.layers.Activation('linear', name='value_out')(value)          
    optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)          
    model = keras.models.Model(inputs=[_input, _input_context, empty, advantage, old_prediction], outputs=[policy_out, value_out])          
    self.estimator = keras.models.Model(inputs=[_input, _input_context, empty], outputs=[policy_out, value_out])  
    
    # Compile the model          
    model.compile(optimizer=optimizer, loss={'policy_out': PPO_loss(advantage=advantage, old_prediction=old_prediction), 'value_out': 'mse'})          
    print(model.summary())         
    return model

\`\`\`",t2_j682712,False,,0,False,TypeError: Cannot convert a symbolic Keras input/output to a numpy array.,[],r/tensorflow,False,6,,0,,,False,t3_lpkwns,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1614018813.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m reusing old code that was origionally written for TF-1 but I keep getting the following error:```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you&amp;#39;re trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Whenever I run `model.fit`. I believe its an issue in reusing old code but it has been implemented in the same way just using TF 2&lt;/p&gt;

&lt;p&gt;(Model code)&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_input = keras.layers.Input(             
                            shape=(self.statesize,), name=&amp;#39;input_state&amp;#39;)          
_input_context = keras.layers.Input(             
                            shape=(self.num_intruders, 7), name=&amp;#39;input_context&amp;#39;)
empty = keras.layers.Input(shape=(HIDDEN_SIZE,), name=&amp;#39;empty&amp;#39;)          
advantage = keras.layers.Input(shape=(1,), name=&amp;quot;advantage&amp;quot;)          
old_prediction = keras.layers.Input(shape=(self.actionsize,), name=&amp;#39;old_predictions&amp;#39;)         

flatten_context = keras.layers.Flatten()(_input_context)           
h1 = keras.layers.Dense(HIDDEN_SIZE, activation=&amp;#39;relu&amp;#39;)(flatten_context)
combine = keras.layers.concatenate([_input, h1], axis=1)          
h2 = keras.layers.Dense(256, activation=&amp;#39;relu&amp;#39;)(combine)         
h3 = keras.layers.Dense(256, activation=&amp;#39;relu&amp;#39;)(h2)          
out = keras.layers.Dense(self.actionsize+1, activation=None)(h3)          
policy = keras.layers.Lambda(lambda x: x[:, :self.actionsize], output_shape=(self.actionsize,))(out)         
value = keras.layers.Lambda(lambda x: x[:, self.actionsize:], output_shape=(self.valuesize,))(out)          
policy_out = keras.layers.Activation(&amp;#39;softmax&amp;#39;, name=&amp;#39;policy_out&amp;#39;)(policy)         
value_out = keras.layers.Activation(&amp;#39;linear&amp;#39;, name=&amp;#39;value_out&amp;#39;)(value)          
optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)          
model = keras.models.Model(inputs=[_input, _input_context, empty, advantage, old_prediction], outputs=[policy_out, value_out])          
self.estimator = keras.models.Model(inputs=[_input, _input_context, empty], outputs=[policy_out, value_out])  

# Compile the model          
model.compile(optimizer=optimizer, loss={&amp;#39;policy_out&amp;#39;: PPO_loss(advantage=advantage, old_prediction=old_prediction), &amp;#39;value_out&amp;#39;: &amp;#39;mse&amp;#39;})          
print(model.summary())         
return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lpkwns,True,,The_Dov,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lpkwns/typeerror_cannot_convert_a_symbolic_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lpkwns/typeerror_cannot_convert_a_symbolic_keras/,22217,1613990013.0,0,,False,,,,,,,,,
58,,tensorflow," 

**System information**

* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
* TensorFlow installed from (source or binary):
* [https://github.com/tensorflow/models](https://github.com/tensorflow/models)
* TensorFlow version: 2
* Python version: 3.7.3
* Installed using virtualenv? pip? conda?: conda and pip

**Describe the problem**  
I have downloaded and installed tensorflow, and I'm attempting to train a custom model, but keep getting runtime errors or notfounderrors to do with tenorflow lib files.  
**Provide the exact sequence of commands / steps that you executed before running into the problem**  
\`WORKSPACE\_PATH = 'Tensorflow/workspace'  
SCRIPTS\_PATH = 'Tensorflow/scripts'  
APIMODEL\_PATH = 'Tensorflow/models'  
ANNOTATION\_PATH = WORKSPACE\_PATH+'/annotations'  
IMAGE\_PATH = WORKSPACE\_PATH+'/images'  
MODEL\_PATH = WORKSPACE\_PATH+'/models'  
PRETRAINED\_MODEL\_PATH = WORKSPACE\_PATH+'/pre-trained-models'  
CONFIG\_PATH = MODEL\_PATH+'/my\_ssd\_mobnet/pipeline.config'  
CHECKPOINT\_PATH = MODEL\_PATH+'/my\_ssd\_mobnet/'

labels = \[{'name':'title', 'id':1}, {'name':'xaxis', 'id':2}, {'name':'yaxis', 'id':3}, {'name':'bar', 'id':4}, {'name':'key', 'id':5}\]

with open(ANNOTATION\_PATH + '\\label\_map.pbtxt', 'w') as f:  
for label in labels:  
f.write('item { \\n')  
f.write('\\tname:'{}'\\n'.format(label\['name'\]))  
f.write('\\tid:{}\\n'.format(label\['id'\]))  
f.write('}\\n')

!python {SCRIPTS\_PATH + '/generate\_tfrecord.py'} -x {IMAGE\_PATH + '/train'} -l {ANNOTATION\_PATH + '/label\_map.pbtxt'} -o {ANNOTATION\_PATH + '/train.record'}  
!python {SCRIPTS\_PATH + '/generate\_tfrecord.py'} -x{IMAGE\_PATH + '/test'} -l {ANNOTATION\_PATH + '/label\_map.pbtxt'} -o {ANNOTATION\_PATH + '/test.record'}

!cd Tensorflow &amp;&amp; git clone [https://github.com/tensorflow/models](https://github.com/tensorflow/models)

CUSTOM\_MODEL\_NAME = 'my\_ssd\_mobnet'  
!mkdir {'Tensorflow\\workspace\\models\\'+CUSTOM\_MODEL\_NAME}  
!cp {PRETRAINED\_MODEL\_PATH+'/ssd\_mobilenet\_v2\_fpnlite\_320x320\_coco17\_tpu-8/pipeline.config'} {MODEL\_PATH+'/'+CUSTOM\_MODEL\_NAME}

import tensorflow as tf  
from object\_detection.utils import config\_util  
from object\_detection.protos import pipeline\_pb2  
from google.protobuf import text\_format

CONFIG\_PATH = MODEL\_PATH+'/'+CUSTOM\_MODEL\_NAME+'/pipeline.config'

config = config\_util.get\_configs\_from\_pipeline\_file(CONFIG\_PATH)  
config  
{'model': ssd {  
num\_classes: 90  
image\_resizer {  
fixed\_shape\_resizer {  
height: 320  
width: 320  
}  
}  
feature\_extractor {  
type: ""ssd\_mobilenet\_v2\_fpn\_keras""  
depth\_multiplier: 1.0  
min\_depth: 16  
conv\_hyperparams {  
regularizer {  
l2\_regularizer {  
weight: 3.9999998989515007e-05  
}  
}  
initializer {  
random\_normal\_initializer {  
mean: 0.0  
stddev: 0.009999999776482582  
}  
}  
activation: RELU\_6  
batch\_norm {  
decay: 0.996999979019165  
scale: true  
epsilon: 0.0010000000474974513  
}  
}  
use\_depthwise: true  
override\_base\_feature\_extractor\_hyperparams: true  
fpn {  
min\_level: 3  
max\_level: 7  
additional\_layer\_depth: 128  
}  
}  
box\_coder {  
faster\_rcnn\_box\_coder {  
y\_scale: 10.0  
x\_scale: 10.0  
height\_scale: 5.0  
width\_scale: 5.0  
}  
}  
matcher {  
argmax\_matcher {  
matched\_threshold: 0.5  
unmatched\_threshold: 0.5  
ignore\_thresholds: false  
negatives\_lower\_than\_unmatched: true  
force\_match\_for\_each\_row: true  
use\_matmul\_gather: true  
}  
}  
similarity\_calculator {  
iou\_similarity {  
}  
}  
box\_predictor {  
weight\_shared\_convolutional\_box\_predictor {  
conv\_hyperparams {  
regularizer {  
l2\_regularizer {  
weight: 3.9999998989515007e-05  
}  
}  
initializer {  
random\_normal\_initializer {  
mean: 0.0  
stddev: 0.009999999776482582  
}  
}  
activation: RELU\_6  
batch\_norm {  
decay: 0.996999979019165  
scale: true  
epsilon: 0.0010000000474974513  
}  
}  
depth: 128  
num\_layers\_before\_predictor: 4  
kernel\_size: 3  
class\_prediction\_bias\_init: -4.599999904632568  
share\_prediction\_tower: true  
use\_depthwise: true  
}  
}  
anchor\_generator {  
multiscale\_anchor\_generator {  
min\_level: 3  
max\_level: 7  
anchor\_scale: 4.0  
aspect\_ratios: 1.0  
aspect\_ratios: 2.0  
aspect\_ratios: 0.5  
scales\_per\_octave: 2  
}  
}  
post\_processing {  
batch\_non\_max\_suppression {  
score\_threshold: 9.99999993922529e-09  
iou\_threshold: 0.6000000238418579  
max\_detections\_per\_class: 100  
max\_total\_detections: 100  
use\_static\_shapes: false  
}  
score\_converter: SIGMOID  
}  
normalize\_loss\_by\_num\_matches: true  
loss {  
localization\_loss {  
weighted\_smooth\_l1 {  
}  
}  
classification\_loss {  
weighted\_sigmoid\_focal {  
gamma: 2.0  
alpha: 0.25  
}  
}  
classification\_weight: 1.0  
localization\_weight: 1.0  
}  
encode\_background\_as\_zeros: true  
normalize\_loc\_loss\_by\_codesize: true  
inplace\_batchnorm\_update: true  
freeze\_batchnorm: false  
}, 'train\_config': batch\_size: 128  
data\_augmentation\_options {  
random\_horizontal\_flip {  
}  
}  
data\_augmentation\_options {  
random\_crop\_image {  
min\_object\_covered: 0.0  
min\_aspect\_ratio: 0.75  
max\_aspect\_ratio: 3.0  
min\_area: 0.75  
max\_area: 1.0  
overlap\_thresh: 0.0  
}  
}  
sync\_replicas: true  
optimizer {  
momentum\_optimizer {  
learning\_rate {  
cosine\_decay\_learning\_rate {  
learning\_rate\_base: 0.07999999821186066  
total\_steps: 50000  
warmup\_learning\_rate: 0.026666000485420227  
warmup\_steps: 1000  
}  
}  
momentum\_optimizer\_value: 0.8999999761581421  
}  
use\_moving\_average: false  
}  
fine\_tune\_checkpoint: ""PATH\_TO\_BE\_CONFIGURED""  
num\_steps: 50000  
startup\_delay\_steps: 0.0  
replicas\_to\_aggregate: 8  
max\_number\_of\_boxes: 100  
unpad\_groundtruth\_tensors: false  
fine\_tune\_checkpoint\_type: ""classification""  
fine\_tune\_checkpoint\_version: V2, 'train\_input\_config': label\_map\_path: ""PATH\_TO\_BE\_CONFIGURED""  
tf\_record\_input\_reader {  
input\_path: ""PATH\_TO\_BE\_CONFIGURED""  
}, 'eval\_config': metrics\_set: ""coco\_detection\_metrics""  
use\_moving\_averages: false, 'eval\_input\_configs': \[label\_map\_path: ""PATH\_TO\_BE\_CONFIGURED""  
shuffle: false  
num\_epochs: 1  
tf\_record\_input\_reader {  
input\_path: ""PATH\_TO\_BE\_CONFIGURED""  
}  
\], 'eval\_input\_config': label\_map\_path: ""PATH\_TO\_BE\_CONFIGURED""  
shuffle: false  
num\_epochs: 1  
tf\_record\_input\_reader {  
input\_path: ""PATH\_TO\_BE\_CONFIGURED""  
}}  
pipeline\_config = pipeline\_p

pipeline\_config = pipeline\_pb2.TrainEvalPipelineConfig()  
with tf.io.gfile.GFile(CONFIG\_PATH, ""r"") as f:  
proto\_str = f.read()  
text\_format.Merge(proto\_str, pipeline\_config)  
pipeline\_config.model.ssd.num\_classes = 2  
pipeline\_config.train\_config.batch\_size = 4  
pipeline\_config.train\_config.fine\_tune\_checkpoint = PRETRAINED\_MODEL\_PATH+'/ssd\_mobilenet\_v2\_fpnlite\_320x320\_coco17\_tpu-8/checkpoint/ckpt-0'  
pipeline\_config.train\_config.fine\_tune\_checkpoint\_type = ""detection""  
pipeline\_config.train\_input\_reader.label\_map\_path= ANNOTATION\_PATH + '/label\_map.pbtxt'  
pipeline\_config.train\_input\_reader.tf\_record\_input\_reader.input\_path\[:\] = \[ANNOTATION\_PATH + '/train.record'\]  
pipeline\_config.eval\_input\_reader\[0\].label\_map\_path = ANNOTATION\_PATH + '/label\_map.pbtxt'  
pipeline\_config.eval\_input\_reader\[0\].tf\_record\_input\_reader.input\_path\[:\] = \[ANNOTATION\_PATH + '/test.record'\]

config\_text = text\_format.MessageToString(pipeline\_config)  
with tf.io.gfile.GFile(CONFIG\_PATH, ""wb"") as f:  
f.write(config\_text)

print(""""""python {}/research/object\_detection/model\_main\_tf2.py --model\_dir={}/{} --pipeline\_config\_path={}/{}/pipeline.config --num\_train\_steps=5000"""""".format(APIMODEL\_PATH, MODEL\_PATH,CUSTOM\_MODEL\_NAME,MODEL\_PATH,CUSTOM\_MODEL\_NAME))

import os  
from object\_detection.utils import label\_map\_util  
from object\_detection.utils import visualization\_utils as viz\_utils  
from object\_detection.builders import model\_builder

# Load pipeline config and build a detection model

configs = config\_util.get\_configs\_from\_pipeline\_file(CONFIG\_PATH)  
detection\_model = model\_builder.build(model\_config=configs\['model'\], is\_training=False)

# Restore checkpoint

ckpt = tf.compat.v2.train.Checkpoint(model=detection\_model)  
ckpt.restore(os.path.join(CHECKPOINT\_PATH, 'ckpt-6')).expect\_partial()

u/tf.function  
def detect\_fn(image):  
image, shapes = detection\_model.preprocess(image)  
prediction\_dict = detection\_model.predict(image, shapes)  
detections = detection\_model.postprocess(prediction\_dict, shapes)  
return detections  
\#---------------------This Is Where The error Happens ----------------------------------------\`

**Error Message**  
\`---------------------------------------------------------------------------  
RuntimeError Traceback (most recent call last)  
C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py\_checkpoint\_reader.py in NewCheckpointReader(filepattern)  
94 try:  
\---&gt; 95 return CheckpointReader(compat.as\_bytes(filepattern))  
96 # TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the

RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/my\_ssd\_mobnet/ckpt-6

During handling of the above exception, another exception occurred:

NotFoundError Traceback (most recent call last)  
C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py in restore(self, save\_path, options)  
2259 try:  
\-&gt; 2260 status = self.read(save\_path, options=options)  
2261 except errors\_impl.NotFoundError:

C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py in read(self, save\_path, options)  
2147 options = options or checkpoint\_options.CheckpointOptions()  
\-&gt; 2148 return self.\_saver.restore(save\_path=save\_path, options=options)  
2149

C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py in restore(self, save\_path, options)  
1291 return InitializationOnlyStatus(self.\_graph\_view, ops.uid())  
\-&gt; 1292 reader = py\_checkpoint\_reader.NewCheckpointReader(save\_path)  
1293 graph\_building = not context.executing\_eagerly()

C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py\_checkpoint\_reader.py in NewCheckpointReader(filepattern)  
98 except RuntimeError as e:  
\---&gt; 99 error\_translator(e)

C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py\_checkpoint\_reader.py in error\_translator(e)  
34 'matching files for') in error\_message:  
\---&gt; 35 raise errors\_impl.NotFoundError(None, None, error\_message)  
36 elif 'Sliced checkpoints are not supported' in error\_message or (

NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/my\_ssd\_mobnet/ckpt-6

During handling of the above exception, another exception occurred:

NotFoundError Traceback (most recent call last)  
in  
5 # Restore checkpoint  
6 ckpt = tf.compat.v2.train.Checkpoint(model=detection\_model)  
\----&gt; 7 ckpt.restore(os.path.join(CHECKPOINT\_PATH, 'ckpt-6')).expect\_partial()  
8  
9 u/tf.function

C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py in restore(self, save\_path, options)  
2263 None, None,  
2264 ""Could not find checkpoint or SavedModel at {}.""  
\-&gt; 2265 .format(orig\_save\_path))  
2266 # Create the save counter now so it gets initialized with other variables  
2267 # when graph building. Creating it earlier would lead to errors when using,

NotFoundError: Could not find checkpoint or SavedModel at Tensorflow/workspace/models/my\_ssd\_mobnet/ckpt-6.\`",t2_5o5amyn9,False,,0,False,Load Train Model From Checkpoint - NotFoundError,[],r/tensorflow,False,6,,0,,,False,t3_lpkurv,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1614018645.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;System information&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit&lt;/li&gt;
&lt;li&gt;TensorFlow installed from (source or binary):&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/tensorflow/models""&gt;https://github.com/tensorflow/models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TensorFlow version: 2&lt;/li&gt;
&lt;li&gt;Python version: 3.7.3&lt;/li&gt;
&lt;li&gt;Installed using virtualenv? pip? conda?: conda and pip&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Describe the problem&lt;/strong&gt;&lt;br/&gt;
I have downloaded and installed tensorflow, and I&amp;#39;m attempting to train a custom model, but keep getting runtime errors or notfounderrors to do with tenorflow lib files.&lt;br/&gt;
&lt;strong&gt;Provide the exact sequence of commands / steps that you executed before running into the problem&lt;/strong&gt;&lt;br/&gt;
`WORKSPACE_PATH = &amp;#39;Tensorflow/workspace&amp;#39;&lt;br/&gt;
SCRIPTS_PATH = &amp;#39;Tensorflow/scripts&amp;#39;&lt;br/&gt;
APIMODEL_PATH = &amp;#39;Tensorflow/models&amp;#39;&lt;br/&gt;
ANNOTATION_PATH = WORKSPACE_PATH+&amp;#39;/annotations&amp;#39;&lt;br/&gt;
IMAGE_PATH = WORKSPACE_PATH+&amp;#39;/images&amp;#39;&lt;br/&gt;
MODEL_PATH = WORKSPACE_PATH+&amp;#39;/models&amp;#39;&lt;br/&gt;
PRETRAINED_MODEL_PATH = WORKSPACE_PATH+&amp;#39;/pre-trained-models&amp;#39;&lt;br/&gt;
CONFIG_PATH = MODEL_PATH+&amp;#39;/my_ssd_mobnet/pipeline.config&amp;#39;&lt;br/&gt;
CHECKPOINT_PATH = MODEL_PATH+&amp;#39;/my_ssd_mobnet/&amp;#39;&lt;/p&gt;

&lt;p&gt;labels = [{&amp;#39;name&amp;#39;:&amp;#39;title&amp;#39;, &amp;#39;id&amp;#39;:1}, {&amp;#39;name&amp;#39;:&amp;#39;xaxis&amp;#39;, &amp;#39;id&amp;#39;:2}, {&amp;#39;name&amp;#39;:&amp;#39;yaxis&amp;#39;, &amp;#39;id&amp;#39;:3}, {&amp;#39;name&amp;#39;:&amp;#39;bar&amp;#39;, &amp;#39;id&amp;#39;:4}, {&amp;#39;name&amp;#39;:&amp;#39;key&amp;#39;, &amp;#39;id&amp;#39;:5}]&lt;/p&gt;

&lt;p&gt;with open(ANNOTATION_PATH + &amp;#39;\label_map.pbtxt&amp;#39;, &amp;#39;w&amp;#39;) as f:&lt;br/&gt;
for label in labels:&lt;br/&gt;
f.write(&amp;#39;item { \n&amp;#39;)&lt;br/&gt;
f.write(&amp;#39;\tname:&amp;#39;{}&amp;#39;\n&amp;#39;.format(label[&amp;#39;name&amp;#39;]))&lt;br/&gt;
f.write(&amp;#39;\tid:{}\n&amp;#39;.format(label[&amp;#39;id&amp;#39;]))&lt;br/&gt;
f.write(&amp;#39;}\n&amp;#39;)&lt;/p&gt;

&lt;p&gt;!python {SCRIPTS_PATH + &amp;#39;/generate_tfrecord.py&amp;#39;} -x {IMAGE_PATH + &amp;#39;/train&amp;#39;} -l {ANNOTATION_PATH + &amp;#39;/label_map.pbtxt&amp;#39;} -o {ANNOTATION_PATH + &amp;#39;/train.record&amp;#39;}&lt;br/&gt;
!python {SCRIPTS_PATH + &amp;#39;/generate_tfrecord.py&amp;#39;} -x{IMAGE_PATH + &amp;#39;/test&amp;#39;} -l {ANNOTATION_PATH + &amp;#39;/label_map.pbtxt&amp;#39;} -o {ANNOTATION_PATH + &amp;#39;/test.record&amp;#39;}&lt;/p&gt;

&lt;p&gt;!cd Tensorflow &amp;amp;&amp;amp; git clone &lt;a href=""https://github.com/tensorflow/models""&gt;https://github.com/tensorflow/models&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CUSTOM_MODEL_NAME = &amp;#39;my_ssd_mobnet&amp;#39;&lt;br/&gt;
!mkdir {&amp;#39;Tensorflow\workspace\models\&amp;#39;+CUSTOM_MODEL_NAME}&lt;br/&gt;
!cp {PRETRAINED_MODEL_PATH+&amp;#39;/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config&amp;#39;} {MODEL_PATH+&amp;#39;/&amp;#39;+CUSTOM_MODEL_NAME}&lt;/p&gt;

&lt;p&gt;import tensorflow as tf&lt;br/&gt;
from object_detection.utils import config_util&lt;br/&gt;
from object_detection.protos import pipeline_pb2&lt;br/&gt;
from google.protobuf import text_format&lt;/p&gt;

&lt;p&gt;CONFIG_PATH = MODEL_PATH+&amp;#39;/&amp;#39;+CUSTOM_MODEL_NAME+&amp;#39;/pipeline.config&amp;#39;&lt;/p&gt;

&lt;p&gt;config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)&lt;br/&gt;
config&lt;br/&gt;
{&amp;#39;model&amp;#39;: ssd {&lt;br/&gt;
num_classes: 90&lt;br/&gt;
image_resizer {&lt;br/&gt;
fixed_shape_resizer {&lt;br/&gt;
height: 320&lt;br/&gt;
width: 320&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
feature_extractor {&lt;br/&gt;
type: &amp;quot;ssd_mobilenet_v2_fpn_keras&amp;quot;&lt;br/&gt;
depth_multiplier: 1.0&lt;br/&gt;
min_depth: 16&lt;br/&gt;
conv_hyperparams {&lt;br/&gt;
regularizer {&lt;br/&gt;
l2_regularizer {&lt;br/&gt;
weight: 3.9999998989515007e-05&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
initializer {&lt;br/&gt;
random_normal_initializer {&lt;br/&gt;
mean: 0.0&lt;br/&gt;
stddev: 0.009999999776482582&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
activation: RELU_6&lt;br/&gt;
batch_norm {&lt;br/&gt;
decay: 0.996999979019165&lt;br/&gt;
scale: true&lt;br/&gt;
epsilon: 0.0010000000474974513&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
use_depthwise: true&lt;br/&gt;
override_base_feature_extractor_hyperparams: true&lt;br/&gt;
fpn {&lt;br/&gt;
min_level: 3&lt;br/&gt;
max_level: 7&lt;br/&gt;
additional_layer_depth: 128&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
box_coder {&lt;br/&gt;
faster_rcnn_box_coder {&lt;br/&gt;
y_scale: 10.0&lt;br/&gt;
x_scale: 10.0&lt;br/&gt;
height_scale: 5.0&lt;br/&gt;
width_scale: 5.0&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
matcher {&lt;br/&gt;
argmax_matcher {&lt;br/&gt;
matched_threshold: 0.5&lt;br/&gt;
unmatched_threshold: 0.5&lt;br/&gt;
ignore_thresholds: false&lt;br/&gt;
negatives_lower_than_unmatched: true&lt;br/&gt;
force_match_for_each_row: true&lt;br/&gt;
use_matmul_gather: true&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
similarity_calculator {&lt;br/&gt;
iou_similarity {&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
box_predictor {&lt;br/&gt;
weight_shared_convolutional_box_predictor {&lt;br/&gt;
conv_hyperparams {&lt;br/&gt;
regularizer {&lt;br/&gt;
l2_regularizer {&lt;br/&gt;
weight: 3.9999998989515007e-05&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
initializer {&lt;br/&gt;
random_normal_initializer {&lt;br/&gt;
mean: 0.0&lt;br/&gt;
stddev: 0.009999999776482582&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
activation: RELU_6&lt;br/&gt;
batch_norm {&lt;br/&gt;
decay: 0.996999979019165&lt;br/&gt;
scale: true&lt;br/&gt;
epsilon: 0.0010000000474974513&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
depth: 128&lt;br/&gt;
num_layers_before_predictor: 4&lt;br/&gt;
kernel_size: 3&lt;br/&gt;
class_prediction_bias_init: -4.599999904632568&lt;br/&gt;
share_prediction_tower: true&lt;br/&gt;
use_depthwise: true&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
anchor_generator {&lt;br/&gt;
multiscale_anchor_generator {&lt;br/&gt;
min_level: 3&lt;br/&gt;
max_level: 7&lt;br/&gt;
anchor_scale: 4.0&lt;br/&gt;
aspect_ratios: 1.0&lt;br/&gt;
aspect_ratios: 2.0&lt;br/&gt;
aspect_ratios: 0.5&lt;br/&gt;
scales_per_octave: 2&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
post_processing {&lt;br/&gt;
batch_non_max_suppression {&lt;br/&gt;
score_threshold: 9.99999993922529e-09&lt;br/&gt;
iou_threshold: 0.6000000238418579&lt;br/&gt;
max_detections_per_class: 100&lt;br/&gt;
max_total_detections: 100&lt;br/&gt;
use_static_shapes: false&lt;br/&gt;
}&lt;br/&gt;
score_converter: SIGMOID&lt;br/&gt;
}&lt;br/&gt;
normalize_loss_by_num_matches: true&lt;br/&gt;
loss {&lt;br/&gt;
localization_loss {&lt;br/&gt;
weighted_smooth_l1 {&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
classification_loss {&lt;br/&gt;
weighted_sigmoid_focal {&lt;br/&gt;
gamma: 2.0&lt;br/&gt;
alpha: 0.25&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
classification_weight: 1.0&lt;br/&gt;
localization_weight: 1.0&lt;br/&gt;
}&lt;br/&gt;
encode_background_as_zeros: true&lt;br/&gt;
normalize_loc_loss_by_codesize: true&lt;br/&gt;
inplace_batchnorm_update: true&lt;br/&gt;
freeze_batchnorm: false&lt;br/&gt;
}, &amp;#39;train_config&amp;#39;: batch_size: 128&lt;br/&gt;
data_augmentation_options {&lt;br/&gt;
random_horizontal_flip {&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
data_augmentation_options {&lt;br/&gt;
random_crop_image {&lt;br/&gt;
min_object_covered: 0.0&lt;br/&gt;
min_aspect_ratio: 0.75&lt;br/&gt;
max_aspect_ratio: 3.0&lt;br/&gt;
min_area: 0.75&lt;br/&gt;
max_area: 1.0&lt;br/&gt;
overlap_thresh: 0.0&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
sync_replicas: true&lt;br/&gt;
optimizer {&lt;br/&gt;
momentum_optimizer {&lt;br/&gt;
learning_rate {&lt;br/&gt;
cosine_decay_learning_rate {&lt;br/&gt;
learning_rate_base: 0.07999999821186066&lt;br/&gt;
total_steps: 50000&lt;br/&gt;
warmup_learning_rate: 0.026666000485420227&lt;br/&gt;
warmup_steps: 1000&lt;br/&gt;
}&lt;br/&gt;
}&lt;br/&gt;
momentum_optimizer_value: 0.8999999761581421&lt;br/&gt;
}&lt;br/&gt;
use_moving_average: false&lt;br/&gt;
}&lt;br/&gt;
fine_tune_checkpoint: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
num_steps: 50000&lt;br/&gt;
startup_delay_steps: 0.0&lt;br/&gt;
replicas_to_aggregate: 8&lt;br/&gt;
max_number_of_boxes: 100&lt;br/&gt;
unpad_groundtruth_tensors: false&lt;br/&gt;
fine_tune_checkpoint_type: &amp;quot;classification&amp;quot;&lt;br/&gt;
fine_tune_checkpoint_version: V2, &amp;#39;train_input_config&amp;#39;: label_map_path: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
tf_record_input_reader {&lt;br/&gt;
input_path: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
}, &amp;#39;eval_config&amp;#39;: metrics_set: &amp;quot;coco_detection_metrics&amp;quot;&lt;br/&gt;
use_moving_averages: false, &amp;#39;eval_input_configs&amp;#39;: [label_map_path: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
shuffle: false&lt;br/&gt;
num_epochs: 1&lt;br/&gt;
tf_record_input_reader {&lt;br/&gt;
input_path: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
}&lt;br/&gt;
], &amp;#39;eval_input_config&amp;#39;: label_map_path: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
shuffle: false&lt;br/&gt;
num_epochs: 1&lt;br/&gt;
tf_record_input_reader {&lt;br/&gt;
input_path: &amp;quot;PATH_TO_BE_CONFIGURED&amp;quot;&lt;br/&gt;
}}&lt;br/&gt;
pipeline_config = pipeline_p&lt;/p&gt;

&lt;p&gt;pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()&lt;br/&gt;
with tf.io.gfile.GFile(CONFIG_PATH, &amp;quot;r&amp;quot;) as f:&lt;br/&gt;
proto_str = f.read()&lt;br/&gt;
text_format.Merge(proto_str, pipeline_config)&lt;br/&gt;
pipeline_config.model.ssd.num_classes = 2&lt;br/&gt;
pipeline_config.train_config.batch_size = 4&lt;br/&gt;
pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+&amp;#39;/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0&amp;#39;&lt;br/&gt;
pipeline_config.train_config.fine_tune_checkpoint_type = &amp;quot;detection&amp;quot;&lt;br/&gt;
pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + &amp;#39;/label_map.pbtxt&amp;#39;&lt;br/&gt;
pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + &amp;#39;/train.record&amp;#39;]&lt;br/&gt;
pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + &amp;#39;/label_map.pbtxt&amp;#39;&lt;br/&gt;
pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + &amp;#39;/test.record&amp;#39;]&lt;/p&gt;

&lt;p&gt;config_text = text_format.MessageToString(pipeline_config)&lt;br/&gt;
with tf.io.gfile.GFile(CONFIG_PATH, &amp;quot;wb&amp;quot;) as f:&lt;br/&gt;
f.write(config_text)&lt;/p&gt;

&lt;p&gt;print(&amp;quot;&amp;quot;&amp;quot;python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=5000&amp;quot;&amp;quot;&amp;quot;.format(APIMODEL_PATH, MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))&lt;/p&gt;

&lt;p&gt;import os&lt;br/&gt;
from object_detection.utils import label_map_util&lt;br/&gt;
from object_detection.utils import visualization_utils as viz_utils&lt;br/&gt;
from object_detection.builders import model_builder&lt;/p&gt;

&lt;h1&gt;Load pipeline config and build a detection model&lt;/h1&gt;

&lt;p&gt;configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)&lt;br/&gt;
detection_model = model_builder.build(model_config=configs[&amp;#39;model&amp;#39;], is_training=False)&lt;/p&gt;

&lt;h1&gt;Restore checkpoint&lt;/h1&gt;

&lt;p&gt;ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)&lt;br/&gt;
ckpt.restore(os.path.join(CHECKPOINT_PATH, &amp;#39;ckpt-6&amp;#39;)).expect_partial()&lt;/p&gt;

&lt;p&gt;&lt;a href=""/u/tf""&gt;u/tf&lt;/a&gt;.function&lt;br/&gt;
def detect_fn(image):&lt;br/&gt;
image, shapes = detection_model.preprocess(image)&lt;br/&gt;
prediction_dict = detection_model.predict(image, shapes)&lt;br/&gt;
detections = detection_model.postprocess(prediction_dict, shapes)&lt;br/&gt;
return detections&lt;br/&gt;
#---------------------This Is Where The error Happens ----------------------------------------`&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Error Message&lt;/strong&gt;&lt;br/&gt;
`---------------------------------------------------------------------------&lt;br/&gt;
RuntimeError Traceback (most recent call last)&lt;br/&gt;
C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\py_checkpoint_reader.py in NewCheckpointReader(filepattern)&lt;br/&gt;
94 try:&lt;br/&gt;
---&amp;gt; 95 return CheckpointReader(compat.as_bytes(filepattern))&lt;br/&gt;
96 # TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the&lt;/p&gt;

&lt;p&gt;RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6&lt;/p&gt;

&lt;p&gt;During handling of the above exception, another exception occurred:&lt;/p&gt;

&lt;p&gt;NotFoundError Traceback (most recent call last)&lt;br/&gt;
C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\tracking\util.py in restore(self, save_path, options)&lt;br/&gt;
2259 try:&lt;br/&gt;
-&amp;gt; 2260 status = self.read(save_path, options=options)&lt;br/&gt;
2261 except errors_impl.NotFoundError:&lt;/p&gt;

&lt;p&gt;C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\tracking\util.py in read(self, save_path, options)&lt;br/&gt;
2147 options = options or checkpoint_options.CheckpointOptions()&lt;br/&gt;
-&amp;gt; 2148 return self._saver.restore(save_path=save_path, options=options)&lt;br/&gt;
2149&lt;/p&gt;

&lt;p&gt;C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\tracking\util.py in restore(self, save_path, options)&lt;br/&gt;
1291 return InitializationOnlyStatus(self._graph_view, ops.uid())&lt;br/&gt;
-&amp;gt; 1292 reader = py_checkpoint_reader.NewCheckpointReader(save_path)&lt;br/&gt;
1293 graph_building = not context.executing_eagerly()&lt;/p&gt;

&lt;p&gt;C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\py_checkpoint_reader.py in NewCheckpointReader(filepattern)&lt;br/&gt;
98 except RuntimeError as e:&lt;br/&gt;
---&amp;gt; 99 error_translator(e)&lt;/p&gt;

&lt;p&gt;C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\py_checkpoint_reader.py in error_translator(e)&lt;br/&gt;
34 &amp;#39;matching files for&amp;#39;) in error_message:&lt;br/&gt;
---&amp;gt; 35 raise errors_impl.NotFoundError(None, None, error_message)&lt;br/&gt;
36 elif &amp;#39;Sliced checkpoints are not supported&amp;#39; in error_message or (&lt;/p&gt;

&lt;p&gt;NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6&lt;/p&gt;

&lt;p&gt;During handling of the above exception, another exception occurred:&lt;/p&gt;

&lt;p&gt;NotFoundError Traceback (most recent call last)&lt;br/&gt;
in&lt;br/&gt;
5 # Restore checkpoint&lt;br/&gt;
6 ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)&lt;br/&gt;
----&amp;gt; 7 ckpt.restore(os.path.join(CHECKPOINT_PATH, &amp;#39;ckpt-6&amp;#39;)).expect_partial()&lt;br/&gt;
8&lt;br/&gt;
9 &lt;a href=""/u/tf""&gt;u/tf&lt;/a&gt;.function&lt;/p&gt;

&lt;p&gt;C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\tracking\util.py in restore(self, save_path, options)&lt;br/&gt;
2263 None, None,&lt;br/&gt;
2264 &amp;quot;Could not find checkpoint or SavedModel at {}.&amp;quot;&lt;br/&gt;
-&amp;gt; 2265 .format(orig_save_path))&lt;br/&gt;
2266 # Create the save counter now so it gets initialized with other variables&lt;br/&gt;
2267 # when graph building. Creating it earlier would lead to errors when using,&lt;/p&gt;

&lt;p&gt;NotFoundError: Could not find checkpoint or SavedModel at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6.`&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lpkurv,True,,Fawcett_C,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/lpkurv/load_train_model_from_checkpoint_notfounderror/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lpkurv/load_train_model_from_checkpoint_notfounderror/,22217,1613989845.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
59,,tensorflow,"I am glad to present the TensorFlow implementation of ""Gradient Centralization"" a new optimization technique to sizeably boost your performance 🚀, available as a ready-to-use Python package!

&amp;#x200B;

Project Repo: [https://github.com/Rishit-dagli/Gradient-Centralization-TensorFlow](https://github.com/Rishit-dagli/Gradient-Centralization-TensorFlow)

&amp;#x200B;

Please consider giving it a ⭐ if you like it😎. Here is an example showing the impact of the package!

https://preview.redd.it/69woozdxjui61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=0f3acbaf28a0dbc05455e1633eee9a82a95dae17",t2_7t6vk108,False,,0,False,A package to sizeably boost your performance,[],r/tensorflow,False,6,,0,70.0,,False,t3_loyy58,False,dark,1.0,,public,16,0,{},140.0,,False,[],,False,False,,{},Project,False,16,,False,https://a.thumbs.redditmedia.com/V4dWJzLKm-NslihC7_4PdCQ2iDItaZnsDXkSgT-lgT8.jpg,False,,[],{},,True,,1613949038.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am glad to present the TensorFlow implementation of &amp;quot;Gradient Centralization&amp;quot; a new optimization technique to sizeably boost your performance 🚀, available as a ready-to-use Python package!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Project Repo: &lt;a href=""https://github.com/Rishit-dagli/Gradient-Centralization-TensorFlow""&gt;https://github.com/Rishit-dagli/Gradient-Centralization-TensorFlow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Please consider giving it a ⭐ if you like it😎. Here is an example showing the impact of the package!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/69woozdxjui61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f3acbaf28a0dbc05455e1633eee9a82a95dae17""&gt;https://preview.redd.it/69woozdxjui61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f3acbaf28a0dbc05455e1633eee9a82a95dae17&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,loyy58,True,,Rishit-dagli,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/loyy58/a_package_to_sizeably_boost_your_performance/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/loyy58/a_package_to_sizeably_boost_your_performance/,22217,1613920238.0,0,,False,,,,,"{'69woozdxjui61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 54, 'x': 108, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1be266f2df063daa221a29172a0d6d381b15c8a1'}, {'y': 108, 'x': 216, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=93a169daf89016be447c2c9099bf2c1d5d69d66b'}, {'y': 160, 'x': 320, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ade816c0250c3dc6598824627287ebcdab6d2cd'}, {'y': 320, 'x': 640, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c78236f661111d39c52cb52a26bea5be9ae1f9a6'}, {'y': 480, 'x': 960, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c26374fd603c12fb526c1d43e7417c5ff77d891'}, {'y': 540, 'x': 1080, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b5e39dfd79e08359bdd039727701c33b570a9ab'}], 's': {'y': 640, 'x': 1280, 'u': 'https://preview.redd.it/69woozdxjui61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=0f3acbaf28a0dbc05455e1633eee9a82a95dae17'}, 'id': '69woozdxjui61'}}",,,,
60,,tensorflow,"I have a dataset that contains a lot of audio files that I want Tensorflow to differentiate from. (For example, this audio is a women counting numbers, this audio is just plain static)

I have no idea where to start and googling just gives me some specific datasets that are used to differentiate songs. 

What is a good place to start for audio processing?",t2_5bnw38vl,False,,0,False,Tensorflow Tutorials for Audio Processing? Preferably Seperating Different Types of Audio,[],r/tensorflow,False,6,,0,,,False,t3_lotve4,False,dark,0.91,,public,8,0,{},,,False,[],,False,False,,{},,False,8,,False,self,False,,[],{},,True,,1613929972.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset that contains a lot of audio files that I want Tensorflow to differentiate from. (For example, this audio is a women counting numbers, this audio is just plain static)&lt;/p&gt;

&lt;p&gt;I have no idea where to start and googling just gives me some specific datasets that are used to differentiate songs. &lt;/p&gt;

&lt;p&gt;What is a good place to start for audio processing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lotve4,True,,TuckleBuck88,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lotve4/tensorflow_tutorials_for_audio_processing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lotve4/tensorflow_tutorials_for_audio_processing/,22217,1613901172.0,0,,False,,,,,,,,,
61,,tensorflow,"I'm working on an experiment where users can interact with a 3D object using their gestures or hands. Posenet/Handpose is a great library, but the performance is not up to par just yet, without any 3d object the frame rate hovers around 10-12FPS which is not enough if you want to build an interactive installation.

Is there a way to optimize this, especially on macOS?  

I've tried the following;

* Using web worker (didn't help much)
* Using WebSocket and run TensorFlow on the server (Didn't help much, because I can't run the GPU backend)

What I haven't tried.

* Run a TPU server, a bit excessive and perhaps costly? Or is there an alternative for this?
* Run it on an Nvidia platform (Might need to rent)",t2_13dwm0,False,,0,False,[Help] How to optimize posenet or handpose javascript?,[],r/tensorflow,False,6,,0,,,False,t3_loy144,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613946128.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on an experiment where users can interact with a 3D object using their gestures or hands. Posenet/Handpose is a great library, but the performance is not up to par just yet, without any 3d object the frame rate hovers around 10-12FPS which is not enough if you want to build an interactive installation.&lt;/p&gt;

&lt;p&gt;Is there a way to optimize this, especially on macOS?  &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve tried the following;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Using web worker (didn&amp;#39;t help much)&lt;/li&gt;
&lt;li&gt;Using WebSocket and run TensorFlow on the server (Didn&amp;#39;t help much, because I can&amp;#39;t run the GPU backend)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What I haven&amp;#39;t tried.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Run a TPU server, a bit excessive and perhaps costly? Or is there an alternative for this?&lt;/li&gt;
&lt;li&gt;Run it on an Nvidia platform (Might need to rent)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,loy144,True,,buangakun3,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/loy144/help_how_to_optimize_posenet_or_handpose/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/loy144/help_how_to_optimize_posenet_or_handpose/,22217,1613917328.0,0,,False,,,,,,,,,
62,,tensorflow,"Good day all

I am have some issues with false positives with my custom fine tuned object detection model. Let's say for example I am detecting cats. It does this extremely well, but now and then will come across an image with no cats in it, and will instead classify a bush or a dog as a cat.

I would love to pass it these examples with no cats during training, but all the tutorials I have come across only allow for positive examples.

Does anyone know how to do this?

Thanks in advance.",t2_3tqdenkk,False,,0,False,Negative Examples in Tensorflow Object Detection API,[],r/tensorflow,False,6,,0,,,False,t3_lovb7t,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613935954.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Good day all&lt;/p&gt;

&lt;p&gt;I am have some issues with false positives with my custom fine tuned object detection model. Let&amp;#39;s say for example I am detecting cats. It does this extremely well, but now and then will come across an image with no cats in it, and will instead classify a bush or a dog as a cat.&lt;/p&gt;

&lt;p&gt;I would love to pass it these examples with no cats during training, but all the tutorials I have come across only allow for positive examples.&lt;/p&gt;

&lt;p&gt;Does anyone know how to do this?&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lovb7t,True,,SilverStalker1,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lovb7t/negative_examples_in_tensorflow_object_detection/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lovb7t/negative_examples_in_tensorflow_object_detection/,22217,1613907154.0,0,,False,,,,,,,,,
63,,tensorflow,"I am using Keras for boundary/contour detection using a Unet. When I use binary cross-entropy as the loss, the losses decrease over time as expected the predicted boundaries look reasonable

However, I have tried custom losses for Dice, Focal, IOU, with varying LRs, and none of them are working well. I either get NaNs or non-decreasing/barely-decreasing values for the losses. This is regardless of what I use for the LR, whether it be .01 to 1e-6, or whether I vary the `ALPHA` and `GAMMA` and other parameters.  This doesn't make sense since for my images, most of the pixels are the background, and the pixels corresponding to boundaries are the minority. For imbalanced datasets, IOU, Dice, and Focal should work better than binary Cross-Entropy

The code I used for the losses are from https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch#Jaccard/Intersection-over-Union-(IoU)-Loss

	def DiceLoss(targets, inputs, smooth=1e-6):
	    
	    #flatten label and prediction tensors
	    inputs = K.flatten(inputs)
	    targets = K.flatten(targets)
	    
	    intersection = K.sum(K.dot(targets, inputs))
	    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)
	    return 1 - dice

	ALPHA = 0.8
	GAMMA = 2

	def FocalLoss(targets, inputs, alpha=ALPHA, gamma=GAMMA):    
	    
	    inputs = K.flatten(inputs)
	    targets = K.flatten(targets)
	    
	    BCE = K.binary_crossentropy(targets, inputs)
	    BCE_EXP = K.exp(-BCE)
	    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)
	    
	    return focal_loss

	def IoULoss(targets, inputs, smooth=1e-6):
    
	    #flatten label and prediction tensors
	    inputs = K.flatten(inputs)
	    targets = K.flatten(targets)
	    
	    intersection = K.sum(K.dot(targets, inputs))
	    total = K.sum(targets) + K.sum(inputs)
	    union = total - intersection
	    
	    IoU = (intersection + smooth) / (union + smooth)
	    return 1 - IoU

Even if I try different code for the losses, such as the code below

	smooth = 1.
	def dice_coef(y_true, y_pred):
	    y_true_f = K.flatten(y_true)
	    y_pred_f = K.flatten(y_pred)
	    intersection = K.sum(y_true_f * y_pred_f)
	    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


	def dice_coef_loss(y_true, y_pred):
	    return -dice_coef(y_true, y_pred)

the loss values still don't improve. That is, it will show something like

    loss: nan - dice_coef_loss: .9607 - val_loss: nan - val_dice_coef_loss: .9631

and the values won't change much for each epoch


can anyone help?",t2_tpult,False,,0,False,"Why loss values don't make sense for Dice, Focal, IOU for boundary detection Unet in Keras?",[],r/tensorflow,False,6,,0,,,False,t3_lor73t,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,1613894069.0,,[],{},,True,,1613918975.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using Keras for boundary/contour detection using a Unet. When I use binary cross-entropy as the loss, the losses decrease over time as expected the predicted boundaries look reasonable&lt;/p&gt;

&lt;p&gt;However, I have tried custom losses for Dice, Focal, IOU, with varying LRs, and none of them are working well. I either get NaNs or non-decreasing/barely-decreasing values for the losses. This is regardless of what I use for the LR, whether it be .01 to 1e-6, or whether I vary the &lt;code&gt;ALPHA&lt;/code&gt; and &lt;code&gt;GAMMA&lt;/code&gt; and other parameters.  This doesn&amp;#39;t make sense since for my images, most of the pixels are the background, and the pixels corresponding to boundaries are the minority. For imbalanced datasets, IOU, Dice, and Focal should work better than binary Cross-Entropy&lt;/p&gt;

&lt;p&gt;The code I used for the losses are from &lt;a href=""https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch#Jaccard/Intersection-over-Union-(IoU)-Loss""&gt;https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch#Jaccard/Intersection-over-Union-(IoU)-Loss&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def DiceLoss(targets, inputs, smooth=1e-6):

    #flatten label and prediction tensors
    inputs = K.flatten(inputs)
    targets = K.flatten(targets)

    intersection = K.sum(K.dot(targets, inputs))
    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)
    return 1 - dice

ALPHA = 0.8
GAMMA = 2

def FocalLoss(targets, inputs, alpha=ALPHA, gamma=GAMMA):    

    inputs = K.flatten(inputs)
    targets = K.flatten(targets)

    BCE = K.binary_crossentropy(targets, inputs)
    BCE_EXP = K.exp(-BCE)
    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)

    return focal_loss

def IoULoss(targets, inputs, smooth=1e-6):

    #flatten label and prediction tensors
    inputs = K.flatten(inputs)
    targets = K.flatten(targets)

    intersection = K.sum(K.dot(targets, inputs))
    total = K.sum(targets) + K.sum(inputs)
    union = total - intersection

    IoU = (intersection + smooth) / (union + smooth)
    return 1 - IoU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even if I try different code for the losses, such as the code below&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;smooth = 1.
def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the loss values still don&amp;#39;t improve. That is, it will show something like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;loss: nan - dice_coef_loss: .9607 - val_loss: nan - val_dice_coef_loss: .9631
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and the values won&amp;#39;t change much for each epoch&lt;/p&gt;

&lt;p&gt;can anyone help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lor73t,True,,74throwaway,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lor73t/why_loss_values_dont_make_sense_for_dice_focal/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lor73t/why_loss_values_dont_make_sense_for_dice_focal/,22217,1613890175.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/3pwSy4C0OWiBJzXfUfnFygBU9SZNHmXZo-5T6LVgmUg.jpg?auto=webp&amp;s=80185fc68be6081a4d830cc24777396528527a29', 'width': 100, 'height': 100}, 'resolutions': [], 'variants': {}, 'id': 'XWOEd64309mcrHY_OqldxFXbkpSYVLdfYNbpBvwhEtY'}], 'enabled': False}",,,,,,
64,,tensorflow,"~~Hello,~~

~~I am currently doing a lab on Transfer Learning and we use TensorFlow in class. I am using the cats and dogs images to experiment with Transfer Learning concepts.~~

~~Before the transfer learning stage, I need to load images of the cats and dogs from the file I have unzipped. I have written the following code to load the images from this unzipped file in Google Colab:~~

~~from tensorflow.keras.preprocessing import imageimport numpy as npfname = fname = '/Users/xx/documents/yy6/dogs-vs-cats/train/dog.2964.jpg'img = image.load\_img(fname, target\_size=(150, 150))x = image.img\_to\_array(img)x = x.reshape((1,) + x.shape)x /= 256.plt.imshow(x\[0\])~~[~~plt.show~~](https://plt.show)~~()~~

~~However, when I run this code, I get the following error message:~~

~~No such file or directory: '/Users/xx/documents/yy/dogs-vs-cats/train'~~

~~The dogs-vs-cats file is in my documents folder so I'm unsure why this error shows up~~.

**Figured it out. Thanks!**",t2_8klj1zmc,False,,0,False,Stuck on a file path error for loading images,[],r/tensorflow,False,6,,0,,,False,t3_loohe1,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,1613882360.0,,[],{},,True,,1613908869.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;del&gt;Hello,&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;I am currently doing a lab on Transfer Learning and we use TensorFlow in class. I am using the cats and dogs images to experiment with Transfer Learning concepts.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Before the transfer learning stage, I need to load images of the cats and dogs from the file I have unzipped. I have written the following code to load the images from this unzipped file in Google Colab:&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;from tensorflow.keras.preprocessing import imageimport numpy as npfname = fname = &amp;#39;/Users/xx/documents/yy6/dogs-vs-cats/train/dog.2964.jpg&amp;#39;img = image.load_img(fname, target_size=(150, 150))x = image.img_to_array(img)x = x.reshape((1,) + x.shape)x /= 256.plt.imshow(x[0])&lt;/del&gt;&lt;a href=""https://plt.show""&gt;&lt;del&gt;plt.show&lt;/del&gt;&lt;/a&gt;&lt;del&gt;()&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;However, when I run this code, I get the following error message:&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;No such file or directory: &amp;#39;/Users/xx/documents/yy/dogs-vs-cats/train&amp;#39;&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;The dogs-vs-cats file is in my documents folder so I&amp;#39;m unsure why this error shows up&lt;/del&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figured it out. Thanks!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,loohe1,True,,Certain-Fortune-9079,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/loohe1/stuck_on_a_file_path_error_for_loading_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/loohe1/stuck_on_a_file_path_error_for_loading_images/,22217,1613880069.0,2,,False,,,,,,,,,
65,,tensorflow,,t2_2vlttls,False,,0,False,Generating cooking recipes using TensorFlow and LSTM Recurrent Neural Network: A step-by-step guide,[],r/tensorflow,False,6,,0,93.0,,False,t3_lo3cne,False,dark,0.96,,public,24,0,{},140.0,,False,[],,False,False,,{},Project,False,24,,False,https://b.thumbs.redditmedia.com/om8BTn6VG1-st2X6L_uCfoQIsSbTUx87wlvk81XBc0A.jpg,False,,[],{},,False,,1613840913.0,text,6,,,text,trekhleb.dev,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lo3cne,True,,trekhleb,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lo3cne/generating_cooking_recipes_using_tensorflow_and/,all_ads,False,https://trekhleb.dev/blog/2020/recipes-generation/,22217,1613812113.0,0,,False,link,https://trekhleb.dev/blog/2020/recipes-generation/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MlkMFOL-rjj8OhRySNLipKqp_RXQ3wGUzMNnCAfuOjo.jpg?auto=webp&amp;s=0429b6926e076e76ea8d2095f0df9e9f373d0058', 'width': 940, 'height': 628}, 'resolutions': [{'url': 'https://external-preview.redd.it/MlkMFOL-rjj8OhRySNLipKqp_RXQ3wGUzMNnCAfuOjo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b343e0340c3c9b231fdfd4cbaa07d4b92766637c', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/MlkMFOL-rjj8OhRySNLipKqp_RXQ3wGUzMNnCAfuOjo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3fea118013911138d61ce0d2c9e68a92652ffbb', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/MlkMFOL-rjj8OhRySNLipKqp_RXQ3wGUzMNnCAfuOjo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=01764f5290231a0ba2732625a290da9f92086acb', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/MlkMFOL-rjj8OhRySNLipKqp_RXQ3wGUzMNnCAfuOjo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1ecf89e6dba3ab2bcfb9bc45f2a5dc28260e591', 'width': 640, 'height': 427}], 'variants': {}, 'id': 'DvsblfympnujR_-zqC1DkZqhTIxiWRbBysfX_03TmxQ'}], 'enabled': False}",,,,,,
66,,tensorflow,"Hi guys, tensorflow / python noob here .

Planning to develop a tensorflow + elastic search Api for image analysis .

After deploying a test project my conclusions are :

Tensorflow imports in python take as long as 20+sec to finish.

Image analysis with elastic search queries only takes 0.005 sec .

So my question is, is it possible to run a script that works as an API and import tensorflow only once following a while loop that gets new images fed to , avoiding this way to run the imports every time ?

I know for an array of images this can be done but not sure about sending new images in real time .

Thanks",t2_k4t6mbz,False,,0,False,Tensorflow Python import - Can it be imported only once before running a while loop for multiple images ?,[],r/tensorflow,False,6,,0,,,False,t3_lob74w,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1613868879.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, tensorflow / python noob here .&lt;/p&gt;

&lt;p&gt;Planning to develop a tensorflow + elastic search Api for image analysis .&lt;/p&gt;

&lt;p&gt;After deploying a test project my conclusions are :&lt;/p&gt;

&lt;p&gt;Tensorflow imports in python take as long as 20+sec to finish.&lt;/p&gt;

&lt;p&gt;Image analysis with elastic search queries only takes 0.005 sec .&lt;/p&gt;

&lt;p&gt;So my question is, is it possible to run a script that works as an API and import tensorflow only once following a while loop that gets new images fed to , avoiding this way to run the imports every time ?&lt;/p&gt;

&lt;p&gt;I know for an array of images this can be done but not sure about sending new images in real time .&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lob74w,True,,Triptonpt,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/lob74w/tensorflow_python_import_can_it_be_imported_only/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lob74w/tensorflow_python_import_can_it_be_imported_only/,22217,1613840079.0,0,,False,,,,,,,,,
67,,tensorflow,,t2_ggszd,False,,0,False,I taught a TensorFlow model to tell if one is not wearing a mask. It even gets angry when the mask is covering the chin and not the nose 😅 Runs as a WebAssembly application entirely inside the browser. No server interaction / storage whatsoever.,[],r/tensorflow,False,6,,0,87.0,,False,t3_lnnhaq,False,dark,0.82,,public,28,0,{},140.0,,False,[],,False,False,,{},,False,28,,False,https://b.thumbs.redditmedia.com/S2cZMICR_aY4Ajrbkg7CqjPJ0hhkKr6PQ1M3kKfxvFc.jpg,False,,[],{},,False,,1613789753.0,text,6,,,text,heroeswearmasks.fun,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lnnhaq,True,,preslavrachev,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/lnnhaq/i_taught_a_tensorflow_model_to_tell_if_one_is_not/,all_ads,False,https://heroeswearmasks.fun/,22217,1613760953.0,0,,False,link,https://heroeswearmasks.fun/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?auto=webp&amp;s=7093d1ea4ecc51af87386d509adebdfd07dcc9c1', 'width': 1280, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0d474f5faec8f47813a3cabbace8b194c5b7ff9', 'width': 108, 'height': 67}, {'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f4cc54c6773992652e5697f52e50ff003c98032', 'width': 216, 'height': 135}, {'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26e8de7dcfa7dbd2b5993429b9d6403db28680a5', 'width': 320, 'height': 200}, {'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f202fa531ce88216e38a445b568f5c48a6b9e774', 'width': 640, 'height': 400}, {'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9096d4fca2a9ca8cdb0621da9e53cd2ad6506a98', 'width': 960, 'height': 600}, {'url': 'https://external-preview.redd.it/cYRSTJzjkHnihJxsC74DFddpW9Vf994QEYmL59ZVqVg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7be6ea0d95df0d3a17400fdfb3223de6cacbfc08', 'width': 1080, 'height': 675}], 'variants': {}, 'id': 'JFo8tCWcNS8PxdeQhPnvccKU8YMbAXxgXL9P2_YtHOE'}], 'enabled': False}",,,,,,
68,,tensorflow,"In [The Sequential model  |  TensorFlow Core](https://www.tensorflow.org/guide/keras/sequential_model#specifying_the_input_shape_in_advance) section [Specifying the input shape in advance](https://www.tensorflow.org/guide/keras/sequential_model#specifying_the_input_shape_in_advance) it says:

&gt; Generally, all layers in Keras need to know the shape of their inputs in order to be able to create their weights. So when you create a layer like this, initially, it has no weights:

```python
layer = layers.Dense(3)
print(layer.weights)  # Empty

# Output
[]
```

But if I specify the `input_shape`, why the output is still empty?

```python
layer = layers.Dense(2, input_shape=(4,))

print(layer.weights)  # Still empty
```",t2_34u8pe8t,False,,0,False,layer doesn't create weights when given input shape,[],r/tensorflow,False,6,,0,,,False,t3_lo1n24,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1613833429.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In &lt;a href=""https://www.tensorflow.org/guide/keras/sequential_model#specifying_the_input_shape_in_advance""&gt;The Sequential model  |  TensorFlow Core&lt;/a&gt; section &lt;a href=""https://www.tensorflow.org/guide/keras/sequential_model#specifying_the_input_shape_in_advance""&gt;Specifying the input shape in advance&lt;/a&gt; it says:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Generally, all layers in Keras need to know the shape of their inputs in order to be able to create their weights. So when you create a layer like this, initially, it has no weights:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;```python
layer = layers.Dense(3)
print(layer.weights)  # Empty&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;p&gt;[]
```&lt;/p&gt;

&lt;p&gt;But if I specify the &lt;code&gt;input_shape&lt;/code&gt;, why the output is still empty?&lt;/p&gt;

&lt;p&gt;```python
layer = layers.Dense(2, input_shape=(4,))&lt;/p&gt;

&lt;p&gt;print(layer.weights)  # Still empty
```&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lo1n24,True,,Ynjxsjmh,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/lo1n24/layer_doesnt_create_weights_when_given_input_shape/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lo1n24/layer_doesnt_create_weights_when_given_input_shape/,22217,1613804629.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
69,,tensorflow,"Both legacy companies and many tech companies doing commercial ML have pain points regarding:

- Moving to the cloud,
- Creating and managing ML pipelines,
- Scaling,
- Dealing with sensitive data at scale,
- And about a million other problems.

At the same time, if we want to be serious and actually have models touch real-life business problems and real people, we have to deal with the essentials like:

- acquiring &amp; cleaning large amounts of data;
- setting up tracking and versioning for experiments and model training runs;
- setting up the deployment and monitoring pipelines for the models that do get to production. 
- and we need to find a way to scale our ML operations to the needs of the business and/or users of our ML models.

This article gives you broad overview on the topic:

[What is MLOps](https://neptune.ai/blog/mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective&amp;utm_content=tensorflow)",t2_5hfacnnv,False,,0,False,"[Overview] MLOps: What It Is, Why it Matters, and How To Implement it",[],r/tensorflow,False,6,,0,,,False,t3_lnb0w0,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},Discussion,False,4,,False,self,False,,[],{},,True,,1613752617.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Both legacy companies and many tech companies doing commercial ML have pain points regarding:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Moving to the cloud,&lt;/li&gt;
&lt;li&gt;Creating and managing ML pipelines,&lt;/li&gt;
&lt;li&gt;Scaling,&lt;/li&gt;
&lt;li&gt;Dealing with sensitive data at scale,&lt;/li&gt;
&lt;li&gt;And about a million other problems.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the same time, if we want to be serious and actually have models touch real-life business problems and real people, we have to deal with the essentials like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;acquiring &amp;amp; cleaning large amounts of data;&lt;/li&gt;
&lt;li&gt;setting up tracking and versioning for experiments and model training runs;&lt;/li&gt;
&lt;li&gt;setting up the deployment and monitoring pipelines for the models that do get to production. &lt;/li&gt;
&lt;li&gt;and we need to find a way to scale our ML operations to the needs of the business and/or users of our ML models.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article gives you broad overview on the topic:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective&amp;amp;utm_content=tensorflow""&gt;What is MLOps&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lnb0w0,True,,kk_ai,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lnb0w0/overview_mlops_what_it_is_why_it_matters_and_how/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lnb0w0/overview_mlops_what_it_is_why_it_matters_and_how/,22217,1613723817.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?auto=webp&amp;s=874615a9296bc300eb9acaf00c00fb97b729fa3f', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9b2fd767ec6b7fc35f8d1ce19f887487ce65b27', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7deb11953582b676d7aaea352055378062f6df09', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=50c25964e0b5873fe8d044ec7d568af5b9e69daf', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a80d48c989893db1019bd23fbe34cf6889cf6a2', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=26e901401e153f64203dc3232e4bf93f90212dc0', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/avB9zeexGy9-Ag-cOYKHGl_UtRdOWxXQkIutcIIdtvQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=46230a655dedeeedf2435c3a899c08439a33d536', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'TJKZMEW5FoNNmDLcx7H8GdUQ_sfMR34xpl_gU9pPsDQ'}], 'enabled': False}",,,,,,
70,,tensorflow,"Hi, i'm a tensorflow noob, I would appreciate it if you could help me with this.
I have 3 tensors of shape (?,15) and I want to get the Cartesian product of all the possible combinations, my output should be of dimension (?,15,15,15,3). How can I do it ?",t2_rfmc5,False,,0,False,Cartesian product of tensors with batch dimension in Tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_lni852,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613776541.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, i&amp;#39;m a tensorflow noob, I would appreciate it if you could help me with this.
I have 3 tensors of shape (?,15) and I want to get the Cartesian product of all the possible combinations, my output should be of dimension (?,15,15,15,3). How can I do it ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lni852,True,,holypapa96,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/lni852/cartesian_product_of_tensors_with_batch_dimension/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lni852/cartesian_product_of_tensors_with_batch_dimension/,22217,1613747741.0,0,,False,,,,,,,,,
71,,tensorflow,"This is the model we implemented so far. The output of the model shall be the input, sorted by the output probabilities of the output layer.

 

`def createGeneratorModel():`  
`inputs = keras.Input(shape=(8,))`  
`bn1 = keras.layers.BatchNormalization()(inputs)`  
`x = layers.Dense(8, activation=""sigmoid"")(bn1)`  
`bn2 = keras.layers.BatchNormalization()(x)`  
`outputs = layers.Dense(8, activation=""sigmoid"")(bn2)`

  
`def custom_layer(tensor):`  
`outputs = tensor[0]`  
`inputs = tensor[1]`  
`indices = tf.argsort(outputs,direction=""ASCENDING"",name=None)`

`sorted_tensor = tf.gather(inputs, indices, axis=0, batch_dims=0)`  
`return sorted_tensor`  


`lambda_layer = layers.Lambda(custom_layer,name=""lambda_layer"")([outputs,inputs])`  
`model = keras.Model(inputs=inputs, outputs=lambda_layer, name=""gen_model"")`

`return model`

&amp;#x200B;

This is the error we get:

""Input 0 of layer batch\_normalization is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: \[None, None, 8\]""

&amp;#x200B;

We appreciate any help",t2_zwyyg,False,,0,False,How to sort Tensor Layer outputs with the inputs of another layer in the same model?,[],r/tensorflow,False,6,,0,,,False,t3_lmp4i7,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1613690577.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is the model we implemented so far. The output of the model shall be the input, sorted by the output probabilities of the output layer.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;def createGeneratorModel():&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = keras.Input(shape=(8,))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bn1 = keras.layers.BatchNormalization()(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.Dense(8, activation=&amp;quot;sigmoid&amp;quot;)(bn1)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bn2 = keras.layers.BatchNormalization()(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;outputs = layers.Dense(8, activation=&amp;quot;sigmoid&amp;quot;)(bn2)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;def custom_layer(tensor):&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;outputs = tensor[0]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = tensor[1]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;indices = tf.argsort(outputs,direction=&amp;quot;ASCENDING&amp;quot;,name=None)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sorted_tensor = tf.gather(inputs, indices, axis=0, batch_dims=0)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;return sorted_tensor&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;lambda_layer = layers.Lambda(custom_layer,name=&amp;quot;lambda_layer&amp;quot;)([outputs,inputs])&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model = keras.Model(inputs=inputs, outputs=lambda_layer, name=&amp;quot;gen_model&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;return model&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;This is the error we get:&lt;/p&gt;

&lt;p&gt;&amp;quot;Input 0 of layer batch_normalization is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: [None, None, 8]&amp;quot;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;We appreciate any help&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lmp4i7,True,,leKiller,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lmp4i7/how_to_sort_tensor_layer_outputs_with_the_inputs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lmp4i7/how_to_sort_tensor_layer_outputs_with_the_inputs/,22217,1613661777.0,0,,False,,,,,,,,,
72,,tensorflow,,t2_44mbtmjy,False,,0,False,State of the art in GANs for Image Editing!,[],r/tensorflow,False,6,,0,86.0,,False,t3_lmy62p,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/TpTetEWviEmoEvDxsB30Gn2oESAQQSkc1BFebiIaK-s.jpg,False,,[],{},,False,,1613713490.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lmy62p,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lmy62p/state_of_the_art_in_gans_for_image_editing/,all_ads,False,/r/LatestInML/comments/lmxy31/state_of_the_art_in_gans_for_image_editing/,22217,1613684690.0,0,,False,link,/r/LatestInML/comments/lmxy31/state_of_the_art_in_gans_for_image_editing/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?auto=webp&amp;s=dc70bc3fccb972a3313e4700efed6c7da58760b4', 'width': 1100, 'height': 682}, 'resolutions': [{'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1888d9373f1a711aa095dc88c3d726ad02c5e311', 'width': 108, 'height': 66}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0acebe3cfb5a6d8060d81cda3c2b5d200fe65ec0', 'width': 216, 'height': 133}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab0e444054d4ad9b85b8a723e49962e38ac2473a', 'width': 320, 'height': 198}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cbd6cbce5992de2c5ff1d447bfac19cd3f282a88', 'width': 640, 'height': 396}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3aa8f2eddb91f1a474fcbc537cd4292b1d2ad35e', 'width': 960, 'height': 595}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a914bfbf5976e0d8ae0af41cb5a3557612aa9268', 'width': 1080, 'height': 669}], 'variants': {}, 'id': 'YbpejjwhDw2FwwSvQD8VYhblnYxjCZirHStTymA-XIE'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2102.01187)\n\nhttps://preview.redd.it/mywodpkt1bi61.png?width=2114&amp;format=png&amp;auto=webp&amp;s=120550747d92245557331c97b58612eefb59d1ea\n\n👇 Free extension to get code for ML papers (❤️' by Andrew Ng)\n\nChrome: [https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil](https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil)\n\nFirefox: [https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex](https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex)"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in GANs for Image Editing!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 86, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'mywodpkt1bi61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6650cbce2c36b514c777f5aec8fe0f310521bb7'}, {'y': 134, 'x': 216, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1463a78ce2ea3ff82c7cbf7f1d474bd25d3992a7'}, {'y': 199, 'x': 320, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c918025f26d561ba4e33ea30d87383715290a3ba'}, {'y': 398, 'x': 640, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e48254663a327df5ca526ed583aeea2bec9c8e6d'}, {'y': 597, 'x': 960, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a7a0e2ea30982e7bcf546da9d7d0ff9f3686b00'}, {'y': 672, 'x': 1080, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e2973b83469d1169d90938e3fd9fbb1de9835225'}], 's': {'y': 1316, 'x': 2114, 'u': 'https://preview.redd.it/mywodpkt1bi61.png?width=2114&amp;format=png&amp;auto=webp&amp;s=120550747d92245557331c97b58612eefb59d1ea'}, 'id': 'mywodpkt1bi61'}}, 'name': 't3_lmxy31', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 16, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/TpTetEWviEmoEvDxsB30Gn2oESAQQSkc1BFebiIaK-s.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1613712934.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2102.01187""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/mywodpkt1bi61.png?width=2114&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=120550747d92245557331c97b58612eefb59d1ea""&gt;https://preview.redd.it/mywodpkt1bi61.png?width=2114&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=120550747d92245557331c97b58612eefb59d1ea&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39; by Andrew Ng)&lt;/p&gt;\n\n&lt;p&gt;Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?auto=webp&amp;s=dc70bc3fccb972a3313e4700efed6c7da58760b4', 'width': 1100, 'height': 682}, 'resolutions': [{'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1888d9373f1a711aa095dc88c3d726ad02c5e311', 'width': 108, 'height': 66}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0acebe3cfb5a6d8060d81cda3c2b5d200fe65ec0', 'width': 216, 'height': 133}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab0e444054d4ad9b85b8a723e49962e38ac2473a', 'width': 320, 'height': 198}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cbd6cbce5992de2c5ff1d447bfac19cd3f282a88', 'width': 640, 'height': 396}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3aa8f2eddb91f1a474fcbc537cd4292b1d2ad35e', 'width': 960, 'height': 595}, {'url': 'https://external-preview.redd.it/VetdfQRTBJSeX-7HQbXdVaxfirPcF8t_z_Nv_siTrKs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a914bfbf5976e0d8ae0af41cb5a3557612aa9268', 'width': 1080, 'height': 669}], 'variants': {}, 'id': 'YbpejjwhDw2FwwSvQD8VYhblnYxjCZirHStTymA-XIE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lmxy31', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/lmxy31/state_of_the_art_in_gans_for_image_editing/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/lmxy31/state_of_the_art_in_gans_for_image_editing/', 'subreddit_subscribers': 6676, 'created_utc': 1613684134.0, 'num_crossposts': 9, 'media': None, 'is_video': False}]",t3_lmxy31,
73,,tensorflow,"I am trying to train my model using Keras and TensorFlow 2.x, while using the model.fit() method I ran into this error

Link to complete code - [Code](https://colab.research.google.com/drive/1nxjfPUWFWDW9jtoVK7AzKWuTT-C2o-Cb)

Link to download the 'imdb-train-val-testN.pickle' [.pickle file](https://github.com/addy1997/Task9-personality-prediction/blob/main/imdb-train-val-testN.pickle)

The line that throws error

    N_epoch = 3  for i in range(N_epoch):     model.fit(x=train_X,y=train_Y,batch_size=32,epochs=10,verbose=1, validation_data=(val_X,val_Y))     output = model.predict_proba(val_X, batch_size=10, verbose=1)     # find validation accuracy using the best threshold value t     vacc = np.max([np.sum((output[:,1]&gt;t)==(val_Y[:,1]&gt;0.5))*1.0/len(output) for t in np.arange(0.0, 1.0, 0.01)])     # find validation AUC     vauc = roc_auc_score(val_Y, output)     val_acc.append(vacc)     val_auc.append(vauc)     print('Epoch {}: validation accuracy = {:.3%}, validation AUC = {:.3%}'.format(epoch, vacc, vauc))     epoch += 1      print('{} epochs passed'.format(epoch)) print('Accuracy on validation dataset:') print(val_acc) print('AUC on validation dataset:') print(val_auc) 

Error

    Epoch 1/10 --------------------------------------------------------------------------- RuntimeError                              Traceback (most recent call last)  &lt;ipython-input-73-4871a80f91a3&gt; in &lt;module&gt;()       2        3 for i in range(N_epoch): ----&gt; 4     model.fit(x=train_X,y=train_Y,batch_size=32,epochs=10,verbose=1, validation_data=(val_X,val_Y))       5     output = model.predict_proba(val_X, batch_size=10, verbose=1)       6     # find validation accuracy using the best threshold value t  9 frames  /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)     975           except Exception as e:  # pylint:disable=broad-except     976             if hasattr(e, ""ag_error_metadata""): --&gt; 977               raise e.ag_error_metadata.to_exception(e)     978             else:     979               raise  RuntimeError: in user code:      /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *         return step_function(self, iterator)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **         outputs = model.distribute_strategy.run(run_step, args=(data,))     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run         return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica         return 
    self._call_for_each_replica(fn, args, kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica         return fn(*args, **kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **         outputs = model.train_step(data)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:757 train_step         self.optimizer.minimize(loss, self.trainable_variables, tape=tape)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize         return self.apply_gradients(grads_and_vars, name=name)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:635 apply_gradients         ""name"": name,     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2941 merge_call         return self._merge_call(merge_fn, args, kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2948 _merge_call         return merge_fn(self._strategy, *args, **kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:683 _distributed_apply  **         var, apply_grad_to_update_var, args=(grad,), group=False))     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2494 update         return self._update(var, fn, args, kwargs, group)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3431 _update         return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3437 _update_non_slot         result = fn(*args, **kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:650 apply_grad_to_update_var  **         ""Cannot use a constraint function on a sparse variable."")      RuntimeError: Cannot use a constraint function on a sparse variable.",t2_4zfw022b,False,,0,False,RuntimeError: Cannot use a constraint function on a sparse variable in google colab,[],r/tensorflow,False,6,,0,,,False,t3_lmuay9,False,dark,0.99,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613703671.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to train my model using Keras and TensorFlow 2.x, while using the model.fit() method I ran into this error&lt;/p&gt;

&lt;p&gt;Link to complete code - &lt;a href=""https://colab.research.google.com/drive/1nxjfPUWFWDW9jtoVK7AzKWuTT-C2o-Cb""&gt;Code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Link to download the &amp;#39;imdb-train-val-testN.pickle&amp;#39; &lt;a href=""https://github.com/addy1997/Task9-personality-prediction/blob/main/imdb-train-val-testN.pickle""&gt;.pickle file&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The line that throws error&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;N_epoch = 3  for i in range(N_epoch):     model.fit(x=train_X,y=train_Y,batch_size=32,epochs=10,verbose=1, validation_data=(val_X,val_Y))     output = model.predict_proba(val_X, batch_size=10, verbose=1)     # find validation accuracy using the best threshold value t     vacc = np.max([np.sum((output[:,1]&amp;gt;t)==(val_Y[:,1]&amp;gt;0.5))*1.0/len(output) for t in np.arange(0.0, 1.0, 0.01)])     # find validation AUC     vauc = roc_auc_score(val_Y, output)     val_acc.append(vacc)     val_auc.append(vauc)     print(&amp;#39;Epoch {}: validation accuracy = {:.3%}, validation AUC = {:.3%}&amp;#39;.format(epoch, vacc, vauc))     epoch += 1      print(&amp;#39;{} epochs passed&amp;#39;.format(epoch)) print(&amp;#39;Accuracy on validation dataset:&amp;#39;) print(val_acc) print(&amp;#39;AUC on validation dataset:&amp;#39;) print(val_auc) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Error&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Epoch 1/10 --------------------------------------------------------------------------- RuntimeError                              Traceback (most recent call last)  &amp;lt;ipython-input-73-4871a80f91a3&amp;gt; in &amp;lt;module&amp;gt;()       2        3 for i in range(N_epoch): ----&amp;gt; 4     model.fit(x=train_X,y=train_Y,batch_size=32,epochs=10,verbose=1, validation_data=(val_X,val_Y))       5     output = model.predict_proba(val_X, batch_size=10, verbose=1)       6     # find validation accuracy using the best threshold value t  9 frames  /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)     975           except Exception as e:  # pylint:disable=broad-except     976             if hasattr(e, &amp;quot;ag_error_metadata&amp;quot;): --&amp;gt; 977               raise e.ag_error_metadata.to_exception(e)     978             else:     979               raise  RuntimeError: in user code:      /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *         return step_function(self, iterator)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **         outputs = model.distribute_strategy.run(run_step, args=(data,))     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run         return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica         return 
self._call_for_each_replica(fn, args, kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica         return fn(*args, **kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **         outputs = model.train_step(data)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:757 train_step         self.optimizer.minimize(loss, self.trainable_variables, tape=tape)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize         return self.apply_gradients(grads_and_vars, name=name)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:635 apply_gradients         &amp;quot;name&amp;quot;: name,     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2941 merge_call         return self._merge_call(merge_fn, args, kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2948 _merge_call         return merge_fn(self._strategy, *args, **kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:683 _distributed_apply  **         var, apply_grad_to_update_var, args=(grad,), group=False))     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2494 update         return self._update(var, fn, args, kwargs, group)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3431 _update         return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3437 _update_non_slot         result = fn(*args, **kwargs)     /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:650 apply_grad_to_update_var  **         &amp;quot;Cannot use a constraint function on a sparse variable.&amp;quot;)      RuntimeError: Cannot use a constraint function on a sparse variable.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lmuay9,True,,Adwait1997,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lmuay9/runtimeerror_cannot_use_a_constraint_function_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lmuay9/runtimeerror_cannot_use_a_constraint_function_on/,22217,1613674871.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&amp;s=73eb91ea5a5347f216c0f0c4d6796396826aae49', 'width': 260, 'height': 260}, 'resolutions': [{'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b647239f77bf713f4a6209cfa4867351c055fd9', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f4234ff3f4f4ebd7f77236dedb03a2faee3e04a', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nkhh65ujo5BznFJFojoMPaKjGuLSpPj6KGhRov-ykOg'}], 'enabled': False}",,,,,,
74,,tensorflow,,t2_5l72vlru,False,,0,False,Error in py2app + tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_lmqhme,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,default,False,,[],{},,False,,1613694142.0,text,6,,,text,self.learnpython,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lmqhme,True,,StrangerousDanger,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lmqhme/error_in_py2app_tensorflow/,all_ads,False,/r/learnpython/comments/lmoxew/error_in_py2app_tensorflow/,22217,1613665342.0,0,,False,,/r/learnpython/comments/lmoxew/error_in_py2app_tensorflow/,,,,,"[{'approved_at_utc': None, 'subreddit': 'learnpython', 'selftext': 'When I run the created app, I get an error:\n\n    from tensorflow_core import *\n      File ""/Users/xxxxxxxxx/Desktop/tensapp/lib/python3.7/site-packages/tensorflow_core/__init__.py"", line 774, in &lt;module&gt;\n        plugin_dir = _os.path.join(s, \'tensorflow-plugins\')\n      File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py"", line 80, in join\n        a = os.fspath(a)\n    TypeError: expected str, bytes or os.PathLike object, not NoneType\n\nThe script runs fine by itself.  I tried several versions of tensorflow.', 'author_fullname': 't2_5l72vlru', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Error in py2app + tensorflow', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnpython', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lmoxew', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1613690026.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnpython', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When I run the created app, I get an error:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from tensorflow_core import *\n  File &amp;quot;/Users/xxxxxxxxx/Desktop/tensapp/lib/python3.7/site-packages/tensorflow_core/__init__.py&amp;quot;, line 774, in &amp;lt;module&amp;gt;\n    plugin_dir = _os.path.join(s, &amp;#39;tensorflow-plugins&amp;#39;)\n  File &amp;quot;/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py&amp;quot;, line 80, in join\n    a = os.fspath(a)\nTypeError: expected str, bytes or os.PathLike object, not NoneType\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The script runs fine by itself.  I tried several versions of tensorflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r8ot', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lmoxew', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'StrangerousDanger', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnpython/comments/lmoxew/error_in_py2app_tensorflow/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnpython/comments/lmoxew/error_in_py2app_tensorflow/', 'subreddit_subscribers': 499207, 'created_utc': 1613661226.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_lmoxew,
75,,tensorflow,"I initially tried running it and it was fine. But after increasing the number of epochs from 5 to 10, it started to make a whirring noise. Then I got the errors below. Should I just switch to an online notebook instead?

&amp;#x200B;

2021-02-18 15:41:39.897160: W tensorflow/stream\_executor/platform/default/dso\_loader.cc:60\] Could not load dynamic library 'cudart64\_110.dll'; dlerror: cudart64\_110.dll not found

2021-02-18 15:41:39.897286: I tensorflow/stream\_executor/cuda/cudart\_stub.cc:29\] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

2021-02-18 15:41:46.473974: I tensorflow/compiler/jit/xla\_cpu\_device.cc:41\] Not creating XLA devices, tf\_xla\_enable\_xla\_devices not set

2021-02-18 15:41:46.476603: W tensorflow/stream\_executor/platform/default/dso\_loader.cc:60\] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found

2021-02-18 15:41:46.476813: W tensorflow/stream\_executor/cuda/cuda\_driver.cc:326\] failed call to cuInit: UNKNOWN ERROR (303)

2021-02-18 15:41:46.489050: I tensorflow/stream\_executor/cuda/cuda\_diagnostics.cc:169\] retrieving CUDA diagnostic information for host: DESKTOP-CM8OSCJ

2021-02-18 15:41:46.489310: I tensorflow/stream\_executor/cuda/cuda\_diagnostics.cc:176\] hostname: DESKTOP-CM8OSCJ

2021-02-18 15:41:46.489818: I tensorflow/core/platform/cpu\_feature\_guard.cc:142\] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2

To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

2021-02-18 15:41:46.491347: I tensorflow/compiler/jit/xla\_gpu\_device.cc:99\] Not creating XLA devices, tf\_xla\_enable\_xla\_devices not set

2021-02-18 15:41:46.707682: I tensorflow/compiler/mlir/mlir\_graph\_optimization\_pass.cc:116\] None of the MLIR optimization passes are enabled (registered 2)",t2_n1jjo,False,,0,False,Whirring coming from laptop when trying to train model,[],r/tensorflow,False,6,,0,,,False,t3_lmpr9k,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1613692273.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I initially tried running it and it was fine. But after increasing the number of epochs from 5 to 10, it started to make a whirring noise. Then I got the errors below. Should I just switch to an online notebook instead?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:39.897160: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;cudart64_110.dll&amp;#39;; dlerror: cudart64_110.dll not found&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:39.897286: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.473974: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.476603: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;nvcuda.dll&amp;#39;; dlerror: nvcuda.dll not found&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.476813: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.489050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-CM8OSCJ&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.489310: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-CM8OSCJ&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.489818: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2&lt;/p&gt;

&lt;p&gt;To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.491347: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set&lt;/p&gt;

&lt;p&gt;2021-02-18 15:41:46.707682: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lmpr9k,True,,Ghostie__,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lmpr9k/whirring_coming_from_laptop_when_trying_to_train/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lmpr9k/whirring_coming_from_laptop_when_trying_to_train/,22217,1613663473.0,0,,False,,,,,,,,,
76,,tensorflow,I am studying to take the tensorflow developer certificate. I do not have a GPU at my disposal. I have a macbook pro early 2015 model with 16GB RAM running Big Sur 11.1. Should this be sufficient to clear the exam?,t2_etja0,False,,0,False,TF developer certificate hardware necessary,[],r/tensorflow,False,6,,0,,,False,t3_lmfprl,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1613658087.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am studying to take the tensorflow developer certificate. I do not have a GPU at my disposal. I have a macbook pro early 2015 model with 16GB RAM running Big Sur 11.1. Should this be sufficient to clear the exam?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lmfprl,True,,mbkv,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lmfprl/tf_developer_certificate_hardware_necessary/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lmfprl/tf_developer_certificate_hardware_necessary/,22217,1613629287.0,0,,False,,,,,,,,,
77,,tensorflow,"Hi Team,
I am trying to run MiME algortihm (multi level embeddings)(link:https://github.com/mp2893/mime)
I have tried setting up the code in TF2.0 format but no matter what i try, it doesn't run on a GPU ( tried colab pro, kaggle).
It sometimes throw an error saying OOM or ' Cannot create a tensor proto whose content is larger than 2GB'

I know I am asking a lot here, but can anyone help me in identifying the issue? I run it for a sample sequences for 10k users. If i reduce that number then it runs but i want to run it for 100k so will need a GPU for this.
 The code is a bit complex but the path is : https://colab.research.google.com/drive/1qZ_Qt3JxC59J60iThEqEctJhnumE3WmL?usp=sharing",t2_4vrmhuu,False,,0,False,Need Help in running code on GPU,[],r/tensorflow,False,6,,0,,,False,t3_lme4fv,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1613652781.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Team,
I am trying to run MiME algortihm (multi level embeddings)(link:&lt;a href=""https://github.com/mp2893/mime""&gt;https://github.com/mp2893/mime&lt;/a&gt;)
I have tried setting up the code in TF2.0 format but no matter what i try, it doesn&amp;#39;t run on a GPU ( tried colab pro, kaggle).
It sometimes throw an error saying OOM or &amp;#39; Cannot create a tensor proto whose content is larger than 2GB&amp;#39;&lt;/p&gt;

&lt;p&gt;I know I am asking a lot here, but can anyone help me in identifying the issue? I run it for a sample sequences for 10k users. If i reduce that number then it runs but i want to run it for 100k so will need a GPU for this.
 The code is a bit complex but the path is : &lt;a href=""https://colab.research.google.com/drive/1qZ_Qt3JxC59J60iThEqEctJhnumE3WmL?usp=sharing""&gt;https://colab.research.google.com/drive/1qZ_Qt3JxC59J60iThEqEctJhnumE3WmL?usp=sharing&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lme4fv,True,,shenron91,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lme4fv/need_help_in_running_code_on_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lme4fv/need_help_in_running_code_on_gpu/,22217,1613623981.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/CnaXYx5NDjobeyUZmOaf32RD5JN5yMosdxPPZ3nsPh0.jpg?auto=webp&amp;s=ee19bc5b06d81af6a2c5f8bc0567991572ceb6ea', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/CnaXYx5NDjobeyUZmOaf32RD5JN5yMosdxPPZ3nsPh0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c69dee90faf830fef3fc37b3faadb2926aeb75a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/CnaXYx5NDjobeyUZmOaf32RD5JN5yMosdxPPZ3nsPh0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e5cc472a801dfcf72ba865a7cfc66df95ca5305', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/CnaXYx5NDjobeyUZmOaf32RD5JN5yMosdxPPZ3nsPh0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b414e404c9f9cfa079b73081922d4ef2389c7ca8', 'width': 320, 'height': 320}], 'variants': {}, 'id': '6iz0AJ-8tCBlpR01HlktoIoEYZdQVYiG_5dCOdn47c0'}], 'enabled': False}",,,,,,
78,,tensorflow,"Hi guys,

I'm trying to fit a time series model on the [Bach chorales](https://homl.info/bach) dataset.

When I preprocess all of the dataset, here is how it looks like (the train dataset):

    [[[78, 69, 62, 50],
      [78, 69, 62, 50],
      [78, 69, 62, 50],
      [78, 69, 62, 50],
      [78, 69, 62, 62],
      [78, 69, 62, 62],
      ...
      [74, 66, 57, 38],
      [74, 66, 57, 38]],
     [[70, 65, 62, 46],
      [70, 65, 62, 46],
      [70, 65, 62, 46],
      ...,
      [72, 67, 64, 48],
      [72, 67, 64, 48],
      [72, 67, 64, 48],
      [72, 67, 64, 48]]]

The ellipsis above indicate that the dataset continues. 

Here's my code with the model and the fitting step:

    model = keras.models.Sequential([
        keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=""relu""),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=""relu""),
        keras.layers.BatchNormalization(),
        keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=""relu""),
        keras.layers.BatchNormalization(),
        keras.layers.LSTM(128, return_sequences=True),
        keras.layers.LSTM(128),
        keras.layers.Dense(4)
    ])
    optimizer = keras.optimizers.SGD(lr=1e-2, clipnorm=1.)
    model.compile(loss=""sparse_categorical_crossentropy"",
                  optimizer=optimizer,
                  metrics=[""accuracy"", ""sparse_top_k_categorical_accuracy""])
    history = model.fit(train_new, epochs=2,
                        validation_data=valid_new)

It's giving me this error:

    ValueError: Input 0 of layer sequential_16 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1]

I don't understand why this is happening. I have 3 dimensions in my dataset. The first dimension is one giant list that contains all the batches, the second dimension are the batches - lists of timesteps and the third dimension are the timesteps themselves (within a list). I tried adding different dimensions at different places, but I get the same error.

**What do I need to do in order to make this code work?**",t2_4hmz4ifh,False,,0,False,I've got a dimension error when I try to fit a model and I can't figure out why,[],r/tensorflow,False,6,,0,,,False,t3_lm1r1f,False,dark,1.0,,public,11,0,{},,,False,[],,False,False,,{},Question,False,11,,False,self,False,,[],{},,True,,1613616942.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to fit a time series model on the &lt;a href=""https://homl.info/bach""&gt;Bach chorales&lt;/a&gt; dataset.&lt;/p&gt;

&lt;p&gt;When I preprocess all of the dataset, here is how it looks like (the train dataset):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[[78, 69, 62, 50],
  [78, 69, 62, 50],
  [78, 69, 62, 50],
  [78, 69, 62, 50],
  [78, 69, 62, 62],
  [78, 69, 62, 62],
  ...
  [74, 66, 57, 38],
  [74, 66, 57, 38]],
 [[70, 65, 62, 46],
  [70, 65, 62, 46],
  [70, 65, 62, 46],
  ...,
  [72, 67, 64, 48],
  [72, 67, 64, 48],
  [72, 67, 64, 48],
  [72, 67, 64, 48]]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The ellipsis above indicate that the dataset continues. &lt;/p&gt;

&lt;p&gt;Here&amp;#39;s my code with the model and the fitting step:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = keras.models.Sequential([
    keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=&amp;quot;relu&amp;quot;),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=&amp;quot;relu&amp;quot;),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=&amp;quot;relu&amp;quot;),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(128, return_sequences=True),
    keras.layers.LSTM(128),
    keras.layers.Dense(4)
])
optimizer = keras.optimizers.SGD(lr=1e-2, clipnorm=1.)
model.compile(loss=&amp;quot;sparse_categorical_crossentropy&amp;quot;,
              optimizer=optimizer,
              metrics=[&amp;quot;accuracy&amp;quot;, &amp;quot;sparse_top_k_categorical_accuracy&amp;quot;])
history = model.fit(train_new, epochs=2,
                    validation_data=valid_new)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;#39;s giving me this error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ValueError: Input 0 of layer sequential_16 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I don&amp;#39;t understand why this is happening. I have 3 dimensions in my dataset. The first dimension is one giant list that contains all the batches, the second dimension are the batches - lists of timesteps and the third dimension are the timesteps themselves (within a list). I tried adding different dimensions at different places, but I get the same error.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What do I need to do in order to make this code work?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lm1r1f,True,,A_Time_Space_Person,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/lm1r1f/ive_got_a_dimension_error_when_i_try_to_fit_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lm1r1f/ive_got_a_dimension_error_when_i_try_to_fit_a/,22217,1613588142.0,0,,False,,,,,,,,,
79,,tensorflow,"I am trying to create a data set (images) to train a model, but taking 1000 screenshots and editing it to the right size + labeling is the only way to do this? This seems like a big time sink.  


Im building it off a 3d game

&amp;#x200B;

I will keep reading about this",t2_4y9mm,False,,0,False,How to get 1000 images to train model efficiently,[],r/tensorflow,False,6,,0,,,False,t3_lm9n6e,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1613638553.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to create a data set (images) to train a model, but taking 1000 screenshots and editing it to the right size + labeling is the only way to do this? This seems like a big time sink.  &lt;/p&gt;

&lt;p&gt;Im building it off a 3d game&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I will keep reading about this&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lm9n6e,True,,krazyking,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lm9n6e/how_to_get_1000_images_to_train_model_efficiently/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lm9n6e/how_to_get_1000_images_to_train_model_efficiently/,22217,1613609753.0,0,,False,,,,,,,,,
80,,tensorflow,"I have created a custom layer for a model in keras but when I try to save it, keras throws this error: 

```
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5o.pyx"", line 202, in h5py.h5o.link
RuntimeError: Unable to create link (name already exists)
```

As I searched the above error, I found out that there are a couple of duplicate weight names inside my model 

eg: 

```
8 transformer_test/attention_test/dense/kernel:0
9 transformer_test/attention_test/dense/bias:0
10 transformer_test/attention_test/dense/kernel:0
11 transformer_test/attention_test/dense/bias:0
```

**The question is: What is causing those duplicate weight names? How could I prevent this from happening?**

Here is the specific layer's code: 

```python
class AttentionTest(Layer):
    """"""
    Multi-Head Convolutional Self Attention Layer
    """"""
    def __init__(self, dk, dv, num_heads, filter_size, **kwargs):
        self.dk = dk
        self.dv = dv
        self.num_heads = num_heads
        self.filter_size = filter_size
        self.conv_q = Conv1D(self.dk * self.num_heads, self.filter_size, padding='causal')
        self.conv_k = Conv1D(self.dk * self.num_heads, self.filter_size, padding='causal')
        self.dense_v = Dense(self.dv * self.num_heads)
        super(AttentionTest, self).__init__(**kwargs)
    
    def split_heads(self, x, batch_size, dim):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, dim))
        return tf.transpose(x, perm=[0, 2, 1, 3])  
    
    def build(self, input_shape):
        self.linear_1 = Dense(input_shape[-1], 
                        activation='relu')
            
        self.linear_2 = Dense(input_shape[-1])
        super(AttentionTest, self).build(input_shape)

    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]
        time_steps = tf.shape(inputs)[1]
        
        q = self.conv_q(inputs)
        k = self.conv_k(inputs)
        v = self.dense_v(inputs)
        
        q = self.split_heads(q, batch_size, self.dk)
        k = self.split_heads(k, batch_size, self.dk)
        v = self.split_heads(v, batch_size, self.dv)

        mask = 1 - tf.linalg.band_part(tf.ones((batch_size, self.num_heads, time_steps, time_steps)), -1, 0)
        dk = tf.cast(self.dk, tf.float32)
        score = tf.nn.softmax(tf.matmul(q, k, transpose_b=True)/tf.math.sqrt(dk) + mask * -1e9)
        outputs = tf.matmul(score, v)
        outputs = tf.transpose(outputs, perm=[0, 2, 1, 3])
        
        outputs = tf.reshape(outputs, (batch_size, time_steps, outputs.shape[-1]*outputs.shape[-2]))
        outputs = self.linear_1(outputs)
        outputs = self.linear_2(outputs)
        return outputs
```


And below you can see the full weight name list:

```
0 time2_vector/weight_linear:0
1 time2_vector/bias_linear:0
2 time2_vector/weight_periodic:0
3 time2_vector/bias_periodic:0
4 transformer_test/attention_test/conv1d/kernel:0
5 transformer_test/attention_test/conv1d/bias:0
6 transformer_test/attention_test/conv1d_1/kernel:0
7 transformer_test/attention_test/conv1d_1/bias:0
8 transformer_test/attention_test/dense/kernel:0
9 transformer_test/attention_test/dense/bias:0
10 transformer_test/attention_test/dense/kernel:0
11 transformer_test/attention_test/dense/bias:0
12 transformer_test/attention_test/dense_1/kernel:0
13 transformer_test/attention_test/dense_1/bias:0
14 transformer_test/layer_normalization/gamma:0
15 transformer_test/layer_normalization/beta:0
16 transformer_test/layer_normalization_1/gamma:0
17 transformer_test/layer_normalization_1/beta:0
18 transformer_test/conv1d_2/kernel:0
19 transformer_test/conv1d_2/bias:0
20 transformer_test/conv1d/kernel:0
21 transformer_test/conv1d/bias:0
22 transformer_test_1/attention_test_1/conv1d_3/kernel:0
23 transformer_test_1/attention_test_1/conv1d_3/bias:0
24 transformer_test_1/attention_test_1/conv1d_4/kernel:0
25 transformer_test_1/attention_test_1/conv1d_4/bias:0
26 transformer_test_1/attention_test_1/dense_1/kernel:0
27 transformer_test_1/attention_test_1/dense_1/bias:0
28 transformer_test_1/attention_test_1/dense/kernel:0
29 transformer_test_1/attention_test_1/dense/bias:0
30 transformer_test_1/attention_test_1/dense_1/kernel:0
31 transformer_test_1/attention_test_1/dense_1/bias:0
32 transformer_test_1/layer_normalization_2/gamma:0
33 transformer_test_1/layer_normalization_2/beta:0
34 transformer_test_1/layer_normalization_3/gamma:0
35 transformer_test_1/layer_normalization_3/beta:0
36 transformer_test_1/conv1d_5/kernel:0
37 transformer_test_1/conv1d_5/bias:0
38 transformer_test_1/conv1d/kernel:0
39 transformer_test_1/conv1d/bias:0
40 transformer_test_2/attention_test_2/conv1d_6/kernel:0
41 transformer_test_2/attention_test_2/conv1d_6/bias:0
42 transformer_test_2/attention_test_2/conv1d_7/kernel:0
43 transformer_test_2/attention_test_2/conv1d_7/bias:0
44 transformer_test_2/attention_test_2/dense_2/kernel:0
45 transformer_test_2/attention_test_2/dense_2/bias:0
46 transformer_test_2/attention_test_2/dense/kernel:0
47 transformer_test_2/attention_test_2/dense/bias:0
48 transformer_test_2/attention_test_2/dense_1/kernel:0
49 transformer_test_2/attention_test_2/dense_1/bias:0
50 transformer_test_2/layer_normalization_4/gamma:0
51 transformer_test_2/layer_normalization_4/beta:0
52 transformer_test_2/layer_normalization_5/gamma:0
53 transformer_test_2/layer_normalization_5/beta:0
54 transformer_test_2/conv1d_8/kernel:0
55 transformer_test_2/conv1d_8/bias:0
56 transformer_test_2/conv1d/kernel:0
57 transformer_test_2/conv1d/bias:0
58 dense_3/kernel:0
59 dense_3/bias:0
```",t2_7djjp,False,,0,False,Keras custom layer can't be saved because of duplicate weight names,[],r/tensorflow,False,6,,0,,,False,t3_llrvbo,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1613587987.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have created a custom layer for a model in keras but when I try to save it, keras throws this error: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
  File &amp;quot;h5py/_objects.pyx&amp;quot;, line 54, in h5py._objects.with_phil.wrapper
  File &amp;quot;h5py/_objects.pyx&amp;quot;, line 55, in h5py._objects.with_phil.wrapper
  File &amp;quot;h5py/h5o.pyx&amp;quot;, line 202, in h5py.h5o.link
RuntimeError: Unable to create link (name already exists)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As I searched the above error, I found out that there are a couple of duplicate weight names inside my model &lt;/p&gt;

&lt;p&gt;eg: &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
8 transformer_test/attention_test/dense/kernel:0
9 transformer_test/attention_test/dense/bias:0
10 transformer_test/attention_test/dense/kernel:0
11 transformer_test/attention_test/dense/bias:0
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The question is: What is causing those duplicate weight names? How could I prevent this from happening?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here is the specific layer&amp;#39;s code: &lt;/p&gt;

&lt;p&gt;```python
class AttentionTest(Layer):
    &amp;quot;&amp;quot;&amp;quot;
    Multi-Head Convolutional Self Attention Layer
    &amp;quot;&amp;quot;&amp;quot;
    def &lt;strong&gt;init&lt;/strong&gt;(self, dk, dv, num&lt;em&gt;heads, filter_size, **kwargs):
        self.dk = dk
        self.dv = dv
        self.num_heads = num_heads
        self.filter_size = filter_size
        self.conv_q = Conv1D(self.dk * self.num_heads, self.filter_size, padding=&amp;#39;causal&amp;#39;)
        self.conv_k = Conv1D(self.dk * self.num_heads, self.filter_size, padding=&amp;#39;causal&amp;#39;)
        self.dense_v = Dense(self.dv * self.num_heads)
        super(AttentionTest, self).&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_(**kwargs)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def split_heads(self, x, batch_size, dim):
    x = tf.reshape(x, (batch_size, -1, self.num_heads, dim))
    return tf.transpose(x, perm=[0, 2, 1, 3])  

def build(self, input_shape):
    self.linear_1 = Dense(input_shape[-1], 
                    activation=&amp;#39;relu&amp;#39;)

    self.linear_2 = Dense(input_shape[-1])
    super(AttentionTest, self).build(input_shape)

def call(self, inputs):
    batch_size = tf.shape(inputs)[0]
    time_steps = tf.shape(inputs)[1]

    q = self.conv_q(inputs)
    k = self.conv_k(inputs)
    v = self.dense_v(inputs)

    q = self.split_heads(q, batch_size, self.dk)
    k = self.split_heads(k, batch_size, self.dk)
    v = self.split_heads(v, batch_size, self.dv)

    mask = 1 - tf.linalg.band_part(tf.ones((batch_size, self.num_heads, time_steps, time_steps)), -1, 0)
    dk = tf.cast(self.dk, tf.float32)
    score = tf.nn.softmax(tf.matmul(q, k, transpose_b=True)/tf.math.sqrt(dk) + mask * -1e9)
    outputs = tf.matmul(score, v)
    outputs = tf.transpose(outputs, perm=[0, 2, 1, 3])

    outputs = tf.reshape(outputs, (batch_size, time_steps, outputs.shape[-1]*outputs.shape[-2]))
    outputs = self.linear_1(outputs)
    outputs = self.linear_2(outputs)
    return outputs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;And below you can see the full weight name list:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
0 time2_vector/weight_linear:0
1 time2_vector/bias_linear:0
2 time2_vector/weight_periodic:0
3 time2_vector/bias_periodic:0
4 transformer_test/attention_test/conv1d/kernel:0
5 transformer_test/attention_test/conv1d/bias:0
6 transformer_test/attention_test/conv1d_1/kernel:0
7 transformer_test/attention_test/conv1d_1/bias:0
8 transformer_test/attention_test/dense/kernel:0
9 transformer_test/attention_test/dense/bias:0
10 transformer_test/attention_test/dense/kernel:0
11 transformer_test/attention_test/dense/bias:0
12 transformer_test/attention_test/dense_1/kernel:0
13 transformer_test/attention_test/dense_1/bias:0
14 transformer_test/layer_normalization/gamma:0
15 transformer_test/layer_normalization/beta:0
16 transformer_test/layer_normalization_1/gamma:0
17 transformer_test/layer_normalization_1/beta:0
18 transformer_test/conv1d_2/kernel:0
19 transformer_test/conv1d_2/bias:0
20 transformer_test/conv1d/kernel:0
21 transformer_test/conv1d/bias:0
22 transformer_test_1/attention_test_1/conv1d_3/kernel:0
23 transformer_test_1/attention_test_1/conv1d_3/bias:0
24 transformer_test_1/attention_test_1/conv1d_4/kernel:0
25 transformer_test_1/attention_test_1/conv1d_4/bias:0
26 transformer_test_1/attention_test_1/dense_1/kernel:0
27 transformer_test_1/attention_test_1/dense_1/bias:0
28 transformer_test_1/attention_test_1/dense/kernel:0
29 transformer_test_1/attention_test_1/dense/bias:0
30 transformer_test_1/attention_test_1/dense_1/kernel:0
31 transformer_test_1/attention_test_1/dense_1/bias:0
32 transformer_test_1/layer_normalization_2/gamma:0
33 transformer_test_1/layer_normalization_2/beta:0
34 transformer_test_1/layer_normalization_3/gamma:0
35 transformer_test_1/layer_normalization_3/beta:0
36 transformer_test_1/conv1d_5/kernel:0
37 transformer_test_1/conv1d_5/bias:0
38 transformer_test_1/conv1d/kernel:0
39 transformer_test_1/conv1d/bias:0
40 transformer_test_2/attention_test_2/conv1d_6/kernel:0
41 transformer_test_2/attention_test_2/conv1d_6/bias:0
42 transformer_test_2/attention_test_2/conv1d_7/kernel:0
43 transformer_test_2/attention_test_2/conv1d_7/bias:0
44 transformer_test_2/attention_test_2/dense_2/kernel:0
45 transformer_test_2/attention_test_2/dense_2/bias:0
46 transformer_test_2/attention_test_2/dense/kernel:0
47 transformer_test_2/attention_test_2/dense/bias:0
48 transformer_test_2/attention_test_2/dense_1/kernel:0
49 transformer_test_2/attention_test_2/dense_1/bias:0
50 transformer_test_2/layer_normalization_4/gamma:0
51 transformer_test_2/layer_normalization_4/beta:0
52 transformer_test_2/layer_normalization_5/gamma:0
53 transformer_test_2/layer_normalization_5/beta:0
54 transformer_test_2/conv1d_8/kernel:0
55 transformer_test_2/conv1d_8/bias:0
56 transformer_test_2/conv1d/kernel:0
57 transformer_test_2/conv1d/bias:0
58 dense_3/kernel:0
59 dense_3/bias:0
&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,llrvbo,True,,chrispanag,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/llrvbo/keras_custom_layer_cant_be_saved_because_of/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/llrvbo/keras_custom_layer_cant_be_saved_because_of/,22217,1613559187.0,0,,False,,,,,,,,,
81,,tensorflow,,t2_p3jl6tq,False,,0,False,Identifying and Removing Outliers Using Python Packages,[],r/tensorflow,False,6,,0,73.0,,False,t3_llybvo,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},Discussion,False,0,,False,https://b.thumbs.redditmedia.com/BvZAV0CK9enUSobfim5cEwA0xBV36swszBzq8uRyWDA.jpg,False,,[],{},,False,,1613608037.0,text,6,,,text,dasca.org,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,llybvo,True,,sharmaniti437,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/llybvo/identifying_and_removing_outliers_using_python/,all_ads,False,https://www.dasca.org/world-of-big-data/article/identifying-and-removing-outliers-using-python-packages,22217,1613579237.0,0,,False,link,https://www.dasca.org/world-of-big-data/article/identifying-and-removing-outliers-using-python-packages,"{'images': [{'source': {'url': 'https://external-preview.redd.it/5y22GOF0halT933YXOjKV2-2WnXNeWoe9q4kXOFTfcY.jpg?auto=webp&amp;s=46ffdef1e983c3dd7daef4f7a32d800900cbd1a3', 'width': 800, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/5y22GOF0halT933YXOjKV2-2WnXNeWoe9q4kXOFTfcY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97709bb7baaa4bc30d60969c653c4311313d9743', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/5y22GOF0halT933YXOjKV2-2WnXNeWoe9q4kXOFTfcY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c08a48be2b851304e43041544c35d7620a6467e6', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/5y22GOF0halT933YXOjKV2-2WnXNeWoe9q4kXOFTfcY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7630ad401bb852c4666330c66d0d11ab6d136fca', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/5y22GOF0halT933YXOjKV2-2WnXNeWoe9q4kXOFTfcY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b1a024db574c67223fe7b73295906dbf9b01664', 'width': 640, 'height': 336}], 'variants': {}, 'id': '_gvlHJ_gJN7WF8wN4ykHptZgMusY_1RsqjBpsdbymj0'}], 'enabled': False}",,,,,,
82,,tensorflow,"I'm quite new in tensroflow and i'm confused with the different ways of saving a model: h5 and pb (i think there is another extension) 
So, what are the main differences between these ways of saving a model? Saving a model in one format is ""better"" than saving it in the other? In what situations is better to use each one?",t2_68dbbu5e,False,,0,False,Begginer's question about save models,[],r/tensorflow,False,6,,0,,,False,t3_lljxi6,False,dark,1.0,,public,10,0,{},,,False,[],,False,False,,{},Question,False,10,,False,self,False,,[],{},,True,,1613557850.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m quite new in tensroflow and i&amp;#39;m confused with the different ways of saving a model: h5 and pb (i think there is another extension) 
So, what are the main differences between these ways of saving a model? Saving a model in one format is &amp;quot;better&amp;quot; than saving it in the other? In what situations is better to use each one?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lljxi6,True,,OnionFred,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/lljxi6/begginers_question_about_save_models/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lljxi6/begginers_question_about_save_models/,22217,1613529050.0,0,,False,,,,,,,,,
83,,tensorflow,"Hello, 

I’m currently using some DICOM files that we’re looking to experiment with and if we can train a model on.

I’ve seen tensorflow building a CNN etc with 128x128x3 channel images for cats &amp; dogs ha and how it classified the types.

In this proof of concept, we’re using 16 bit grayscale imaging data, eventually 3D vokumes but we’re starting with 2D slices.

What I’m unsure of is in tensorflow (using Keras apis), are these CNNs able to function on 16 bit images (so two bytes per pixel)? Or would I just treat it as a 2 channel image and mathematically it would still work the same? I could convert it to a regular 8 bit image accepting it would lose some image detail too I suppose and see if I can get decent results. More curious if anything about the theory of handling an image where each pixel &gt; 1 byte, but not multi channel

I tried googling just I didn’t even know how to ask the question ha

Thanks!",t2_frov5i7,False,,0,False,Questions on CNN and 16 bit images,[],r/tensorflow,False,6,,0,,,False,t3_llneaj,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,True,self,False,,[],{},,True,,1613569969.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, &lt;/p&gt;

&lt;p&gt;I’m currently using some DICOM files that we’re looking to experiment with and if we can train a model on.&lt;/p&gt;

&lt;p&gt;I’ve seen tensorflow building a CNN etc with 128x128x3 channel images for cats &amp;amp; dogs ha and how it classified the types.&lt;/p&gt;

&lt;p&gt;In this proof of concept, we’re using 16 bit grayscale imaging data, eventually 3D vokumes but we’re starting with 2D slices.&lt;/p&gt;

&lt;p&gt;What I’m unsure of is in tensorflow (using Keras apis), are these CNNs able to function on 16 bit images (so two bytes per pixel)? Or would I just treat it as a 2 channel image and mathematically it would still work the same? I could convert it to a regular 8 bit image accepting it would lose some image detail too I suppose and see if I can get decent results. More curious if anything about the theory of handling an image where each pixel &amp;gt; 1 byte, but not multi channel&lt;/p&gt;

&lt;p&gt;I tried googling just I didn’t even know how to ask the question ha&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,llneaj,True,,boomerang473,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/llneaj/questions_on_cnn_and_16_bit_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/llneaj/questions_on_cnn_and_16_bit_images/,22217,1613541169.0,0,,False,,,,,,,,,
84,,tensorflow,"I can't seem to find any documentation on how to use this model.

I am trying to use it to print out the objects that appear in a video

any help would be greatly appreciated",t2_3hnxzv4t,False,,0,False,How to use FasterRCNN Openimages v4?,[],r/tensorflow,False,6,,0,,,False,t3_llara2,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1613530477.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I can&amp;#39;t seem to find any documentation on how to use this model.&lt;/p&gt;

&lt;p&gt;I am trying to use it to print out the objects that appear in a video&lt;/p&gt;

&lt;p&gt;any help would be greatly appreciated&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,llara2,True,,toushi100,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/llara2/how_to_use_fasterrcnn_openimages_v4/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/llara2/how_to_use_fasterrcnn_openimages_v4/,22217,1613501677.0,0,,False,,,,,,,,,
85,,tensorflow,,t2_79p1h62w,False,,0,False,2021 looks like a year filled with opportunities for technology trends,[],r/tensorflow,False,6,,0,64.0,,False,t3_llaqw9,False,dark,0.67,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/O3GqUs-cRlypOQq5_zRIvcLoE3hbBw4AG5UA_y4I-Bc.jpg,False,,[],{},,False,,1613530452.0,text,6,,,text,artiba.org,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,llaqw9,True,,Shradha_Singh,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/llaqw9/2021_looks_like_a_year_filled_with_opportunities/,all_ads,False,https://www.artiba.org/blog/top-5-emerging-ai-trends-in-2021,22217,1613501652.0,0,,False,link,https://www.artiba.org/blog/top-5-emerging-ai-trends-in-2021,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VlqSprODJDZuJMpMv6vgOP7ud-bIYaQolhug4kWZDiA.jpg?auto=webp&amp;s=940265c5a734cec8d8976c198f9ce4a500fea548', 'width': 800, 'height': 370}, 'resolutions': [{'url': 'https://external-preview.redd.it/VlqSprODJDZuJMpMv6vgOP7ud-bIYaQolhug4kWZDiA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=27f49536961260c00cb0177092f40df239dc8791', 'width': 108, 'height': 49}, {'url': 'https://external-preview.redd.it/VlqSprODJDZuJMpMv6vgOP7ud-bIYaQolhug4kWZDiA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=571fa969415603a04888e70edb293a6f0747caf4', 'width': 216, 'height': 99}, {'url': 'https://external-preview.redd.it/VlqSprODJDZuJMpMv6vgOP7ud-bIYaQolhug4kWZDiA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f04aa1054c3a94ef277f49a044d7943fa0e2bd49', 'width': 320, 'height': 148}, {'url': 'https://external-preview.redd.it/VlqSprODJDZuJMpMv6vgOP7ud-bIYaQolhug4kWZDiA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fafdde0c5f929019f5ce56599892084907b51d4e', 'width': 640, 'height': 296}], 'variants': {}, 'id': 'Kp_2myDz1aCC56kSoIgZ--KfLcjco74jFTwS3Lx9tD0'}], 'enabled': False}",,,,,,
86,,tensorflow,"I defined a model using tf.keras (v2.3.0) and I want to perfrom quantization aware training in this way:

    import tensorflow as tf
    from tensorflow.keras import layers #i tried to replace with tf.python.keras.layers.VersionAwareLayers
    import tensorflow_model_optimization as tfmot
    
    def build_model():
        inputs = tf.keras.Input()
        x = layers.Conv2D(24, 5, 2, 'relu')(inputs)
        x = layers.BatchNormalization()(x)
        # more layers...
        logits = layers.Softmax()(x)
        model = tf.keras.Model(inputs=inputs, outputs=logits)
        return model
        
    model = build_model()
    # training code
    q_aware_model = tfmot.quantization.keras.quantize_model(model)

I get this error: 

**RuntimeError: Layer batch\_normalization\_2:&lt;class 'tensorflow.python.keras.layers.normalization\_v2.BatchNormalization'&gt; is not supported. You can quantize this layer by passing a 'tfmot.quantization.keras.QuantizeConfig' instance to the 'quantize\_anotate\_layer' API**

However, if I define the model as a keras [MobilenetV2](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/applications/mobilenet_v2.py), which contains the same BatchNormalization layer, everything works fine. Where is the difference? How can I fix this problem?",t2_sm74p,False,,0,False,"Cannot quantize custom model with BatchNorm, but MobileNet can",[],r/tensorflow,False,6,,0,,,False,t3_ll1vo7,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1613503545.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I defined a model using tf.keras (v2.3.0) and I want to perfrom quantization aware training in this way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
from tensorflow.keras import layers #i tried to replace with tf.python.keras.layers.VersionAwareLayers
import tensorflow_model_optimization as tfmot

def build_model():
    inputs = tf.keras.Input()
    x = layers.Conv2D(24, 5, 2, &amp;#39;relu&amp;#39;)(inputs)
    x = layers.BatchNormalization()(x)
    # more layers...
    logits = layers.Softmax()(x)
    model = tf.keras.Model(inputs=inputs, outputs=logits)
    return model

model = build_model()
# training code
q_aware_model = tfmot.quantization.keras.quantize_model(model)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I get this error: &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RuntimeError: Layer batch_normalization_2:&amp;lt;class &amp;#39;tensorflow.python.keras.layers.normalization\_v2.BatchNormalization&amp;#39;&amp;gt; is not supported. You can quantize this layer by passing a &amp;#39;tfmot.quantization.keras.QuantizeConfig&amp;#39; instance to the &amp;#39;quantize_anotate_layer&amp;#39; API&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;However, if I define the model as a keras &lt;a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/applications/mobilenet_v2.py""&gt;MobilenetV2&lt;/a&gt;, which contains the same BatchNormalization layer, everything works fine. Where is the difference? How can I fix this problem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ll1vo7,True,,fralbalbero,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ll1vo7/cannot_quantize_custom_model_with_batchnorm_but/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ll1vo7/cannot_quantize_custom_model_with_batchnorm_but/,22217,1613474745.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
87,,tensorflow,"I want to get a head combined with a body preserving art style. Or that head generating a body around it (image completion) using a trained model from a dataset.  
In short:  
**Input 1:** Single image of a head X in style A  
**Input 2:** Single image of a body Y in style B  
**Data I have:** a lot of same-size images of characters (with heads and bodies) in style B  
**Output:** Single image of body Y with head X in style B (rather seamless, but no need to be perfect)

Couple of days ago I ran into a big list of Google collabs but most don't describe properly what they do, and the few that do, won't do what I need.  
What application or project do you recommend for this? If it's a project, will it run on CPU? I've got Windows and can install Anaconda.  
**Bottom line:** is there in the very least an application or project that just gets head X into body Y regardless of style?

&amp;#x200B;

My experience so far:

In RunwayML I trained a StyleGAN model with art portraits of the same style and size, but after that, it does only image synthesis (creates new random portraits with the same style)😒 . It won't take an input photo and turn it into a portrait in that style. At a fairly expensive subscription and machine-use fee, I think it offered very little bang for the buck.

Artbreeder portrait tools are better and fees are quite lower, and include using uploaded photos as inputs, mixing photos and creating new ""genes"" for the faces that may include an art style. However, its portrait tools are limited to heads only, from the neck up. It's also terrible at preserving features such as piercings, tattoos, horns, elf ears etc.

Big thanks to anyone who might help.",t2_a6akog5y,False,,0,False,Looking for app or project: Combining head with body preserving style?,[],r/tensorflow,False,6,,0,,,False,t3_lkscmg,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1613467370.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to get a head combined with a body preserving art style. Or that head generating a body around it (image completion) using a trained model from a dataset.&lt;br/&gt;
In short:&lt;br/&gt;
&lt;strong&gt;Input 1:&lt;/strong&gt; Single image of a head X in style A&lt;br/&gt;
&lt;strong&gt;Input 2:&lt;/strong&gt; Single image of a body Y in style B&lt;br/&gt;
&lt;strong&gt;Data I have:&lt;/strong&gt; a lot of same-size images of characters (with heads and bodies) in style B&lt;br/&gt;
&lt;strong&gt;Output:&lt;/strong&gt; Single image of body Y with head X in style B (rather seamless, but no need to be perfect)&lt;/p&gt;

&lt;p&gt;Couple of days ago I ran into a big list of Google collabs but most don&amp;#39;t describe properly what they do, and the few that do, won&amp;#39;t do what I need.&lt;br/&gt;
What application or project do you recommend for this? If it&amp;#39;s a project, will it run on CPU? I&amp;#39;ve got Windows and can install Anaconda.&lt;br/&gt;
&lt;strong&gt;Bottom line:&lt;/strong&gt; is there in the very least an application or project that just gets head X into body Y regardless of style?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My experience so far:&lt;/p&gt;

&lt;p&gt;In RunwayML I trained a StyleGAN model with art portraits of the same style and size, but after that, it does only image synthesis (creates new random portraits with the same style)😒 . It won&amp;#39;t take an input photo and turn it into a portrait in that style. At a fairly expensive subscription and machine-use fee, I think it offered very little bang for the buck.&lt;/p&gt;

&lt;p&gt;Artbreeder portrait tools are better and fees are quite lower, and include using uploaded photos as inputs, mixing photos and creating new &amp;quot;genes&amp;quot; for the faces that may include an art style. However, its portrait tools are limited to heads only, from the neck up. It&amp;#39;s also terrible at preserving features such as piercings, tattoos, horns, elf ears etc.&lt;/p&gt;

&lt;p&gt;Big thanks to anyone who might help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lkscmg,True,,shadowrunelectric,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lkscmg/looking_for_app_or_project_combining_head_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lkscmg/looking_for_app_or_project_combining_head_with/,22217,1613438570.0,0,,False,,,,,,,,,
88,,tensorflow,"I am training a model using tf.Keras. The code is the following.

    class CustomCallback(tf.keras.callbacks.Callback):
        def __init__(self, val_dataset, **kwargs):
            self.val_dataset = val_dataset
            super().__init__(**kwargs)
        def on_train_batch_end(self, batch, logs=None):
          
            if batch%1000 == 0:
            val = self.model.evaluate(self.val_dataset, return_dict=True)
            print(""*** Val accuracy: %.2f ***"" % (val['sparse_categorical_accuracy']))
    
            super().on_train_batch_end(batch, logs)
    
    ## DATASET ##
    
    # Create a dictionary describing the features.
    image_feature_description = {
        'train/label' : tf.io.FixedLenFeature((), tf.int64),
         'train/image' : tf.io.FixedLenFeature((), tf.string)
    }
    
    
    def _parse_image_function(example_proto):
      # Parse the input tf.train.Example proto using the dictionary above.
      parsed_features = tf.io.parse_single_example(example_proto, image_feature_description)
      image = tf.image.decode_jpeg(parsed_features['train/image'])
      image = tf.image.resize(image, [224,224])
      # augmentation
    
      image = tf.image.random_flip_left_right(image)
      image = tf.image.random_brightness(image, 0.2)
      image = tf.image.random_jpeg_quality(image, 50, 95)
      image = image/255.0
    
     
      label = tf.cast(parsed_features['train/label'], tf.int32)
      return image, label
    
    def load_dataset(filenames, labeled=True):
        ignore_order = tf.data.Options()
        ignore_order.experimental_deterministic = False  # disable order, increase speed
        dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files
        dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order
        dataset = dataset.map(partial(_parse_image_function), num_parallel_calls=AUTOTUNE)
    
        return dataset
    
    def get_datasets(filenames, labeled=True, BATCH=64):
        dataset = load_dataset(filenames, labeled=labeled)
        train_dataset = dataset.skip(2000)
        val_dataset = dataset.take(2000)
        train_dataset = train_dataset.shuffle(4096)
        train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
        train_dataset = train_dataset.batch(BATCH)
        val_dataset = val_dataset.batch(BATCH)
        return train_dataset, val_dataset
    
    
    
    train_dataset, val_dataset = get_datasets('data/train_224.tfrecords', BATCH=64)
    
    
    ## CALLBACKS ##
    
    log_path = './logs/' + datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
    checkpoint_path = './checkpoints/' + datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
    
    
    tb_callback = tf.keras.callbacks.TensorBoard(
        log_path,
        update_freq=100,
        profile_batch=0)
    
    
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_path+'/weights.{epoch:02d}-{accuracy:.2f}.hdf5',
        save_weights_only=False,
        save_freq=200)
    
    
    custom_callback = CustomCallback(val_dataset=val_dataset)
    
    
    ## MODEL ##
    
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        0.005, decay_steps=300, decay_rate=0.98, staircase=True
    )
    
    model = tf.keras.applications.MobileNetV2(
        include_top=True,
        weights=None,
        classes=2,
        alpha=0.25)
    
    model.compile(
        optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
        metrics=['accuracy', 'sparse_categorical_accuracy'])
    
    model.fit(train_dataset,
                epochs=NUM_EPOCHS,
                shuffle=True,
                validation_data=val_dataset,
                validation_steps=None,
                callbacks=[model_checkpoint_callback, tb_callback, custom_callback])
    
    model.save('model.hdf5')
    
    

At the end of each epoch I can see a spike in the batch accuracy and loss, as you can see in the figure below. After the spike, the metrics gradually return to previous values and keep improving.

What could be the reason for this strange behaviour?

https://preview.redd.it/sg8lcdieylh61.png?width=417&amp;format=png&amp;auto=webp&amp;s=7c93ff11fe29da2cb8d90591ce44c69b8da92c3e",t2_sm74p,False,,0,False,Large spikes after each epoch using tf.Keras API,[],r/tensorflow,False,6,,0,140.0,,False,t3_lka1ig,False,dark,0.88,,public,6,0,{},140.0,,False,[],,False,False,,{},,False,6,,False,https://b.thumbs.redditmedia.com/7G-L-vBwCGMKgT6XW-jHfSdhD50OjSMHXOS-MTfx70M.jpg,False,,[],{},,True,,1613409649.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am training a model using tf.Keras. The code is the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class CustomCallback(tf.keras.callbacks.Callback):
    def __init__(self, val_dataset, **kwargs):
        self.val_dataset = val_dataset
        super().__init__(**kwargs)
    def on_train_batch_end(self, batch, logs=None):

        if batch%1000 == 0:
        val = self.model.evaluate(self.val_dataset, return_dict=True)
        print(&amp;quot;*** Val accuracy: %.2f ***&amp;quot; % (val[&amp;#39;sparse_categorical_accuracy&amp;#39;]))

        super().on_train_batch_end(batch, logs)

## DATASET ##

# Create a dictionary describing the features.
image_feature_description = {
    &amp;#39;train/label&amp;#39; : tf.io.FixedLenFeature((), tf.int64),
     &amp;#39;train/image&amp;#39; : tf.io.FixedLenFeature((), tf.string)
}


def _parse_image_function(example_proto):
  # Parse the input tf.train.Example proto using the dictionary above.
  parsed_features = tf.io.parse_single_example(example_proto, image_feature_description)
  image = tf.image.decode_jpeg(parsed_features[&amp;#39;train/image&amp;#39;])
  image = tf.image.resize(image, [224,224])
  # augmentation

  image = tf.image.random_flip_left_right(image)
  image = tf.image.random_brightness(image, 0.2)
  image = tf.image.random_jpeg_quality(image, 50, 95)
  image = image/255.0


  label = tf.cast(parsed_features[&amp;#39;train/label&amp;#39;], tf.int32)
  return image, label

def load_dataset(filenames, labeled=True):
    ignore_order = tf.data.Options()
    ignore_order.experimental_deterministic = False  # disable order, increase speed
    dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files
    dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order
    dataset = dataset.map(partial(_parse_image_function), num_parallel_calls=AUTOTUNE)

    return dataset

def get_datasets(filenames, labeled=True, BATCH=64):
    dataset = load_dataset(filenames, labeled=labeled)
    train_dataset = dataset.skip(2000)
    val_dataset = dataset.take(2000)
    train_dataset = train_dataset.shuffle(4096)
    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
    train_dataset = train_dataset.batch(BATCH)
    val_dataset = val_dataset.batch(BATCH)
    return train_dataset, val_dataset



train_dataset, val_dataset = get_datasets(&amp;#39;data/train_224.tfrecords&amp;#39;, BATCH=64)


## CALLBACKS ##

log_path = &amp;#39;./logs/&amp;#39; + datetime.datetime.now().strftime(&amp;quot;%Y%m%d-%H%M%S&amp;quot;)
checkpoint_path = &amp;#39;./checkpoints/&amp;#39; + datetime.datetime.now().strftime(&amp;quot;%Y%m%d-%H%M%S&amp;quot;)


tb_callback = tf.keras.callbacks.TensorBoard(
    log_path,
    update_freq=100,
    profile_batch=0)


model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path+&amp;#39;/weights.{epoch:02d}-{accuracy:.2f}.hdf5&amp;#39;,
    save_weights_only=False,
    save_freq=200)


custom_callback = CustomCallback(val_dataset=val_dataset)


## MODEL ##

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    0.005, decay_steps=300, decay_rate=0.98, staircase=True
)

model = tf.keras.applications.MobileNetV2(
    include_top=True,
    weights=None,
    classes=2,
    alpha=0.25)

model.compile(
    optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=[&amp;#39;accuracy&amp;#39;, &amp;#39;sparse_categorical_accuracy&amp;#39;])

model.fit(train_dataset,
            epochs=NUM_EPOCHS,
            shuffle=True,
            validation_data=val_dataset,
            validation_steps=None,
            callbacks=[model_checkpoint_callback, tb_callback, custom_callback])

model.save(&amp;#39;model.hdf5&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the end of each epoch I can see a spike in the batch accuracy and loss, as you can see in the figure below. After the spike, the metrics gradually return to previous values and keep improving.&lt;/p&gt;

&lt;p&gt;What could be the reason for this strange behaviour?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/sg8lcdieylh61.png?width=417&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7c93ff11fe29da2cb8d90591ce44c69b8da92c3e""&gt;https://preview.redd.it/sg8lcdieylh61.png?width=417&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7c93ff11fe29da2cb8d90591ce44c69b8da92c3e&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lka1ig,True,,fralbalbero,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lka1ig/large_spikes_after_each_epoch_using_tfkeras_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lka1ig/large_spikes_after_each_epoch_using_tfkeras_api/,22217,1613380849.0,0,,False,,,,,"{'sg8lcdieylh61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 184, 'x': 108, 'u': 'https://preview.redd.it/sg8lcdieylh61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c420155f5f8f1c7fd8781dd8a58cf8e7eda73959'}, {'y': 369, 'x': 216, 'u': 'https://preview.redd.it/sg8lcdieylh61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=425a0bc45c5728e43366cfca486472f289fcd1f7'}, {'y': 547, 'x': 320, 'u': 'https://preview.redd.it/sg8lcdieylh61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=783bdac58ce30ffccc05464a47114dbb002008e6'}], 's': {'y': 713, 'x': 417, 'u': 'https://preview.redd.it/sg8lcdieylh61.png?width=417&amp;format=png&amp;auto=webp&amp;s=7c93ff11fe29da2cb8d90591ce44c69b8da92c3e'}, 'id': 'sg8lcdieylh61'}}",,,,
89,,tensorflow,"I've a Flask+React web app. When the user submits an image file, I would pass it to two models: one to perform image captioning, the other to perform object detection. The two models' outputs are then processed before being collectively added to a database. The user can upload multiple images in a single submission, potentially in the hundreds.

Is it possible to send each image to the models for inference asynchronously? The image doesn't need to be sent to both models in parallel, that can be done sequentially, but I would like each image to be processed asynchronously from each other. The application design I've in mind is that when the web form is submitted, each uploaded image will be sent to the Flask backend as individual API calls. Perhaps each image will be sent to the models in a thread, and they'll all be managed by a threadpool?

This is my first time working with Tensorflow for a production system (I'm using TF2) and I've never touched concurrent programming outside of practice projects in school, so I'm not familiar with whether the two can be combined. In its current state, the web page is blocked while both file uploading and server-side inferencing are running. It doesn't seem to be a good idea for the web page to be unusable from the moment a user submits hundreds of images to upload until the two models finish producing outputs for them all, one by one in a single thread.",t2_tugum,False,,0,False,Can I send inputs to my models for inference asynchronously?,[],r/tensorflow,False,6,,0,,,False,t3_lk5lj7,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,1613363331.0,,[],{},,True,,1613391909.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve a Flask+React web app. When the user submits an image file, I would pass it to two models: one to perform image captioning, the other to perform object detection. The two models&amp;#39; outputs are then processed before being collectively added to a database. The user can upload multiple images in a single submission, potentially in the hundreds.&lt;/p&gt;

&lt;p&gt;Is it possible to send each image to the models for inference asynchronously? The image doesn&amp;#39;t need to be sent to both models in parallel, that can be done sequentially, but I would like each image to be processed asynchronously from each other. The application design I&amp;#39;ve in mind is that when the web form is submitted, each uploaded image will be sent to the Flask backend as individual API calls. Perhaps each image will be sent to the models in a thread, and they&amp;#39;ll all be managed by a threadpool?&lt;/p&gt;

&lt;p&gt;This is my first time working with Tensorflow for a production system (I&amp;#39;m using TF2) and I&amp;#39;ve never touched concurrent programming outside of practice projects in school, so I&amp;#39;m not familiar with whether the two can be combined. In its current state, the web page is blocked while both file uploading and server-side inferencing are running. It doesn&amp;#39;t seem to be a good idea for the web page to be unusable from the moment a user submits hundreds of images to upload until the two models finish producing outputs for them all, one by one in a single thread.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lk5lj7,True,,kimtaengsshi9,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lk5lj7/can_i_send_inputs_to_my_models_for_inference/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lk5lj7/can_i_send_inputs_to_my_models_for_inference/,22217,1613363109.0,0,,False,,,,,,,,,
90,,tensorflow,"

I was working off some github code where I'm training a model to  recognize laughter.  This particular bit of code is giving me problems:

&amp;#x200B;

    from keras.models import Sequential
    from keras.layers import Dense, BatchNormalization, Flatten
    
    lr_model = Sequential()
    # lr_model.add(keras.Input((None, 128)))
    lr_model.add(BatchNormalization(input_shape=(10, 128)))
    lr_model.add(Flatten())
    lr_model.add(Dense(1, activation='sigmoid'))
    
    # try using different optimizers and different optimizer configs
    lr_model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    
    batch_size=32
    
    CV_frac = 0.1
    train_gen = data_generator(batch_size,'../Data/bal_laugh_speech_subset.tfrecord', 0, 1-CV_frac)
    val_gen = data_generator(128,'../Data/bal_laugh_speech_subset.tfrecord', 1-CV_frac, 1)
    
    rec_len = 18768
    
    lr_h = lr_model.fit_generator(train_gen,steps_per_epoch=int(rec_len*(1-CV_frac))//batch_size, epochs=100, 
                           validation_data=val_gen, validation_steps=int(rec_len*CV_frac)//128,
                           verbose=0, callbacks=[TQDMNotebookCallback()])

&amp;#x200B;

&amp;#x200B;

I get the following error:

&amp;#x200B;

&amp;#x200B;

    ---------------------------------------------------------------------------
    KeyError                                  Traceback (most recent call last)
    &lt;ipython-input-15-9eced074de11&gt; in &lt;module&gt;
          7 rec_len = 18768
          8 
    ----&gt; 9 lr_h = lr_model.fit_generator(train_gen,steps_per_epoch=int(rec_len*(1-CV_frac))//batch_size, epochs=100, 
         10                        validation_data=val_gen, validation_steps=int(rec_len*CV_frac)//128,
         11                        verbose=0, callbacks=[TQDMNotebookCallback()])
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
       1845                   'will be removed in a future version. '
       1846                   'Please use `Model.fit`, which supports generators.')
    -&gt; 1847     return self.fit(
       1848         generator,
       1849         steps_per_epoch=steps_per_epoch,
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
       1103               logs = tmp_logs  # No error, now safe to assign to logs.
       1104               end_step = step + data_handler.step_increment
    -&gt; 1105               callbacks.on_train_batch_end(end_step, logs)
       1106               if self.stop_training:
       1107                 break
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
        452     """"""
        453     if self._should_call_train_batch_hooks:
    --&gt; 454       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
        455 
        456   def on_test_batch_begin(self, batch, logs=None):
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
        294       self._call_batch_begin_hook(mode, batch, logs)
        295     elif hook == 'end':
    --&gt; 296       self._call_batch_end_hook(mode, batch, logs)
        297     else:
        298       raise ValueError('Unrecognized hook: {}'.format(hook))
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs)
        314       self._batch_times.append(batch_time)
        315 
    --&gt; 316     self._call_batch_hook_helper(hook_name, batch, logs)
        317 
        318     if len(self._batch_times) &gt;= self._num_batches_for_timing_check:
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs)
        358         if numpy_logs is None:  # Only convert once.
        359           numpy_logs = tf_utils.to_numpy_or_python_type(logs)
    --&gt; 360         hook(batch, numpy_logs)
        361 
        362     if self._check_timing:
    
    ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
        708     """"""
        709     # For backwards compatibility.
    --&gt; 710     self.on_batch_end(batch, logs=logs)
        711 
        712   @doc_controls.for_subclass_implementers
    
    ~/env/py385/lib/python3.8/site-packages/keras_tqdm/tqdm_callback.py in on_batch_end(self, batch, logs)
        115         self.inner_count += update
        116         if self.inner_count &lt; self.inner_total:
    --&gt; 117             self.append_logs(logs)
        118             metrics = self.format_metrics(self.running_logs)
        119             desc = self.inner_description_update.format(epoch=self.epoch, metrics=metrics)
    
    ~/env/py385/lib/python3.8/site-packages/keras_tqdm/tqdm_callback.py in append_logs(self, logs)
        134 
        135     def append_logs(self, logs):
    --&gt; 136         metrics = self.params['metrics']
        137         for metric, value in six.iteritems(logs):
        138             if metric in metrics:
    
    KeyError: 'metrics'
    
    

All the other KeyError 'metrics' problems I've googled have to do with  something else called livelossplot.  Any help will be much appreciated!",t2_4cvk20aa,False,,0,False,KeyError 'metrics' when trying to train a model in tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_lkb576,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613414393.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was working off some github code where I&amp;#39;m training a model to  recognize laughter.  This particular bit of code is giving me problems:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, Flatten

lr_model = Sequential()
# lr_model.add(keras.Input((None, 128)))
lr_model.add(BatchNormalization(input_shape=(10, 128)))
lr_model.add(Flatten())
lr_model.add(Dense(1, activation=&amp;#39;sigmoid&amp;#39;))

# try using different optimizers and different optimizer configs
lr_model.compile(loss=&amp;#39;binary_crossentropy&amp;#39;,
              optimizer=&amp;#39;adam&amp;#39;,
              metrics=[&amp;#39;accuracy&amp;#39;])

batch_size=32

CV_frac = 0.1
train_gen = data_generator(batch_size,&amp;#39;../Data/bal_laugh_speech_subset.tfrecord&amp;#39;, 0, 1-CV_frac)
val_gen = data_generator(128,&amp;#39;../Data/bal_laugh_speech_subset.tfrecord&amp;#39;, 1-CV_frac, 1)

rec_len = 18768

lr_h = lr_model.fit_generator(train_gen,steps_per_epoch=int(rec_len*(1-CV_frac))//batch_size, epochs=100, 
                       validation_data=val_gen, validation_steps=int(rec_len*CV_frac)//128,
                       verbose=0, callbacks=[TQDMNotebookCallback()])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I get the following error:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&amp;lt;ipython-input-15-9eced074de11&amp;gt; in &amp;lt;module&amp;gt;
      7 rec_len = 18768
      8 
----&amp;gt; 9 lr_h = lr_model.fit_generator(train_gen,steps_per_epoch=int(rec_len*(1-CV_frac))//batch_size, epochs=100, 
     10                        validation_data=val_gen, validation_steps=int(rec_len*CV_frac)//128,
     11                        verbose=0, callbacks=[TQDMNotebookCallback()])

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1845                   &amp;#39;will be removed in a future version. &amp;#39;
   1846                   &amp;#39;Please use `Model.fit`, which supports generators.&amp;#39;)
-&amp;gt; 1847     return self.fit(
   1848         generator,
   1849         steps_per_epoch=steps_per_epoch,

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1103               logs = tmp_logs  # No error, now safe to assign to logs.
   1104               end_step = step + data_handler.step_increment
-&amp;gt; 1105               callbacks.on_train_batch_end(end_step, logs)
   1106               if self.stop_training:
   1107                 break

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
    452     &amp;quot;&amp;quot;&amp;quot;
    453     if self._should_call_train_batch_hooks:
--&amp;gt; 454       self._call_batch_hook(ModeKeys.TRAIN, &amp;#39;end&amp;#39;, batch, logs=logs)
    455 
    456   def on_test_batch_begin(self, batch, logs=None):

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
    294       self._call_batch_begin_hook(mode, batch, logs)
    295     elif hook == &amp;#39;end&amp;#39;:
--&amp;gt; 296       self._call_batch_end_hook(mode, batch, logs)
    297     else:
    298       raise ValueError(&amp;#39;Unrecognized hook: {}&amp;#39;.format(hook))

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs)
    314       self._batch_times.append(batch_time)
    315 
--&amp;gt; 316     self._call_batch_hook_helper(hook_name, batch, logs)
    317 
    318     if len(self._batch_times) &amp;gt;= self._num_batches_for_timing_check:

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs)
    358         if numpy_logs is None:  # Only convert once.
    359           numpy_logs = tf_utils.to_numpy_or_python_type(logs)
--&amp;gt; 360         hook(batch, numpy_logs)
    361 
    362     if self._check_timing:

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
    708     &amp;quot;&amp;quot;&amp;quot;
    709     # For backwards compatibility.
--&amp;gt; 710     self.on_batch_end(batch, logs=logs)
    711 
    712   @doc_controls.for_subclass_implementers

~/env/py385/lib/python3.8/site-packages/keras_tqdm/tqdm_callback.py in on_batch_end(self, batch, logs)
    115         self.inner_count += update
    116         if self.inner_count &amp;lt; self.inner_total:
--&amp;gt; 117             self.append_logs(logs)
    118             metrics = self.format_metrics(self.running_logs)
    119             desc = self.inner_description_update.format(epoch=self.epoch, metrics=metrics)

~/env/py385/lib/python3.8/site-packages/keras_tqdm/tqdm_callback.py in append_logs(self, logs)
    134 
    135     def append_logs(self, logs):
--&amp;gt; 136         metrics = self.params[&amp;#39;metrics&amp;#39;]
    137         for metric, value in six.iteritems(logs):
    138             if metric in metrics:

KeyError: &amp;#39;metrics&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the other KeyError &amp;#39;metrics&amp;#39; problems I&amp;#39;ve googled have to do with  something else called livelossplot.  Any help will be much appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lkb576,True,,imstupidfeelbad,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lkb576/keyerror_metrics_when_trying_to_train_a_model_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lkb576/keyerror_metrics_when_trying_to_train_a_model_in/,22217,1613385593.0,0,,False,,,,,,,,,
91,,tensorflow,"Hello there. I'm thinking of using Genetic Algorithm to tune Hyper-parameters of Neural Networks.

Apart form this [paper](https://arxiv.org/pdf/2006.12703.pdf) and this blog [blog](https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164), I don't find anything that relates with the topic. However there are many GA libraries such as PyGAD etc, but they only apply GA onto weights to fine tune the model instead of finding the best hyper-parameters.

By any chance, anyone here tried anything like this before, as in using GA to find the best hyperparameter in a Tensorflow/Keras Model? Mind share your thoughts?

Thanks!

Add-Ons:

The  library/package I used applies GA on the weight training process, where  it chooses parents(fittest solution/group of weights) and gives off  offspring(of the fittest solution/group of weights) etc. On the other  hand, I was thinking if it can do things like finding the optimal  solution/chromosome/set of parameter as parents in a population(fittest  set of hyperparameters) and give off offspring(better than the fittest  one) kind of.",t2_8349k9p0,False,,0,False,Deep Neural network Hyper-parameter Tuning with Genetic Algorithm,[],r/tensorflow,False,6,,0,,,False,t3_ljm88o,False,dark,1.0,,public,20,0,{},,,False,[],,False,False,,{},,False,20,,False,self,1613349232.0,,[],{},,True,,1613328140.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello there. I&amp;#39;m thinking of using Genetic Algorithm to tune Hyper-parameters of Neural Networks.&lt;/p&gt;

&lt;p&gt;Apart form this &lt;a href=""https://arxiv.org/pdf/2006.12703.pdf""&gt;paper&lt;/a&gt; and this blog &lt;a href=""https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164""&gt;blog&lt;/a&gt;, I don&amp;#39;t find anything that relates with the topic. However there are many GA libraries such as PyGAD etc, but they only apply GA onto weights to fine tune the model instead of finding the best hyper-parameters.&lt;/p&gt;

&lt;p&gt;By any chance, anyone here tried anything like this before, as in using GA to find the best hyperparameter in a Tensorflow/Keras Model? Mind share your thoughts?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;Add-Ons:&lt;/p&gt;

&lt;p&gt;The  library/package I used applies GA on the weight training process, where  it chooses parents(fittest solution/group of weights) and gives off  offspring(of the fittest solution/group of weights) etc. On the other  hand, I was thinking if it can do things like finding the optimal  solution/chromosome/set of parameter as parents in a population(fittest  set of hyperparameters) and give off offspring(better than the fittest  one) kind of.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ljm88o,True,,Obvious-Salad4973,,17,True,all_ads,False,[],False,,/r/tensorflow/comments/ljm88o/deep_neural_network_hyperparameter_tuning_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ljm88o/deep_neural_network_hyperparameter_tuning_with/,22217,1613299340.0,1,,False,,,,,,,,,
92,,tensorflow,"I've written my own neural net framework and I want to benchmark its performance against tensorflow. Current run-time stats on the XOR problem are 37ms @ 0.01 target error and 462ms @ 10k epochs, no gpu processing or anything fancy. I want to benchmark this against other frameworks to see how it's fairing, but I'm too new to them to give this a fair run. Tensorflow for .net core is giving me problems. Any help or run-time stats for the same problem would be very appreciated.",t2_3pdcdfte,False,,0,False,Benchmarking against tensorflow: need an assist,[],r/tensorflow,False,6,,0,,,False,t3_ljrlio,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1613349034.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve written my own neural net framework and I want to benchmark its performance against tensorflow. Current run-time stats on the XOR problem are 37ms @ 0.01 target error and 462ms @ 10k epochs, no gpu processing or anything fancy. I want to benchmark this against other frameworks to see how it&amp;#39;s fairing, but I&amp;#39;m too new to them to give this a fair run. Tensorflow for .net core is giving me problems. Any help or run-time stats for the same problem would be very appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ljrlio,True,,AConcernedCoder,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ljrlio/benchmarking_against_tensorflow_need_an_assist/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ljrlio/benchmarking_against_tensorflow_need_an_assist/,22217,1613320234.0,0,,False,,,,,,,,,
93,,tensorflow,,t2_93q3vyj,False,,0,False,Creating Age Prediction Model in 10 Minutes TENSORFLOW CHALLENGE,[],r/tensorflow,False,6,,0,105.0,,False,t3_lk0qss,False,dark,0.67,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NxNrIwejnPI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Coding a Deep Learning Age Prediction Model in 10 Minutes', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NxNrIwejnPI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Hunter Mitchell', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/NxNrIwejnPI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCLBcKas2IYWtMwIzr9mPi4Q'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NxNrIwejnPI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lk0qss', 'height': 200}",Project / Challenge,False,1,,False,https://b.thumbs.redditmedia.com/Q4m6XDm3rvFX85C2d7ZJYBg5MLC_nc_Vz3PhPjyBe4Q.jpg,False,,[],{},,False,,1613375872.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lk0qss,True,,godismysavior69,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lk0qss/creating_age_prediction_model_in_10_minutes/,all_ads,False,https://youtu.be/NxNrIwejnPI,22217,1613347072.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Coding a Deep Learning Age Prediction Model in 10 Minutes', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NxNrIwejnPI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Hunter Mitchell', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/NxNrIwejnPI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCLBcKas2IYWtMwIzr9mPi4Q'}}",False,rich:video,https://youtu.be/NxNrIwejnPI,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WhgnTbBA_zu2F8-PB7_UmhKfxvLomy2KDYxmCsCW6_g.jpg?auto=webp&amp;s=886fe12b662640b949ee5b7d216c719b9528b84b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/WhgnTbBA_zu2F8-PB7_UmhKfxvLomy2KDYxmCsCW6_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=757d66e259f00adc464f04598b84e1aebb6a52b3', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/WhgnTbBA_zu2F8-PB7_UmhKfxvLomy2KDYxmCsCW6_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a63c3970e6f098f2261e1e0d4a104c9a3b78eba', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/WhgnTbBA_zu2F8-PB7_UmhKfxvLomy2KDYxmCsCW6_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd83b5c9811e0237728f0b71cb4eaab0da5c6c60', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'sgb6o66SPD8mwCRqtd-8knGCWehZ0kqjUsQdaGsNVGM'}], 'enabled': False}",,,,,,
94,,tensorflow,"Trained a neural model to detect whether the mouth is opened or not. Just provide the cropped face roi and get the output. I converted model into popular formats: pb, h5, tflite, onnx, js. You can use the model to detect yawning. https://github.com/iglaweb/HippoYD

JS Demo is at https://igla.su/mouth-open-js/",t2_1069v9,False,,0,False,Mouth openness detection with DNN,[],r/tensorflow,False,6,,0,,,False,t3_lj8ldn,False,dark,0.93,,public,22,0,{},,,False,[],,False,False,,{},Project,False,22,,False,self,False,,[],{},,True,,1613277181.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Trained a neural model to detect whether the mouth is opened or not. Just provide the cropped face roi and get the output. I converted model into popular formats: pb, h5, tflite, onnx, js. You can use the model to detect yawning. &lt;a href=""https://github.com/iglaweb/HippoYD""&gt;https://github.com/iglaweb/HippoYD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;JS Demo is at &lt;a href=""https://igla.su/mouth-open-js/""&gt;https://igla.su/mouth-open-js/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lj8ldn,True,,iglaweb,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lj8ldn/mouth_openness_detection_with_dnn/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lj8ldn/mouth_openness_detection_with_dnn/,22217,1613248381.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?auto=webp&amp;s=ba307190d13a736ff335252fcde9eefd17e6be50', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0545416e5deb894f81e90ce1dcd93acc700fe40b', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff7b4175bf1b9ff3e1f69cc6b148ab6dc344dc11', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=680dfa26f6493040dbf0d755e595d774ae161e70', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'ksYP-l3VbTqB9qMbGb6zbd9Mw6rCYwSnQsJUCYcBuU0'}], 'enabled': False}",,,,,,
95,,tensorflow,"Hi everyone,

 I am trying to use a model saved in .h5 format to analyze a video stream and identify the speed in real time. How do I implement this in Python?

Thank you in advance!",t2_79ozyttf,False,,0,False,How to use my model to analyze real time data?,[],r/tensorflow,False,6,,0,,,False,t3_ljjrvk,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1613315702.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I am trying to use a model saved in .h5 format to analyze a video stream and identify the speed in real time. How do I implement this in Python?&lt;/p&gt;

&lt;p&gt;Thank you in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ljjrvk,True,,sleepingmousie,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ljjrvk/how_to_use_my_model_to_analyze_real_time_data/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ljjrvk/how_to_use_my_model_to_analyze_real_time_data/,22217,1613286902.0,0,,False,,,,,,,,,
96,,tensorflow,"Hi,

&amp;#x200B;

I have a working script largely based on the titanic tutorial: [https://www.tensorflow.org/tutorials/estimator/linear](https://www.tensorflow.org/tutorials/estimator/linear)

My question is, how to I use something like `linear_est.predict()`  to feed the trained model some new data to make predictions on?

So I have training data, evaluation data, both with 3 features and 1 label.

Then I want to feed it 3 features and no label, to see what it would predict as the output (boolean if that matters).

Thanks  


Edit: I think I got it working just by using the same format as train and eval, but with an empty value in the pred dataset?  


so my training and eval lines look like this:   


`train_input_fn = make_input_fn(dftrain, y_train)`    
`eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)`

Then my pred line is the same:  


`pred_input_fn = make_input_fn(df_pred, y_pred, num_epochs=1, shuffle=False)`  


Where y\_pred is basically always going to be an empty label column.  


The output looks correct to me, something I'd expect to have a low prediction value came out with 15% true and 85% false.  


If anyone can confirm this is okay or suggest a better way, or a resource that uses .predict, that would be great!",t2_80ont,False,,0,False,How to make predictions on unseen data without a label after training a Linear Classifier?,[],r/tensorflow,False,6,,0,,,False,t3_lj85em,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,1613247704.0,,[],{},,True,,1613275856.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have a working script largely based on the titanic tutorial: &lt;a href=""https://www.tensorflow.org/tutorials/estimator/linear""&gt;https://www.tensorflow.org/tutorials/estimator/linear&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My question is, how to I use something like &lt;code&gt;linear_est.predict()&lt;/code&gt;  to feed the trained model some new data to make predictions on?&lt;/p&gt;

&lt;p&gt;So I have training data, evaluation data, both with 3 features and 1 label.&lt;/p&gt;

&lt;p&gt;Then I want to feed it 3 features and no label, to see what it would predict as the output (boolean if that matters).&lt;/p&gt;

&lt;p&gt;Thanks  &lt;/p&gt;

&lt;p&gt;Edit: I think I got it working just by using the same format as train and eval, but with an empty value in the pred dataset?  &lt;/p&gt;

&lt;p&gt;so my training and eval lines look like this:   &lt;/p&gt;

&lt;p&gt;&lt;code&gt;train_input_fn = make_input_fn(dftrain, y_train)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then my pred line is the same:  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;pred_input_fn = make_input_fn(df_pred, y_pred, num_epochs=1, shuffle=False)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;Where y_pred is basically always going to be an empty label column.  &lt;/p&gt;

&lt;p&gt;The output looks correct to me, something I&amp;#39;d expect to have a low prediction value came out with 15% true and 85% false.  &lt;/p&gt;

&lt;p&gt;If anyone can confirm this is okay or suggest a better way, or a resource that uses .predict, that would be great!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lj85em,True,,Cwlrs,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lj85em/how_to_make_predictions_on_unseen_data_without_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lj85em/how_to_make_predictions_on_unseen_data_without_a/,22217,1613247056.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
97,,tensorflow,"After several hours of Google searching, I cannot find a straightforward answer. I'm not working with the W model, so my RPi doesn't have a wireless adapter. I have found results that all involve cloning repos on the RPi itself, but I have no clue how to go about it. Do I need a Raspberian build that already has TF built-in to it? Or is there a way I can scp all the files over to my Pi?

I've tried what's listed [here](https://github.com/cloudwiser/TensorFlowLiteRPIZero), but instead downloading TF and its dependencies on my local machine, but didn't know what to do in regards to the file path.

If anyone knows of a good guide or knows how to do this...please let me know. Thanks

 **Update**: I used my Pi Zero as a USB gadget, and basically shared the internet connection on my laptop with the Pi Zero via USB as an ethernet connection, and that got my Pi Zero online. I am writing a tutorial as I go throughout this whole process and will publish on Medium (including the actual usage of these packages...it's going to be the whole project)! As of now, I am still having an issue finding a Tensorflow Google Coral wheel that is compatible with Pi Zero's armv6l architecture. ",t2_lp5yrdf,False,,0,False,How do you install TF (and TFLite) on a Raspberry Pi Zero?,[],r/tensorflow,False,6,,0,,,False,t3_linbf7,False,dark,0.9,,public,15,0,{},,,False,[],,False,False,,{},Question,False,15,,False,self,1613275495.0,,[],{},,True,,1613200078.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;After several hours of Google searching, I cannot find a straightforward answer. I&amp;#39;m not working with the W model, so my RPi doesn&amp;#39;t have a wireless adapter. I have found results that all involve cloning repos on the RPi itself, but I have no clue how to go about it. Do I need a Raspberian build that already has TF built-in to it? Or is there a way I can scp all the files over to my Pi?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve tried what&amp;#39;s listed &lt;a href=""https://github.com/cloudwiser/TensorFlowLiteRPIZero""&gt;here&lt;/a&gt;, but instead downloading TF and its dependencies on my local machine, but didn&amp;#39;t know what to do in regards to the file path.&lt;/p&gt;

&lt;p&gt;If anyone knows of a good guide or knows how to do this...please let me know. Thanks&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: I used my Pi Zero as a USB gadget, and basically shared the internet connection on my laptop with the Pi Zero via USB as an ethernet connection, and that got my Pi Zero online. I am writing a tutorial as I go throughout this whole process and will publish on Medium (including the actual usage of these packages...it&amp;#39;s going to be the whole project)! As of now, I am still having an issue finding a Tensorflow Google Coral wheel that is compatible with Pi Zero&amp;#39;s armv6l architecture. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,linbf7,True,,seekingstars,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/linbf7/how_do_you_install_tf_and_tflite_on_a_raspberry/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/linbf7/how_do_you_install_tf_and_tflite_on_a_raspberry/,22217,1613171278.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WawJ-DJA7KIHtlqb4W0aKDPMYdZpuPQkwtSZ8AUsUd8.jpg?auto=webp&amp;s=a95b9b0d0790418fb2b44ac8e06b8a8422b7af14', 'width': 200, 'height': 200}, 'resolutions': [{'url': 'https://external-preview.redd.it/WawJ-DJA7KIHtlqb4W0aKDPMYdZpuPQkwtSZ8AUsUd8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a04983d952a0591ac76f330ad7daf3524fb21ca7', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'SI1PJ6BxqqNaHyaFo1TLHdKNZue4cI4eKqHhRlxwqRo'}], 'enabled': False}",,,,,,
98,,tensorflow,,t2_2vsjwr3g,False,,0,False,3D Scene Understanding with TensorFlow 3D,[],r/tensorflow,False,6,,0,140.0,,False,t3_lijili,False,dark,1.0,,public,6,0,{},140.0,,False,[],,False,False,,{},,False,6,,False,https://b.thumbs.redditmedia.com/zC2pUI9oGA7-K1bq9-7iq-mTs5dWtPUIm-8dGbMcOfA.jpg,False,,[],{},,False,,1613189269.0,text,6,,,text,ai.googleblog.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lijili,True,,AR_MR_XR,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lijili/3d_scene_understanding_with_tensorflow_3d/,all_ads,False,https://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html?m=1,22217,1613160469.0,0,,False,link,https://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html?m=1,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&amp;s=d45552298a94c0bc0e771853afe179cbb0e3f951', 'width': 1200, 'height': 1200}, 'resolutions': [{'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=467975d187bd3f0e5cf8f0880665db7e4eca4fcb', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=121a848b6e9c40ce8f4c995b663108493b3b069d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e62560ba614db17109e1924a187a6575b9f7399', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=46bf2a0eba7661a832cec202bf2cec4660a37b4e', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=73be8d146553ec5d17c995a6cc1c0f963532ae61', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=af590ed730005b197bb9c10c9bc2c173078730ef', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': 'q7V8BDv9opANwPukjjPK-R82fNE4Qq4vwXKRxiy1DHo'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'AR_MR_XR', 'selftext': '', 'author_fullname': 't2_2vsjwr3g', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '3D Scene Understanding with TensorFlow 3D', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/AR_MR_XR', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lijga6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'restricted', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Software', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/zC2pUI9oGA7-K1bq9-7iq-mTs5dWtPUIm-8dGbMcOfA.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1613189083.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'ai.googleblog.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html?m=1', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&amp;s=d45552298a94c0bc0e771853afe179cbb0e3f951', 'width': 1200, 'height': 1200}, 'resolutions': [{'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=467975d187bd3f0e5cf8f0880665db7e4eca4fcb', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=121a848b6e9c40ce8f4c995b663108493b3b069d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e62560ba614db17109e1924a187a6575b9f7399', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=46bf2a0eba7661a832cec202bf2cec4660a37b4e', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=73be8d146553ec5d17c995a6cc1c0f963532ae61', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=af590ed730005b197bb9c10c9bc2c173078730ef', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': 'q7V8BDv9opANwPukjjPK-R82fNE4Qq4vwXKRxiy1DHo'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'c05d4abe-0700-11e9-bf42-0e081c054816', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_t9z3q', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#e8e8e8', 'id': 'lijga6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AR_MR_XR', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/AR_MR_XR/comments/lijga6/3d_scene_understanding_with_tensorflow_3d/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html?m=1', 'subreddit_subscribers': 6064, 'created_utc': 1613160283.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_lijga6,
99,,tensorflow,"Hey!

I'm following [this](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html) installation guide for object detection using tensorflow 2, my goal is to train a CNN using my GPU. Tensorflow seems to recognize it after the [GPU support](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#gpu-support-optional) section and everything runs smoothly. However, after I install the [Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#install-the-object-detection-api), tensorflow just starts ignoring it and runs on CPU. Any help would be deeply apreciated, thanks!",t2_3908cnyv,False,,0,False,GPU bug using tensorflow 2.x Object Detection API,[],r/tensorflow,False,6,,0,,,False,t3_limkyu,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1613198031.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m following &lt;a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html""&gt;this&lt;/a&gt; installation guide for object detection using tensorflow 2, my goal is to train a CNN using my GPU. Tensorflow seems to recognize it after the &lt;a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#gpu-support-optional""&gt;GPU support&lt;/a&gt; section and everything runs smoothly. However, after I install the &lt;a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#install-the-object-detection-api""&gt;Object Detection API&lt;/a&gt;, tensorflow just starts ignoring it and runs on CPU. Any help would be deeply apreciated, thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,limkyu,True,,smcsb,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/limkyu/gpu_bug_using_tensorflow_2x_object_detection_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/limkyu/gpu_bug_using_tensorflow_2x_object_detection_api/,22217,1613169231.0,0,,False,,,,,,,,,
100,,tensorflow,,t2_1krqyfrs,False,,0,False,Sign Language Detection in Real-Time on Raspberry Pi using OpenCV AI Kit,[],r/tensorflow,False,6,,0,140.0,,False,t3_lhgamu,False,dark,0.99,,public,134,2,{},140.0,,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/0cc76l1e6tg61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1080, 'scrubber_media_url': 'https://v.redd.it/0cc76l1e6tg61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/0cc76l1e6tg61/DASHPlaylist.mpd?a=1618044660%2CODk3ZjEyYTRmZmJiMmQzZDI0NjNkZjE2NTEzNGI0NjE5Nzk5NGI4MTBmNGNiNDhkYTk0OTAxODkxNjNiYzBiYw%3D%3D&amp;v=1&amp;f=sd', 'duration': 41, 'hls_url': 'https://v.redd.it/0cc76l1e6tg61/HLSPlaylist.m3u8?a=1618044660%2CZTZjODk2ZmQwYzE0NDk0YThiZmY4YTdmZDJkM2Q1YjdhM2YzMDMyMmQ1NTAwYjcyNmE3ZTg4OTBhZGYxNzViZg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': True, 'transcoding_status': 'completed'}}",True,False,,{},Project,False,134,,False,https://b.thumbs.redditmedia.com/MFTSlGGqTomQ1B-B1bNSovTsyF6hcI1qSoNrkwUtI7E.jpg,False,,[],{},,False,,1613060753.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lhgamu,True,,AugmentedStartups,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/lhgamu/sign_language_detection_in_realtime_on_raspberry/,all_ads,False,https://v.redd.it/0cc76l1e6tg61,22217,1613031953.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/0cc76l1e6tg61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1080, 'scrubber_media_url': 'https://v.redd.it/0cc76l1e6tg61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/0cc76l1e6tg61/DASHPlaylist.mpd?a=1618044660%2CODk3ZjEyYTRmZmJiMmQzZDI0NjNkZjE2NTEzNGI0NjE5Nzk5NGI4MTBmNGNiNDhkYTk0OTAxODkxNjNiYzBiYw%3D%3D&amp;v=1&amp;f=sd', 'duration': 41, 'hls_url': 'https://v.redd.it/0cc76l1e6tg61/HLSPlaylist.m3u8?a=1618044660%2CZTZjODk2ZmQwYzE0NDk0YThiZmY4YTdmZDJkM2Q1YjdhM2YzMDMyMmQ1NTAwYjcyNmE3ZTg4OTBhZGYxNzViZg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': True, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/0cc76l1e6tg61,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?format=pjpg&amp;auto=webp&amp;s=04f6d22f70c0ef81eae5b2cecd1fda6dda03ebb9', 'width': 1080, 'height': 1080}, 'resolutions': [{'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4fe4811db73684592f1fe1fb858d8776eb5cdb5c', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e7954281d182f7d87d46f6cb7281a06251e5180d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7b5eeda177e63833c24240a886304dc26a7d7562', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c80f6b125c558c37b0ef3cc3204fd4cf789cddaf', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=601d49161a2fbfde571fdd264423513dc06368f8', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/kyPBEo_D40bGFa9s3sVYfPbX6A_niCN8iuGPnoBNn6c.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7748ce505cd40abb1dfceb5890aded0c224b9359', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': 'MPZYU04ORU8qjP_jwxnhXVsZtRJ_NS14Yt4WMErPg88'}], 'enabled': False}",,,,,,
101,,tensorflow,"If I install all the external dependencies of Tensor Flow such as the Bazel, make, on my linux machine, and build Tensor Flow from source, would I be able to arrive at a binary code I can feed into some server machine to just run? 

I am also asking whether the python API calls a bunch of dynamically linked libraries, and then somehow the have a model.build() command or a model.compile() command that produces a binary in the directory in my linux machine?",t2_6fht034r,False,,0,False,Is Tensor Flow Compilable to a binary?,[],r/tensorflow,False,6,,0,,,False,t3_lhterw,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1613102881.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I install all the external dependencies of Tensor Flow such as the Bazel, make, on my linux machine, and build Tensor Flow from source, would I be able to arrive at a binary code I can feed into some server machine to just run? &lt;/p&gt;

&lt;p&gt;I am also asking whether the python API calls a bunch of dynamically linked libraries, and then somehow the have a model.build() command or a model.compile() command that produces a binary in the directory in my linux machine?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lhterw,True,,GingerGengar123,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lhterw/is_tensor_flow_compilable_to_a_binary/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lhterw/is_tensor_flow_compilable_to_a_binary/,22217,1613074081.0,0,,False,,,,,,,,,
102,,tensorflow,"I understand the simple tf.distribute.mirroredStrategy(), it's actually pretty simple.   I'm hoping to scale a large problem across multiple computers so I'm trying to learn how to use multiWorkerMirrorredStrategy() but I have not found a good example yet.

My understanding is that I would write one python script and distribute it across the machines.   Then I define the roles of each machine via the environment variable TF\_CONFIG.   I create the strategy and then do something like:

    mystrategy = tf.distribute.multiWorkerMirroredStrategy()
    with mystrategy.scope():
        model = buildModel()
        model.compile()
        model.fit(x_train, y_train)

That's all very straightforward.   My question is about the data.   This code is executed on all nodes.   Is each node supposed to parse TF\_CONFIG and load its own subset of data?    Does just the chief load all  the data and then the scope block parses out shards?   Or does each node load all the data?",t2_7osuk,False,,0,False,tf.distribute.multiWorkerMirroredStrategy and data sharding,[],r/tensorflow,False,6,,0,,,False,t3_lhxsgx,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613114497.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I understand the simple tf.distribute.mirroredStrategy(), it&amp;#39;s actually pretty simple.   I&amp;#39;m hoping to scale a large problem across multiple computers so I&amp;#39;m trying to learn how to use multiWorkerMirrorredStrategy() but I have not found a good example yet.&lt;/p&gt;

&lt;p&gt;My understanding is that I would write one python script and distribute it across the machines.   Then I define the roles of each machine via the environment variable TF_CONFIG.   I create the strategy and then do something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mystrategy = tf.distribute.multiWorkerMirroredStrategy()
with mystrategy.scope():
    model = buildModel()
    model.compile()
    model.fit(x_train, y_train)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;#39;s all very straightforward.   My question is about the data.   This code is executed on all nodes.   Is each node supposed to parse TF_CONFIG and load its own subset of data?    Does just the chief load all  the data and then the scope block parses out shards?   Or does each node load all the data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lhxsgx,True,,Simusid,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lhxsgx/tfdistributemultiworkermirroredstrategy_and_data/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lhxsgx/tfdistributemultiworkermirroredstrategy_and_data/,22217,1613085697.0,0,,False,,,,,,,,,
103,,tensorflow,"I did pretty much the same as in every tutorial concerning GANs, yet the Gradients of my models are just NaN.

Code:

    
    with tf.GradientTape() as gt, tf.GradientTape() as dt:
    
        ab_fake = model(l_real, training=True)

        ab_real_logit = D(ab_real, training=True)
        ab_fake_logit = D(ab_fake, training=True)


        G_loss = get_g_loss(ab_fake_logit)

        D_loss = get_d_loss(ab_real_logit, ab_fake_logit)


    model_grad = gt.gradient(G_loss, model.trainable_variables)
    print(model_grad)
    #model.optimizer.apply_gradients(zip(model_grad, model.trainable_variables))
    D_grad = dt.gradient(D_loss, D.trainable_variables)
    #D.optimizer.apply_gradients(zip(D_grad, D.trainable_variables))
    print(model_grad)

The gradients of the Generator (model) are just NaN, the gradients of the Discriminator (D) or mostly NaN.

Edit:
I may have found the problem. Using a BatchNormalization- and/or a GlobalAveragePooling2D-Layer in the Discriminator is somehow responsible for this problem. 
Using LayerNormalization and GlobalMaxPool2D seems to be ok. Does anyone know why the gradient can not be computed with BatchNorm and GlobalAveragePooling2D?",t2_6ge6wg,False,,0,False,NaN-Gradients with GradientTape,[],r/tensorflow,False,6,,0,,,False,t3_lhrft8,False,dark,0.99,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1613131854.0,,[],{},,True,,1613097840.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I did pretty much the same as in every tutorial concerning GANs, yet the Gradients of my models are just NaN.&lt;/p&gt;

&lt;p&gt;Code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;with tf.GradientTape() as gt, tf.GradientTape() as dt:

    ab_fake = model(l_real, training=True)

    ab_real_logit = D(ab_real, training=True)
    ab_fake_logit = D(ab_fake, training=True)


    G_loss = get_g_loss(ab_fake_logit)

    D_loss = get_d_loss(ab_real_logit, ab_fake_logit)


model_grad = gt.gradient(G_loss, model.trainable_variables)
print(model_grad)
#model.optimizer.apply_gradients(zip(model_grad, model.trainable_variables))
D_grad = dt.gradient(D_loss, D.trainable_variables)
#D.optimizer.apply_gradients(zip(D_grad, D.trainable_variables))
print(model_grad)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The gradients of the Generator (model) are just NaN, the gradients of the Discriminator (D) or mostly NaN.&lt;/p&gt;

&lt;p&gt;Edit:
I may have found the problem. Using a BatchNormalization- and/or a GlobalAveragePooling2D-Layer in the Discriminator is somehow responsible for this problem. 
Using LayerNormalization and GlobalMaxPool2D seems to be ok. Does anyone know why the gradient can not be computed with BatchNorm and GlobalAveragePooling2D?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lhrft8,True,,Jonny_dr,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lhrft8/nangradients_with_gradienttape/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lhrft8/nangradients_with_gradienttape/,22217,1613069040.0,0,,False,,,,,,,,,
104,,tensorflow,,t2_7ue4oltt,False,,0,False,"Used my library Handsfree.js to remix ""Piano Genie"" so that you can generate music handsfree with Magenta.js. Source and info in comments!",[],r/tensorflow,False,6,,0,78.0,,False,t3_lh7lae,False,dark,0.94,,public,24,1,{},140.0,,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/2yv4nlrtmqg61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/2yv4nlrtmqg61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/2yv4nlrtmqg61/DASHPlaylist.mpd?a=1618044670%2CMmM5M2FjMWM1Y2UzNDIwZWZiMjY4NjM0NDM0Y2UyMjM3ZTAxZDEzOGJhMDY0N2JkYmRmMDI4ZjcyNmI3MGM2ZQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 23, 'hls_url': 'https://v.redd.it/2yv4nlrtmqg61/HLSPlaylist.m3u8?a=1618044670%2CYmYzMmVjOTVhMDBmMWY0ODkyYTBhYzYzNjc2MGI4YzEyYzJiYzkwODg3ZjAwZWQzODFlYTBkNjI0ZDFmNzFlNw%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},Project,False,24,,True,https://b.thumbs.redditmedia.com/oc556jR8cmKLXeGF2QqGpTiZ5isDzWmOkNfFmJnEERA.jpg,False,,[],{},,False,,1613029907.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lh7lae,True,,MIDIBlocks,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lh7lae/used_my_library_handsfreejs_to_remix_piano_genie/,all_ads,False,https://v.redd.it/2yv4nlrtmqg61,22217,1613001107.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/2yv4nlrtmqg61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/2yv4nlrtmqg61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/2yv4nlrtmqg61/DASHPlaylist.mpd?a=1618044670%2CMmM5M2FjMWM1Y2UzNDIwZWZiMjY4NjM0NDM0Y2UyMjM3ZTAxZDEzOGJhMDY0N2JkYmRmMDI4ZjcyNmI3MGM2ZQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 23, 'hls_url': 'https://v.redd.it/2yv4nlrtmqg61/HLSPlaylist.m3u8?a=1618044670%2CYmYzMmVjOTVhMDBmMWY0ODkyYTBhYzYzNjc2MGI4YzEyYzJiYzkwODg3ZjAwZWQzODFlYTBkNjI0ZDFmNzFlNw%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/2yv4nlrtmqg61,"{'images': [{'source': {'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?format=pjpg&amp;auto=webp&amp;s=8c94ed6baa7e93e82fe1a5d303cfd531388c7a0b', 'width': 1920, 'height': 1080}, 'resolutions': [{'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0074b2d9ebac4f9c1e2e551565f655dfe38fce46', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4552272ea1cb61be713a56339f50a388b0d201de', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a5e89d5f0b56db9afd8892122232d81862f30419', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a9012046e6bb4c37f9b547ccf40be6084217e104', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=dd74bd54443b341c8c790b03adb8d9f4a7eab918', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/AMGAjRMcW8xJJdwa6Fr_DOoJFivB6FTuy84-1hBv454.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c0258b546fd0ea298417d0a543baddd4b02d5a1b', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '0NTvX1G4b6K3zaHnbVQUqDR5g3WFxxMeKclIDppr2b4'}], 'enabled': False}",,,,,,
105,,tensorflow,"I am wondering if it is safe to send a job to the GPU while it is in use for a job started in another thread. Does it just wait for the job to finish and then complete the next job? My main concern is data integrity, would there be any issues with multiple threads calling the GPU?",t2_6qvny,False,,0,False,How does TF-gpu behave when predict() is called from different threads?,[],r/tensorflow,False,6,,0,,,False,t3_lh91p5,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1613034243.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am wondering if it is safe to send a job to the GPU while it is in use for a job started in another thread. Does it just wait for the job to finish and then complete the next job? My main concern is data integrity, would there be any issues with multiple threads calling the GPU?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lh91p5,True,,Yogi_DMT,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lh91p5/how_does_tfgpu_behave_when_predict_is_called_from/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lh91p5/how_does_tfgpu_behave_when_predict_is_called_from/,22217,1613005443.0,0,,False,,,,,,,,,
106,,tensorflow,"I might be in over my head on this, but I was hoping to install tensorflow gpu enabled. I saw on the Tensorflow [website](https://www.tensorflow.org/install/gpu) that it's required to have cuda 11 which needs drivers of 450.x or higher. Am I out of luck on this?

https://preview.redd.it/dsm2bzbugsg61.png?width=1107&amp;format=png&amp;auto=webp&amp;s=9b187764c174bafb871290fbe7bafde936ca8243",t2_1hhi911s,False,,0,False,Beginner Question about Enabling GPU,[],r/tensorflow,False,6,,0,59.0,,False,t3_lhed26,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://a.thumbs.redditmedia.com/QKP2R9lyhcYY-qvp441xtzgnJy8l1ex1vVZbSZl_Nj8.jpg,False,,[],{},,True,,1613052236.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I might be in over my head on this, but I was hoping to install tensorflow gpu enabled. I saw on the Tensorflow &lt;a href=""https://www.tensorflow.org/install/gpu""&gt;website&lt;/a&gt; that it&amp;#39;s required to have cuda 11 which needs drivers of 450.x or higher. Am I out of luck on this?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/dsm2bzbugsg61.png?width=1107&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9b187764c174bafb871290fbe7bafde936ca8243""&gt;https://preview.redd.it/dsm2bzbugsg61.png?width=1107&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9b187764c174bafb871290fbe7bafde936ca8243&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lhed26,True,,ImaJimmy,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/lhed26/beginner_question_about_enabling_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lhed26/beginner_question_about_enabling_gpu/,22217,1613023436.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,"{'dsm2bzbugsg61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 46, 'x': 108, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=35b8f35e11e016aab5c5447c00656f055f93a22f'}, {'y': 92, 'x': 216, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b454ca44592275e0d7516df9f7dd91ebccb0c503'}, {'y': 136, 'x': 320, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7ed260b2088c8e2e7e323285aa1b3154e1b59a2'}, {'y': 272, 'x': 640, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d3556d0be637c0fe77f306a76f6dadee80edf10b'}, {'y': 409, 'x': 960, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f092db397a1f6d25429f0d65c4d38411b88a895f'}, {'y': 460, 'x': 1080, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53360791a035f5c623a707fe8470dc8b182fb708'}], 's': {'y': 472, 'x': 1107, 'u': 'https://preview.redd.it/dsm2bzbugsg61.png?width=1107&amp;format=png&amp;auto=webp&amp;s=9b187764c174bafb871290fbe7bafde936ca8243'}, 'id': 'dsm2bzbugsg61'}}",,,,
107,,tensorflow,,t2_1ffz9tjt,False,,0,False,Minimal implementation of SSD: Single Shot MultiBox Detector,[],r/tensorflow,False,6,,0,78.0,,False,t3_lh70nd,False,dark,0.56,,public,1,0,{},140.0,,False,[],,False,False,,{},Project,False,1,,False,https://b.thumbs.redditmedia.com/y0j-8XAX5M8SnSHVcWG5Pc9hNffSo_vCb88Vnzr1D8w.jpg,False,,[],{},,False,,1613028337.0,text,6,,,text,reddit.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lh70nd,True,,1991viet,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lh70nd/minimal_implementation_of_ssd_single_shot/,all_ads,False,https://www.reddit.com/gallery/lh70nd,22217,1612999537.0,0,,False,,https://www.reddit.com/gallery/lh70nd,,True,"{'avkcpjv6iqg61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/avkcpjv6iqg61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=687f741296fc14c84b9a4f5c2ab793aaea7fb8ee'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/avkcpjv6iqg61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=91ff2242a368447b83688e7bfd4f6b0c505ed8c9'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/avkcpjv6iqg61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=f67c21610f361dafdb7cd9ee252bdd5e70214697'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/avkcpjv6iqg61.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=947cc1b0d74ca9bd7d6989249f2a30a8d7516cda'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/avkcpjv6iqg61.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=6bb1e972694e5d2d7cc6bd64c392b16a08947d99'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/avkcpjv6iqg61.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=44c9a27440d54802ab6f2dd0bcfa87a9929f8146'}], 's': {'y': 720, 'gif': 'https://i.redd.it/avkcpjv6iqg61.gif', 'mp4': 'https://preview.redd.it/avkcpjv6iqg61.gif?format=mp4&amp;s=b720e2a12190e56144378a7a0e0ca9aeff1bf5cd', 'x': 1280}, 'id': 'avkcpjv6iqg61'}, 'dkeuftt6iqg61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 71, 'x': 108, 'u': 'https://preview.redd.it/dkeuftt6iqg61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=883e3457117451ebeb3867b233a38cfd63e9d3a7'}, {'y': 143, 'x': 216, 'u': 'https://preview.redd.it/dkeuftt6iqg61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2826c7141e89706cee98dd14a69d5d3a6652cb4e'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/dkeuftt6iqg61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9a67e1aae97a0fe8f38f5f586aeedc9d9ab798f'}], 's': {'y': 333, 'x': 500, 'u': 'https://preview.redd.it/dkeuftt6iqg61.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;s=e32570e3b60ca692a5aa8abc1cd373e7ab4201c8'}, 'id': 'dkeuftt6iqg61'}, '0e309pt6iqg61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/0e309pt6iqg61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=877230b0565cda778d9b4effc8e0e98073cb0839'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/0e309pt6iqg61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2132edfb2c8b01bf0617e87c1127cc3475c5e58d'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/0e309pt6iqg61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=523c0df622c098a4a709c46dde28c35dd74a1a66'}], 's': {'y': 612, 'x': 612, 'u': 'https://preview.redd.it/0e309pt6iqg61.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;s=01a923df5c93e3f6bfb93ce41722b6d0a4efd219'}, 'id': '0e309pt6iqg61'}, 'r9uhzlt6iqg61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 204, 'x': 108, 'u': 'https://preview.redd.it/r9uhzlt6iqg61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=68ad24e1c6d578a650098f5a8b23a14095a1bfd9'}, {'y': 409, 'x': 216, 'u': 'https://preview.redd.it/r9uhzlt6iqg61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f3bb67faca530f1081d3069ddbcd1089c9835f6'}, {'y': 606, 'x': 320, 'u': 'https://preview.redd.it/r9uhzlt6iqg61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c8610a77b94156c2c6cc2daf93af9baf3aa6e1bd'}], 's': {'y': 699, 'x': 369, 'u': 'https://preview.redd.it/r9uhzlt6iqg61.png?width=369&amp;format=png&amp;auto=webp&amp;s=bd2ad2480885feea175453d4dc8d177620a24cf3'}, 'id': 'r9uhzlt6iqg61'}, '4g92nmt6iqg61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 32, 'x': 108, 'u': 'https://preview.redd.it/4g92nmt6iqg61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=08c72a3cd18929af9ffcd61d19edfb0cb07f05c4'}, {'y': 64, 'x': 216, 'u': 'https://preview.redd.it/4g92nmt6iqg61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d29abad9bfe98b175ecb21c14e80a3f9dd745b8'}, {'y': 95, 'x': 320, 'u': 'https://preview.redd.it/4g92nmt6iqg61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=78b67d641e3d7e0f93cf228e5106c344017ca43d'}, {'y': 190, 'x': 640, 'u': 'https://preview.redd.it/4g92nmt6iqg61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aecf6b0c6cc22a0c6e3c42c254160fd57d4b167a'}], 's': {'y': 216, 'x': 726, 'u': 'https://preview.redd.it/4g92nmt6iqg61.png?width=726&amp;format=png&amp;auto=webp&amp;s=cdbaca9916299bf1ca8d6636a7a3686cda2f7577'}, 'id': '4g92nmt6iqg61'}}","{'items': [{'media_id': 'avkcpjv6iqg61', 'id': 27256358}, {'media_id': 'dkeuftt6iqg61', 'id': 27256359}, {'media_id': '0e309pt6iqg61', 'id': 27256360}, {'media_id': 'r9uhzlt6iqg61', 'id': 27256361}, {'media_id': '4g92nmt6iqg61', 'id': 27256362}]}",,,
108,,tensorflow,,t2_68tp0yii,False,,0,False,Checkout my new Tensorflow Lite app: Palapa! Social network meets active learning to empower communities to create computer vision AIs.,[],r/tensorflow,False,6,,0,105.0,,False,t3_lhc70f,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/H1ZZsO8oJSE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Automate your setup with artificial intelligence', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/H1ZZsO8oJSE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Palapa', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/H1ZZsO8oJSE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_Kber2ZFb4fR0NSqABKh_g'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/H1ZZsO8oJSE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lhc70f', 'height': 200}",,False,1,,False,https://a.thumbs.redditmedia.com/Fhgh5GbgLCXTRwnDw2wixElDXvMixwOtKq2UafQYlO0.jpg,False,,[],{},,False,,1613044192.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lhc70f,True,,saad2xi,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lhc70f/checkout_my_new_tensorflow_lite_app_palapa_social/,all_ads,False,https://youtu.be/H1ZZsO8oJSE,22217,1613015392.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Automate your setup with artificial intelligence', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/H1ZZsO8oJSE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Palapa', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/H1ZZsO8oJSE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_Kber2ZFb4fR0NSqABKh_g'}}",False,rich:video,https://youtu.be/H1ZZsO8oJSE,"{'images': [{'source': {'url': 'https://external-preview.redd.it/XRM4x0RWa8HiLM6kNLcw33MRJsxJ_VOYeW3LwVgj0CI.jpg?auto=webp&amp;s=4c9c46c8b155ba26c96cb9f5302aa180229338f5', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/XRM4x0RWa8HiLM6kNLcw33MRJsxJ_VOYeW3LwVgj0CI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=288e52a31e5dc3812c6559014956ad83bf69c1f6', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/XRM4x0RWa8HiLM6kNLcw33MRJsxJ_VOYeW3LwVgj0CI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=416b7c7c5b81ccb2ffdbd15ad4a9cf779d823db6', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/XRM4x0RWa8HiLM6kNLcw33MRJsxJ_VOYeW3LwVgj0CI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9bb576de6301103b592930e7bd158f16e330262f', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'p2QrWjXsJU2exuus4YWxmenfdeRB05vOG71K_c3fH4Y'}], 'enabled': False}",,,,,,
109,,tensorflow,"I am a beginner in machine learning and have created a sequential model using tf keras. I am confused on how to use my\_model to get a predictions based on one instance. The model uses 4 features columns and tries to determine the label ""diff"". I have posted the model code for context. The following code is from google machine learning crash course and my model is able to be compiled. I am confused on how to use the generated model to predict a value. My model code will be posted under the prediction code(calling my model)

&amp;#x200B;

&amp;#x200B;

    x={'homePAG':np.int64(7), 'awayPAG':np.int64(7), 'homePPG':np.int64(7), 'awayPPG':np.int64(7)}
    my_model.predict(x)

The error given is : 

&gt;ValueError: Failed to find data adapter that can handle input: (&lt;class 'dict'&gt; containing {""&lt;class 'str'&gt;""} keys and {""&lt;class 'numpy.int64'&gt;""} values), &lt;class 'NoneType'&gt;

Attempting to change the shape:

    z=np.array([[10,10,10,10]])
    my_model.predict(z)

&gt;ValueError: ('We expected a dictionary here. Instead we got: ', &lt;tf.Tensor 'IteratorGetNext:0' shape=(None, 4) dtype=int64&gt;) 

&amp;#x200B;

Below is the model code from google crashcourse with machine learning.

    
    feature_columns = []
    
    homePAG = tf.feature_column.numeric_column(""homePAG"")
    feature_columns.append(homePAG)
    
    awayPAG = tf.feature_column.numeric_column(""awayPAG"")
    feature_columns.append(awayPAG)
    
    homePPG = tf.feature_column.numeric_column(""homePPG"")
    feature_columns.append(homePPG)
    
    awayPPG = tf.feature_column.numeric_column(""awayPPG"")
    feature_columns.append(awayPPG)
    
    fp_feature_layer = layers.DenseFeatures(feature_columns)
    
    def create_model(my_learning_rate, feature_layer):
      """"""Create and compile a simple linear regression model.""""""
      # Most simple tf.keras models are sequential.
      model = tf.keras.models.Sequential()
    
      # Add the layer containing the feature columns to the model.
      model.add(feature_layer)
    
      # Add one linear layer to the model to yield a simple linear regressor.
      model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))
    
      # Construct the layers into a model that TensorFlow can execute.
      model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),
                    loss=""mean_squared_error"",
                    metrics=[tf.keras.metrics.RootMeanSquaredError()])
    
      return model           
    
    
    def train_model(model, dataset, epochs, batch_size, label_name):
      """"""Feed a dataset into the model in order to train it.""""""
    
      features = {name:np.array(value) for name, value in dataset.items()}
      label = np.array(features.pop(label_name))
      history = model.fit(x=features, y=label, batch_size=batch_size,
                          epochs=epochs, shuffle=True)
    
      # The list of epochs is stored separately from the rest of history.
      epochs = history.epoch
      
      # Isolate the mean absolute error for each epoch.
      hist = pd.DataFrame(history.history)
      rmse = hist[""root_mean_squared_error""]
    
      return epochs, rmse   
    
    
    def plot_the_loss_curve(epochs, rmse):
      """"""Plot a curve of loss vs. epoch.""""""
    
      plt.figure()
      plt.xlabel(""Epoch"")
      plt.ylabel(""Root Mean Squared Error"")
    
      plt.plot(epochs, rmse, label=""Loss"")
      plt.legend()
      plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])
      plt.show()  
    
    print(""Defined the create_model, train_model, and plot_the_loss_curve functions."")
    
    # The following variables are the hyperparameters.
    learning_rate = 0.01
    epochs = 10
    batch_size = 75
    label_name = 'diff'
    
    # Create and compile the model's topography.
    my_model = create_model(learning_rate, fp_feature_layer)
    
    # Train the model on the training set.
    epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)
    
    plot_the_loss_curve(epochs, rmse)
    
    print(""\n: Evaluate the new model against the test set:"")
    test_features = {name:np.array(value) for name, value in test_df.items()}
    test_label = np.array(test_features.pop(label_name))
    #test_label=tf.convert_to_tensor(test_label)
    my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)
    For this code I receive error :
    
    

Thanks in advance!",t2_4o67fdjz,False,,0,False,Unable to predict with tf.keras sequential model,[],r/tensorflow,False,6,,0,,,False,t3_lh6omo,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1613027405.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a beginner in machine learning and have created a sequential model using tf keras. I am confused on how to use my_model to get a predictions based on one instance. The model uses 4 features columns and tries to determine the label &amp;quot;diff&amp;quot;. I have posted the model code for context. The following code is from google machine learning crash course and my model is able to be compiled. I am confused on how to use the generated model to predict a value. My model code will be posted under the prediction code(calling my model)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x={&amp;#39;homePAG&amp;#39;:np.int64(7), &amp;#39;awayPAG&amp;#39;:np.int64(7), &amp;#39;homePPG&amp;#39;:np.int64(7), &amp;#39;awayPPG&amp;#39;:np.int64(7)}
my_model.predict(x)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The error given is : &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ValueError: Failed to find data adapter that can handle input: (&amp;lt;class &amp;#39;dict&amp;#39;&amp;gt; containing {&amp;quot;&amp;lt;class &amp;#39;str&amp;#39;&amp;gt;&amp;quot;} keys and {&amp;quot;&amp;lt;class &amp;#39;numpy.int64&amp;#39;&amp;gt;&amp;quot;} values), &amp;lt;class &amp;#39;NoneType&amp;#39;&amp;gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Attempting to change the shape:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;z=np.array([[10,10,10,10]])
my_model.predict(z)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;ValueError: (&amp;#39;We expected a dictionary here. Instead we got: &amp;#39;, &amp;lt;tf.Tensor &amp;#39;IteratorGetNext:0&amp;#39; shape=(None, 4) dtype=int64&amp;gt;) &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Below is the model code from google crashcourse with machine learning.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;feature_columns = []

homePAG = tf.feature_column.numeric_column(&amp;quot;homePAG&amp;quot;)
feature_columns.append(homePAG)

awayPAG = tf.feature_column.numeric_column(&amp;quot;awayPAG&amp;quot;)
feature_columns.append(awayPAG)

homePPG = tf.feature_column.numeric_column(&amp;quot;homePPG&amp;quot;)
feature_columns.append(homePPG)

awayPPG = tf.feature_column.numeric_column(&amp;quot;awayPPG&amp;quot;)
feature_columns.append(awayPPG)

fp_feature_layer = layers.DenseFeatures(feature_columns)

def create_model(my_learning_rate, feature_layer):
  &amp;quot;&amp;quot;&amp;quot;Create and compile a simple linear regression model.&amp;quot;&amp;quot;&amp;quot;
  # Most simple tf.keras models are sequential.
  model = tf.keras.models.Sequential()

  # Add the layer containing the feature columns to the model.
  model.add(feature_layer)

  # Add one linear layer to the model to yield a simple linear regressor.
  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))

  # Construct the layers into a model that TensorFlow can execute.
  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),
                loss=&amp;quot;mean_squared_error&amp;quot;,
                metrics=[tf.keras.metrics.RootMeanSquaredError()])

  return model           


def train_model(model, dataset, epochs, batch_size, label_name):
  &amp;quot;&amp;quot;&amp;quot;Feed a dataset into the model in order to train it.&amp;quot;&amp;quot;&amp;quot;

  features = {name:np.array(value) for name, value in dataset.items()}
  label = np.array(features.pop(label_name))
  history = model.fit(x=features, y=label, batch_size=batch_size,
                      epochs=epochs, shuffle=True)

  # The list of epochs is stored separately from the rest of history.
  epochs = history.epoch

  # Isolate the mean absolute error for each epoch.
  hist = pd.DataFrame(history.history)
  rmse = hist[&amp;quot;root_mean_squared_error&amp;quot;]

  return epochs, rmse   


def plot_the_loss_curve(epochs, rmse):
  &amp;quot;&amp;quot;&amp;quot;Plot a curve of loss vs. epoch.&amp;quot;&amp;quot;&amp;quot;

  plt.figure()
  plt.xlabel(&amp;quot;Epoch&amp;quot;)
  plt.ylabel(&amp;quot;Root Mean Squared Error&amp;quot;)

  plt.plot(epochs, rmse, label=&amp;quot;Loss&amp;quot;)
  plt.legend()
  plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])
  plt.show()  

print(&amp;quot;Defined the create_model, train_model, and plot_the_loss_curve functions.&amp;quot;)

# The following variables are the hyperparameters.
learning_rate = 0.01
epochs = 10
batch_size = 75
label_name = &amp;#39;diff&amp;#39;

# Create and compile the model&amp;#39;s topography.
my_model = create_model(learning_rate, fp_feature_layer)

# Train the model on the training set.
epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)

plot_the_loss_curve(epochs, rmse)

print(&amp;quot;\n: Evaluate the new model against the test set:&amp;quot;)
test_features = {name:np.array(value) for name, value in test_df.items()}
test_label = np.array(test_features.pop(label_name))
#test_label=tf.convert_to_tensor(test_label)
my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)
For this code I receive error :
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lh6omo,True,,RS_Tnap,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lh6omo/unable_to_predict_with_tfkeras_sequential_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lh6omo/unable_to_predict_with_tfkeras_sequential_model/,22217,1612998605.0,0,,False,,,,,,,,,
110,,tensorflow,,t2_6jmxg,False,,0,False,I want to add another step here where after reading the images the dataset is split into the image (X) and the BBox (Y) information as TensorFlow objects for RESNET50. Should I index through the ds_train or there is a better way. Thank you.,[],r/tensorflow,False,6,,0,,,False,t3_lgw5iy,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,default,False,,[],{},,False,,1613000072.0,text,6,,,text,reddit.com,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lgw5iy,True,,dirtygrip,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lgw5iy/i_want_to_add_another_step_here_where_after/,all_ads,False,https://www.reddit.com/gallery/lgw5iy,22217,1612971272.0,0,,False,,https://www.reddit.com/gallery/lgw5iy,,True,"{'wuq39vh65og61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 16, 'x': 108, 'u': 'https://preview.redd.it/wuq39vh65og61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=425a7fb47615eebe762d5e6a3c6873f3216bd684'}, {'y': 32, 'x': 216, 'u': 'https://preview.redd.it/wuq39vh65og61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1310528aeb8f5da68e9df3073f93c0f2e1338814'}, {'y': 48, 'x': 320, 'u': 'https://preview.redd.it/wuq39vh65og61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f810896b4b0236cdc430343250425efc47434772'}, {'y': 96, 'x': 640, 'u': 'https://preview.redd.it/wuq39vh65og61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=50b20ba13ce717a550ed50f50458c9b012a08fd4'}], 's': {'y': 110, 'x': 730, 'u': 'https://preview.redd.it/wuq39vh65og61.png?width=730&amp;format=png&amp;auto=webp&amp;s=de6e4f287f553377c768a6e9b2797f480dd30719'}, 'id': 'wuq39vh65og61'}, 'dqjji4c85og61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 14, 'x': 108, 'u': 'https://preview.redd.it/dqjji4c85og61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b07b041bbe7765a1d281e55a66edeeac458a9bbc'}, {'y': 29, 'x': 216, 'u': 'https://preview.redd.it/dqjji4c85og61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5d137b70e1b9e751f9d3a3fff37e9c85c811bb0'}, {'y': 43, 'x': 320, 'u': 'https://preview.redd.it/dqjji4c85og61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=493bc2b889b0c6fefede066ffe803e4502e59b2c'}], 's': {'y': 63, 'x': 463, 'u': 'https://preview.redd.it/dqjji4c85og61.png?width=463&amp;format=png&amp;auto=webp&amp;s=95593fd490c652e5c41f75e310509dff0d545c25'}, 'id': 'dqjji4c85og61'}}","{'items': [{'caption': 'Image read function', 'media_id': 'wuq39vh65og61', 'id': 27179175}, {'media_id': 'dqjji4c85og61', 'id': 27179176}]}",,,
111,,tensorflow,"Hello all !

Is it possible to train tensorflow to recognize certain data in a text such as a city, brand names, etc.?

I'm just starting out, do you have good resources for this kind of word processing?

&amp;#x200B;

Thank you for your answers ;)",t2_15o843,False,,0,False,Recognition of a text type,[],r/tensorflow,False,6,,0,,,False,t3_lgqiau,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1612979930.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all !&lt;/p&gt;

&lt;p&gt;Is it possible to train tensorflow to recognize certain data in a text such as a city, brand names, etc.?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m just starting out, do you have good resources for this kind of word processing?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you for your answers ;)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lgqiau,True,,Romaixn,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/lgqiau/recognition_of_a_text_type/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lgqiau/recognition_of_a_text_type/,22217,1612951130.0,0,,False,,,,,,,,,
112,,tensorflow,,t2_4inj0xvu,False,,0,False,Emotion Detection on Reddit with Neuronal Networks,[],r/tensorflow,False,6,,0,78.0,,False,t3_lg0r43,False,dark,0.87,,public,12,0,{},140.0,,False,[],,False,False,,{},,False,12,,False,https://b.thumbs.redditmedia.com/XAj-vzJ5gfEY9NYEhs3g2LucjUNPdQ6sP8hWqfJR7mM.jpg,False,,[],{},,False,,1612898377.0,text,6,,,text,linkedin.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lg0r43,True,,edthyme,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lg0r43/emotion_detection_on_reddit_with_neuronal_networks/,all_ads,False,https://www.linkedin.com/pulse/emotion-detection-reddit-neuronal-networks-eduard-cimbru/?published=t&amp;trackingId=kyZPFrm4QPiP9w3Y4q14Lw%3D%3D,22217,1612869577.0,0,,False,link,https://www.linkedin.com/pulse/emotion-detection-reddit-neuronal-networks-eduard-cimbru/?published=t&amp;trackingId=kyZPFrm4QPiP9w3Y4q14Lw%3D%3D,"{'images': [{'source': {'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?auto=webp&amp;s=ab6e594b7e671abf725697acd6e0eff8b9dcecf0', 'width': 1280, 'height': 720}, 'resolutions': [{'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b92626c319c3af3ae1a85e200096d50d483b6c9a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d36fe6d7410383078306efb08e7441233219ea48', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45ee23936413d492f315856f5e2e7c0f0bcfb49f', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8681f827c6f8fae2bda21e34a51f666717227c57', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=916a0d9057c06070e3115beefacd11f4ef58b10e', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/TxD5luOcpCXfgw8YOkh9MvUemZo1andqGPgJQksS-Q4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a76b98787290f8942fddc36add82213611a6f3c0', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '8HmYlXatrK3nYYH3FmEVWf-GJHD73hJCd7S5OXInjRI'}], 'enabled': False}",,,,,,
113,,tensorflow,"I am using tensorflow 2.4.1 with numpy 1.20.0, and I am trying to create a model using LSTM.

    model = Sequential()
    model.add(LSTM(256, input_shape=(1, 66), return_sequences=True ))

Adding that LSTM layer gives me this error:

    Traceback (most recent call last):
      File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 517, in _method_wrapper
        result = method(self, *args, **kwargs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py"", line 208, in add
        layer(x)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 660, in __call__
        return super(RNN, self).__call__(inputs, **kwargs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 951, in __call__
        return self._functional_construction_call(inputs, args, kwargs,
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1090, in _functional_construction_call
        outputs = self._keras_tensor_symbolic_call(
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 822, in _keras_tensor_symbolic_call
        return self._infer_output_signature(inputs, args, kwargs, input_masks)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 863, in _infer_output_signature
        outputs = call_fn(inputs, *args, **kwargs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py"", line 1157, in call
        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 859, in _process_inputs
        initial_state = self.get_initial_state(inputs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 642, in get_initial_state
        init_state = get_initial_state_fn(
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 2506, in get_initial_state
        return list(_generate_zero_filled_state_for_cell(
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 2987, in _generate_zero_filled_state_for_cell
        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 3003, in _generate_zero_filled_state
        return nest.map_structure(create_zeros, state_size)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py"", line 659, in map_structure
        structure[0], [func(*x) for x in entries],
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py"", line 659, in &lt;listcomp&gt;
        structure[0], [func(*x) for x in entries],
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py"", line 3000, in create_zeros
        return array_ops.zeros(init_state_size, dtype=dtype)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 201, in wrapper
        return target(*args, **kwargs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 2819, in wrapped
        tensor = fun(*args, **kwargs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 2868, in zeros
        output = _constant_if_small(zero, shape, dtype, name)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 2804, in _constant_if_small
        if np.prod(shape) &lt; 1000:
      File ""&lt;__array_function__ internals&gt;"", line 5, in prod
      File ""/home/sakuya/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py"", line 3030, in prod
        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,
      File ""/home/sakuya/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py"", line 87, in _wrapreduction
        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
      File ""/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 852, in __array__
        raise NotImplementedError(
    NotImplementedError: Cannot convert a symbolic Tensor (lstm_19/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported

I have no idea where I am going wrong here, but I can add the layer if I do not specify the input shape, but I need to do that.",t2_57bsp,False,,0,False,Numpy-related error when building model,[],r/tensorflow,False,6,,0,,,False,t3_lgcgby,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1612930848.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using tensorflow 2.4.1 with numpy 1.20.0, and I am trying to create a model using LSTM.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = Sequential()
model.add(LSTM(256, input_shape=(1, 66), return_sequences=True ))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Adding that LSTM layer gives me this error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Traceback (most recent call last):
  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py&amp;quot;, line 517, in _method_wrapper
    result = method(self, *args, **kwargs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py&amp;quot;, line 208, in add
    layer(x)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 660, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&amp;quot;, line 951, in __call__
    return self._functional_construction_call(inputs, args, kwargs,
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&amp;quot;, line 1090, in _functional_construction_call
    outputs = self._keras_tensor_symbolic_call(
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&amp;quot;, line 822, in _keras_tensor_symbolic_call
    return self._infer_output_signature(inputs, args, kwargs, input_masks)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&amp;quot;, line 863, in _infer_output_signature
    outputs = call_fn(inputs, *args, **kwargs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py&amp;quot;, line 1157, in call
    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 859, in _process_inputs
    initial_state = self.get_initial_state(inputs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 642, in get_initial_state
    init_state = get_initial_state_fn(
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 2506, in get_initial_state
    return list(_generate_zero_filled_state_for_cell(
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 2987, in _generate_zero_filled_state_for_cell
    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 3003, in _generate_zero_filled_state
    return nest.map_structure(create_zeros, state_size)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py&amp;quot;, line 659, in map_structure
    structure[0], [func(*x) for x in entries],
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py&amp;quot;, line 659, in &amp;lt;listcomp&amp;gt;
    structure[0], [func(*x) for x in entries],
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py&amp;quot;, line 3000, in create_zeros
    return array_ops.zeros(init_state_size, dtype=dtype)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py&amp;quot;, line 201, in wrapper
    return target(*args, **kwargs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py&amp;quot;, line 2819, in wrapped
    tensor = fun(*args, **kwargs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py&amp;quot;, line 2868, in zeros
    output = _constant_if_small(zero, shape, dtype, name)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py&amp;quot;, line 2804, in _constant_if_small
    if np.prod(shape) &amp;lt; 1000:
  File &amp;quot;&amp;lt;__array_function__ internals&amp;gt;&amp;quot;, line 5, in prod
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py&amp;quot;, line 3030, in prod
    return _wrapreduction(a, np.multiply, &amp;#39;prod&amp;#39;, axis, dtype, out,
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py&amp;quot;, line 87, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
  File &amp;quot;/home/sakuya/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py&amp;quot;, line 852, in __array__
    raise NotImplementedError(
NotImplementedError: Cannot convert a symbolic Tensor (lstm_19/strided_slice:0) to a numpy array. This error may indicate that you&amp;#39;re trying to pass a Tensor to a NumPy call, which is not supported
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have no idea where I am going wrong here, but I can add the layer if I do not specify the input shape, but I need to do that.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lgcgby,True,,lastorder,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/lgcgby/numpyrelated_error_when_building_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lgcgby/numpyrelated_error_when_building_model/,22217,1612902048.0,0,,False,,,,,,,,,
114,,tensorflow,"I am trying to implement a simple bayes by backprop regression using the following tutorial

`\``[`http://krasserm.github.io/2019/03/14/bayesian-neural-networks/`](http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)`\``

But my regressor is no where near learning. below is my model, can anyone suggest a simple implementation of the tutorial?

\`\`\`

def prior(kernel\_size, bias\_size, dtype=None):  
n = kernel\_size + bias\_size  
prior\_model = tf.keras.Sequential(\[  
tfp.layers.DistributionLambda(  
 lambda t:tfd.MultivariateNormalDiag(loc=tf.zeros(n), scale\_diag=tf.ones(n))  
)  
\])  
 return prior\_model  
def posterior(kernel\_size, bias\_size,dtype=None):  
n = kernel\_size + bias\_size  
posterior\_model = tf.keras.Sequential(\[  
tfp.layers.VariableLayer(tfp.layers.MultivariateNormalTriL.params\_size(n),dtype=dtype),  
tfp.layers.MultivariateNormalTriL(n)  
\])  
 return posterior\_model  
model = tf.keras.Sequential(\[  
tfp.layers.DenseVariational(units=20,input\_shape=(1,),make\_prior\_fn=prior, make\_posterior\_fn=posterior,kl\_weight=1/x\_train.shape\[0\]),  
tf.keras.layers.ReLU(),  
tfp.layers.DenseVariational(units=20,make\_prior\_fn=prior, make\_posterior\_fn=posterior,kl\_weight=1/x\_train.shape\[0\]),  
tfp.layers.DenseVariational(units=1,make\_prior\_fn=prior, make\_posterior\_fn=posterior,kl\_weight=1/x\_train.shape\[0\])  
\])  
model.compile(loss=tf.keras.losses.MeanSquaredError() , optimizer=tf.keras.optimizers.Adam(lr=0.001),metrics=\['mae'\])  
print(model.summary())  
history = model.fit(x\_train, y\_train, batch\_size=batch\_size, epochs=500,verbose=2)

\`\`\`",t2_9za0dnh8,False,,0,False,Bayes by backprop implementation using tfp,[],r/tensorflow,False,6,,0,,,False,t3_lfxipy,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1612885533.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to implement a simple bayes by backprop regression using the following tutorial&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\&lt;/code&gt;&lt;code&gt;[&lt;/code&gt;&lt;a href=""http://krasserm.github.io/2019/03/14/bayesian-neural-networks/%60%5D(http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)%60%5C%60%60""&gt;http://krasserm.github.io/2019/03/14/bayesian-neural-networks/`](http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)`\``&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But my regressor is no where near learning. below is my model, can anyone suggest a simple implementation of the tutorial?&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;def prior(kernel_size, bias_size, dtype=None):&lt;br/&gt;
n = kernel_size + bias_size&lt;br/&gt;
prior_model = tf.keras.Sequential([&lt;br/&gt;
tfp.layers.DistributionLambda(&lt;br/&gt;
 lambda t:tfd.MultivariateNormalDiag(loc=tf.zeros(n), scale_diag=tf.ones(n))&lt;br/&gt;
)&lt;br/&gt;
])&lt;br/&gt;
 return prior_model&lt;br/&gt;
def posterior(kernel_size, bias_size,dtype=None):&lt;br/&gt;
n = kernel_size + bias_size&lt;br/&gt;
posterior_model = tf.keras.Sequential([&lt;br/&gt;
tfp.layers.VariableLayer(tfp.layers.MultivariateNormalTriL.params_size(n),dtype=dtype),&lt;br/&gt;
tfp.layers.MultivariateNormalTriL(n)&lt;br/&gt;
])&lt;br/&gt;
 return posterior_model&lt;br/&gt;
model = tf.keras.Sequential([&lt;br/&gt;
tfp.layers.DenseVariational(units=20,input_shape=(1,),make_prior_fn=prior, make_posterior_fn=posterior,kl_weight=1/x_train.shape[0]),&lt;br/&gt;
tf.keras.layers.ReLU(),&lt;br/&gt;
tfp.layers.DenseVariational(units=20,make_prior_fn=prior, make_posterior_fn=posterior,kl_weight=1/x_train.shape[0]),&lt;br/&gt;
tfp.layers.DenseVariational(units=1,make_prior_fn=prior, make_posterior_fn=posterior,kl_weight=1/x_train.shape[0])&lt;br/&gt;
])&lt;br/&gt;
model.compile(loss=tf.keras.losses.MeanSquaredError() , optimizer=tf.keras.optimizers.Adam(lr=0.001),metrics=[&amp;#39;mae&amp;#39;])&lt;br/&gt;
print(model.summary())&lt;br/&gt;
history = model.fit(x_train, y_train, batch_size=batch_size, epochs=500,verbose=2)&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lfxipy,True,,_tfp_beginner,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lfxipy/bayes_by_backprop_implementation_using_tfp/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lfxipy/bayes_by_backprop_implementation_using_tfp/,22217,1612856733.0,0,,False,,,,,,,,,
115,,tensorflow,"I passed the tensorflow in Nov 2020. I can't find a way to show my profile on the network. Anyone could show me how to do it please? Thanks very much!

[https://developers.google.com/certification/directory/tensorflow](https://developers.google.com/certification/directory/tensorflow)",t2_1hcpfl3g,False,,0,False,How to show my profile on TensorFlow Certificate Network when I passed the exam?,[],r/tensorflow,False,6,,0,,,False,t3_lfnzvd,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1612852997.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I passed the tensorflow in Nov 2020. I can&amp;#39;t find a way to show my profile on the network. Anyone could show me how to do it please? Thanks very much!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://developers.google.com/certification/directory/tensorflow""&gt;https://developers.google.com/certification/directory/tensorflow&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lfnzvd,True,,Winnie0123,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lfnzvd/how_to_show_my_profile_on_tensorflow_certificate/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lfnzvd/how_to_show_my_profile_on_tensorflow_certificate/,22217,1612824197.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?auto=webp&amp;s=9ce9682d3f6ebc0f09f836bb40af23b31aeac627', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c249fade1d71c5d1497ceb8f9734a9b96b5cfac', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb1c1b85f846b91998107968b29b172e8c89a7bc', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2110ebadda6de754d3b914124a28bcd9818b05b1', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3929a1263d43c1b6b2b805ecc3a3c8dd6c3e033a', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=43e8f6e930201e8210ed63a4d009df8ac6507250', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/U2pE2MWftcE4f1kFC5B5DaIUKy0jQtLlJnq5yoOU_5I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=26fce4c77f678f424d718847a547ff4baf0a5e71', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'RVezF73oAvIyrFAU832B2jcIwg15M5guS8Lib_Gi-S4'}], 'enabled': False}",,,,,,
116,,tensorflow,"Hello everyone. I am an M.D. I am doing medical data analysis (not image at least now), I am using Matlab . I have seen TensorFlow, I wander is it worth for me to learn it? to make regression analysis KM plots etc. ?  I tried to install to give a try. I wanted to use swift for tensor flow into Xcode. I couldn't make it work. I installed the package. I can see that on toolchains. 

can someone give me an idea about Tensor Flow , if it is worth to use for me ? 

https://preview.redd.it/3i9mgg3mq9g61.png?width=942&amp;format=png&amp;auto=webp&amp;s=3bc453eb8c03a7026cb10d357d16a6f44945cb59",t2_53mg8uus,False,,0,False,New Programmer question,[],r/tensorflow,False,6,,0,98.0,,False,t3_lfdm6f,False,dark,0.67,,public,3,0,{},140.0,,False,[],,False,False,,{},,False,3,,False,https://b.thumbs.redditmedia.com/YZCx1GEiJzWs9IDpbfbZTjyyrh0VwvcJKDNprPTqg9A.jpg,False,,[],{},,True,,1612825376.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone. I am an M.D. I am doing medical data analysis (not image at least now), I am using Matlab . I have seen TensorFlow, I wander is it worth for me to learn it? to make regression analysis KM plots etc. ?  I tried to install to give a try. I wanted to use swift for tensor flow into Xcode. I couldn&amp;#39;t make it work. I installed the package. I can see that on toolchains. &lt;/p&gt;

&lt;p&gt;can someone give me an idea about Tensor Flow , if it is worth to use for me ? &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3i9mgg3mq9g61.png?width=942&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3bc453eb8c03a7026cb10d357d16a6f44945cb59""&gt;https://preview.redd.it/3i9mgg3mq9g61.png?width=942&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3bc453eb8c03a7026cb10d357d16a6f44945cb59&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lfdm6f,True,,onqun,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/lfdm6f/new_programmer_question/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lfdm6f/new_programmer_question/,22217,1612796576.0,0,,False,,,,,"{'3i9mgg3mq9g61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 75, 'x': 108, 'u': 'https://preview.redd.it/3i9mgg3mq9g61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bfe1330b05813a179495b228ce280fed736e8670'}, {'y': 151, 'x': 216, 'u': 'https://preview.redd.it/3i9mgg3mq9g61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7bba0403a84fb4c1dc9f8607e6ea3449277e76dd'}, {'y': 224, 'x': 320, 'u': 'https://preview.redd.it/3i9mgg3mq9g61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=43284b49087a88cb2045d4ddee55323e75dbfcae'}, {'y': 449, 'x': 640, 'u': 'https://preview.redd.it/3i9mgg3mq9g61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=969c390636900ac8bd41caf2d7029781fb849246'}], 's': {'y': 662, 'x': 942, 'u': 'https://preview.redd.it/3i9mgg3mq9g61.png?width=942&amp;format=png&amp;auto=webp&amp;s=3bc453eb8c03a7026cb10d357d16a6f44945cb59'}, 'id': '3i9mgg3mq9g61'}}",,,,
117,,tensorflow,"If I redo all my python code in tf C++ API, Cython, and if necessary C++ would it actually be any faster if the most time consuming part is training the models? Does TF’s python API already execute the code in a similar way to how it would with the C++ API?",t2_7nkszese,False,,0,False,C++ vs Python,[],r/tensorflow,False,6,,0,,,False,t3_lf01of,False,dark,0.95,,public,15,0,{},,,False,[],,False,False,,{},Question,False,15,,False,self,False,,[],{},,True,,1612774050.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I redo all my python code in tf C++ API, Cython, and if necessary C++ would it actually be any faster if the most time consuming part is training the models? Does TF’s python API already execute the code in a similar way to how it would with the C++ API?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lf01of,True,,BestUCanIsGoodEnough,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/lf01of/c_vs_python/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lf01of/c_vs_python/,22217,1612745250.0,0,,False,,,,,,,,,
118,,tensorflow,"AI colleagues, Indeed.com estimates average US salaries for [**Certified Deep Learning Engineer**](https://www.indeed.com/career/deep-learning-engineer/salaries)  at $166k+. This Deep Learning with TensorFlow 2.0 Certification Training is curated with the help of experienced industry professionals as per the latest requirements &amp; demands. This course will help you master popular algorithms like CNN, RCNN, RNN, LSTM, RBM using the latest TensorFlow 2.0 package in Python. You will be working on various real-time projects like Emotion and Gender Detection, Auto Image Captioning using CNN and LSTM. Skill-based training modules include: : 1) Getting Started with TensorFlow 2.0, 2) Convolution Neural Network, 3) Regional CNN, 4) Boltzmann Machine &amp; Autoencoder, 5) Generative Adversarial Network(GANEmotion and Gender Detection, 7) Introduction RNN and GRU, 8) LSTM,and  9) Auto Image Captioning Using CNN LSTM.

Enroll today (individuals &amp; teams are welcome): [https://fxo.co/AA8u](https://fxo.co/AA8u) 

Much career success, Lawrence E. Wilson - [Artificial Intelligence Academy](https://aimlacademy.blogspot.com/2021/02/certified-deep-learning-engineer-deep.html) (tinyurl.com/52s6gqb9) 

[Certified Deep Learning Engineer - Deep Learning with TensorFlow 2.0 Certification Training ](https://preview.redd.it/5u84c3cqjbg61.jpg?width=300&amp;format=pjpg&amp;auto=webp&amp;s=2789c15a36e5c9f40529ad5edd375ddc78625731)",t2_36ixj,False,,0,False,Certified Deep Learning Engineer - Deep Learning with TensorFlow 2.0 Certification Training,[],r/tensorflow,False,6,,0,78.0,,False,t3_lflvr3,False,dark,0.38,,public,0,0,{},140.0,,False,[],,False,False,,{},Discussion,False,0,,False,https://a.thumbs.redditmedia.com/ZHRnOyeH4Sy4k_qPzhNHuOIleUCdmzPWnnIW1w-Biy0.jpg,False,,[],{},,True,,1612847253.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;AI colleagues, Indeed.com estimates average US salaries for &lt;a href=""https://www.indeed.com/career/deep-learning-engineer/salaries""&gt;&lt;strong&gt;Certified Deep Learning Engineer&lt;/strong&gt;&lt;/a&gt;  at $166k+. This Deep Learning with TensorFlow 2.0 Certification Training is curated with the help of experienced industry professionals as per the latest requirements &amp;amp; demands. This course will help you master popular algorithms like CNN, RCNN, RNN, LSTM, RBM using the latest TensorFlow 2.0 package in Python. You will be working on various real-time projects like Emotion and Gender Detection, Auto Image Captioning using CNN and LSTM. Skill-based training modules include: : 1) Getting Started with TensorFlow 2.0, 2) Convolution Neural Network, 3) Regional CNN, 4) Boltzmann Machine &amp;amp; Autoencoder, 5) Generative Adversarial Network(GANEmotion and Gender Detection, 7) Introduction RNN and GRU, 8) LSTM,and  9) Auto Image Captioning Using CNN LSTM.&lt;/p&gt;

&lt;p&gt;Enroll today (individuals &amp;amp; teams are welcome): &lt;a href=""https://fxo.co/AA8u""&gt;https://fxo.co/AA8u&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Much career success, Lawrence E. Wilson - &lt;a href=""https://aimlacademy.blogspot.com/2021/02/certified-deep-learning-engineer-deep.html""&gt;Artificial Intelligence Academy&lt;/a&gt; (tinyurl.com/52s6gqb9) &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/5u84c3cqjbg61.jpg?width=300&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2789c15a36e5c9f40529ad5edd375ddc78625731""&gt;Certified Deep Learning Engineer - Deep Learning with TensorFlow 2.0 Certification Training &lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lflvr3,True,,lwilson747,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lflvr3/certified_deep_learning_engineer_deep_learning/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lflvr3/certified_deep_learning_engineer_deep_learning/,22217,1612818453.0,0,,False,,,,,"{'5u84c3cqjbg61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/5u84c3cqjbg61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8dbe60f0a69ac1661699b9577af442726030faa8'}, {'y': 120, 'x': 216, 'u': 'https://preview.redd.it/5u84c3cqjbg61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8b1ec105adc3a28be61ab69f24c611abaf17222'}], 's': {'y': 168, 'x': 300, 'u': 'https://preview.redd.it/5u84c3cqjbg61.jpg?width=300&amp;format=pjpg&amp;auto=webp&amp;s=2789c15a36e5c9f40529ad5edd375ddc78625731'}, 'id': '5u84c3cqjbg61'}}",,,,
119,,tensorflow,"I am thinking about the possibilities of measuring the water quantity of a container using any vision system. 

I come across time of flight cameras which can work on short ranges and can give water level. 

I would like to know about your thoughts on that.",t2_rgur5s,False,,0,False,Any thoughts on measuring the water level of a glass using vision,[],r/tensorflow,False,6,,0,,,False,t3_lf3ubn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,self,False,,[],{},,True,,1612786829.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am thinking about the possibilities of measuring the water quantity of a container using any vision system. &lt;/p&gt;

&lt;p&gt;I come across time of flight cameras which can work on short ranges and can give water level. &lt;/p&gt;

&lt;p&gt;I would like to know about your thoughts on that.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,lf3ubn,True,,Ahmad401,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lf3ubn/any_thoughts_on_measuring_the_water_level_of_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lf3ubn/any_thoughts_on_measuring_the_water_level_of_a/,22217,1612758029.0,0,,False,,,,,,,,,
120,,tensorflow,"* Overview &amp; Demo = [https://www.youtube.com/watch?v=cN7d8c-3Vxc](https://www.youtube.com/watch?v=cN7d8c-3Vxc)
* Docs = [https://aiqc.readthedocs.io/](https://aiqc.readthedocs.io/)
* \`pip install aiqc\`

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

I built this library because I was tired of screenshotting my hyperparameters and graphs.

It fills in a lot of the gaps that between sklearn and keras.

Feel free to ask any questions.

https://preview.redd.it/scvqm8dea2g61.png?width=1035&amp;format=png&amp;auto=webp&amp;s=1e8585d08bc53dced61650758578a4ab47f19a28",t2_10lvda,False,,0,False,"AIQC for Keras (data prep, param tuning, viz &amp; metrics)",[],r/tensorflow,False,6,,0,105.0,,False,t3_lembk5,False,dark,1.0,,public,7,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cN7d8c-3Vxc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AIQC - Overview &amp; Demo', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cN7d8c-3Vxc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Layne Sadler', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cN7d8c-3Vxc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCEskjKq4H54TPyLilMbx40g'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cN7d8c-3Vxc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lembk5', 'height': 200}",,False,7,,False,https://a.thumbs.redditmedia.com/s6X21B-QoP9CcE7vJjV0C9tib6t9Bj2ERMig8sEFgA8.jpg,1612738184.0,,[],{},,True,,1612732850.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;ul&gt;
&lt;li&gt;Overview &amp;amp; Demo = &lt;a href=""https://www.youtube.com/watch?v=cN7d8c-3Vxc""&gt;https://www.youtube.com/watch?v=cN7d8c-3Vxc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs = &lt;a href=""https://aiqc.readthedocs.io/""&gt;https://aiqc.readthedocs.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;`pip install aiqc`&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;_______________________&lt;/p&gt;

&lt;p&gt;I built this library because I was tired of screenshotting my hyperparameters and graphs.&lt;/p&gt;

&lt;p&gt;It fills in a lot of the gaps that between sklearn and keras.&lt;/p&gt;

&lt;p&gt;Feel free to ask any questions.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/scvqm8dea2g61.png?width=1035&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1e8585d08bc53dced61650758578a4ab47f19a28""&gt;https://preview.redd.it/scvqm8dea2g61.png?width=1035&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1e8585d08bc53dced61650758578a4ab47f19a28&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lembk5,True,,HashRocketSyntax,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lembk5/aiqc_for_keras_data_prep_param_tuning_viz_metrics/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lembk5/aiqc_for_keras_data_prep_param_tuning_viz_metrics/,22217,1612704050.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AIQC - Overview &amp; Demo', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cN7d8c-3Vxc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Layne Sadler', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cN7d8c-3Vxc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCEskjKq4H54TPyLilMbx40g'}}",False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/CwS7kwWYi8Z3lsL3f0-Qgq8CgiNR70J_6wEIyTYl0N8.jpg?auto=webp&amp;s=7271d4585c2b04178002dda8a7546b5b6ecd6901', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/CwS7kwWYi8Z3lsL3f0-Qgq8CgiNR70J_6wEIyTYl0N8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9883bd95c6d988d219b4d1b454eb42e7b13b0d0', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/CwS7kwWYi8Z3lsL3f0-Qgq8CgiNR70J_6wEIyTYl0N8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2cfbda7156ffeff9464ff613a16dac12b6315919', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/CwS7kwWYi8Z3lsL3f0-Qgq8CgiNR70J_6wEIyTYl0N8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=83b2c7e0205fed95c371335ab1d2da5865708b07', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'TmDc-QOTCllhWc6XGcx8Ke9_hVipP9wqtBR5Xe3zFbI'}], 'enabled': False}",,"{'scvqm8dea2g61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 59, 'x': 108, 'u': 'https://preview.redd.it/scvqm8dea2g61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b294399e4fdba74a19eb85861a945a01d93a5af'}, {'y': 118, 'x': 216, 'u': 'https://preview.redd.it/scvqm8dea2g61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=df86725d47f747c9a2cdf7385eafd33bb3a245eb'}, {'y': 175, 'x': 320, 'u': 'https://preview.redd.it/scvqm8dea2g61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc94e3fbd4a0a3ad3393b38353e3ab922bcdb2fb'}, {'y': 351, 'x': 640, 'u': 'https://preview.redd.it/scvqm8dea2g61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=13c7689b57691bf803026b1cebb9b75db3a97d07'}, {'y': 527, 'x': 960, 'u': 'https://preview.redd.it/scvqm8dea2g61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=85d890347720380799c83da301517e6c2ac33a97'}], 's': {'y': 569, 'x': 1035, 'u': 'https://preview.redd.it/scvqm8dea2g61.png?width=1035&amp;format=png&amp;auto=webp&amp;s=1e8585d08bc53dced61650758578a4ab47f19a28'}, 'id': 'scvqm8dea2g61'}}",,,,
121,,tensorflow,,t2_683tvs22,False,,0,False,"Using StyleGAN2 (built on TF) to project Mickey Mouse as cat, dog, lion, human, ...",[],r/tensorflow,False,6,,0,105.0,,False,t3_lenvr6,False,dark,1.0,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0KTtxOH_wJM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'StyleGAN2 + Mickey Mouse', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0KTtxOH_wJM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/0KTtxOH_wJM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/N2AIyt'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0KTtxOH_wJM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/lenvr6', 'height': 200}",Project,False,2,,False,https://b.thumbs.redditmedia.com/ULjTZ54kV_y7e_wD1hJzVAN89n8aEjITTPzSj5eA2Cs.jpg,False,,[],{},,False,,1612738397.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lenvr6,True,,N2AI,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lenvr6/using_stylegan2_built_on_tf_to_project_mickey/,all_ads,False,https://youtu.be/0KTtxOH_wJM,22217,1612709597.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'StyleGAN2 + Mickey Mouse', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0KTtxOH_wJM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/0KTtxOH_wJM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/N2AIyt'}}",False,rich:video,https://youtu.be/0KTtxOH_wJM,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ABrJ9o4fI5v3ZmJNQSiC8-qcv5GG4fFIoFnITh7dOu8.jpg?auto=webp&amp;s=4022bc0f3e64d6e9c5e7cc7d28bd9bb98d83f9d9', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/ABrJ9o4fI5v3ZmJNQSiC8-qcv5GG4fFIoFnITh7dOu8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5431db5550abe85efde608018eff5ab84068eaae', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/ABrJ9o4fI5v3ZmJNQSiC8-qcv5GG4fFIoFnITh7dOu8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1318d1f2812af2bc93ac84860c030e93b5c63190', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/ABrJ9o4fI5v3ZmJNQSiC8-qcv5GG4fFIoFnITh7dOu8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a63c1dccfac7e491831ba9ae7a775cd4a95d0963', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'XCFKZS4RYEpThgEHG_ejZL2azoQNbfM7MOqtRiqw6Lk'}], 'enabled': False}",,,,,,
122,,tensorflow,"I'm trying to build a english to assamese transliteration model. I tried character level NMT with attention, but not satisfied with the results, considering the Assamese language consists of prefix/suffixes. Currently exploring WFST. Has anybody worked on something similar?",t2_7s6uxray,False,,0,False,Suggestions on building machine transliteration models,[],r/tensorflow,False,6,,0,,,False,t3_leq0w1,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1612745059.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to build a english to assamese transliteration model. I tried character level NMT with attention, but not satisfied with the results, considering the Assamese language consists of prefix/suffixes. Currently exploring WFST. Has anybody worked on something similar?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,leq0w1,True,,ckraybpytao,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/leq0w1/suggestions_on_building_machine_transliteration/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/leq0w1/suggestions_on_building_machine_transliteration/,22217,1612716259.0,0,,False,,,,,,,,,
123,,tensorflow,,t2_44mbtmjy,False,,0,False,From Google researchers: State of the art in Video Stabilization!,[],r/tensorflow,False,6,,0,44.0,,False,t3_le5o0s,False,dark,0.94,,public,14,0,{},140.0,,False,[],,False,False,,{},,False,14,,False,https://a.thumbs.redditmedia.com/1BcTRdli7lDkVwclp6PEiRt_ng4sZM2XKATKOoh62C8.jpg,False,,[],{},,False,,1612670974.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,le5o0s,True,,MLtinkerer,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/le5o0s/from_google_researchers_state_of_the_art_in_video/,all_ads,False,/r/LatestInML/comments/le5kx1/from_google_researchers_state_of_the_art_in_video/,22217,1612642174.0,0,,False,,/r/LatestInML/comments/le5kx1/from_google_researchers_state_of_the_art_in_video/,,,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2102.01279)\n\nhttps://preview.redd.it/k76d6c4tywf61.jpg?width=2032&amp;format=pjpg&amp;auto=webp&amp;s=2418f3e9e08b3e58ce9b2ee76499ea6205c8ed02\n\n👇 Free extension to get code for ML papers (❤️' by Andrew Ng)   \nChrome: [https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil](https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil)\n\nFirefox: [https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex](https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex)"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'From Google researchers: State of the art in Video Stabilization!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 44, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'k76d6c4tywf61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 34, 'x': 108, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49d04422b79300b139bbb7ae8e9d04317c0e1250'}, {'y': 69, 'x': 216, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9639b5ad92ff9fad76b61f77cfcb40d981cc589a'}, {'y': 102, 'x': 320, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=141778c1b5c3b5460c3c15d1061af90280b33832'}, {'y': 205, 'x': 640, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae54026b4cb2a50c443b29f34d2087634caa031d'}, {'y': 308, 'x': 960, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9f676c8b2af19af09c338835af563ad66fd26b75'}, {'y': 347, 'x': 1080, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7de9766427dbc146e960b8407e44232f5a1141b3'}], 's': {'y': 653, 'x': 2032, 'u': 'https://preview.redd.it/k76d6c4tywf61.jpg?width=2032&amp;format=pjpg&amp;auto=webp&amp;s=2418f3e9e08b3e58ce9b2ee76499ea6205c8ed02'}, 'id': 'k76d6c4tywf61'}}, 'name': 't3_le5kx1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 27, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 27, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/1BcTRdli7lDkVwclp6PEiRt_ng4sZM2XKATKOoh62C8.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1612670744.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2102.01279""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/k76d6c4tywf61.jpg?width=2032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2418f3e9e08b3e58ce9b2ee76499ea6205c8ed02""&gt;https://preview.redd.it/k76d6c4tywf61.jpg?width=2032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2418f3e9e08b3e58ce9b2ee76499ea6205c8ed02&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39; by Andrew Ng)&lt;br/&gt;\nChrome: &lt;a href=""https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'le5kx1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/le5kx1/from_google_researchers_state_of_the_art_in_video/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/le5kx1/from_google_researchers_state_of_the_art_in_video/', 'subreddit_subscribers': 6676, 'created_utc': 1612641944.0, 'num_crossposts': 9, 'media': None, 'is_video': False}]",t3_le5kx1,
124,,tensorflow,"EDIT 4: This is actually a known bug in the TF fork for mac M1 :(  [https://github.com/apple/tensorflow\_macos/issues/145](https://github.com/apple/tensorflow_macos/issues/145) 

Please disregard this post.

Below is are two screenshots, one of a confusion matrix plot on my mac, the other running on Kaggle. The Kaggle result is the one expected.

[Results on my Mac M1 \(incorrect results\)](https://preview.redd.it/j6nm032cauf61.png?width=722&amp;format=png&amp;auto=webp&amp;s=16a8c646a0155a96c5d66d911ee245fdba379126)

[Results on Kaggle \(expected results\)](https://preview.redd.it/yvdyw71cauf61.png?width=728&amp;format=png&amp;auto=webp&amp;s=c4511a42f688fcac651b00fb664f5bd9eac3448a)

This is the same code.

Any ideas what is wrong with my machine's TF?

More information:

\- it was ridiculously difficult to install Tensorflow on my mac. I managed to make it work with Anaconda, using Jupyter Notebooks. I'm aware that Anaconda is running on Rosetta 2, but that should interfere with anything, right?

\- This is an exercise from here: [https://deeplizard.com/learn/video/km7pxKy4UHU](https://deeplizard.com/learn/video/km7pxKy4UHU) .

I'm not very experienced and might be making some basic mistake. So please don't discard obvious solutions! :)

EDIT: link to Kaggle notebook: [https://www.kaggle.com/nandomachado/test-notebook](https://www.kaggle.com/nandomachado/test-notebook) .

EDIT 2: I added seeds to random, np.random and tf.random. Every single value is identical between my computer and Kaggle up to model.predict (where the values are very different).

EDIT 3: Link to model.predict outputs, for reference: [https://imgur.com/2lkvKVp](https://imgur.com/2lkvKVp) .

EDIT 4: This is actually a known bug in the TF fork for mac M1 :(  [https://github.com/apple/tensorflow\_macos/issues/145](https://github.com/apple/tensorflow_macos/issues/145) ",t2_exw45,False,,0,False,"Same code, conflicting results between my mac m1 and Kaggle",[],r/tensorflow,False,6,,0,73.0,,False,t3_ldvpjq,False,dark,0.84,,public,8,0,{},140.0,,False,[],,False,False,,{},,False,8,,True,https://b.thumbs.redditmedia.com/p3uq6si5hPBaAVOUy1Cw1laypkh4ufqDneCE2OUxuPA.jpg,1612738565.0,,[],{},,True,,1612638541.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;EDIT 4: This is actually a known bug in the TF fork for mac M1 :(  &lt;a href=""https://github.com/apple/tensorflow_macos/issues/145""&gt;https://github.com/apple/tensorflow_macos/issues/145&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Please disregard this post.&lt;/p&gt;

&lt;p&gt;Below is are two screenshots, one of a confusion matrix plot on my mac, the other running on Kaggle. The Kaggle result is the one expected.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/j6nm032cauf61.png?width=722&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16a8c646a0155a96c5d66d911ee245fdba379126""&gt;Results on my Mac M1 (incorrect results)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/yvdyw71cauf61.png?width=728&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c4511a42f688fcac651b00fb664f5bd9eac3448a""&gt;Results on Kaggle (expected results)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is the same code.&lt;/p&gt;

&lt;p&gt;Any ideas what is wrong with my machine&amp;#39;s TF?&lt;/p&gt;

&lt;p&gt;More information:&lt;/p&gt;

&lt;p&gt;- it was ridiculously difficult to install Tensorflow on my mac. I managed to make it work with Anaconda, using Jupyter Notebooks. I&amp;#39;m aware that Anaconda is running on Rosetta 2, but that should interfere with anything, right?&lt;/p&gt;

&lt;p&gt;- This is an exercise from here: &lt;a href=""https://deeplizard.com/learn/video/km7pxKy4UHU""&gt;https://deeplizard.com/learn/video/km7pxKy4UHU&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not very experienced and might be making some basic mistake. So please don&amp;#39;t discard obvious solutions! :)&lt;/p&gt;

&lt;p&gt;EDIT: link to Kaggle notebook: &lt;a href=""https://www.kaggle.com/nandomachado/test-notebook""&gt;https://www.kaggle.com/nandomachado/test-notebook&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;EDIT 2: I added seeds to random, np.random and tf.random. Every single value is identical between my computer and Kaggle up to model.predict (where the values are very different).&lt;/p&gt;

&lt;p&gt;EDIT 3: Link to model.predict outputs, for reference: &lt;a href=""https://imgur.com/2lkvKVp""&gt;https://imgur.com/2lkvKVp&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;EDIT 4: This is actually a known bug in the TF fork for mac M1 :(  &lt;a href=""https://github.com/apple/tensorflow_macos/issues/145""&gt;https://github.com/apple/tensorflow_macos/issues/145&lt;/a&gt; &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ldvpjq,True,,icenando,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/ldvpjq/same_code_conflicting_results_between_my_mac_m1/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ldvpjq/same_code_conflicting_results_between_my_mac_m1/,22217,1612609741.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/qlhaE4JInuVD7IL-mhj-2qrDNiGMZ4fHwPOHyAYPcLQ.jpg?auto=webp&amp;s=fdb7dfff573adfeb0b52ed9889eef46f7db15aae', 'width': 600, 'height': 315}, 'resolutions': [{'url': 'https://external-preview.redd.it/qlhaE4JInuVD7IL-mhj-2qrDNiGMZ4fHwPOHyAYPcLQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f3aff3b975d1e6c25f04885ed6994c0441bfea5e', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/qlhaE4JInuVD7IL-mhj-2qrDNiGMZ4fHwPOHyAYPcLQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=88722ea71fdfbf55c2e2bb75c8ac699473fd1638', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/qlhaE4JInuVD7IL-mhj-2qrDNiGMZ4fHwPOHyAYPcLQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4d8995371b6f6d8e2479e4535dc4c7a54ba5e4d', 'width': 320, 'height': 168}], 'variants': {}, 'id': '3uQQfW8soS3-wYiBJEnBaOPoWAZvboyd9oC8U3wVtIY'}], 'enabled': False}",,"{'yvdyw71cauf61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 117, 'x': 108, 'u': 'https://preview.redd.it/yvdyw71cauf61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f9026ca68561888198835ee373cde0668588952'}, {'y': 234, 'x': 216, 'u': 'https://preview.redd.it/yvdyw71cauf61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2055a03aa83dcb96f499eb2e0c9e730f7da84729'}, {'y': 348, 'x': 320, 'u': 'https://preview.redd.it/yvdyw71cauf61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c878db19142594108d375fcb81f357f94506f95e'}, {'y': 696, 'x': 640, 'u': 'https://preview.redd.it/yvdyw71cauf61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4991e8a5e6d6b9404483c8456f7da7e299df631e'}], 's': {'y': 792, 'x': 728, 'u': 'https://preview.redd.it/yvdyw71cauf61.png?width=728&amp;format=png&amp;auto=webp&amp;s=c4511a42f688fcac651b00fb664f5bd9eac3448a'}, 'id': 'yvdyw71cauf61'}, 'j6nm032cauf61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 104, 'x': 108, 'u': 'https://preview.redd.it/j6nm032cauf61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=adbd3f092bacc045ecc119f92871132bab720fbf'}, {'y': 208, 'x': 216, 'u': 'https://preview.redd.it/j6nm032cauf61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff90e08f88c8a97af4d5f1e34cbc796645e29fdf'}, {'y': 309, 'x': 320, 'u': 'https://preview.redd.it/j6nm032cauf61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0f0c39b5c9994300cfb6748454d060e8f0780f6'}, {'y': 618, 'x': 640, 'u': 'https://preview.redd.it/j6nm032cauf61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4aa02ee07c0a1c69329990b60dac38e7b14361df'}], 's': {'y': 698, 'x': 722, 'u': 'https://preview.redd.it/j6nm032cauf61.png?width=722&amp;format=png&amp;auto=webp&amp;s=16a8c646a0155a96c5d66d911ee245fdba379126'}, 'id': 'j6nm032cauf61'}}",,,,
125,,tensorflow,"Hi everyone!

I have a project that I need help with. This project includes detecting object in a video down to an accuracy of a few pixels (stable background). If anyone one has any expertise please message me. I would love to get some help from this community. Thank you all 🙏🏻",t2_9q39cpqq,False,,0,False,COMPUTER VISION OBJECT DETECTION,[],r/tensorflow,False,6,,0,,,False,t3_le5qpz,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1612671188.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;

&lt;p&gt;I have a project that I need help with. This project includes detecting object in a video down to an accuracy of a few pixels (stable background). If anyone one has any expertise please message me. I would love to get some help from this community. Thank you all 🙏🏻&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,le5qpz,True,,nomeaningg,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/le5qpz/computer_vision_object_detection/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/le5qpz/computer_vision_object_detection/,22217,1612642388.0,0,,False,,,,,,,,,
126,,tensorflow,"I'm trying to convert this model to a tensorflow.js format so I can perform in-browser client-side inference of the model. To do this, the model needs to be in the SavedModel format as specified [here](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter).

By using a simple python script to restore the model and save it in this SavedModel format, I've managed to obtain a .pb file as expected:

    import os
    import tensorflow as tf
    
    trained_checkpoint_prefix = 'models/snap-0'
    export_dir = os.path.join('export_dir', '0')
    
    graph = tf.Graph()
    with tf.compat.v1.Session(graph=graph) as sess:
        # Restore from checkpoint
        loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + '.meta')
        loader.restore(sess, trained_checkpoint_prefix)
    
        # Export checkpoint to SavedModel
        builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)
        builder.add_meta_graph_and_variables(sess, [tf.saved_model.SERVING], strip_default_attrs=True)
        builder.save() 

However, when I try to then convert this SavedModel format with tfjs converter, it seems that it expects some SignatureDefs to be saved, which have been lost in the conversion process so I get these error messages:

`RuntimeError: MetaGraphDef associated with tags 'serve' could not be found in SavedModel.`

`ValueError: Signature 'serving_default' does not exist. The following signatures are available: KeysView(_SignatureMap({}))`

`MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs: #no output`

It seems I need to provide some sort of signature for the inputs and outputs of the network, although I'm really unfamiliar with this process so am unsure how I would do so.

Does anybody have an insight into how I could solve this?

For reference, [this is the github repo](https://github.com/JiahuiYu/generative_inpainting/) and [here is the model](https://drive.google.com/drive/folders/1y7Irxm3HSHGvp546hZdAZwuNmhLUVcjO) I'm restoring from",t2_hv8pm,False,,0,False,Unable to restore model from checkpoint format to SavedModel format and convert to Tensorflow.js format,[],r/tensorflow,False,6,,0,,,False,t3_le3luq,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1612636610.0,,[],{},,True,,1612665221.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to convert this model to a tensorflow.js format so I can perform in-browser client-side inference of the model. To do this, the model needs to be in the SavedModel format as specified &lt;a href=""https://github.com/tensorflow/tfjs/tree/master/tfjs-converter""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;By using a simple python script to restore the model and save it in this SavedModel format, I&amp;#39;ve managed to obtain a .pb file as expected:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
import tensorflow as tf

trained_checkpoint_prefix = &amp;#39;models/snap-0&amp;#39;
export_dir = os.path.join(&amp;#39;export_dir&amp;#39;, &amp;#39;0&amp;#39;)

graph = tf.Graph()
with tf.compat.v1.Session(graph=graph) as sess:
    # Restore from checkpoint
    loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + &amp;#39;.meta&amp;#39;)
    loader.restore(sess, trained_checkpoint_prefix)

    # Export checkpoint to SavedModel
    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)
    builder.add_meta_graph_and_variables(sess, [tf.saved_model.SERVING], strip_default_attrs=True)
    builder.save() 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, when I try to then convert this SavedModel format with tfjs converter, it seems that it expects some SignatureDefs to be saved, which have been lost in the conversion process so I get these error messages:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;RuntimeError: MetaGraphDef associated with tags &amp;#39;serve&amp;#39; could not be found in SavedModel.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ValueError: Signature &amp;#39;serving_default&amp;#39; does not exist. The following signatures are available: KeysView(_SignatureMap({}))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;MetaGraphDef with tag-set: &amp;#39;serve&amp;#39; contains the following SignatureDefs: #no output&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It seems I need to provide some sort of signature for the inputs and outputs of the network, although I&amp;#39;m really unfamiliar with this process so am unsure how I would do so.&lt;/p&gt;

&lt;p&gt;Does anybody have an insight into how I could solve this?&lt;/p&gt;

&lt;p&gt;For reference, &lt;a href=""https://github.com/JiahuiYu/generative_inpainting/""&gt;this is the github repo&lt;/a&gt; and &lt;a href=""https://drive.google.com/drive/folders/1y7Irxm3HSHGvp546hZdAZwuNmhLUVcjO""&gt;here is the model&lt;/a&gt; I&amp;#39;m restoring from&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,le3luq,True,,nickc98,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/le3luq/unable_to_restore_model_from_checkpoint_format_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/le3luq/unable_to_restore_model_from_checkpoint_format_to/,22217,1612636421.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
127,,tensorflow,"Howdy folks. I've been googling my way around and tried to make tensorflow use my rtx 3090 for training of some basic models. As I've figured out the main Problem is, that you will need cuda 11+ and cuDNN 8+. Both are not available or not compatible with the packages from conda afaik. So I've read about a docker container from nvidia but this is more a workaround I guess? Following another tutorial, I set up a conda env with just tensorflow-gpu and let it self find its way. By default that will result in cuda 10 and cuDNN 7 beeing installed. I've tried training one of my models and the gpu gets detected but does not seem to be any faster than my cpu. It does spin up its fans, so it does something at least.
So what is the cleanest way to set this up? Anyone experienced, especially with arch linux? When will the tensorflow+cuda 11 be on available with conda?",t2_czeka7g,False,,0,False,How do you set up tensorflow-gpu for rtx 3090 running linux properly?,[],r/tensorflow,False,6,,0,,,False,t3_le2ao8,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1612661533.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Howdy folks. I&amp;#39;ve been googling my way around and tried to make tensorflow use my rtx 3090 for training of some basic models. As I&amp;#39;ve figured out the main Problem is, that you will need cuda 11+ and cuDNN 8+. Both are not available or not compatible with the packages from conda afaik. So I&amp;#39;ve read about a docker container from nvidia but this is more a workaround I guess? Following another tutorial, I set up a conda env with just tensorflow-gpu and let it self find its way. By default that will result in cuda 10 and cuDNN 7 beeing installed. I&amp;#39;ve tried training one of my models and the gpu gets detected but does not seem to be any faster than my cpu. It does spin up its fans, so it does something at least.
So what is the cleanest way to set this up? Anyone experienced, especially with arch linux? When will the tensorflow+cuda 11 be on available with conda?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,le2ao8,True,,mrtnb249,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/le2ao8/how_do_you_set_up_tensorflowgpu_for_rtx_3090/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/le2ao8/how_do_you_set_up_tensorflowgpu_for_rtx_3090/,22217,1612632733.0,0,,False,,,,,,,,,
128,,tensorflow,,t2_71atywgj,False,,0,False,Neural Networks Generate New Dwight Schrute Quotes,[],r/tensorflow,False,6,,0,105.0,,False,t3_ld7yko,False,dark,0.89,,public,38,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VSxcfD2lGnM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Networks Generate New Dwight Schrute Quotes', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VSxcfD2lGnM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The Teen Innovator', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VSxcfD2lGnM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCHGbO2h8gRi-w4tx_nZcMMw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VSxcfD2lGnM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ld7yko', 'height': 200}",,False,38,,False,https://b.thumbs.redditmedia.com/ny0Dmfyif-BB0Hmk6Ec16mk-gSSTnnlaeA2dxOtAnSU.jpg,False,,[],{'gid_1': 1},,False,,1612563234.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ld7yko,True,,Snoo28889,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/ld7yko/neural_networks_generate_new_dwight_schrute_quotes/,all_ads,False,https://youtu.be/VSxcfD2lGnM,22217,1612534434.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Networks Generate New Dwight Schrute Quotes', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VSxcfD2lGnM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The Teen Innovator', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VSxcfD2lGnM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCHGbO2h8gRi-w4tx_nZcMMw'}}",False,rich:video,https://youtu.be/VSxcfD2lGnM,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MJNIA0NoKLVq0QTFzBaMjqBlNY8PgGL3qDSEMx8uuwM.jpg?auto=webp&amp;s=7d18d24918f691c74dc03d92ac22dff1d8ad31be', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/MJNIA0NoKLVq0QTFzBaMjqBlNY8PgGL3qDSEMx8uuwM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=80074119014234996d0b95dca8c5734e0b95636d', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/MJNIA0NoKLVq0QTFzBaMjqBlNY8PgGL3qDSEMx8uuwM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9b88e3bcec2e287157f7927c34d7bd9ced63c82', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/MJNIA0NoKLVq0QTFzBaMjqBlNY8PgGL3qDSEMx8uuwM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=678f80a3ad99d6d01b802770caed46b27cf874b5', 'width': 320, 'height': 240}], 'variants': {}, 'id': '5hE7X9_1tX8ncVmL00uzpfBdujPB3HYdQLacXfkgxCA'}], 'enabled': False}",,,,,,
129,,tensorflow,"I am trying to figure out how to generate images using vector graphics instead of raster images like normal.  I can not find any resources that seem to be handling a similar goal.  

&amp;#x200B;

I have built a system that follows the Pix2Pix tutorial, but there is not a nice way to create derivatives.  I have tried a brute force method (subtract before image from after image divided by parameters) and a more clever method using triangle areas, but the images never stop looking like random messes.

&amp;#x200B;

I tried using TensorFlow agents to do RI learning, but once again just end up with random messes.  

&amp;#x200B;

Is there maybe a paper or resource out there that I am missing because I do not know the right search terms?",t2_71n0sfuq,False,,0,False,GAN for vector images,[],r/tensorflow,False,6,,0,,,False,t3_ldbsmt,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1612573748.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to figure out how to generate images using vector graphics instead of raster images like normal.  I can not find any resources that seem to be handling a similar goal.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have built a system that follows the Pix2Pix tutorial, but there is not a nice way to create derivatives.  I have tried a brute force method (subtract before image from after image divided by parameters) and a more clever method using triangle areas, but the images never stop looking like random messes.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I tried using TensorFlow agents to do RI learning, but once again just end up with random messes.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is there maybe a paper or resource out there that I am missing because I do not know the right search terms?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ldbsmt,True,,DrOchensati,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ldbsmt/gan_for_vector_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ldbsmt/gan_for_vector_images/,22217,1612544948.0,0,,False,,,,,,,,,
130,,tensorflow,"Anyone who is interested in deep learning image captioning has probably come across the [Show, Attend and Tell](https://arxiv.org/abs/1502.03044) paper. And anyone who is interested in implementing the architecture in TensorFlow has probably come across TensorFlow's [tutorial](https://www.tensorflow.org/tutorials/text/image_captioning). [@ratthachat](https://www.kaggle.com/ratthachat) provided a great [notebook](https://www.kaggle.com/ratthachat/flickr-image-captioning-tpu-tf2-glove) that extends TensorFlow's tutorial with additions such as TPU training, Efficientnet encoder, and Glove embeddings. When I was interested in image captioning for my own custom dataset his tutorial was the best starting point I could find online. While working on my own dataset I needed to customize his notebook to add the features listed below. After doing so, I felt many others could benefit from the extensions so I am deciding to share it. Hope you all find it helpful.

* Bleu Score metrics
* Decoders
* 1. Pure Sampling
* 2. Top K Sampling
* 3. Greedy Search
* 4. Beam Search
* Scheduled Sampling from [https://arxiv.org/pdf/1506.03099.pdf](https://arxiv.org/pdf/1506.03099.pdf)
* Early Stopping based off of validation bleu score

[https://www.kaggle.com/kagglethomas88/flickr-image-captioning-tpu-tf2-glove-extended](https://www.kaggle.com/kagglethomas88/flickr-image-captioning-tpu-tf2-glove-extended)",t2_83w9rbaf,False,,0,False,"Image Captioning with Visual Attention: TF, TPU, BLEU, BEAM",[],r/tensorflow,False,6,,0,,,False,t3_lcsgrv,False,dark,1.0,,public,12,0,{},,,False,[],,False,False,,{},,False,12,,False,self,False,,[],{},,True,,1612507576.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone who is interested in deep learning image captioning has probably come across the &lt;a href=""https://arxiv.org/abs/1502.03044""&gt;Show, Attend and Tell&lt;/a&gt; paper. And anyone who is interested in implementing the architecture in TensorFlow has probably come across TensorFlow&amp;#39;s &lt;a href=""https://www.tensorflow.org/tutorials/text/image_captioning""&gt;tutorial&lt;/a&gt;. &lt;a href=""https://www.kaggle.com/ratthachat""&gt;@ratthachat&lt;/a&gt; provided a great &lt;a href=""https://www.kaggle.com/ratthachat/flickr-image-captioning-tpu-tf2-glove""&gt;notebook&lt;/a&gt; that extends TensorFlow&amp;#39;s tutorial with additions such as TPU training, Efficientnet encoder, and Glove embeddings. When I was interested in image captioning for my own custom dataset his tutorial was the best starting point I could find online. While working on my own dataset I needed to customize his notebook to add the features listed below. After doing so, I felt many others could benefit from the extensions so I am deciding to share it. Hope you all find it helpful.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bleu Score metrics&lt;/li&gt;
&lt;li&gt;Decoders&lt;/li&gt;
&lt;li&gt;1. Pure Sampling&lt;/li&gt;
&lt;li&gt;2. Top K Sampling&lt;/li&gt;
&lt;li&gt;3. Greedy Search&lt;/li&gt;
&lt;li&gt;4. Beam Search&lt;/li&gt;
&lt;li&gt;Scheduled Sampling from &lt;a href=""https://arxiv.org/pdf/1506.03099.pdf""&gt;https://arxiv.org/pdf/1506.03099.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Early Stopping based off of validation bleu score&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=""https://www.kaggle.com/kagglethomas88/flickr-image-captioning-tpu-tf2-glove-extended""&gt;https://www.kaggle.com/kagglethomas88/flickr-image-captioning-tpu-tf2-glove-extended&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lcsgrv,True,,International_Fix_94,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lcsgrv/image_captioning_with_visual_attention_tf_tpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lcsgrv/image_captioning_with_visual_attention_tf_tpu/,22217,1612478776.0,0,,False,,,,,,,,,
131,,tensorflow,"I built some wheels for the new Tensorflow 2.4.1 with CUDA 11 and cuDNN 8 in case anyone finds them useful

[https://github.com/davidenunes/tensorflow-wheels](https://github.com/davidenunes/tensorflow-wheels)

in case anyone finding these useful, contribute to my coffee addiction 🤣☕ and support these builds and related projects here: [https://github.com/sponsors/davidenunes](https://github.com/sponsors/davidenunes) or [https://ko-fi.com/davidenunes](https://ko-fi.com/davidenunes)

or just say hi [@davidelnunes](https://twitter.com/davidelnunes) on Twitter.",t2_ropk4,False,,0,False,[P] Latest TensorFlow 2.4.1 optimized wheels with CUDA 11 and Python3.8,[],r/tensorflow,False,6,,0,,,False,t3_lcfwnu,False,dark,0.86,,public,10,0,{},,,False,[],,False,False,,{},,False,10,,False,self,False,,[],{},,True,,1612475010.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I built some wheels for the new Tensorflow 2.4.1 with CUDA 11 and cuDNN 8 in case anyone finds them useful&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/davidenunes/tensorflow-wheels""&gt;https://github.com/davidenunes/tensorflow-wheels&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;in case anyone finding these useful, contribute to my coffee addiction 🤣☕ and support these builds and related projects here: &lt;a href=""https://github.com/sponsors/davidenunes""&gt;https://github.com/sponsors/davidenunes&lt;/a&gt; or &lt;a href=""https://ko-fi.com/davidenunes""&gt;https://ko-fi.com/davidenunes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;or just say hi &lt;a href=""https://twitter.com/davidelnunes""&gt;@davidelnunes&lt;/a&gt; on Twitter.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lcfwnu,True,,davex32,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lcfwnu/p_latest_tensorflow_241_optimized_wheels_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lcfwnu/p_latest_tensorflow_241_optimized_wheels_with/,22217,1612446210.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?auto=webp&amp;s=4a3257282561a396d8b2bc2a884f26eb86eb3e9f', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c48d068f1c08ba8529402d9020d5e84d66e5f84', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=799614b370c6fc744ddafdfd32c91c32a860ca04', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5417762d9b98409b174c1ac5d2a4edffec3bdb18', 'width': 320, 'height': 320}], 'variants': {}, 'id': '69OwC9Le6WPJSo1bqK--28JfBCNBnzn-hbX3LmD0fCE'}], 'enabled': False}",,,,,,
132,,tensorflow,,t2_44mbtmjy,False,,0,False,Latest from Stanford researchers: Embodied Intelligence via Learning and Evolution!,[],r/tensorflow,False,6,,0,68.0,,False,t3_lcuqpj,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/j48FGb37nDuzZ5dK403sVrgITCyMOA0bgwstH11IDYw.jpg,False,,[],{},,False,,1612513847.0,text,6,,,text,self.LatestInML,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lcuqpj,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lcuqpj/latest_from_stanford_researchers_embodied/,all_ads,False,/r/LatestInML/comments/lcupbc/latest_from_stanford_researchers_embodied/,22217,1612485047.0,0,,False,link,/r/LatestInML/comments/lcupbc/latest_from_stanford_researchers_embodied/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?auto=webp&amp;s=7693b00f12bb489fa4bc7777f3e392ab2e23ee83', 'width': 1148, 'height': 558}, 'resolutions': [{'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92bdf4c23c47a4885bf59041a7aa5133d8a816b1', 'width': 108, 'height': 52}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aaa7b97b3a6b09153515c8d504e52b1b4660d004', 'width': 216, 'height': 104}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ecd537633c443b38545d6632e71a537320c81bc', 'width': 320, 'height': 155}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2dd5922b546953588f9dae9eaf1dde70eb379c6', 'width': 640, 'height': 311}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54ec15bbf9ae75db27e795b179d2e679c4947b71', 'width': 960, 'height': 466}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=008fdad95b89eec78dd6f32fe2f2c21b566c6024', 'width': 1080, 'height': 524}], 'variants': {}, 'id': '9-gV98jN20yRLuBEYwnbXaELMAvT4YuYYkBh8A6LNHs'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2102.02202)\n\nhttps://reddit.com/link/lcupbc/video/y9lh3yi00kf61/player\n\n👇 Free extension to get code for ML papers (❤️' by Andrew Ng)   \nChrome: https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from Stanford researchers: Embodied Intelligence via Learning and Evolution!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 68, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'y9lh3yi00kf61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/lcupbc/asset/y9lh3yi00kf61/DASHPlaylist.mpd?a=1618044675%2CMWRmOGRkNmUzOGFiOWUxYWQ4ZDdlOWQwNmNiYzNlYjk5M2EwOTI3MjA3OWQ4NmI1NWViNjY1YzI2NzBhOWNjNQ%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/lcupbc/asset/y9lh3yi00kf61/HLSPlaylist.m3u8?a=1618044675%2CZWIyNDY4OWE4OWViMjY2NmZmNDA4MDJlNTg0NjlkYWZmOTEzMjJiNTgxZDNiNWY0Mjg4YjBkMjBlZDhiODYxNA%3D%3D&amp;v=1&amp;f=sd', 'id': 'y9lh3yi00kf61', 'isGif': False}}, 'name': 't3_lcupbc', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 23, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 23, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/j48FGb37nDuzZ5dK403sVrgITCyMOA0bgwstH11IDYw.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1612513738.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2102.02202""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/lcupbc/video/y9lh3yi00kf61/player""&gt;https://reddit.com/link/lcupbc/video/y9lh3yi00kf61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39; by Andrew Ng)&lt;br/&gt;\nChrome: &lt;a href=""https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?auto=webp&amp;s=7693b00f12bb489fa4bc7777f3e392ab2e23ee83', 'width': 1148, 'height': 558}, 'resolutions': [{'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92bdf4c23c47a4885bf59041a7aa5133d8a816b1', 'width': 108, 'height': 52}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aaa7b97b3a6b09153515c8d504e52b1b4660d004', 'width': 216, 'height': 104}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ecd537633c443b38545d6632e71a537320c81bc', 'width': 320, 'height': 155}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2dd5922b546953588f9dae9eaf1dde70eb379c6', 'width': 640, 'height': 311}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54ec15bbf9ae75db27e795b179d2e679c4947b71', 'width': 960, 'height': 466}, {'url': 'https://external-preview.redd.it/zOq7VIYWl1FW7Q-FAgF_UEpEmGRpJW2h3QzMPm6uImc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=008fdad95b89eec78dd6f32fe2f2c21b566c6024', 'width': 1080, 'height': 524}], 'variants': {}, 'id': '9-gV98jN20yRLuBEYwnbXaELMAvT4YuYYkBh8A6LNHs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lcupbc', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/lcupbc/latest_from_stanford_researchers_embodied/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/lcupbc/latest_from_stanford_researchers_embodied/', 'subreddit_subscribers': 6676, 'created_utc': 1612484938.0, 'num_crossposts': 9, 'media': None, 'is_video': False}]",t3_lcupbc,
133,,tensorflow,"I'm trying to build the Tensorflow 1.15.3 C API using CUDA 10.1 with CUDNN 7. I need that particular Tensorflow and CUDA version.

* Building using this docker image: nvidia/cuda:10.1-cudnn7-devel-centos7
* Using Bazel 0.26.1
* Using this command: bazel build --jobs=4 --ram\_utilization\_factor 50 --config=opt //tensorflow/tools/lib\_package:libtensorflow

However, when I compile, I'm getting this error, any ideas?

    INFO: From Compiling external/nccl_archive/src/collectives/device/sum_i8_all_gather.cu.cc:
    /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits: In static member function 'static constexpr long double std::numeric_limits&lt;long double&gt;::denorm_min()':
    /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits:1758:65: error: expected ')' before numeric constant
           denorm_min() _GLIBCXX_USE_NOEXCEPT { return __LDBL_DENORM_MIN__; }
                                                                     ^
    /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits:1758:68: error: cannot convert 'double (*)(const char*)throw ()' to 'long double' in return
           denorm_min() _GLIBCXX_USE_NOEXCEPT { return __LDBL_DENORM_MIN__; }
                                                                        ^
    /usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits:1758:71: error: body of constexpr function 'static constexpr long double std::numeric_limits&lt;long double&gt;::denorm_min()' not a return-statement
           denorm_min() _GLIBCXX_USE_NOEXCEPT { return __LDBL_DENORM_MIN__; }
                                                                           ^
    ERROR: /root/.cache/bazel/_bazel_root/99ae3da81ec09400d29866a6fee32a8f/external/nccl_archive/BUILD.bazel:53:1: output 'external/nccl_archive/_objs/device_lib/sum_i8_all_gather.cu.o' was not created
    ERROR: /root/.cache/bazel/_bazel_root/99ae3da81ec09400d29866a6fee32a8f/external/nccl_archive/BUILD.bazel:53:1: not all outputs were created or valid
    Target //tensorflow/tools/lib_package:libtensorflow failed to build",t2_11vxbwus,False,,0,False,Tensorflow build error,[],r/tensorflow,False,6,,0,,,False,t3_lcmup4,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1612493453.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to build the Tensorflow 1.15.3 C API using CUDA 10.1 with CUDNN 7. I need that particular Tensorflow and CUDA version.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Building using this docker image: nvidia/cuda:10.1-cudnn7-devel-centos7&lt;/li&gt;
&lt;li&gt;Using Bazel 0.26.1&lt;/li&gt;
&lt;li&gt;Using this command: bazel build --jobs=4 --ram_utilization_factor 50 --config=opt //tensorflow/tools/lib_package:libtensorflow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, when I compile, I&amp;#39;m getting this error, any ideas?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;INFO: From Compiling external/nccl_archive/src/collectives/device/sum_i8_all_gather.cu.cc:
/usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits: In static member function &amp;#39;static constexpr long double std::numeric_limits&amp;lt;long double&amp;gt;::denorm_min()&amp;#39;:
/usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits:1758:65: error: expected &amp;#39;)&amp;#39; before numeric constant
       denorm_min() _GLIBCXX_USE_NOEXCEPT { return __LDBL_DENORM_MIN__; }
                                                                 ^
/usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits:1758:68: error: cannot convert &amp;#39;double (*)(const char*)throw ()&amp;#39; to &amp;#39;long double&amp;#39; in return
       denorm_min() _GLIBCXX_USE_NOEXCEPT { return __LDBL_DENORM_MIN__; }
                                                                    ^
/usr/lib/gcc/x86_64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/limits:1758:71: error: body of constexpr function &amp;#39;static constexpr long double std::numeric_limits&amp;lt;long double&amp;gt;::denorm_min()&amp;#39; not a return-statement
       denorm_min() _GLIBCXX_USE_NOEXCEPT { return __LDBL_DENORM_MIN__; }
                                                                       ^
ERROR: /root/.cache/bazel/_bazel_root/99ae3da81ec09400d29866a6fee32a8f/external/nccl_archive/BUILD.bazel:53:1: output &amp;#39;external/nccl_archive/_objs/device_lib/sum_i8_all_gather.cu.o&amp;#39; was not created
ERROR: /root/.cache/bazel/_bazel_root/99ae3da81ec09400d29866a6fee32a8f/external/nccl_archive/BUILD.bazel:53:1: not all outputs were created or valid
Target //tensorflow/tools/lib_package:libtensorflow failed to build
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lcmup4,True,,osred78,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lcmup4/tensorflow_build_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lcmup4/tensorflow_build_error/,22217,1612464653.0,0,,False,,,,,,,,,
134,,tensorflow,"Just finished this project! An unfiltered review of pizza places in your city.

There are only 18 authentic pizza places out of 362 in Boston. This is what an AI said. Combining computer vision and machine learning to ease the search for Neapolitan pizza based on photos from public crowd-sourced reviews.

Check your city and learn what’s going on under the hood – [https://vasilykorf.com/find-pizza/](https://vasilykorf.com/find-pizza/)

I would be glad to receive your feedback.",t2_jthip,False,,0,False,Project – Find Neapolitan pizza with AI help,[],r/tensorflow,False,6,,0,,,False,t3_lcmmiz,False,dark,0.76,,public,2,0,{},,,False,[],,False,False,,{},Project,False,2,,False,self,False,,[],{},,True,,1612492880.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just finished this project! An unfiltered review of pizza places in your city.&lt;/p&gt;

&lt;p&gt;There are only 18 authentic pizza places out of 362 in Boston. This is what an AI said. Combining computer vision and machine learning to ease the search for Neapolitan pizza based on photos from public crowd-sourced reviews.&lt;/p&gt;

&lt;p&gt;Check your city and learn what’s going on under the hood – &lt;a href=""https://vasilykorf.com/find-pizza/""&gt;https://vasilykorf.com/find-pizza/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I would be glad to receive your feedback.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lcmmiz,True,,korfich,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/lcmmiz/project_find_neapolitan_pizza_with_ai_help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lcmmiz/project_find_neapolitan_pizza_with_ai_help/,22217,1612464080.0,0,,False,,,,,,,,,
135,,tensorflow,"Suppose I have a tensor of shape (batch, width, height, 1) that is greyscale input images, and another tensor of shape (batch, kernel_width, kernel_height). I want to use the kernels stored in the second tensor to convolve the input images. What's the best way to do this?


For context my input ""images"" are actually 2-d histograms. I am trying to classify the sources of data, but some sources have thousands of data points and some only have a few. I want to incorporate the sample size into the network by blurring/smoothing the histograms when they were built without much data. And I want the network to learn how much blurring to apply.

Network structured as followed:  

Inputs = images, n_obs. 

n_obs goes through a dense(10) then back to dense(1) with relu activations to get a diffusion constant for each input image.  

Kernels = identity + diffusion_constants  

Kernels are then normalized to sum to 1. So if the diffusion constant is high, it applies a uniform kernel blur. If it is 0, it applies an identity convolution and doesn't change the input.

I just need to figure out how to apply those kernels in a way that allows back propagation of gradients to learn how much blurring to apply.",t2_f9thu,False,,0,False,Applying a different convolution kernel to each image in batch,[],r/tensorflow,False,6,,0,,,False,t3_lckdye,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,True,self,False,,[],{},,True,,1612487165.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Suppose I have a tensor of shape (batch, width, height, 1) that is greyscale input images, and another tensor of shape (batch, kernel_width, kernel_height). I want to use the kernels stored in the second tensor to convolve the input images. What&amp;#39;s the best way to do this?&lt;/p&gt;

&lt;p&gt;For context my input &amp;quot;images&amp;quot; are actually 2-d histograms. I am trying to classify the sources of data, but some sources have thousands of data points and some only have a few. I want to incorporate the sample size into the network by blurring/smoothing the histograms when they were built without much data. And I want the network to learn how much blurring to apply.&lt;/p&gt;

&lt;p&gt;Network structured as followed:  &lt;/p&gt;

&lt;p&gt;Inputs = images, n_obs. &lt;/p&gt;

&lt;p&gt;n_obs goes through a dense(10) then back to dense(1) with relu activations to get a diffusion constant for each input image.  &lt;/p&gt;

&lt;p&gt;Kernels = identity + diffusion_constants  &lt;/p&gt;

&lt;p&gt;Kernels are then normalized to sum to 1. So if the diffusion constant is high, it applies a uniform kernel blur. If it is 0, it applies an identity convolution and doesn&amp;#39;t change the input.&lt;/p&gt;

&lt;p&gt;I just need to figure out how to apply those kernels in a way that allows back propagation of gradients to learn how much blurring to apply.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lckdye,True,,Tgs91,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/lckdye/applying_a_different_convolution_kernel_to_each/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lckdye/applying_a_different_convolution_kernel_to_each/,22217,1612458365.0,0,,False,,,,,,,,,
136,,tensorflow,,t2_44mbtmjy,False,,0,False,Latest from google researchers: state of the art in video stabilization!,[],r/tensorflow,False,6,,0,71.0,,False,t3_lc6d8m,False,dark,0.89,,public,7,0,{},140.0,,False,[],,False,False,,{},,False,7,,False,https://b.thumbs.redditmedia.com/sl2tvu1dqmRZXkGhgwnaw6-XQwZvqOzxpPj1SseBzTg.jpg,False,,[],{},,False,,1612438042.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lc6d8m,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lc6d8m/latest_from_google_researchers_state_of_the_art/,all_ads,False,/r/LatestInML/comments/lc64ei/latest_from_google_researchers_state_of_the_art/,22217,1612409242.0,0,,False,link,/r/LatestInML/comments/lc64ei/latest_from_google_researchers_state_of_the_art/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?auto=webp&amp;s=4e738a002de3f9450789d69fc6115e5a7fd3f041', 'width': 1240, 'height': 632}, 'resolutions': [{'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e95fa3897baf4356be692bc81ee171b81487339a', 'width': 108, 'height': 55}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d1a5f0ba46416713344bc45640347b69a1d14ed', 'width': 216, 'height': 110}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a0a403c0e7cf2b6351b10f601a1155de610873be', 'width': 320, 'height': 163}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8552e95eaceb767319081c80956741a94412eeb3', 'width': 640, 'height': 326}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9ba49f60c13c0e444d3e0f54aec37fe35bf0642a', 'width': 960, 'height': 489}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=22331740e5f91099692c467312e9479f556dc5b6', 'width': 1080, 'height': 550}], 'variants': {}, 'id': 'VZmZjUxqj5ORIGN95ja4d0G8KXzabDQtbpllGn1KoX0'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2102.01279)\n\nhttps://reddit.com/link/lc64ei/video/65g4j80modf61/player\n\n👇 Free extension to get code for ML papers (❤️' by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from google researchers: state of the art in video stabilization!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 71, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'65g4j80modf61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/lc64ei/asset/65g4j80modf61/DASHPlaylist.mpd?a=1618044675%2CMzk0YWQ3NzFiZmEyM2MzMjRkNTJjNGE0ZWQwODdhZGQ3MDE0MTkxY2NhODdhMTE5ZTg4ZTgyNDNlNTZmODY1Mw%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/lc64ei/asset/65g4j80modf61/HLSPlaylist.m3u8?a=1618044675%2CNmI3MDE4MmM0Y2Y3NTA0ODQyNjU0YWNhZDBhODFhNGQxYTlhZWIxYmIyOWJkZTljMTM2MzNiOWZkMjE0MmE5OQ%3D%3D&amp;v=1&amp;f=sd', 'id': '65g4j80modf61', 'isGif': False}}, 'name': 't3_lc64ei', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 41, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 41, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/sl2tvu1dqmRZXkGhgwnaw6-XQwZvqOzxpPj1SseBzTg.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1612437264.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2102.01279""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/lc64ei/video/65g4j80modf61/player""&gt;https://reddit.com/link/lc64ei/video/65g4j80modf61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39; by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/find-code-for-research-pa/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?auto=webp&amp;s=4e738a002de3f9450789d69fc6115e5a7fd3f041', 'width': 1240, 'height': 632}, 'resolutions': [{'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e95fa3897baf4356be692bc81ee171b81487339a', 'width': 108, 'height': 55}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d1a5f0ba46416713344bc45640347b69a1d14ed', 'width': 216, 'height': 110}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a0a403c0e7cf2b6351b10f601a1155de610873be', 'width': 320, 'height': 163}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8552e95eaceb767319081c80956741a94412eeb3', 'width': 640, 'height': 326}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9ba49f60c13c0e444d3e0f54aec37fe35bf0642a', 'width': 960, 'height': 489}, {'url': 'https://external-preview.redd.it/BCtig_3O7m4KzmmlzHKo3G-36_DczlX2F8QxESWLPJw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=22331740e5f91099692c467312e9479f556dc5b6', 'width': 1080, 'height': 550}], 'variants': {}, 'id': 'VZmZjUxqj5ORIGN95ja4d0G8KXzabDQtbpllGn1KoX0'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lc64ei', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/lc64ei/latest_from_google_researchers_state_of_the_art/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/lc64ei/latest_from_google_researchers_state_of_the_art/', 'subreddit_subscribers': 6676, 'created_utc': 1612408464.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_lc64ei,
137,,tensorflow,,t2_44mbtmjy,False,,0,False,Latest from KDnuggets: Find code implementation for any AI/ML paper using this new chrome extension,[],r/tensorflow,False,6,,0,,,False,t3_lcagq3,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,default,False,,[],{},,False,,1612452886.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lcagq3,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lcagq3/latest_from_kdnuggets_find_code_implementation/,all_ads,False,/r/LatestInML/comments/lcag4n/latest_from_kdnuggets_find_code_implementation/,22217,1612424086.0,0,,False,link,/r/LatestInML/comments/lcag4n/latest_from_kdnuggets_find_code_implementation/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?auto=webp&amp;s=02659bad52081873a10146ca8daad01706405bee', 'width': 1202, 'height': 234}, 'resolutions': [{'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3e5dbc27f65729bfccb1f019f5c4fdf4705dc15', 'width': 108, 'height': 21}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=438e1c7ce9e109e9bfc7476344700ec350e37edb', 'width': 216, 'height': 42}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2085485fec5b5e1b2c6490d7efb502dcc22eccbf', 'width': 320, 'height': 62}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f721d898297cce574f35eb473bc6efa3c5767f1', 'width': 640, 'height': 124}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57823910b22cd3dc8c1cb72538b0587a78805ce3', 'width': 960, 'height': 186}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6fd62fb158b9fd6f72ad0536f2e8c7102775c6f', 'width': 1080, 'height': 210}], 'variants': {}, 'id': '1IgdrGJHua-eumc0w7TSLq57TXilPA59tdWiEScPk-8'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': '[https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html](https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html)', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from KDnuggets: Find code implementation for any AI/ML paper using this new chrome extension', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lcag4n', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 5, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1612452819.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html""&gt;https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?auto=webp&amp;s=02659bad52081873a10146ca8daad01706405bee', 'width': 1202, 'height': 234}, 'resolutions': [{'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3e5dbc27f65729bfccb1f019f5c4fdf4705dc15', 'width': 108, 'height': 21}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=438e1c7ce9e109e9bfc7476344700ec350e37edb', 'width': 216, 'height': 42}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2085485fec5b5e1b2c6490d7efb502dcc22eccbf', 'width': 320, 'height': 62}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f721d898297cce574f35eb473bc6efa3c5767f1', 'width': 640, 'height': 124}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57823910b22cd3dc8c1cb72538b0587a78805ce3', 'width': 960, 'height': 186}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6fd62fb158b9fd6f72ad0536f2e8c7102775c6f', 'width': 1080, 'height': 210}], 'variants': {}, 'id': '1IgdrGJHua-eumc0w7TSLq57TXilPA59tdWiEScPk-8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lcag4n', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/lcag4n/latest_from_kdnuggets_find_code_implementation/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/lcag4n/latest_from_kdnuggets_find_code_implementation/', 'subreddit_subscribers': 6676, 'created_utc': 1612424019.0, 'num_crossposts': 9, 'media': None, 'is_video': False}]",t3_lcag4n,
138,,tensorflow,,t2_418wb,False,,0,False,Noob question about minimizing regression models (Tensorflow.JS),[],r/tensorflow,False,6,,0,,,False,t3_lc4lvw,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,default,False,,[],{},,False,,1612432700.0,text,6,,,text,self.TensorFlowJS,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lc4lvw,True,,ashmortar,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lc4lvw/noob_question_about_minimizing_regression_models/,all_ads,False,/r/TensorFlowJS/comments/lc4h2n/noob_question_about_minimizing_regression_models/,22217,1612403900.0,0,,False,,/r/TensorFlowJS/comments/lc4h2n/noob_question_about_minimizing_regression_models/,,,,,"[{'approved_at_utc': None, 'subreddit': 'TensorFlowJS', 'selftext': ""Hey all, this is perhaps a really abstract question, but I am trying to write a generalized curve fitting model and (at least for polynomials so far) it works great in terms of making predictions, but I'm having trouble extracting the coefficient values from my variables.\n\nI am essentially passing the degree of the polynomial as a parameter to my typescript class.  It then generates an appropriate loss function, set of randomly initialized variable scalars and then performs stochastic gradient descent on the training data using least means squared error.\n\nIt's possible my issue lies in the fact that I'm normalizing down my data prior to training, so when making predictions I denormalize the result.\n\nDo I need to somehow denormalize the coefficients? Is that possible?"", 'author_fullname': 't2_418wb', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Noob question about minimizing regression models', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/TensorFlowJS', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_lc4h2n', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1612432304.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.TensorFlowJS', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all, this is perhaps a really abstract question, but I am trying to write a generalized curve fitting model and (at least for polynomials so far) it works great in terms of making predictions, but I&amp;#39;m having trouble extracting the coefficient values from my variables.&lt;/p&gt;\n\n&lt;p&gt;I am essentially passing the degree of the polynomial as a parameter to my typescript class.  It then generates an appropriate loss function, set of randomly initialized variable scalars and then performs stochastic gradient descent on the training data using least means squared error.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s possible my issue lies in the fact that I&amp;#39;m normalizing down my data prior to training, so when making predictions I denormalize the result.&lt;/p&gt;\n\n&lt;p&gt;Do I need to somehow denormalize the coefficients? Is that possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_22lifv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'lc4h2n', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ashmortar', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/TensorFlowJS/comments/lc4h2n/noob_question_about_minimizing_regression_models/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://www.reddit.com/r/TensorFlowJS/comments/lc4h2n/noob_question_about_minimizing_regression_models/', 'subreddit_subscribers': 328, 'created_utc': 1612403504.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_lc4h2n,
139,,tensorflow,"For my thesis, I am attempting to detect faults/inconsistencies in 3D prints.   
Generating data takes a long time (because the print process takes a long time). For this reason my dataset is limited. I've got two classes which each have about 100-150 images each. This adds up to a total of about 250-300 images.Then I augmented those images 8 times with rotations and flips. I first tried to train on EfficientdetD0 but the results were pretty disappointing. Perhaps only a quarter of errors were getting detected.  
Someone on this subreddit told me I should use an architecture like "" [SSD ResNet50 V1 FPN 640x640 (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz) "" because this appearantly works better for small datasets, though I don't know why. So I went and tried it. I trained with the same parameters as before and for roughly the same time. The results were even worse.

Right now I would like to train a model from scratch and compare the results to the results I got using transfer learning, however I have no clue on how I should get started with this. I've been googling about but I haven't found a clear explanation just yet. Could somebody please point me in the right direction?

Also why should [SSD ResNet50 V1 FPN 640x640 (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz)  work better with smaller datasets, and why shouldn't I just use ResNet 151? From what I've gathered this should work better than 50 in my case because it goed deeper, no?",t2_14tmdx,False,,0,False,Training architecture fro scratch to use with the object detection API,[],r/tensorflow,False,6,,0,,,False,t3_lbrhy2,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1612398731.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For my thesis, I am attempting to detect faults/inconsistencies in 3D prints.&lt;br/&gt;
Generating data takes a long time (because the print process takes a long time). For this reason my dataset is limited. I&amp;#39;ve got two classes which each have about 100-150 images each. This adds up to a total of about 250-300 images.Then I augmented those images 8 times with rotations and flips. I first tried to train on EfficientdetD0 but the results were pretty disappointing. Perhaps only a quarter of errors were getting detected.&lt;br/&gt;
Someone on this subreddit told me I should use an architecture like &amp;quot; &lt;a href=""http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz""&gt;SSD ResNet50 V1 FPN 640x640 (RetinaNet50)&lt;/a&gt; &amp;quot; because this appearantly works better for small datasets, though I don&amp;#39;t know why. So I went and tried it. I trained with the same parameters as before and for roughly the same time. The results were even worse.&lt;/p&gt;

&lt;p&gt;Right now I would like to train a model from scratch and compare the results to the results I got using transfer learning, however I have no clue on how I should get started with this. I&amp;#39;ve been googling about but I haven&amp;#39;t found a clear explanation just yet. Could somebody please point me in the right direction?&lt;/p&gt;

&lt;p&gt;Also why should &lt;a href=""http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz""&gt;SSD ResNet50 V1 FPN 640x640 (RetinaNet50)&lt;/a&gt;  work better with smaller datasets, and why shouldn&amp;#39;t I just use ResNet 151? From what I&amp;#39;ve gathered this should work better than 50 in my case because it goed deeper, no?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lbrhy2,True,,007Nick700,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/lbrhy2/training_architecture_fro_scratch_to_use_with_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lbrhy2/training_architecture_fro_scratch_to_use_with_the/,22217,1612369931.0,0,,False,,,,,,,,,
140,,tensorflow,"Hi. 

&amp;#x200B;

There is this book [https://d2l.ai/](https://d2l.ai/) about deep learning. The great thing about this book is that it is introduces theory and implements from scratch not using only with library. But the problem is only few chapters are implemented with [tensorflow.](https://tensorflow.Do) Can you suggest this type of book or resource with tensorflow. Thanks in advance.",t2_7g5r4ev6,False,,0,False,Suggestions for book,[],r/tensorflow,False,6,,0,,,False,t3_lbp581,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1612392635.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;There is this book &lt;a href=""https://d2l.ai/""&gt;https://d2l.ai/&lt;/a&gt; about deep learning. The great thing about this book is that it is introduces theory and implements from scratch not using only with library. But the problem is only few chapters are implemented with &lt;a href=""https://tensorflow.Do""&gt;tensorflow.&lt;/a&gt; Can you suggest this type of book or resource with tensorflow. Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lbp581,True,,EnvironmentalStorm43,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/lbp581/suggestions_for_book/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lbp581/suggestions_for_book/,22217,1612363835.0,0,,False,,,,,,,,,
141,,tensorflow,,t2_4ja2g,False,,0,False,Sorting Gems in Path of Exile with Tensorflow,[],r/tensorflow,False,6,,0,140.0,,False,t3_lb84hx,False,dark,1.0,,public,20,0,{},140.0,,False,[],,False,False,,{},Project,False,20,,False,https://b.thumbs.redditmedia.com/6rh1scTLCWZfebM9_Rq-aPWKwuM61dT5KmXAgZmgf1g.jpg,False,,[],{},,False,,1612332756.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,lb84hx,True,,KayRice,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/lb84hx/sorting_gems_in_path_of_exile_with_tensorflow/,all_ads,False,https://github.com/krisives/tensorflow-poe-gem-sorter,22217,1612303956.0,0,,False,link,https://github.com/krisives/tensorflow-poe-gem-sorter,"{'images': [{'source': {'url': 'https://external-preview.redd.it/tRNiWJhHWlMhn3z2VTa41jHh5kgh1WMAckEZGx0IeSM.jpg?auto=webp&amp;s=4499ade29666c797fcb3bfaa9c1da15b1000be6d', 'width': 164, 'height': 164}, 'resolutions': [{'url': 'https://external-preview.redd.it/tRNiWJhHWlMhn3z2VTa41jHh5kgh1WMAckEZGx0IeSM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=00bacceb08751993f8f20af971d40c0657823ffe', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'xMYPXPn1JFaaHqisDwjclBaIPqEv-QaarmFxo5okspg'}], 'enabled': False}",,,,,,
142,,tensorflow,"I'm using image\_dataset\_from\_directory method to load images from file. And I've prepared an label.csv file for each image filename. 

&amp;#x200B;

However, after my first training, all of the prediction makes predict for same class. I'd checked up the directory folder and don't know why. 

&amp;#x200B;

I want to check up the label and image pair to see if any bug, but I don't find a simple way to do this, so I combine the other custom image\_dataset\_from\_directory function that returns image\_path, and compare with the order of given label:

&amp;#x200B;

    def image_dataset_from_directory(directory,
                                     labels='inferred',
                                     label_mode='int',
                                     class_names=None,
                                     color_mode='rgb',
                                     batch_size=32,
                                     image_size=(256, 256),
                                     shuffle=True,
                                     seed=None,
                                     validation_split=None,
                                     subset=None,
                                     interpolation='bilinear',
                                     follow_links=False):
      
      if labels != 'inferred':
        if not isinstance(labels, (list, tuple)):
          raise ValueError(
              '`labels` argument should be a list/tuple of integer labels, of '
              'the same size as the number of image files in the target '
              'directory. If you wish to infer the labels from the subdirectory '
              'names in the target directory, pass `labels=""inferred""`. '
              'If you wish to get a dataset that only contains images '
              '(no labels), pass `label_mode=None`.')
        if class_names:
          raise ValueError('You can only pass `class_names` if the labels are '
                           'inferred from the subdirectory names in the target '
                           'directory (`labels=""inferred""`).')
      if label_mode not in {'int', 'categorical', 'binary', None}:
        raise ValueError(
            '`label_mode` argument must be one of ""int"", ""categorical"", ""binary"", '
            'or None. Received: %s' % (label_mode,))
      if color_mode == 'rgb':
        num_channels = 3
      elif color_mode == 'rgba':
        num_channels = 4
      elif color_mode == 'grayscale':
        num_channels = 1
      else:
        raise ValueError(
            '`color_mode` must be one of {""rbg"", ""rgba"", ""grayscale""}. '
            'Received: %s' % (color_mode,))
      interpolation = image_preprocessing.get_interpolation(interpolation)
      dataset_utils.check_validation_split_arg(
          validation_split, subset, shuffle, seed)
    
      if seed is None:
        seed = np.random.randint(1e6)
      image_paths, labels, class_names = dataset_utils.index_directory(
          directory,
          labels,
          formats=WHITELIST_FORMATS,
          class_names=class_names,
          shuffle=shuffle,
          seed=seed,
          follow_links=follow_links)
    
      if label_mode == 'binary' and len(class_names) != 2:
        raise ValueError(
            'When passing `label_mode=""binary"", there must exactly 2 classes. '
            'Found the following classes: %s' % (class_names,))
    
      image_paths, labels = dataset_utils.get_training_or_validation_split(
          image_paths, labels, validation_split, subset)
    
      dataset = paths_and_labels_to_dataset(
          image_paths=image_paths,
          image_size=image_size,
          num_channels=num_channels,
          labels=labels,
          label_mode=label_mode,
          num_classes=len(class_names),
          interpolation=interpolation)
      if shuffle:
        # Shuffle locally at each iteration
        dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)
      dataset = dataset.batch(batch_size)
      # Users may need to reference `class_names`.
      dataset.class_names = class_names
      return dataset, image_paths

And this is data loader:

    train_dataset, train_path = image_dataset_from_directory(
        img_path,
        labels = labels,
        label_mode = 'binary',
        validation_split = 0.2,
        color_mode = 'rgb',
        subset = 'training',
        image_size = (IMAGE_WIDTH, IMAGE_HEIGHT),
        batch_size = BATCH_SIZE,
        seed = 123
        )

While I print the image and label pair, it's not matching:

    for i in range(len(train_path)):
       
      filename = train_path[i].split('/')[-1]
      print('File: {} label: {}'.format(filename, labels[i]))
    
    It returns:
    
    File: class_1_img.png label: 1
    File: class_1_img.png label: 2
    ... 

The unmatching image-label pair make the training meaningless.

&amp;#x200B;

How could I load image from directory and give label list to make them match order?",t2_11cquw,False,,0,False,"While load images from image_dataset_from_directory, I'm afraid the image file and label is not matching",[],r/tensorflow,False,6,,0,,,False,t3_lbetoi,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1612352994.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using image_dataset_from_directory method to load images from file. And I&amp;#39;ve prepared an label.csv file for each image filename. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;However, after my first training, all of the prediction makes predict for same class. I&amp;#39;d checked up the directory folder and don&amp;#39;t know why. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I want to check up the label and image pair to see if any bug, but I don&amp;#39;t find a simple way to do this, so I combine the other custom image_dataset_from_directory function that returns image_path, and compare with the order of given label:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def image_dataset_from_directory(directory,
                                 labels=&amp;#39;inferred&amp;#39;,
                                 label_mode=&amp;#39;int&amp;#39;,
                                 class_names=None,
                                 color_mode=&amp;#39;rgb&amp;#39;,
                                 batch_size=32,
                                 image_size=(256, 256),
                                 shuffle=True,
                                 seed=None,
                                 validation_split=None,
                                 subset=None,
                                 interpolation=&amp;#39;bilinear&amp;#39;,
                                 follow_links=False):

  if labels != &amp;#39;inferred&amp;#39;:
    if not isinstance(labels, (list, tuple)):
      raise ValueError(
          &amp;#39;`labels` argument should be a list/tuple of integer labels, of &amp;#39;
          &amp;#39;the same size as the number of image files in the target &amp;#39;
          &amp;#39;directory. If you wish to infer the labels from the subdirectory &amp;#39;
          &amp;#39;names in the target directory, pass `labels=&amp;quot;inferred&amp;quot;`. &amp;#39;
          &amp;#39;If you wish to get a dataset that only contains images &amp;#39;
          &amp;#39;(no labels), pass `label_mode=None`.&amp;#39;)
    if class_names:
      raise ValueError(&amp;#39;You can only pass `class_names` if the labels are &amp;#39;
                       &amp;#39;inferred from the subdirectory names in the target &amp;#39;
                       &amp;#39;directory (`labels=&amp;quot;inferred&amp;quot;`).&amp;#39;)
  if label_mode not in {&amp;#39;int&amp;#39;, &amp;#39;categorical&amp;#39;, &amp;#39;binary&amp;#39;, None}:
    raise ValueError(
        &amp;#39;`label_mode` argument must be one of &amp;quot;int&amp;quot;, &amp;quot;categorical&amp;quot;, &amp;quot;binary&amp;quot;, &amp;#39;
        &amp;#39;or None. Received: %s&amp;#39; % (label_mode,))
  if color_mode == &amp;#39;rgb&amp;#39;:
    num_channels = 3
  elif color_mode == &amp;#39;rgba&amp;#39;:
    num_channels = 4
  elif color_mode == &amp;#39;grayscale&amp;#39;:
    num_channels = 1
  else:
    raise ValueError(
        &amp;#39;`color_mode` must be one of {&amp;quot;rbg&amp;quot;, &amp;quot;rgba&amp;quot;, &amp;quot;grayscale&amp;quot;}. &amp;#39;
        &amp;#39;Received: %s&amp;#39; % (color_mode,))
  interpolation = image_preprocessing.get_interpolation(interpolation)
  dataset_utils.check_validation_split_arg(
      validation_split, subset, shuffle, seed)

  if seed is None:
    seed = np.random.randint(1e6)
  image_paths, labels, class_names = dataset_utils.index_directory(
      directory,
      labels,
      formats=WHITELIST_FORMATS,
      class_names=class_names,
      shuffle=shuffle,
      seed=seed,
      follow_links=follow_links)

  if label_mode == &amp;#39;binary&amp;#39; and len(class_names) != 2:
    raise ValueError(
        &amp;#39;When passing `label_mode=&amp;quot;binary&amp;quot;, there must exactly 2 classes. &amp;#39;
        &amp;#39;Found the following classes: %s&amp;#39; % (class_names,))

  image_paths, labels = dataset_utils.get_training_or_validation_split(
      image_paths, labels, validation_split, subset)

  dataset = paths_and_labels_to_dataset(
      image_paths=image_paths,
      image_size=image_size,
      num_channels=num_channels,
      labels=labels,
      label_mode=label_mode,
      num_classes=len(class_names),
      interpolation=interpolation)
  if shuffle:
    # Shuffle locally at each iteration
    dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)
  dataset = dataset.batch(batch_size)
  # Users may need to reference `class_names`.
  dataset.class_names = class_names
  return dataset, image_paths
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is data loader:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_dataset, train_path = image_dataset_from_directory(
    img_path,
    labels = labels,
    label_mode = &amp;#39;binary&amp;#39;,
    validation_split = 0.2,
    color_mode = &amp;#39;rgb&amp;#39;,
    subset = &amp;#39;training&amp;#39;,
    image_size = (IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size = BATCH_SIZE,
    seed = 123
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While I print the image and label pair, it&amp;#39;s not matching:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in range(len(train_path)):

  filename = train_path[i].split(&amp;#39;/&amp;#39;)[-1]
  print(&amp;#39;File: {} label: {}&amp;#39;.format(filename, labels[i]))

It returns:

File: class_1_img.png label: 1
File: class_1_img.png label: 2
... 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The unmatching image-label pair make the training meaningless.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;How could I load image from directory and give label list to make them match order?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,lbetoi,True,,Laurence-Lin,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lbetoi/while_load_images_from_image_dataset_from/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lbetoi/while_load_images_from_image_dataset_from/,22217,1612324194.0,0,,False,,,,,,,,,
143,,tensorflow,"I am trying to create a basic, custom model together with a custom tf.data.Dataset. However, running my code gives me a ""InvalidArgumentError"".

The full error message:

    InvalidArgumentError: Matrix size-incompatible: In[0]: [26,599], In[1]: [15574,2048] [Op:MatMul]

So I have a signal on which I do a certain calculation. This gives me a 2D matrix of 26 rows and 599 columns. I want to group these matrices in a tf.data.Dataset, so that I can use them later to build a model.

The full code and error message are given below. TensorFlow version is 2.3.1.

Could someone please help me identify the issue?

Thanks in advance.

**Dataset creation (tf.data.Dataset)**

    """"""
    Create separate tf.data.Dataset's for the training and test set.
    """"""
    # Create train labels
    signal_matrices_train = signal_matrices.get_xval_set(fold=0, set='train')
    
    matrices_list = []
    label1_list = []
    label2_list = []
    for i in range(len(signal_matrices_train)):
        matrices_list.append(signal_matrices_train[i]['preprocessed']['matrix'])
        label1_list.append(signal_matrices_train[i]['label1']
        label2_list.append(signal_matrices_train[i]['label2'])
    
    train_array = np.dstack(matrices_list)
    train_array = np.swapaxes(train_array, 1, 0) # To get (26, 599) for the signal matrices
    train_label1_array = np.array(label1_list)
    train_label2_array = np.array(label2_list)
    
    if(train_label1_array.shape == train_label2_array.shape):
        temparr = np.column_stack((train_label1_array, train_label2_array))
        train_dataset_tf = tf.data.Dataset.from_tensor_slices((train_array.T, temparr))
    else:
        print('Train: Label1 and label2 array do not have same length.')
        train_dataset_tf = tf.data.Dataset.from_tensor_slices((train_array.T, train_label1_array, train_label2_array))
    
    
    # Same for test labels

After the dataset declarations, I try to check if things are as I would expect:

    """""" Print info about train_dataset_tf """"""
    print('Training dataset:')
    pprint(train_dataset_tf.element_spec)
    print('Length of train_dataset_tf: ', len(train_dataset_tf))
    print('\nTest dataset:')
    pprint(test_dataset_tf.element_spec)
    print('Length of test_dataset_tf: ', len(test_dataset_tf))
    
    
    Output:
    Training dataset:
    (TensorSpec(shape=(26, 599), dtype=tf.float64, name=None),
     TensorSpec(shape=(2,), dtype=tf.int64, name=None))
    Length of train_dataset_tf:  2351
    
    Test dataset:
    (TensorSpec(shape=(26, 599), dtype=tf.float64, name=None),
     TensorSpec(shape=(2,), dtype=tf.int64, name=None))
    Length of test_dataset_tf:  1541

I indeed have matrices of \[26x599\] containing floats and I have two binary classes (one-hot encoded).

Next, I print the first element of the training dataset:

    """""" Give an example of an element in the training dataset """"""
    it = iter(train_dataset_tf)
    print(next(it))
    
    
    Output:
    (&lt;tf.Tensor: shape=(26, 599), dtype=float64, numpy=
    array([[ 0.0072,  0.0100 ,  0.0108, ...,  0.0097,
             0.0070,  0.0091 ],
           [ 0.0070,  0.0092,  0.0099, ...,  0.0090,
             0.0069,  0.0085 ],
           [ 0.0029 ,  0.0041,  0.0044, ...,  0.0039,
             0.0030,  0.0040],
           ...,
           [-0.0047, -0.0049, -0.0047, ..., -0.0054,
            -0.0057, -0.0047],
           [-0.0045, -0.0050 , -0.0049, ..., -0.0056,
            -0.0057, -0.0046],
           [-0.0042, -0.0049, -0.0047, ..., -0.0056,
            -0.0059, -0.0043]])&gt;, &lt;tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])&gt;)

The last step of the dataset creation is to generate batches with a size of 32:

    """""" Create batches of training data """"""
    train_batches = train_dataset_tf.shuffle(5000, seed=17, reshuffle_each_iteration=True).batch(BATCH_SIZE, drop_remainder=True) # Buffer size = 5000 and batch size = 32 (buffer size greater or equal to dataset size is recommended)

**Model creation**

    """""" Model declaration """"""
    # Source: https://www.tensorflow.org/tutorials/keras/classification#preprocess_the_data
    model = Sequential()
    model.add(Input(shape=[26,599], batch_size=BATCH_SIZE, name='input'))
    model.add(Flatten(input_shape=[26, 599], data_format=None, name='flatten1')) # Go from 2D [26x599] to 1D [15 574]
    model.add(Dense(2048, activation='relu', name='dense1', input_shape=[15574]))
    model.add(Dense(512, activation='relu', name='dense2'))
    model.add(Dense(128, activation='relu', name='dense3'))
    model.add(Dense(NUM_CLASSES, activation='sigmoid', name='dense_classification')) # Output layer that does classification
    
    model.compile('sgd', 'binary_crossentropy', metrics=['accuracy'])

Next, I try to check if the model declaration is correct. I do this with model.summary():

    model.summary()
    
    
    Output:
    Model: ""sequential""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    flatten1 (Flatten)           (32, 15574)               0         
    _________________________________________________________________
    dense1 (Dense)               (32, 2048)                31897600  
    _________________________________________________________________
    dense2 (Dense)               (32, 512)                 1049088   
    _________________________________________________________________
    dense3 (Dense)               (32, 128)                 65664     
    _________________________________________________________________
    dense_classification (Dense) (32, 2)                   258       
    =================================================================
    Total params: 33,012,610
    Trainable params: 33,012,610
    Non-trainable params: 0

In my eyes, this seems to be correct.

The final step is to train the model. This part also contains the full error message that is thrown:

    # Definition of callbacks
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0, mode='auto', verbose=1)
    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=14, verbose=0, mode='auto', restore_best_weights=True)
    csv_logger = CSVLogger(LOGFILE, separator=',', append=True)
    
    # Train the model
    history = model.fit(
        train_dataset_tf,
        batch_size=BATCH_SIZE,
        epochs=5,
        verbose=2,
        callbacks = [reduce_lr, csv_logger, early_stop],
        shuffle=True
    )
    
    
    Output:
    Epoch 1/5
    ---------------------------------------------------------------------------
    InvalidArgumentError                      Traceback (most recent call last)
    &lt;ipython-input-39-9d9a4ccaf472&gt; in &lt;module&gt;
         35     callbacks = [reduce_lr, csv_logger, early_stop],
         36     class_weight = CLASS_WEIGHTS,
    ---&gt; 37     shuffle=True
         38 )
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
        106   def _method_wrapper(self, *args, **kwargs):
        107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
    --&gt; 108       return method(self, *args, **kwargs)
        109 
        110     # Running inside `run_distribute_coordinator` already.
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
       1096                 batch_size=batch_size):
       1097               callbacks.on_train_batch_begin(step)
    -&gt; 1098               tmp_logs = train_function(iterator)
       1099               if data_handler.should_sync:
       1100                 context.async_wait()
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_function(iterator)
        804       def train_function(iterator):
        805         """"""Runs a training execution with one step.""""""
    --&gt; 806         return step_function(self, iterator)
        807 
        808     else:
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in step_function(model, iterator)
        794 
        795       data = next(iterator)
    --&gt; 796       outputs = model.distribute_strategy.run(run_step, args=(data,))
        797       outputs = reduce_per_replica(
        798           outputs, self.distribute_strategy, reduction='first')
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in run(***failed resolving arguments***)
       1209       fn = autograph.tf_convert(
       1210           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)
    -&gt; 1211       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
       1212 
       1213   # TODO(b/151224785): Remove deprecated alias.
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
       2583       kwargs = {}
       2584     with self._container_strategy().scope():
    -&gt; 2585       return self._call_for_each_replica(fn, args, kwargs)
       2586 
       2587   def _call_for_each_replica(self, fn, args, kwargs):
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
       2943         self._container_strategy(),
       2944         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
    -&gt; 2945       return fn(*args, **kwargs)
       2946 
       2947   def _reduce_to(self, reduce_op, value, destinations, experimental_hints):
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
        273   def wrapper(*args, **kwargs):
        274     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):
    --&gt; 275       return func(*args, **kwargs)
        276 
        277   if inspect.isfunction(func) or inspect.ismethod(func):
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in run_step(data)
        787 
        788       def run_step(data):
    --&gt; 789         outputs = model.train_step(data)
        790         # Ensure counter is updated only if `train_step` succeeds.
        791         with ops.control_dependencies(_minimum_control_deps(outputs)):
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_step(self, data)
        745 
        746     with backprop.GradientTape() as tape:
    --&gt; 747       y_pred = self(x, training=True)
        748       loss = self.compiled_loss(
        749           y, y_pred, sample_weight, regularization_losses=self.losses)
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
        983 
        984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
    --&gt; 985           outputs = call_fn(inputs, *args, **kwargs)
        986 
        987         if self._activity_regularizer:
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py in call(self, inputs, training, mask)
        370       if not self.built:
        371         self._init_graph_network(self.inputs, self.outputs)
    --&gt; 372       return super(Sequential, self).call(inputs, training=training, mask=mask)
        373 
        374     outputs = inputs  # handle the corner case where self.layers is empty
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py in call(self, inputs, training, mask)
        384     """"""
        385     return self._run_internal_graph(
    --&gt; 386         inputs, training=training, mask=mask)
        387 
        388   def compute_output_shape(self, input_shape):
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py in _run_internal_graph(self, inputs, training, mask)
        506 
        507         args, kwargs = node.map_arguments(tensor_dict)
    --&gt; 508         outputs = node.layer(*args, **kwargs)
        509 
        510         # Update tensor_dict.
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
        983 
        984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
    --&gt; 985           outputs = call_fn(inputs, *args, **kwargs)
        986 
        987         if self._activity_regularizer:
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py in call(self, inputs)
       1196         self.bias,
       1197         self.activation,
    -&gt; 1198         dtype=self._compute_dtype_object)
       1199 
       1200   def compute_output_shape(self, input_shape):
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/layers/ops/core.py in dense(inputs, kernel, bias, activation, dtype)
         51       outputs = sparse_ops.sparse_tensor_dense_matmul(inputs, kernel)
         52     else:
    ---&gt; 53       outputs = gen_math_ops.mat_mul(inputs, kernel)
         54   # Broadcast kernel to inputs.
         55   else:
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py in mat_mul(a, b, transpose_a, transpose_b, name)
       5622       return _result
       5623     except _core._NotOkStatusException as e:
    -&gt; 5624       _ops.raise_from_not_ok_status(e, name)
       5625     except _core._FallbackException:
       5626       pass
    
    ~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
       6841   message = e.message + ("" name: "" + name if name is not None else """")
       6842   # pylint: disable=protected-access
    -&gt; 6843   six.raise_from(core._status_to_exception(e.code, message), None)
       6844   # pylint: enable=protected-access
       6845 
    
    ~/myvenv/project/lib/python3.6/site-packages/six.py in raise_from(value, from_value)
    
    InvalidArgumentError: Matrix size-incompatible: In[0]: [26,599], In[1]: [15574,2048] [Op:MatMul]",t2_kb53x,False,,0,False,Simple custom model with custom tf.data.Dataset does not work,[],r/tensorflow,False,6,,0,,,False,t3_lb3lrq,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1612297786.0,,[],{},,True,,1612321636.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to create a basic, custom model together with a custom tf.data.Dataset. However, running my code gives me a &amp;quot;InvalidArgumentError&amp;quot;.&lt;/p&gt;

&lt;p&gt;The full error message:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;InvalidArgumentError: Matrix size-incompatible: In[0]: [26,599], In[1]: [15574,2048] [Op:MatMul]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I have a signal on which I do a certain calculation. This gives me a 2D matrix of 26 rows and 599 columns. I want to group these matrices in a tf.data.Dataset, so that I can use them later to build a model.&lt;/p&gt;

&lt;p&gt;The full code and error message are given below. TensorFlow version is 2.3.1.&lt;/p&gt;

&lt;p&gt;Could someone please help me identify the issue?&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dataset creation (tf.data.Dataset)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot;
Create separate tf.data.Dataset&amp;#39;s for the training and test set.
&amp;quot;&amp;quot;&amp;quot;
# Create train labels
signal_matrices_train = signal_matrices.get_xval_set(fold=0, set=&amp;#39;train&amp;#39;)

matrices_list = []
label1_list = []
label2_list = []
for i in range(len(signal_matrices_train)):
    matrices_list.append(signal_matrices_train[i][&amp;#39;preprocessed&amp;#39;][&amp;#39;matrix&amp;#39;])
    label1_list.append(signal_matrices_train[i][&amp;#39;label1&amp;#39;]
    label2_list.append(signal_matrices_train[i][&amp;#39;label2&amp;#39;])

train_array = np.dstack(matrices_list)
train_array = np.swapaxes(train_array, 1, 0) # To get (26, 599) for the signal matrices
train_label1_array = np.array(label1_list)
train_label2_array = np.array(label2_list)

if(train_label1_array.shape == train_label2_array.shape):
    temparr = np.column_stack((train_label1_array, train_label2_array))
    train_dataset_tf = tf.data.Dataset.from_tensor_slices((train_array.T, temparr))
else:
    print(&amp;#39;Train: Label1 and label2 array do not have same length.&amp;#39;)
    train_dataset_tf = tf.data.Dataset.from_tensor_slices((train_array.T, train_label1_array, train_label2_array))


# Same for test labels
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the dataset declarations, I try to check if things are as I would expect:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot; Print info about train_dataset_tf &amp;quot;&amp;quot;&amp;quot;
print(&amp;#39;Training dataset:&amp;#39;)
pprint(train_dataset_tf.element_spec)
print(&amp;#39;Length of train_dataset_tf: &amp;#39;, len(train_dataset_tf))
print(&amp;#39;\nTest dataset:&amp;#39;)
pprint(test_dataset_tf.element_spec)
print(&amp;#39;Length of test_dataset_tf: &amp;#39;, len(test_dataset_tf))


Output:
Training dataset:
(TensorSpec(shape=(26, 599), dtype=tf.float64, name=None),
 TensorSpec(shape=(2,), dtype=tf.int64, name=None))
Length of train_dataset_tf:  2351

Test dataset:
(TensorSpec(shape=(26, 599), dtype=tf.float64, name=None),
 TensorSpec(shape=(2,), dtype=tf.int64, name=None))
Length of test_dataset_tf:  1541
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I indeed have matrices of [26x599] containing floats and I have two binary classes (one-hot encoded).&lt;/p&gt;

&lt;p&gt;Next, I print the first element of the training dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot; Give an example of an element in the training dataset &amp;quot;&amp;quot;&amp;quot;
it = iter(train_dataset_tf)
print(next(it))


Output:
(&amp;lt;tf.Tensor: shape=(26, 599), dtype=float64, numpy=
array([[ 0.0072,  0.0100 ,  0.0108, ...,  0.0097,
         0.0070,  0.0091 ],
       [ 0.0070,  0.0092,  0.0099, ...,  0.0090,
         0.0069,  0.0085 ],
       [ 0.0029 ,  0.0041,  0.0044, ...,  0.0039,
         0.0030,  0.0040],
       ...,
       [-0.0047, -0.0049, -0.0047, ..., -0.0054,
        -0.0057, -0.0047],
       [-0.0045, -0.0050 , -0.0049, ..., -0.0056,
        -0.0057, -0.0046],
       [-0.0042, -0.0049, -0.0047, ..., -0.0056,
        -0.0059, -0.0043]])&amp;gt;, &amp;lt;tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last step of the dataset creation is to generate batches with a size of 32:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot; Create batches of training data &amp;quot;&amp;quot;&amp;quot;
train_batches = train_dataset_tf.shuffle(5000, seed=17, reshuffle_each_iteration=True).batch(BATCH_SIZE, drop_remainder=True) # Buffer size = 5000 and batch size = 32 (buffer size greater or equal to dataset size is recommended)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Model creation&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot; Model declaration &amp;quot;&amp;quot;&amp;quot;
# Source: https://www.tensorflow.org/tutorials/keras/classification#preprocess_the_data
model = Sequential()
model.add(Input(shape=[26,599], batch_size=BATCH_SIZE, name=&amp;#39;input&amp;#39;))
model.add(Flatten(input_shape=[26, 599], data_format=None, name=&amp;#39;flatten1&amp;#39;)) # Go from 2D [26x599] to 1D [15 574]
model.add(Dense(2048, activation=&amp;#39;relu&amp;#39;, name=&amp;#39;dense1&amp;#39;, input_shape=[15574]))
model.add(Dense(512, activation=&amp;#39;relu&amp;#39;, name=&amp;#39;dense2&amp;#39;))
model.add(Dense(128, activation=&amp;#39;relu&amp;#39;, name=&amp;#39;dense3&amp;#39;))
model.add(Dense(NUM_CLASSES, activation=&amp;#39;sigmoid&amp;#39;, name=&amp;#39;dense_classification&amp;#39;)) # Output layer that does classification

model.compile(&amp;#39;sgd&amp;#39;, &amp;#39;binary_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, I try to check if the model declaration is correct. I do this with model.summary():&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.summary()


Output:
Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten1 (Flatten)           (32, 15574)               0         
_________________________________________________________________
dense1 (Dense)               (32, 2048)                31897600  
_________________________________________________________________
dense2 (Dense)               (32, 512)                 1049088   
_________________________________________________________________
dense3 (Dense)               (32, 128)                 65664     
_________________________________________________________________
dense_classification (Dense) (32, 2)                   258       
=================================================================
Total params: 33,012,610
Trainable params: 33,012,610
Non-trainable params: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In my eyes, this seems to be correct.&lt;/p&gt;

&lt;p&gt;The final step is to train the model. This part also contains the full error message that is thrown:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Definition of callbacks
reduce_lr = ReduceLROnPlateau(monitor=&amp;#39;val_loss&amp;#39;, factor=0.5, patience=5, min_lr=0, mode=&amp;#39;auto&amp;#39;, verbose=1)
early_stop = EarlyStopping(monitor=&amp;#39;val_loss&amp;#39;, min_delta=0.0001, patience=14, verbose=0, mode=&amp;#39;auto&amp;#39;, restore_best_weights=True)
csv_logger = CSVLogger(LOGFILE, separator=&amp;#39;,&amp;#39;, append=True)

# Train the model
history = model.fit(
    train_dataset_tf,
    batch_size=BATCH_SIZE,
    epochs=5,
    verbose=2,
    callbacks = [reduce_lr, csv_logger, early_stop],
    shuffle=True
)


Output:
Epoch 1/5
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
&amp;lt;ipython-input-39-9d9a4ccaf472&amp;gt; in &amp;lt;module&amp;gt;
     35     callbacks = [reduce_lr, csv_logger, early_stop],
     36     class_weight = CLASS_WEIGHTS,
---&amp;gt; 37     shuffle=True
     38 )

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--&amp;gt; 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1096                 batch_size=batch_size):
   1097               callbacks.on_train_batch_begin(step)
-&amp;gt; 1098               tmp_logs = train_function(iterator)
   1099               if data_handler.should_sync:
   1100                 context.async_wait()

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_function(iterator)
    804       def train_function(iterator):
    805         &amp;quot;&amp;quot;&amp;quot;Runs a training execution with one step.&amp;quot;&amp;quot;&amp;quot;
--&amp;gt; 806         return step_function(self, iterator)
    807 
    808     else:

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in step_function(model, iterator)
    794 
    795       data = next(iterator)
--&amp;gt; 796       outputs = model.distribute_strategy.run(run_step, args=(data,))
    797       outputs = reduce_per_replica(
    798           outputs, self.distribute_strategy, reduction=&amp;#39;first&amp;#39;)

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in run(***failed resolving arguments***)
   1209       fn = autograph.tf_convert(
   1210           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)
-&amp;gt; 1211       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
   1212 
   1213   # TODO(b/151224785): Remove deprecated alias.

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   2583       kwargs = {}
   2584     with self._container_strategy().scope():
-&amp;gt; 2585       return self._call_for_each_replica(fn, args, kwargs)
   2586 
   2587   def _call_for_each_replica(self, fn, args, kwargs):

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2943         self._container_strategy(),
   2944         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-&amp;gt; 2945       return fn(*args, **kwargs)
   2946 
   2947   def _reduce_to(self, reduce_op, value, destinations, experimental_hints):

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    273   def wrapper(*args, **kwargs):
    274     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):
--&amp;gt; 275       return func(*args, **kwargs)
    276 
    277   if inspect.isfunction(func) or inspect.ismethod(func):

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in run_step(data)
    787 
    788       def run_step(data):
--&amp;gt; 789         outputs = model.train_step(data)
    790         # Ensure counter is updated only if `train_step` succeeds.
    791         with ops.control_dependencies(_minimum_control_deps(outputs)):

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_step(self, data)
    745 
    746     with backprop.GradientTape() as tape:
--&amp;gt; 747       y_pred = self(x, training=True)
    748       loss = self.compiled_loss(
    749           y, y_pred, sample_weight, regularization_losses=self.losses)

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--&amp;gt; 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py in call(self, inputs, training, mask)
    370       if not self.built:
    371         self._init_graph_network(self.inputs, self.outputs)
--&amp;gt; 372       return super(Sequential, self).call(inputs, training=training, mask=mask)
    373 
    374     outputs = inputs  # handle the corner case where self.layers is empty

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py in call(self, inputs, training, mask)
    384     &amp;quot;&amp;quot;&amp;quot;
    385     return self._run_internal_graph(
--&amp;gt; 386         inputs, training=training, mask=mask)
    387 
    388   def compute_output_shape(self, input_shape):

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py in _run_internal_graph(self, inputs, training, mask)
    506 
    507         args, kwargs = node.map_arguments(tensor_dict)
--&amp;gt; 508         outputs = node.layer(*args, **kwargs)
    509 
    510         # Update tensor_dict.

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--&amp;gt; 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py in call(self, inputs)
   1196         self.bias,
   1197         self.activation,
-&amp;gt; 1198         dtype=self._compute_dtype_object)
   1199 
   1200   def compute_output_shape(self, input_shape):

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/keras/layers/ops/core.py in dense(inputs, kernel, bias, activation, dtype)
     51       outputs = sparse_ops.sparse_tensor_dense_matmul(inputs, kernel)
     52     else:
---&amp;gt; 53       outputs = gen_math_ops.mat_mul(inputs, kernel)
     54   # Broadcast kernel to inputs.
     55   else:

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py in mat_mul(a, b, transpose_a, transpose_b, name)
   5622       return _result
   5623     except _core._NotOkStatusException as e:
-&amp;gt; 5624       _ops.raise_from_not_ok_status(e, name)
   5625     except _core._FallbackException:
   5626       pass

~/myvenv/project/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6841   message = e.message + (&amp;quot; name: &amp;quot; + name if name is not None else &amp;quot;&amp;quot;)
   6842   # pylint: disable=protected-access
-&amp;gt; 6843   six.raise_from(core._status_to_exception(e.code, message), None)
   6844   # pylint: enable=protected-access
   6845 

~/myvenv/project/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Matrix size-incompatible: In[0]: [26,599], In[1]: [15574,2048] [Op:MatMul]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lb3lrq,True,,mich2000222,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/lb3lrq/simple_custom_model_with_custom_tfdatadataset/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lb3lrq/simple_custom_model_with_custom_tfdatadataset/,22217,1612292836.0,0,,False,,,,,,,,,
144,,tensorflow,"In this article, we’ll compare model-free vs model-based reinforcement learning. Along the way, we will explore:

- Fundamental concepts of Reinforcement Learning (Markov decision processes / Q-Value / Q-Learning / Deep Q Network)
- Difference between model-based and model-free reinforcement learning.
- Discrete mathematical approach to playing tennis – model-free reinforcement learning.
- Tennis game using Deep Q Network – model-based reinforcement learning.
- Comparison/Evaluation
- References to learn more

[RL with pytennis](https://neptune.ai/blog/model-based-and-model-free-reinforcement-learning-pytennis-case-study?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-model-based-and-model-free-reinforcement-learning-pytennis-case-study&amp;utm_content=tensorflow)",t2_5hfacnnv,False,,0,False,[Case Study] Model-Based and Model-Free Reinforcement Learning with Pytennis and Keras,[],r/tensorflow,False,6,,0,,,False,t3_laztlh,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1612312404.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this article, we’ll compare model-free vs model-based reinforcement learning. Along the way, we will explore:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fundamental concepts of Reinforcement Learning (Markov decision processes / Q-Value / Q-Learning / Deep Q Network)&lt;/li&gt;
&lt;li&gt;Difference between model-based and model-free reinforcement learning.&lt;/li&gt;
&lt;li&gt;Discrete mathematical approach to playing tennis – model-free reinforcement learning.&lt;/li&gt;
&lt;li&gt;Tennis game using Deep Q Network – model-based reinforcement learning.&lt;/li&gt;
&lt;li&gt;Comparison/Evaluation&lt;/li&gt;
&lt;li&gt;References to learn more&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/model-based-and-model-free-reinforcement-learning-pytennis-case-study?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-model-based-and-model-free-reinforcement-learning-pytennis-case-study&amp;amp;utm_content=tensorflow""&gt;RL with pytennis&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,laztlh,True,,kk_ai,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/laztlh/case_study_modelbased_and_modelfree_reinforcement/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/laztlh/case_study_modelbased_and_modelfree_reinforcement/,22217,1612283604.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?auto=webp&amp;s=f38d058438e4158002121c105624a9fe89bf8a20', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66166a48214eff26826a1d6fc0045dc5cc376690', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=065ba8cc3f0df0ef7cd7aae64565442062843d35', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5111d77bd8dd263d2421488dbf0c501259e7c2c6', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b59aa7a3beec23bd5f0d9ae0869ca758ca13340c', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e4bd17a76e237ec02e7c892a4307496255c3db35', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/qs4mV-jHYNc2cPBhqwslGLPvLGMFTgY_71Yc1RE1ilI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78c8232867b0ff0575309396d09d451c4f8057d4', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'E_GGuD-OphNFd5H8iacqNBSfD1-rOyjvdgYyWyUwOBM'}], 'enabled': False}",,,,,,
145,,tensorflow,"I'm trying to assign the return value of `get_value()` to a numpy array within a method decorated using `tf.function`. It works only if I call the method directly. However, if I use the result of `tf.numpy_function()` (in `case3`), I get an error.

    import numpy as np
    import tensorflow as tf
    
    
    class Foo:
        def __init__(self):
            self.storage = np.zeros((10, 3, 1))
    
        @staticmethod
        def get_value():
            return np.array([[1], [2], [3]])
    
        @tf.function
        def case1(self):  # works
            self.storage[0] = self.get_value()
    
        def case2(self):  # works
            self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)
    
        @tf.function  # fails
        def case3(self):
            self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)
    
    
    if __name__ == '__main__':
        foo = Foo()
        foo.case1()
        foo.case2()
        foo.case3()

It works for all except `case3()` and raises the following error:

    Traceback (most recent call last):
      File ""/Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py"", line 29, in &lt;module&gt;
        foo.case3()
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
        result = self._call(*args, **kwds)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 871, in _call
        self._initialize(args, kwds, add_initializers_to=initializers)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 725, in _initialize
        self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2969, in _get_concrete_function_internal_garbage_collected
        graph_function, _ = self._maybe_define_function(args, kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3361, in _maybe_define_function
        graph_function = self._create_graph_function(args, kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3196, in _create_graph_function
        func_graph_module.func_graph_from_py_func(
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 990, in func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 634, in wrapped_fn
        out = weak_wrapped_fn().__wrapped__(*args, **kwds)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3887, in bound_method_wrapper
        return wrapped_fn(*args, **kwargs)
      File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 977, in wrapper
        raise e.ag_error_metadata.to_exception(e)
    TypeError: in user code:
    
        /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py:22 case3  *
            self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)
    
        TypeError: __array__() takes 1 positional argument but 2 were given",t2_4jbcsgd0,False,,0,False,cannot assign tf.numpy_function result to a numpy array,[],r/tensorflow,False,6,,0,,,False,t3_layeic,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1612309068.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to assign the return value of &lt;code&gt;get_value()&lt;/code&gt; to a numpy array within a method decorated using &lt;code&gt;tf.function&lt;/code&gt;. It works only if I call the method directly. However, if I use the result of &lt;code&gt;tf.numpy_function()&lt;/code&gt; (in &lt;code&gt;case3&lt;/code&gt;), I get an error.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
import tensorflow as tf


class Foo:
    def __init__(self):
        self.storage = np.zeros((10, 3, 1))

    @staticmethod
    def get_value():
        return np.array([[1], [2], [3]])

    @tf.function
    def case1(self):  # works
        self.storage[0] = self.get_value()

    def case2(self):  # works
        self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)

    @tf.function  # fails
    def case3(self):
        self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)


if __name__ == &amp;#39;__main__&amp;#39;:
    foo = Foo()
    foo.case1()
    foo.case2()
    foo.case3()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It works for all except &lt;code&gt;case3()&lt;/code&gt; and raises the following error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Traceback (most recent call last):
  File &amp;quot;/Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py&amp;quot;, line 29, in &amp;lt;module&amp;gt;
    foo.case3()
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&amp;quot;, line 828, in __call__
    result = self._call(*args, **kwds)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&amp;quot;, line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&amp;quot;, line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py&amp;quot;, line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py&amp;quot;, line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py&amp;quot;, line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&amp;quot;, line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&amp;quot;, line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py&amp;quot;, line 3887, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File &amp;quot;/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&amp;quot;, line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2020.3/scratches/scratch.py:22 case3  *
        self.storage[0] = tf.numpy_function(self.get_value, inp=[], Tout=tf.float32)

    TypeError: __array__() takes 1 positional argument but 2 were given
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,layeic,True,,emadboctor,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/layeic/cannot_assign_tfnumpy_function_result_to_a_numpy/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/layeic/cannot_assign_tfnumpy_function_result_to_a_numpy/,22217,1612280268.0,0,,False,,,,,,,,,
146,,tensorflow,"Im currently building a web-app that uses tensorflow to scan graph data and turn the data into a visualisation, at the minute the app can only detect a small number of objects based on the coco-ssd trained model (Person, phone, bottle) and I'm struggling with 1) finding other tensorflow models that I can implement to improve what can be detected. 2) tensorflow models that can scan for objects and data within a graph and 3) how to add another model into my code without breaking what already works. I'm very new to using tensorflow and machine learning but below is the code for the web-app that requires the tensorflow model.

code snippets on stack overflow

[https://stackoverflow.com/questions/66015902/tensorflow-js-graph-object-detection](https://stackoverflow.com/questions/66015902/tensorflow-js-graph-object-detection)",t2_5o5amyn9,False,,0,False,Tensorflow.js Graph Object Detection,[],r/tensorflow,False,6,,0,,,False,t3_lb3om3,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1612321836.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im currently building a web-app that uses tensorflow to scan graph data and turn the data into a visualisation, at the minute the app can only detect a small number of objects based on the coco-ssd trained model (Person, phone, bottle) and I&amp;#39;m struggling with 1) finding other tensorflow models that I can implement to improve what can be detected. 2) tensorflow models that can scan for objects and data within a graph and 3) how to add another model into my code without breaking what already works. I&amp;#39;m very new to using tensorflow and machine learning but below is the code for the web-app that requires the tensorflow model.&lt;/p&gt;

&lt;p&gt;code snippets on stack overflow&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://stackoverflow.com/questions/66015902/tensorflow-js-graph-object-detection""&gt;https://stackoverflow.com/questions/66015902/tensorflow-js-graph-object-detection&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lb3om3,True,,Fawcett_C,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lb3om3/tensorflowjs_graph_object_detection/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lb3om3/tensorflowjs_graph_object_detection/,22217,1612293036.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
147,,tensorflow,,t2_5mvvi9wt,False,,0,False,"Installing TensorFlow GPU on Windows 10 with compatible CUDA and cuDNN versions can be a cumbersome task. However, there is a little know fact that it can be done by just two commands if we are using Anaconda!! and I hope it equally works for Linux too.",[],r/tensorflow,False,6,,0,105.0,,False,t3_laci7y,False,dark,0.86,,public,25,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/toJe8ZbFhEc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Install TensorFlow GPU on Windows 10 Under 90 Seconds with Just Two Commands | 2021', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/toJe8ZbFhEc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TheCodingBug', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/toJe8ZbFhEc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCcNgapXcZkyW10FIOohZ1uA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/toJe8ZbFhEc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/laci7y', 'height': 200}",Discussion,False,25,,False,https://b.thumbs.redditmedia.com/uu9isK3cAq1DYlIqxD1jwaxfIItaTMD6PkNF0ynXFHI.jpg,False,,[],{},,False,,1612238436.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,laci7y,True,,TheCodingBug,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/laci7y/installing_tensorflow_gpu_on_windows_10_with/,all_ads,False,https://youtu.be/toJe8ZbFhEc,22217,1612209636.0,1,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Install TensorFlow GPU on Windows 10 Under 90 Seconds with Just Two Commands | 2021', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/toJe8ZbFhEc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TheCodingBug', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/toJe8ZbFhEc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCcNgapXcZkyW10FIOohZ1uA'}}",False,rich:video,https://youtu.be/toJe8ZbFhEc,"{'images': [{'source': {'url': 'https://external-preview.redd.it/mcnzN1B2JNogEhIMQswhr1hN-GePOb_PgzWMln45gIE.jpg?auto=webp&amp;s=57c7888fd43198644525cd4a974052ae7b4ebc74', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/mcnzN1B2JNogEhIMQswhr1hN-GePOb_PgzWMln45gIE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1f03d1dc60cab106a4700b5e2613085bdac9872', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/mcnzN1B2JNogEhIMQswhr1hN-GePOb_PgzWMln45gIE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed46dd14a0226fddc6c0026a650c7bc47b540864', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/mcnzN1B2JNogEhIMQswhr1hN-GePOb_PgzWMln45gIE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ffcd6733e68505b744adc62885dc6eac61c223fd', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'rRE23tjsfdB0Lk8VC2Olhalf-UdrLKmMYRvsoEc5WYc'}], 'enabled': False}",,,,,,
148,,tensorflow,"Hello guys, I'm a bit new on tensorflow, I'm trying to make a dataset from ONE folder but the only thing I could made is make a dataset with separate folders using flow_from_directory, which will made a dataset in wich each class is a folder, but I want to make it just from one folder, could you please tell me some way in which I can make it?",t2_45ncd0kr,False,,0,False,Some help with dataset from images,[],r/tensorflow,False,6,,0,,,False,t3_lae906,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1612242623.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys, I&amp;#39;m a bit new on tensorflow, I&amp;#39;m trying to make a dataset from ONE folder but the only thing I could made is make a dataset with separate folders using flow_from_directory, which will made a dataset in wich each class is a folder, but I want to make it just from one folder, could you please tell me some way in which I can make it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,lae906,True,,engdiazmu,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/lae906/some_help_with_dataset_from_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/lae906/some_help_with_dataset_from_images/,22217,1612213823.0,0,,False,,,,,,,,,
149,,tensorflow,"I'm currently trying to build a model that can authenticate a person on their movement data (accelleration etc)  


The dataset is built by me and stored in a JSON file for training in google colab. [Sample  Notebook](https://colab.research.google.com/drive/1lWIdHNklhDY0pD4Z98tcQ7n6UFpMQpnm?usp=sharing)  


Now older versions of the dataset with less worked out fine. But the new version I got has more entries and sudenly I only get a Loss of NaN and Accuracy of 0.5, no matter what I do.  


RAM seems to be an obvious reason, but the RAM usage tracker in colab shows normal levels (2-4gb of the available 13) Also I mocked up dummy datasets with the same, or even bigger sizes and they worked out fine.  


Do you guys have any Idea what is going on here? My only idea going forward is to move over to TFRecords instead of the JSON file.",t2_4hdk4iyy,False,,0,False,bigger Dataset resulting in loss of NaN without exeeding RAM limits,[],r/tensorflow,False,6,,0,,,False,t3_la0d7k,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1612204860.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently trying to build a model that can authenticate a person on their movement data (accelleration etc)  &lt;/p&gt;

&lt;p&gt;The dataset is built by me and stored in a JSON file for training in google colab. &lt;a href=""https://colab.research.google.com/drive/1lWIdHNklhDY0pD4Z98tcQ7n6UFpMQpnm?usp=sharing""&gt;Sample  Notebook&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;Now older versions of the dataset with less worked out fine. But the new version I got has more entries and sudenly I only get a Loss of NaN and Accuracy of 0.5, no matter what I do.  &lt;/p&gt;

&lt;p&gt;RAM seems to be an obvious reason, but the RAM usage tracker in colab shows normal levels (2-4gb of the available 13) Also I mocked up dummy datasets with the same, or even bigger sizes and they worked out fine.  &lt;/p&gt;

&lt;p&gt;Do you guys have any Idea what is going on here? My only idea going forward is to move over to TFRecords instead of the JSON file.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,la0d7k,True,,Cha-Dao_Tech,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/la0d7k/bigger_dataset_resulting_in_loss_of_nan_without/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/la0d7k/bigger_dataset_resulting_in_loss_of_nan_without/,22217,1612176060.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&amp;s=73eb91ea5a5347f216c0f0c4d6796396826aae49', 'width': 260, 'height': 260}, 'resolutions': [{'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b647239f77bf713f4a6209cfa4867351c055fd9', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f4234ff3f4f4ebd7f77236dedb03a2faee3e04a', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nkhh65ujo5BznFJFojoMPaKjGuLSpPj6KGhRov-ykOg'}], 'enabled': False}",,,,,,
150,,tensorflow,"I've been reading about TF Serving quite a bit, trying to decide if it makes sense to be using it for some applications that I'm working on. As I've been studying up on it , I've run into a few things that I can't seem to answer myself, so I thought I would turn to you beautiful people to see if I could find some answers that I haven't been able to figure out so far. 

1) Trying to build the Docker image in the first place. I read through the documentation on [https://www.tensorflow.org/tfx/serving/docker](https://www.tensorflow.org/tfx/serving/docker) and followed the directions to get my model into a Docker image. However, due to the constraints of what I'm working on, I need to be able to build the container from a Dockerfile in the first place. I found the Dockerfile for TF Serving on Github here: [https://github.com/tensorflow/serving/blob/master/tensorflow\_serving/tools/docker/Dockerfile.devel](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile.devel) But when I build that image, it's like... 20 times the size of the 300MB one that I get when following the instructions in the docs. I'm looking for a way to have a Dockerfile that I can build into the 300MB image... so that's one question. 

2) My model currently expects an input of a multi dimensional Tensor. With TF Serving using JSON (a requirement to use instead of gRPC on this project... comes from on high and can't do anything about it), it looks like my options are basically to use something Base64 encoded. Is there a way to circumnavigate this so that I can send a multidimensional Tensor to my model or do I have to rebuild my model so that it can take in a Base64 image? Ideally... I would like to be able to send the file path to the TF Serving Docker and it would pick it up and go from there, but it doesn't seem like that's an option. So I suppose the question is... is base64 the only way to get an image to the model using JSON? 

Thanks for any answers... I've been banging my head on this off and on for the last month and would love any input that you guys can give me!",t2_eni8d,False,,0,False,Couple Questions about TF Serving,[],r/tensorflow,False,6,,0,,,False,t3_la2r4j,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1612213982.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been reading about TF Serving quite a bit, trying to decide if it makes sense to be using it for some applications that I&amp;#39;m working on. As I&amp;#39;ve been studying up on it , I&amp;#39;ve run into a few things that I can&amp;#39;t seem to answer myself, so I thought I would turn to you beautiful people to see if I could find some answers that I haven&amp;#39;t been able to figure out so far. &lt;/p&gt;

&lt;p&gt;1) Trying to build the Docker image in the first place. I read through the documentation on &lt;a href=""https://www.tensorflow.org/tfx/serving/docker""&gt;https://www.tensorflow.org/tfx/serving/docker&lt;/a&gt; and followed the directions to get my model into a Docker image. However, due to the constraints of what I&amp;#39;m working on, I need to be able to build the container from a Dockerfile in the first place. I found the Dockerfile for TF Serving on Github here: &lt;a href=""https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile.devel""&gt;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile.devel&lt;/a&gt; But when I build that image, it&amp;#39;s like... 20 times the size of the 300MB one that I get when following the instructions in the docs. I&amp;#39;m looking for a way to have a Dockerfile that I can build into the 300MB image... so that&amp;#39;s one question. &lt;/p&gt;

&lt;p&gt;2) My model currently expects an input of a multi dimensional Tensor. With TF Serving using JSON (a requirement to use instead of gRPC on this project... comes from on high and can&amp;#39;t do anything about it), it looks like my options are basically to use something Base64 encoded. Is there a way to circumnavigate this so that I can send a multidimensional Tensor to my model or do I have to rebuild my model so that it can take in a Base64 image? Ideally... I would like to be able to send the file path to the TF Serving Docker and it would pick it up and go from there, but it doesn&amp;#39;t seem like that&amp;#39;s an option. So I suppose the question is... is base64 the only way to get an image to the model using JSON? &lt;/p&gt;

&lt;p&gt;Thanks for any answers... I&amp;#39;ve been banging my head on this off and on for the last month and would love any input that you guys can give me!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,la2r4j,True,,TypeAskee,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/la2r4j/couple_questions_about_tf_serving/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/la2r4j/couple_questions_about_tf_serving/,22217,1612185182.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?auto=webp&amp;s=2d566d35e0423b8f6eae3c70bae9648c28071bbf', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dae618cf529f65c144f4dc8969b0c6dddc62348d', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f73bd526415f196e450cba3693a44710d00c30c', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0fc9ec5be0457b96850e051f310664412884ff1b', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c0907d38039cc3e45f892a13a2881f9e80c28cd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f5e135be56a5484f86918cee5b3edd815990e81', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/P5zSEB2b8uyLlx5O-IT665JX07P6AlHWtY_SCq6TUKk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=58012f4d1cc7ae9c02af4c2c9905fdc9e382e767', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '46gTb2-_USvWfnttUjiSscjkesqgkUmfyQheI5He4Yo'}], 'enabled': False}",,,,,,
151,,tensorflow,"If I build tensorflow, will it be optimised for that host? 

The command i am using is...
bazel build —config=opt //tensor flow/tools/pip_package

Will it be optimised? 
Will it use the host’s full instruction set where it can?
Will it avoid instructions the host does not support?

If this is the case. How is the formal release built? Does it override the default settings or is it built on a specified host?

I ask as the formal release uses instructions my host does not have. I am building and using in the same host. I’ve read up on why this has happened. Just not clear on trying to build for my host.",t2_3fsg50pd,False,,0,False,How do I build tensorflow so it is optimised for build machine?,[],r/tensorflow,False,6,,0,,,False,t3_l9msqp,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1612158146.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I build tensorflow, will it be optimised for that host? &lt;/p&gt;

&lt;p&gt;The command i am using is...
bazel build —config=opt //tensor flow/tools/pip_package&lt;/p&gt;

&lt;p&gt;Will it be optimised? 
Will it use the host’s full instruction set where it can?
Will it avoid instructions the host does not support?&lt;/p&gt;

&lt;p&gt;If this is the case. How is the formal release built? Does it override the default settings or is it built on a specified host?&lt;/p&gt;

&lt;p&gt;I ask as the formal release uses instructions my host does not have. I am building and using in the same host. I’ve read up on why this has happened. Just not clear on trying to build for my host.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l9msqp,True,,BillyBag2,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/l9msqp/how_do_i_build_tensorflow_so_it_is_optimised_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l9msqp/how_do_i_build_tensorflow_so_it_is_optimised_for/,22217,1612129346.0,0,,False,,,,,,,,,
152,,tensorflow,,t2_3q2zt1t6,False,,0,False,"Saw this video under r/Python, and found it very helpful.",[],r/tensorflow,False,6,,0,105.0,,False,t3_l9371g,False,dark,0.92,,public,50,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Networks Explained from Scratch using Python', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Bot Academy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/9RN2Wr8xvro/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BotAcademyYT'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/l9371g', 'height': 200}",Project,False,50,,False,https://a.thumbs.redditmedia.com/pwNKs1v66j7NiVh-HHNGgkLc3X1qrN9DPrK641BHt64.jpg,False,,[],{},,False,,1612091839.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l9371g,True,,felix-thebest,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l9371g/saw_this_video_under_rpython_and_found_it_very/,all_ads,False,https://youtube.com/watch?v=9RN2Wr8xvro&amp;feature=share,22217,1612063039.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Networks Explained from Scratch using Python', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Bot Academy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/9RN2Wr8xvro/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BotAcademyYT'}}",False,rich:video,https://youtube.com/watch?v=9RN2Wr8xvro&amp;feature=share,"{'images': [{'source': {'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?auto=webp&amp;s=4891864e648a45e876208ff48ab9fd94b502e755', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e596e300027a26e33a07d246ea9b34821e899af4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4e6eefe7cd288c490e213e9356e402e18e69b36', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed9206d020c938c14e2f27e7ccf0dc7d210fae68', 'width': 320, 'height': 240}], 'variants': {}, 'id': '4EFu5HPPfWH2FsSYZjfnq1GCOvO7Bq6tGdpPrU-LC0E'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '', 'author_fullname': 't2_5y4hzge8', 'saved': False, 'mod_reason_title': None, 'gilded': 1, 'clicked': False, 'title': 'I created a video about Neural Networks that is specifically aimed at Python developers! If you understand the Code, you understand how to create a Neural Network from Scratch! The video took me 200h to create and is fully animated! Hope it helps you guys :)', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'tutorial', 'downs': 0, 'thumbnail_height': 105, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_l8jvev', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.98, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2348, 'total_awards_received': 33, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Networks Explained from Scratch using Python', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Bot Academy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/9RN2Wr8xvro/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BotAcademyYT'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/l8jvev', 'height': 200}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 2348, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/pwNKs1v66j7NiVh-HHNGgkLc3X1qrN9DPrK641BHt64.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 7, 'gid_2': 1}, 'post_hint': 'rich:video', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1612035251.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': True, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtube.com/watch?v=9RN2Wr8xvro&amp;feature=share', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?auto=webp&amp;s=4891864e648a45e876208ff48ab9fd94b502e755', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e596e300027a26e33a07d246ea9b34821e899af4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4e6eefe7cd288c490e213e9356e402e18e69b36', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/_LVlu-KMvJCGw8T59JqY9VKFcYddMaYPLXwec344FEY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed9206d020c938c14e2f27e7ccf0dc7d210fae68', 'width': 320, 'height': 240}], 'variants': {}, 'id': '4EFu5HPPfWH2FsSYZjfnq1GCOvO7Bq6tGdpPrU-LC0E'}], 'enabled': False}, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 500, 'id': 'gid_2', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 100, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/gold_512.png', 'days_of_premium': 7, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/gold_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Gold', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/gold_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/gold_512.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 10, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 6, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 7, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 9, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '7987a74c-04d8-11eb-84ca-0e0ac8b5a78f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'l8jvev', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Jump2Fly', 'discussion_type': None, 'num_comments': 63, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/l8jvev/i_created_a_video_about_neural_networks_that_is/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://youtube.com/watch?v=9RN2Wr8xvro&amp;feature=share', 'subreddit_subscribers': 770033, 'created_utc': 1612006451.0, 'num_crossposts': 1, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Networks Explained from Scratch using Python', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/9RN2Wr8xvro?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Bot Academy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/9RN2Wr8xvro/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BotAcademyYT'}}, 'is_video': False}]",t3_l8jvev,
153,,tensorflow,"I’m having trouble installing tensorflow on on a Mac mini m1. I’m seeing if anyone has any success on installing tensorflow either on anaconda jupyter notebook or on virtual environment?
I’ve installed Python 3.8 and 3.9 but I’m only able to use pyenv 3.9",t2_5g4w5ooa,False,,0,False,Help Installing tensorflow on M1,[],r/tensorflow,False,6,,0,,,False,t3_l9de6k,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1612132382.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m having trouble installing tensorflow on on a Mac mini m1. I’m seeing if anyone has any success on installing tensorflow either on anaconda jupyter notebook or on virtual environment?
I’ve installed Python 3.8 and 3.9 but I’m only able to use pyenv 3.9&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l9de6k,True,,Ant_Wh1sperer,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l9de6k/help_installing_tensorflow_on_m1/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l9de6k/help_installing_tensorflow_on_m1/,22217,1612103582.0,0,,False,,,,,,,,,
154,,tensorflow,"Hey all

I am busy building a custom object detection model and I have several objects at different angles in my data. This is causing a problem as bounding boxes can only be drawn parallel to my axis, which is including unnecessary information for some of my objects.

Is there any efficient way to make training data barring just labelling as is? I could rotate the images, but that won't help as sometimes there is more than one object at different angles.

EDIT - Could I perhaps create a 'fake' training image comprising of correctly orientated examples?",t2_3tqdenkk,False,,0,False,Model Detection API - Making training data with objects at an angle,[],r/tensorflow,False,6,,0,,,False,t3_l9hnsq,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,1612121532.0,,[],{},,True,,1612144540.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all&lt;/p&gt;

&lt;p&gt;I am busy building a custom object detection model and I have several objects at different angles in my data. This is causing a problem as bounding boxes can only be drawn parallel to my axis, which is including unnecessary information for some of my objects.&lt;/p&gt;

&lt;p&gt;Is there any efficient way to make training data barring just labelling as is? I could rotate the images, but that won&amp;#39;t help as sometimes there is more than one object at different angles.&lt;/p&gt;

&lt;p&gt;EDIT - Could I perhaps create a &amp;#39;fake&amp;#39; training image comprising of correctly orientated examples?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l9hnsq,True,,SilverStalker1,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/l9hnsq/model_detection_api_making_training_data_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l9hnsq/model_detection_api_making_training_data_with/,22217,1612115740.0,0,,False,,,,,,,,,
155,,tensorflow,"Hi,

I have a training dataset which is 67% of all my data. Then an evaluation dataset which is 33%.

They've been randomly shuffled. Somehow, there are some values in the evaluation dataset which didn't appear in training. This is causing the following bug:  


`tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[4] = 54 is not in [0, 53)`

&amp;#x200B;

Which, after some googling, is because not all the vocabulary values were found in the training dataset. I want to just extend the vocab size but I'm unsure how to do it.  


The relevant lines of code would be these ones I think:

&amp;#x200B;

`for feature_name in CATEGORICAL_COLUMNS:`  
  `vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column`  
  `feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))`

&amp;#x200B;

Which is a list, and not a scalar length. So I can't simply add to it.  


Any ideas or more information required?",t2_80ont,False,,0,False,Linear Classifier - Training dataset is missing some categorical values which appear in Evaluation dataset. How to handle?,[],r/tensorflow,False,6,,0,,,False,t3_l9lqn9,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1612155241.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I have a training dataset which is 67% of all my data. Then an evaluation dataset which is 33%.&lt;/p&gt;

&lt;p&gt;They&amp;#39;ve been randomly shuffled. Somehow, there are some values in the evaluation dataset which didn&amp;#39;t appear in training. This is causing the following bug:  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[4] = 54 is not in [0, 53)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Which, after some googling, is because not all the vocabulary values were found in the training dataset. I want to just extend the vocab size but I&amp;#39;m unsure how to do it.  &lt;/p&gt;

&lt;p&gt;The relevant lines of code would be these ones I think:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for feature_name in CATEGORICAL_COLUMNS:&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Which is a list, and not a scalar length. So I can&amp;#39;t simply add to it.  &lt;/p&gt;

&lt;p&gt;Any ideas or more information required?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l9lqn9,True,,Cwlrs,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/l9lqn9/linear_classifier_training_dataset_is_missing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l9lqn9/linear_classifier_training_dataset_is_missing/,22217,1612126441.0,0,,False,,,,,,,,,
156,,tensorflow,"I was able to run a sample Google TFLite model on the RPI4, but the custom one I made from Roboflow is not working.

[https://www.youtube.com/watch?v=pXLLNa4IrmM&amp;list=LL&amp;index=1&amp;t=1083s](https://www.youtube.com/watch?v=pXLLNa4IrmM&amp;list=LL&amp;index=1&amp;t=1083s)

This guide uses Roboflow to train a darknet model which is then converted to TFLite. When I run this model on the RPI4, I get this:

2021-01-30 21:42:03.351149: E tensorflow/core/platform/hadoop/hadoop\_file\_system.cc:132\] HadoopFileSystem load error: [libhdfs.so](https://libhdfs.so): cannot open shared object file: No such file or directory

Traceback (most recent call last):

  File ""TFLite\_detection\_webcam.py"", line 138, in &lt;module&gt;

interpreter = Interpreter(model\_path=PATH\_TO\_CKPT)

  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow\_core/lite/python/interpreter.py"", line 207, in \_\_init\_\_

model\_path, self.\_custom\_op\_registerers))

ValueError: Didn't find op for builtin opcode 'RESIZE\_BILINEAR' version '3'

Registration failed.

\------------------------------------------------------------------------------------------------------------------

Does anyone know how to fix this?  If not, does anyone know a better way to run a custom model on the RPI4?",t2_qxtwn,False,,0,False,Trouble running custom TFLite model on RPI4,[],r/tensorflow,False,6,,0,,,False,t3_l96are,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Project RPI4,False,1,,False,self,False,,[],{},,True,,1612102513.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was able to run a sample Google TFLite model on the RPI4, but the custom one I made from Roboflow is not working.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=pXLLNa4IrmM&amp;amp;list=LL&amp;amp;index=1&amp;amp;t=1083s""&gt;https://www.youtube.com/watch?v=pXLLNa4IrmM&amp;amp;list=LL&amp;amp;index=1&amp;amp;t=1083s&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This guide uses Roboflow to train a darknet model which is then converted to TFLite. When I run this model on the RPI4, I get this:&lt;/p&gt;

&lt;p&gt;2021-01-30 21:42:03.351149: E tensorflow/core/platform/hadoop/hadoop_file_system.cc:132] HadoopFileSystem load error: &lt;a href=""https://libhdfs.so""&gt;libhdfs.so&lt;/a&gt;: cannot open shared object file: No such file or directory&lt;/p&gt;

&lt;p&gt;Traceback (most recent call last):&lt;/p&gt;

&lt;p&gt;File &amp;quot;TFLite_detection_webcam.py&amp;quot;, line 138, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;interpreter = Interpreter(model_path=PATH_TO_CKPT)&lt;/p&gt;

&lt;p&gt;File &amp;quot;/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py&amp;quot;, line 207, in __init__&lt;/p&gt;

&lt;p&gt;model_path, self._custom_op_registerers))&lt;/p&gt;

&lt;p&gt;ValueError: Didn&amp;#39;t find op for builtin opcode &amp;#39;RESIZE_BILINEAR&amp;#39; version &amp;#39;3&amp;#39;&lt;/p&gt;

&lt;p&gt;Registration failed.&lt;/p&gt;

&lt;p&gt;------------------------------------------------------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Does anyone know how to fix this?  If not, does anyone know a better way to run a custom model on the RPI4?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l96are,True,,Fish6Chips,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/l96are/trouble_running_custom_tflite_model_on_rpi4/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l96are/trouble_running_custom_tflite_model_on_rpi4/,22217,1612073713.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/LDyZU0Kiwu5Dmgk67_spvSt8_vsLjywOdG8ObLXYhps.jpg?auto=webp&amp;s=aa4262ae675a7c7242fc27e4542e583e501f741d', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/LDyZU0Kiwu5Dmgk67_spvSt8_vsLjywOdG8ObLXYhps.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c58162823a4c3d5e86345fe436428f4f7247a8f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/LDyZU0Kiwu5Dmgk67_spvSt8_vsLjywOdG8ObLXYhps.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0562218bcb713ef48282f62e14272e58405e7e98', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/LDyZU0Kiwu5Dmgk67_spvSt8_vsLjywOdG8ObLXYhps.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9de4c620443f616f3c8eca73c75bf2af411a09e7', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'IowzHIgOGCz5Q6JKFEyOHsqDFLDqhCvBvVQz6P-z-q8'}], 'enabled': False}",,,,,,
157,,tensorflow,"Hi all

I have been working with the tensorflow object detection API and have run into a problem. It seems that  model\_main\_tf2.py does not generate validation loss for display in tensorboard.  Actually, it seems like it does not evaluate at all.

It seems that a few people have had these issues - but I have so far been unable to find a solution.

Does anyone have a solution?

Thank you.

EDIT:

I believe the relevant parts of my code are:

Calling the model - it trains correctly so I believe this is okay

&gt;!python  $TRAIN\_FILE --alsologtostderr --pipeline\_config\_path=""$PIPELINE\_CONFIG\_PATH""  --model\_dir=""$OUTPUT\_PATH"" --checkpoint\_every\_n=100

 The relevant part of my config file

&gt;train\_config {  
&gt;  
&gt;  batch\_size: 4  
&gt;  
&gt;  data\_augmentation\_options {  
&gt;  
&gt;random\_horizontal\_flip {  
&gt;  
&gt;}  
&gt;  
&gt;  }  
&gt;  
&gt;  data\_augmentation\_options {  
&gt;  
&gt;random\_crop\_image {  
&gt;  
&gt;min\_object\_covered: 0.0  
&gt;  
&gt;min\_aspect\_ratio: 0.75  
&gt;  
&gt;max\_aspect\_ratio: 3.0  
&gt;  
&gt;min\_area: 0.75  
&gt;  
&gt;max\_area: 1.0  
&gt;  
&gt;overlap\_thresh: 0.0  
&gt;  
&gt;}  
&gt;  
&gt;  }  
&gt;  
&gt;  sync\_replicas: true  
&gt;  
&gt;  optimizer {  
&gt;  
&gt;momentum\_optimizer {  
&gt;  
&gt;learning\_rate {  
&gt;  
&gt;cosine\_decay\_learning\_rate {  
&gt;  
&gt;learning\_rate\_base: 0.04  
&gt;  
&gt;total\_steps: 100000  
&gt;  
&gt;warmup\_learning\_rate: 0.013333  
&gt;  
&gt;warmup\_steps: 2000  
&gt;  
&gt;}  
&gt;  
&gt;}  
&gt;  
&gt;momentum\_optimizer\_value: 0.9  
&gt;  
&gt;}  
&gt;  
&gt;use\_moving\_average: false  
&gt;  
&gt;  }  
&gt;  
&gt;  fine\_tune\_checkpoint: ""/content/pretrained/ssd\_resnet101\_v1\_fpn\_1024x1024\_coco17\_tpu-8/checkpoint/ckpt-0""  
&gt;  
&gt;  num\_steps: 100000  
&gt;  
&gt;  startup\_delay\_steps: 0.0  
&gt;  
&gt;  replicas\_to\_aggregate: 8  
&gt;  
&gt;  max\_number\_of\_boxes: 100  
&gt;  
&gt;  unpad\_groundtruth\_tensors: false  
&gt;  
&gt;  fine\_tune\_checkpoint\_type: ""detection""  
&gt;  
&gt;  use\_bfloat16: true  
&gt;  
&gt;  fine\_tune\_checkpoint\_version: V2  
&gt;  
&gt;}  
&gt;  
&gt;train\_input\_reader {  
&gt;  
&gt;  label\_map\_path: ""drive/My Drive/project/label\_map.txt""  
&gt;  
&gt;  tf\_record\_input\_reader {  
&gt;  
&gt;input\_path: ""drive/My Drive/project/train.record""  
&gt;  
&gt;  }  
&gt;  
&gt;}  
&gt;  
&gt;eval\_config {  
&gt;  
&gt;  metrics\_set: ""coco\_detection\_metrics""  
&gt;  
&gt;  use\_moving\_averages: false  
&gt;  
&gt;}  
&gt;  
&gt;eval\_input\_reader {  
&gt;  
&gt;  label\_map\_path: ""drive/My Drive/project/label\_map.txt""  
&gt;  
&gt;  shuffle: false  
&gt;  
&gt;  num\_epochs: 1  
&gt;  
&gt;  tf\_record\_input\_reader {  
&gt;  
&gt;input\_path: ""drive/My Drive/project/val.record""  
&gt;  
&gt;  }

All I see in tensorboard and my files are the 'train run.",t2_3tqdenkk,False,,0,False,No validation loss with model_main_tf2.py?,[],r/tensorflow,False,6,,0,,,False,t3_l90amm,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1612073778.0,,[],{},,True,,1612082696.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all&lt;/p&gt;

&lt;p&gt;I have been working with the tensorflow object detection API and have run into a problem. It seems that  model_main_tf2.py does not generate validation loss for display in tensorboard.  Actually, it seems like it does not evaluate at all.&lt;/p&gt;

&lt;p&gt;It seems that a few people have had these issues - but I have so far been unable to find a solution.&lt;/p&gt;

&lt;p&gt;Does anyone have a solution?&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;

&lt;p&gt;EDIT:&lt;/p&gt;

&lt;p&gt;I believe the relevant parts of my code are:&lt;/p&gt;

&lt;p&gt;Calling the model - it trains correctly so I believe this is okay&lt;/p&gt;

&lt;blockquote class=""md-spoiler-text""&gt;
&lt;p&gt;python  $TRAIN_FILE --alsologtostderr --pipeline_config_path=&amp;quot;$PIPELINE_CONFIG_PATH&amp;quot;  --model_dir=&amp;quot;$OUTPUT_PATH&amp;quot; --checkpoint_every_n=100&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The relevant part of my config file&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;train_config {  &lt;/p&gt;

&lt;p&gt;batch_size: 4  &lt;/p&gt;

&lt;p&gt;data_augmentation_options {  &lt;/p&gt;

&lt;p&gt;random_horizontal_flip {  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;data_augmentation_options {  &lt;/p&gt;

&lt;p&gt;random_crop_image {  &lt;/p&gt;

&lt;p&gt;min_object_covered: 0.0  &lt;/p&gt;

&lt;p&gt;min_aspect_ratio: 0.75  &lt;/p&gt;

&lt;p&gt;max_aspect_ratio: 3.0  &lt;/p&gt;

&lt;p&gt;min_area: 0.75  &lt;/p&gt;

&lt;p&gt;max_area: 1.0  &lt;/p&gt;

&lt;p&gt;overlap_thresh: 0.0  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;sync_replicas: true  &lt;/p&gt;

&lt;p&gt;optimizer {  &lt;/p&gt;

&lt;p&gt;momentum_optimizer {  &lt;/p&gt;

&lt;p&gt;learning_rate {  &lt;/p&gt;

&lt;p&gt;cosine_decay_learning_rate {  &lt;/p&gt;

&lt;p&gt;learning_rate_base: 0.04  &lt;/p&gt;

&lt;p&gt;total_steps: 100000  &lt;/p&gt;

&lt;p&gt;warmup_learning_rate: 0.013333  &lt;/p&gt;

&lt;p&gt;warmup_steps: 2000  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;momentum_optimizer_value: 0.9  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;use_moving_average: false  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;fine_tune_checkpoint: &amp;quot;/content/pretrained/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8/checkpoint/ckpt-0&amp;quot;  &lt;/p&gt;

&lt;p&gt;num_steps: 100000  &lt;/p&gt;

&lt;p&gt;startup_delay_steps: 0.0  &lt;/p&gt;

&lt;p&gt;replicas_to_aggregate: 8  &lt;/p&gt;

&lt;p&gt;max_number_of_boxes: 100  &lt;/p&gt;

&lt;p&gt;unpad_groundtruth_tensors: false  &lt;/p&gt;

&lt;p&gt;fine_tune_checkpoint_type: &amp;quot;detection&amp;quot;  &lt;/p&gt;

&lt;p&gt;use_bfloat16: true  &lt;/p&gt;

&lt;p&gt;fine_tune_checkpoint_version: V2  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;train_input_reader {  &lt;/p&gt;

&lt;p&gt;label_map_path: &amp;quot;drive/My Drive/project/label_map.txt&amp;quot;  &lt;/p&gt;

&lt;p&gt;tf_record_input_reader {  &lt;/p&gt;

&lt;p&gt;input_path: &amp;quot;drive/My Drive/project/train.record&amp;quot;  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;eval_config {  &lt;/p&gt;

&lt;p&gt;metrics_set: &amp;quot;coco_detection_metrics&amp;quot;  &lt;/p&gt;

&lt;p&gt;use_moving_averages: false  &lt;/p&gt;

&lt;p&gt;}  &lt;/p&gt;

&lt;p&gt;eval_input_reader {  &lt;/p&gt;

&lt;p&gt;label_map_path: &amp;quot;drive/My Drive/project/label_map.txt&amp;quot;  &lt;/p&gt;

&lt;p&gt;shuffle: false  &lt;/p&gt;

&lt;p&gt;num_epochs: 1  &lt;/p&gt;

&lt;p&gt;tf_record_input_reader {  &lt;/p&gt;

&lt;p&gt;input_path: &amp;quot;drive/My Drive/project/val.record&amp;quot;  &lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;All I see in tensorboard and my files are the &amp;#39;train run.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l90amm,True,,SilverStalker1,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/l90amm/no_validation_loss_with_model_main_tf2py/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l90amm/no_validation_loss_with_model_main_tf2py/,22217,1612053896.0,0,,False,,,,,,,,,
158,,tensorflow,"When I do
“pip install tensorflow==1.15.2” it tells me that it doesn’t exist. I am using python 3.6. What am I doing wrong?

EDIT: I figured it out. Thanks for the help!",t2_1135fr,False,,0,False,Can’t install tensorflow with PIP,[],r/tensorflow,False,6,,0,,,False,t3_l8xn8k,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1612059821.0,,[],{},,True,,1612075005.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When I do
“pip install tensorflow==1.15.2” it tells me that it doesn’t exist. I am using python 3.6. What am I doing wrong?&lt;/p&gt;

&lt;p&gt;EDIT: I figured it out. Thanks for the help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l8xn8k,True,,V0rtexGames,,21,True,all_ads,False,[],False,,/r/tensorflow/comments/l8xn8k/cant_install_tensorflow_with_pip/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l8xn8k/cant_install_tensorflow_with_pip/,22217,1612046205.0,0,,False,,,,,,,,,
159,,tensorflow,"Hello there,

does anybody of you use tensorflow for something besides ML/AI? If yes, what do you use it for? Why not use numpy? I've heard that it's used for big numerical applications, but I didn't find any good examples online.

Have a nice day!",t2_2y5dw7dw,False,,0,False,Usecases besides ML/AI,[],r/tensorflow,False,6,,0,,,False,t3_l8jsjc,False,dark,0.73,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1612034928.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello there,&lt;/p&gt;

&lt;p&gt;does anybody of you use tensorflow for something besides ML/AI? If yes, what do you use it for? Why not use numpy? I&amp;#39;ve heard that it&amp;#39;s used for big numerical applications, but I didn&amp;#39;t find any good examples online.&lt;/p&gt;

&lt;p&gt;Have a nice day!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l8jsjc,True,,tadachs,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/l8jsjc/usecases_besides_mlai/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l8jsjc/usecases_besides_mlai/,22217,1612006128.0,0,,False,,,,,,,,,
160,,tensorflow,"Hi, this is my first time posting in this group so I apologize in advance if this is the wrong place.

I recently picked up the Deep Learning with Python book by Chollet as recommended by Google when first starting to learn Tensorflow. However, I  thought a good place to start would be to learn how to code basic ML models like Linear Regression, Support Vector Machines, Random Forests, and basic methods like nested cross validation, preprocessing, grid search. These are all methods I know how to do in sklearn, but want to know in Tensorflow. What book/place would do a good job of explaining the code and intuition behind those models?

I am not looking for what the models mean or how they work, more so how to write them properly in Tensorflow. I took a look at Tensorflow's tutorial on Linear Regression and it made little sense creating a keras.Sequential model with a Dense layer. Seems similar to a Neural Network. I figure that confusion is because I do not know the reason behind the code.

Thank you in advance.",t2_xuqrxyf,False,,0,False,First time here: Learning Tensorflow with Machine Learning,[],r/tensorflow,False,6,,0,,,False,t3_l86gnv,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},,False,9,,False,self,False,,[],{},,True,,1611988648.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, this is my first time posting in this group so I apologize in advance if this is the wrong place.&lt;/p&gt;

&lt;p&gt;I recently picked up the Deep Learning with Python book by Chollet as recommended by Google when first starting to learn Tensorflow. However, I  thought a good place to start would be to learn how to code basic ML models like Linear Regression, Support Vector Machines, Random Forests, and basic methods like nested cross validation, preprocessing, grid search. These are all methods I know how to do in sklearn, but want to know in Tensorflow. What book/place would do a good job of explaining the code and intuition behind those models?&lt;/p&gt;

&lt;p&gt;I am not looking for what the models mean or how they work, more so how to write them properly in Tensorflow. I took a look at Tensorflow&amp;#39;s tutorial on Linear Regression and it made little sense creating a keras.Sequential model with a Dense layer. Seems similar to a Neural Network. I figure that confusion is because I do not know the reason behind the code.&lt;/p&gt;

&lt;p&gt;Thank you in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l86gnv,True,,jremske,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/l86gnv/first_time_here_learning_tensorflow_with_machine/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l86gnv/first_time_here_learning_tensorflow_with_machine/,22217,1611959848.0,0,,False,,,,,,,,,
161,,tensorflow,"Hello,

I'm trying to develop an android application that uses a deep learning algorithm on the mobile itself, i.e. locally. 

I want to make it run on GPU, and from what I understand there are actually TFLite delegates that can help me achieve that. However, after a little research I found out that I can also use the Arm NN SDK with TFLite. Will the use of Arm NN actually make the application run faster, or is TFLite by itself a good choice?

Thanks in advance!",t2_2ra68cju,False,,0,False,TensorFlow Lite or hardware acceleration sdk for mobile (like Arm NN SDK),[],r/tensorflow,False,6,,0,,,False,t3_l899i3,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,1611970251.0,,[],{},,True,,1611995789.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to develop an android application that uses a deep learning algorithm on the mobile itself, i.e. locally. &lt;/p&gt;

&lt;p&gt;I want to make it run on GPU, and from what I understand there are actually TFLite delegates that can help me achieve that. However, after a little research I found out that I can also use the Arm NN SDK with TFLite. Will the use of Arm NN actually make the application run faster, or is TFLite by itself a good choice?&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l899i3,True,,Agosto44,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l899i3/tensorflow_lite_or_hardware_acceleration_sdk_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l899i3/tensorflow_lite_or_hardware_acceleration_sdk_for/,22217,1611966989.0,0,,False,,,,,,,,,
162,,tensorflow,"Been looking at two of these callbacks. Mind shine a light on shall I just schedule to reduce on certain epoch and why shall one do that instead of using ReduceLROnPlateau?

&amp;#x200B;

Thank you!",t2_8349k9p0,False,,0,False,Keras Callbacks: Learning Rate Schedular VS Reduce Learning rate on the plateau,[],r/tensorflow,False,6,,0,,,False,t3_l7wge4,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1611965558.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Been looking at two of these callbacks. Mind shine a light on shall I just schedule to reduce on certain epoch and why shall one do that instead of using ReduceLROnPlateau?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l7wge4,True,,Obvious-Salad4973,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/l7wge4/keras_callbacks_learning_rate_schedular_vs_reduce/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l7wge4/keras_callbacks_learning_rate_schedular_vs_reduce/,22217,1611936758.0,0,,False,,,,,,,,,
163,,tensorflow,,t2_ibs89,False,,0,False,Interesting use case using TensorFlow JS and custom hardware powered by machine learning.,[],r/tensorflow,False,6,,0,105.0,,False,t3_l7xckz,False,dark,1.0,,public,3,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fY-fMCN7ADw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Automated Videoing Assistant - Made with TensorFlow.js', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fY-fMCN7ADw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TensorFlow', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fY-fMCN7ADw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TensorFlow'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fY-fMCN7ADw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/l7xckz', 'height': 200}",,False,3,,False,https://a.thumbs.redditmedia.com/k8PALu_9_lhq9f2DB9YcYQzM3vm9-k1Rv1qROCFyph4.jpg,False,,[],{},,False,,1611967638.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l7xckz,True,,nbortolotti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l7xckz/interesting_use_case_using_tensorflow_js_and/,all_ads,False,https://www.youtube.com/watch?v=fY-fMCN7ADw,22217,1611938838.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Automated Videoing Assistant - Made with TensorFlow.js', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fY-fMCN7ADw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TensorFlow', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fY-fMCN7ADw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TensorFlow'}}",False,rich:video,https://www.youtube.com/watch?v=fY-fMCN7ADw,"{'images': [{'source': {'url': 'https://external-preview.redd.it/uXbPOvkEO10zdp5dA9cQJz-0JdVtneyD367LRZUBM4c.jpg?auto=webp&amp;s=fbe1a52d1a2c601a9376164504db67ef22a9848e', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/uXbPOvkEO10zdp5dA9cQJz-0JdVtneyD367LRZUBM4c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6903f55dda92d9f4b921ed28eca5b90c618f4a1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/uXbPOvkEO10zdp5dA9cQJz-0JdVtneyD367LRZUBM4c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bda9b9bbacb357d91de8bbce4fb263ddc339aac2', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/uXbPOvkEO10zdp5dA9cQJz-0JdVtneyD367LRZUBM4c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2424a56748c2fdac3165e62729a370507dad5134', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Ow2WgJ_xGYdhGuTuvg5GyVLtnZDxygezMg4-uypKLbw'}], 'enabled': False}",,,,,,
164,,tensorflow,,t2_6cffr6em,False,,0,False,TF based animation,[],r/tensorflow,False,6,,0,105.0,,False,t3_l74ud3,False,dark,0.91,,public,30,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d3tq3uBfInQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'FishPaint', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d3tq3uBfInQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Sova Psilo', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/d3tq3uBfInQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/YerianAlgorithm'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d3tq3uBfInQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/l74ud3', 'height': 200}",Make It Move,False,30,,False,https://a.thumbs.redditmedia.com/EP9BSYQlY1V6vFzDG0X9xEGDU0p3xM0l_JI6f-bBSx0.jpg,False,,[],{},,False,,1611888158.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l74ud3,True,,BlakeYerian,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l74ud3/tf_based_animation/,all_ads,False,https://youtu.be/d3tq3uBfInQ,22217,1611859358.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'FishPaint', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d3tq3uBfInQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Sova Psilo', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/d3tq3uBfInQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/YerianAlgorithm'}}",False,rich:video,https://youtu.be/d3tq3uBfInQ,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ei4D7I0kHrt18ai7dylqpxRuwuCc1XFaHpvH9jXCV4s.jpg?auto=webp&amp;s=be74c9334e80829f01e914a83e7b22dbb1ae8c04', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/ei4D7I0kHrt18ai7dylqpxRuwuCc1XFaHpvH9jXCV4s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a15e46f3fa1d448235621871ec9e83c584c6b59', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/ei4D7I0kHrt18ai7dylqpxRuwuCc1XFaHpvH9jXCV4s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=16da58f3bf0db11ec66c39ab57496202ae386e32', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/ei4D7I0kHrt18ai7dylqpxRuwuCc1XFaHpvH9jXCV4s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1459d2d6bf4364d449eb3c649bd814c4da6d99a1', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Jqip1vV8ijXHVn-aR8-NGPhOnNEpXjITlEvQETUQWPI'}], 'enabled': False}",,,,,,
165,,tensorflow,,t2_44mbtmjy,False,,0,False,Latest from KDnuggets: Find code implementation for any AI/ML paper using this new chrome extension!,[],r/tensorflow,False,6,,0,,,False,t3_l7fasl,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,default,False,,[],{},,False,,1611912683.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l7fasl,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l7fasl/latest_from_kdnuggets_find_code_implementation/,all_ads,False,/r/LatestInML/comments/l7f98o/latest_from_kdnuggets_find_code_implementation/,22217,1611883883.0,0,,False,link,/r/LatestInML/comments/l7f98o/latest_from_kdnuggets_find_code_implementation/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?auto=webp&amp;s=02659bad52081873a10146ca8daad01706405bee', 'width': 1202, 'height': 234}, 'resolutions': [{'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3e5dbc27f65729bfccb1f019f5c4fdf4705dc15', 'width': 108, 'height': 21}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=438e1c7ce9e109e9bfc7476344700ec350e37edb', 'width': 216, 'height': 42}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2085485fec5b5e1b2c6490d7efb502dcc22eccbf', 'width': 320, 'height': 62}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f721d898297cce574f35eb473bc6efa3c5767f1', 'width': 640, 'height': 124}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57823910b22cd3dc8c1cb72538b0587a78805ce3', 'width': 960, 'height': 186}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6fd62fb158b9fd6f72ad0536f2e8c7102775c6f', 'width': 1080, 'height': 210}], 'variants': {}, 'id': '1IgdrGJHua-eumc0w7TSLq57TXilPA59tdWiEScPk-8'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from KDnuggets: Find code implementation for any AI/ML paper using this new chrome extension!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_l7f98o', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 20, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 20, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1611912572.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html""&gt;https://www.kdnuggets.com/2021/01/catalyzex-browser-extension-machine-learning.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?auto=webp&amp;s=02659bad52081873a10146ca8daad01706405bee', 'width': 1202, 'height': 234}, 'resolutions': [{'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3e5dbc27f65729bfccb1f019f5c4fdf4705dc15', 'width': 108, 'height': 21}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=438e1c7ce9e109e9bfc7476344700ec350e37edb', 'width': 216, 'height': 42}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2085485fec5b5e1b2c6490d7efb502dcc22eccbf', 'width': 320, 'height': 62}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f721d898297cce574f35eb473bc6efa3c5767f1', 'width': 640, 'height': 124}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57823910b22cd3dc8c1cb72538b0587a78805ce3', 'width': 960, 'height': 186}, {'url': 'https://external-preview.redd.it/eTftZFzXUkqi1qEEPO-xDCDMkT2126BLpo6nD5d8oOA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6fd62fb158b9fd6f72ad0536f2e8c7102775c6f', 'width': 1080, 'height': 210}], 'variants': {}, 'id': '1IgdrGJHua-eumc0w7TSLq57TXilPA59tdWiEScPk-8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'l7f98o', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/l7f98o/latest_from_kdnuggets_find_code_implementation/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/l7f98o/latest_from_kdnuggets_find_code_implementation/', 'subreddit_subscribers': 6676, 'created_utc': 1611883772.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_l7f98o,
166,,tensorflow,,t2_a0r7u8hy,False,,0,False,"My test data seems to be tailing off. Whereas response is as below. Using relu activation function, what am I missing?",[],r/tensorflow,False,6,,0,140.0,,False,t3_l6w5rv,False,dark,0.86,,public,10,0,{},140.0,,False,[],,True,False,,{},Question,False,10,,False,https://b.thumbs.redditmedia.com/EBx1hhO_fzu_yBx9sthSXrUtX8SjJBgDOi5XnPjoolI.jpg,False,,[],{},,False,,1611868146.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l6w5rv,True,,ep_es_,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/l6w5rv/my_test_data_seems_to_be_tailing_off_whereas/,all_ads,False,https://i.redd.it/u7ij2kjdo2e61.jpg,22217,1611839346.0,0,,False,image,https://i.redd.it/u7ij2kjdo2e61.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?auto=webp&amp;s=afc1849d19b15e694cea13858195e8b76bd06e80', 'width': 3024, 'height': 4032}, 'resolutions': [{'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=520b2cebf6e3617006b7ef199551658325226276', 'width': 108, 'height': 144}, {'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2991ebca7c3c8bb3e99f431ac4612b88c79f3f54', 'width': 216, 'height': 288}, {'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84b277c422b4a5137a2f0aa61d006a457ba0b857', 'width': 320, 'height': 426}, {'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17efe736e2057417413bc3fbbffd1146446f29d6', 'width': 640, 'height': 853}, {'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7bc525d494e67f4b232f3094c5156539907888ca', 'width': 960, 'height': 1280}, {'url': 'https://preview.redd.it/u7ij2kjdo2e61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=623c5e3d2292d2e9c5a210e555cf3d603d871ae9', 'width': 1080, 'height': 1440}], 'variants': {}, 'id': 'q1DcOGSv8WV219SFoXMLwa5vgHy3LVa2uuwDQEYYMws'}], 'enabled': True}",,,,,,
168,,tensorflow,"Hey all

I am new to tensorflow and Python (mostly work in R) and I am busy following this tutorial:

[https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model](https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model)

I am working on a Windows machine and have completed all the steps, and can run the tutorial python notebook. My issue is when I try to train my models using the last command I receive the following errors:

1.  5284 variables\_helper.py:155\] Variable \[ssd\_mobile\_net\_v1fpn\_keras\_feature\_extractor/conv\_pw\_9\_bn/moving\_mean\] is not available in checkpoint
2. Which culminates in ValueError: No variables to save which terminates the command

I have now tried this with multiple models downloaded directly from the object detection model zoo and none have worked. I would deeply appreciate any advice.",t2_3tqdenkk,False,,0,False,No variable available in checkpoint,[],r/tensorflow,False,6,,0,,,False,t3_l70ua6,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1611879004.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all&lt;/p&gt;

&lt;p&gt;I am new to tensorflow and Python (mostly work in R) and I am busy following this tutorial:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model""&gt;https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am working on a Windows machine and have completed all the steps, and can run the tutorial python notebook. My issue is when I try to train my models using the last command I receive the following errors:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 5284 variables_helper.py:155] Variable [ssd_mobile_net_v1fpn_keras_feature_extractor/conv_pw_9_bn/moving_mean] is not available in checkpoint&lt;/li&gt;
&lt;li&gt;Which culminates in ValueError: No variables to save which terminates the command&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have now tried this with multiple models downloaded directly from the object detection model zoo and none have worked. I would deeply appreciate any advice.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l70ua6,True,,SilverStalker1,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l70ua6/no_variable_available_in_checkpoint/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l70ua6/no_variable_available_in_checkpoint/,22217,1611850204.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/0l48OtrZq7-p-6Fszh0mKHVM0yvM1bbGALguExz7w_I.jpg?auto=webp&amp;s=ac4141444ae3063a2d451a07af28326aa37911d4', 'width': 800, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/0l48OtrZq7-p-6Fszh0mKHVM0yvM1bbGALguExz7w_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a015ecea2b6fc3a3815f6ed2c2243083b195057c', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/0l48OtrZq7-p-6Fszh0mKHVM0yvM1bbGALguExz7w_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b8752e02b6e53b6614cb1e83a59b1b697c550ad2', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/0l48OtrZq7-p-6Fszh0mKHVM0yvM1bbGALguExz7w_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e24a51068824b339f4bd72f28ea1ea64d3834b50', 'width': 320, 'height': 240}, {'url': 'https://external-preview.redd.it/0l48OtrZq7-p-6Fszh0mKHVM0yvM1bbGALguExz7w_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0201c26ba16ba9fcd1d8e922e149b6da3b06f376', 'width': 640, 'height': 480}], 'variants': {}, 'id': 'Oevukcdo7MG2IeuL3LW-IyJa7vxaRG-jf-ND9Mvm8GU'}], 'enabled': False}",,,,,,
169,,tensorflow,"Hey! Sorry, if this question does not make 100% sense as my education has not yet reached formal ML classes, but I’ll ask nonetheless.

I want to make a GAN in tensorflow, but instead of just copy and pasting someone’s code, I want to truly understand the bits and parts of it.

From what I know about Naive Bayes, it predicts the distribution of our original data - but after each iteration how can one sample from this distribution, and additionally once you take a sample from this distribution, how can we actually in code pass it to our discriminator?

Thanks everyone :)",t2_9uq9c60e,False,,0,False,How to sample from Naive Bayes PDF and pass it to a discriminator model?,[],r/tensorflow,False,6,,0,,,False,t3_l6qnmh,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1611846687.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey! Sorry, if this question does not make 100% sense as my education has not yet reached formal ML classes, but I’ll ask nonetheless.&lt;/p&gt;

&lt;p&gt;I want to make a GAN in tensorflow, but instead of just copy and pasting someone’s code, I want to truly understand the bits and parts of it.&lt;/p&gt;

&lt;p&gt;From what I know about Naive Bayes, it predicts the distribution of our original data - but after each iteration how can one sample from this distribution, and additionally once you take a sample from this distribution, how can we actually in code pass it to our discriminator?&lt;/p&gt;

&lt;p&gt;Thanks everyone :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l6qnmh,True,,20gunasart,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l6qnmh/how_to_sample_from_naive_bayes_pdf_and_pass_it_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l6qnmh/how_to_sample_from_naive_bayes_pdf_and_pass_it_to/,22217,1611817887.0,0,,False,,,,,,,,,
170,,tensorflow,"Hi /r/tensorflow readers!

We have created a [labelling tool](https://humanlambdas.com/solutions/data-labelling) that can be customized to display all sorts of data models and tasks. Here are a couple of examples for [NLP](https://humanlambdas.com/templates/nlp-news-article-annotation) and [CV](https://humanlambdas.com/templates/computer-vision-annotation). 

I hope some of you will find this useful, and if you have any thoughts I would love to hear your feedback!",t2_bk9jh,False,,0,False,Tool for Complex Data Labelling Tasks,[],r/tensorflow,False,6,,0,,,False,t3_l67vhp,False,dark,0.87,,public,11,1,{},,,False,[],,False,False,,{},Project,False,11,,False,self,False,,[],{},,True,,1611792888.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/tensorflow""&gt;/r/tensorflow&lt;/a&gt; readers!&lt;/p&gt;

&lt;p&gt;We have created a &lt;a href=""https://humanlambdas.com/solutions/data-labelling""&gt;labelling tool&lt;/a&gt; that can be customized to display all sorts of data models and tasks. Here are a couple of examples for &lt;a href=""https://humanlambdas.com/templates/nlp-news-article-annotation""&gt;NLP&lt;/a&gt; and &lt;a href=""https://humanlambdas.com/templates/computer-vision-annotation""&gt;CV&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;I hope some of you will find this useful, and if you have any thoughts I would love to hear your feedback!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l67vhp,True,,bernatfp,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/l67vhp/tool_for_complex_data_labelling_tasks/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l67vhp/tool_for_complex_data_labelling_tasks/,22217,1611764088.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?auto=webp&amp;s=235e2355b6130fbfcb78b89d705af907d386db92', 'width': 2880, 'height': 1800}, 'resolutions': [{'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=72b84a4dca953ac834a8e3f8e4ed6eddb45022b7', 'width': 108, 'height': 67}, {'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=391529d2d5afd4789494398f33e095575e6458f1', 'width': 216, 'height': 135}, {'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0fd8360f94d842f3c3df69621a16b9fbc111da10', 'width': 320, 'height': 200}, {'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36f30f8e4d3e78f928b1f404a13bed8fcd6b0ad5', 'width': 640, 'height': 400}, {'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=250e4fa92b2e3f0487cf1aba5e958362494347fa', 'width': 960, 'height': 600}, {'url': 'https://external-preview.redd.it/FCsoQqCJBLR0U4NXFhqSlTtl3D0eGea4kgPP_frE6x0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d8929d596e259409c5a45d3e24d315b9ce58f967', 'width': 1080, 'height': 675}], 'variants': {}, 'id': '6taeEAVxAwEj0xQWmYL9qf3ZXM5UBBQknCvmdtvgw4U'}], 'enabled': False}",,,,,,
171,,tensorflow,,t2_1krqyfrs,False,,0,False,Would you like to see a Bernie Sanders Detector 🤣🤣🤣,[],r/tensorflow,False,6,,0,115.0,,False,t3_l57vji,False,dark,0.79,,public,85,0,{},140.0,,False,[],,True,False,,{},Discussion,False,85,,False,https://a.thumbs.redditmedia.com/3HRN4Yq8wQ2Yq8X1daAPI7kuZGKB7Lkhy4IVSFbDE40.jpg,False,,[],{},,False,,1611670558.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,l57vji,True,,AugmentedStartups,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/l57vji/would_you_like_to_see_a_bernie_sanders_detector/,all_ads,False,https://i.redd.it/d16we6cucmd61.png,22217,1611641758.0,0,,False,image,https://i.redd.it/d16we6cucmd61.png,"{'images': [{'source': {'url': 'https://preview.redd.it/d16we6cucmd61.png?auto=webp&amp;s=1c237f4d123afa9df16a8da25006bf4788a95ae3', 'width': 892, 'height': 733}, 'resolutions': [{'url': 'https://preview.redd.it/d16we6cucmd61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ace97797dc525b7452d1317de72ec35d1235afe1', 'width': 108, 'height': 88}, {'url': 'https://preview.redd.it/d16we6cucmd61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=350d7b04cf60f0349b0226e4a05611a5eb3826cd', 'width': 216, 'height': 177}, {'url': 'https://preview.redd.it/d16we6cucmd61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1920b91167fa484ed2e2f439014699c11d2c1a45', 'width': 320, 'height': 262}, {'url': 'https://preview.redd.it/d16we6cucmd61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2aa92e5616338646bc7e72e399e3fc942abfa923', 'width': 640, 'height': 525}], 'variants': {}, 'id': '3Ctd7ETOjIIEie1XA2fs2ncrz4E7ghed54UDWeT8aSI'}], 'enabled': True}",,,,,,
172,,tensorflow,"Hi r/tensorflow!

I wonder a bit about the status for TensorFlow conferences this year. I have tried looking after the usual suspects (i.a. O'Reilly) but I can't find any online conference programmed for 2021. A quick Google search doesn't seem to find any relevant TensorFlow event.

Has any of you found anything relevant when it comes to TensorFlow conferences or events online?",t2_9cbgp,False,,0,False,Tensorflow (online) conference in 2021,[],r/tensorflow,False,6,,0,,,False,t3_l5er7x,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1611699087.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/tensorflow""&gt;r/tensorflow&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;I wonder a bit about the status for TensorFlow conferences this year. I have tried looking after the usual suspects (i.a. O&amp;#39;Reilly) but I can&amp;#39;t find any online conference programmed for 2021. A quick Google search doesn&amp;#39;t seem to find any relevant TensorFlow event.&lt;/p&gt;

&lt;p&gt;Has any of you found anything relevant when it comes to TensorFlow conferences or events online?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l5er7x,True,,aramadorc,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l5er7x/tensorflow_online_conference_in_2021/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l5er7x/tensorflow_online_conference_in_2021/,22217,1611670287.0,0,,False,,,,,,,,,
173,,tensorflow,"I'm currently upgrading some TF1 code to TF2, and I'm trying to find a way to match the functionality of the LSTMBlockCell implementation from TF1.  TF2 has tf.raw\_ops.LSTMBlockCell, which is precisely what I'm looking for, but using it gives the following error 'gradient registry has no entry for: LSTMBlockCell'.  TF2 also has tf.raw\_ops.LSTMBlockCellGrad, so it seems there may be a way to use tf.RegisterGradient to couple these two operations.  However, the LSTMBlockCellGrad op doesn't seem to give partials for all of the LSTMBlockCell inputs (LSTMBlockCell has 8 input tensors and LSTMBlockCellGrad returns only 5 partials).  Does anyone have advice on how to proceed?  More generally, has anyone found a way to use LSTMBlockCell in tensorflow 2?",t2_a09fh6rn,False,,0,False,LSTMBlockCell in TensorFlow 2,[],r/tensorflow,False,6,,0,,,False,t3_l5m39a,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1611719737.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently upgrading some TF1 code to TF2, and I&amp;#39;m trying to find a way to match the functionality of the LSTMBlockCell implementation from TF1.  TF2 has tf.raw_ops.LSTMBlockCell, which is precisely what I&amp;#39;m looking for, but using it gives the following error &amp;#39;gradient registry has no entry for: LSTMBlockCell&amp;#39;.  TF2 also has tf.raw_ops.LSTMBlockCellGrad, so it seems there may be a way to use tf.RegisterGradient to couple these two operations.  However, the LSTMBlockCellGrad op doesn&amp;#39;t seem to give partials for all of the LSTMBlockCell inputs (LSTMBlockCell has 8 input tensors and LSTMBlockCellGrad returns only 5 partials).  Does anyone have advice on how to proceed?  More generally, has anyone found a way to use LSTMBlockCell in tensorflow 2?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l5m39a,True,,tflstmq,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l5m39a/lstmblockcell_in_tensorflow_2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l5m39a/lstmblockcell_in_tensorflow_2/,22217,1611690937.0,0,,False,,,,,,,,,
174,,tensorflow,"My second tutorial on how to convert an Autoencoder into a Variational Autoencoder is now out! This time I focus on the loss function of the Variational Autoencoder, discussing in simple terms the mysterious Kullback-Leibler Divergence

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

[https://www.youtube.com/watch?v=lRsqFbgGyKg&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=10](https://www.youtube.com/watch?v=lRsqFbgGyKg&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=10)",t2_12ahau,False,,0,False,I published part 2 of a tutorial that shows how to transform vanilla autoencoders into variational autoencoders,[],r/tensorflow,False,6,,0,,,False,t3_l5c50v,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Project,False,1,,False,self,False,,[],{},,True,,1611689161.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My second tutorial on how to convert an Autoencoder into a Variational Autoencoder is now out! This time I focus on the loss function of the Variational Autoencoder, discussing in simple terms the mysterious Kullback-Leibler Divergence&lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=lRsqFbgGyKg&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=10""&gt;https://www.youtube.com/watch?v=lRsqFbgGyKg&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=10&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l5c50v,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l5c50v/i_published_part_2_of_a_tutorial_that_shows_how/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l5c50v/i_published_part_2_of_a_tutorial_that_shows_how/,22217,1611660361.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rxXY_JpbUwmn70pM6VeOgcYSgSbaPKZHbqO7CHPsRkE.jpg?auto=webp&amp;s=c1bcc80eceec181416fcf3ff31e8938d7284436d', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/rxXY_JpbUwmn70pM6VeOgcYSgSbaPKZHbqO7CHPsRkE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de3ef3d1f8d342f36a6a0cbcac702ebd556cadc1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/rxXY_JpbUwmn70pM6VeOgcYSgSbaPKZHbqO7CHPsRkE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=64e560e9698a42d1f2f987f3b2995587479d2736', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/rxXY_JpbUwmn70pM6VeOgcYSgSbaPKZHbqO7CHPsRkE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=04fd8a92fe33778a875a60caeba7f71c77f3d9dc', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'iahENJ4vkBxSfeR3xx7xH7q6vwyhvWiVg58PJOCSURI'}], 'enabled': False}",,,,,,
175,,tensorflow,,t2_jj0fjpa,False,,0,False,"I used a pre-trained StyleGAN2 model to generate some fake anime characters! I made a video to showcase it, and a link to the colab workbook so you can play around with it too!",[],r/tensorflow,False,6,,0,,,False,t3_l4m1eb,False,dark,0.9,,public,16,0,{},,,False,[],,False,False,,{},Project,False,16,,False,default,False,,[],{},,False,,1611602730.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l4m1eb,True,,cumcopter,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/l4m1eb/i_used_a_pretrained_stylegan2_model_to_generate/,all_ads,False,https://www.youtube.com/watch?v=79iC783_v1o,22217,1611573930.0,0,,False,,https://www.youtube.com/watch?v=79iC783_v1o,,,,,,,
176,,tensorflow,[https://aibharata.medium.com/django-async-vs-fastapi-vs-wsgi-django-choice-of-ml-dl-inference-servers-answering-some-burning-e6a354bf272a](https://aibharata.medium.com/django-async-vs-fastapi-vs-wsgi-django-choice-of-ml-dl-inference-servers-answering-some-burning-e6a354bf272a),t2_4pa3rbfn,False,,0,False,"Deploying TensorFlow Inference Server: Performance comparison of FastAPI, Django Async, Django WSGI",[],r/tensorflow,False,6,,0,,,False,t3_l4nnfw,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,self,False,,[],{},,True,,1611609379.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://aibharata.medium.com/django-async-vs-fastapi-vs-wsgi-django-choice-of-ml-dl-inference-servers-answering-some-burning-e6a354bf272a""&gt;https://aibharata.medium.com/django-async-vs-fastapi-vs-wsgi-django-choice-of-ml-dl-inference-servers-answering-some-burning-e6a354bf272a&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,l4nnfw,True,,damnedAI,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l4nnfw/deploying_tensorflow_inference_server_performance/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l4nnfw/deploying_tensorflow_inference_server_performance/,22217,1611580579.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/SwV5q5JDOSBx6I6AZzZTXDQq0geV9UqC8qUMRv1CVIo.jpg?auto=webp&amp;s=c213a85e74b8b4bee3e9a4fe9f6c3f32b029fae2', 'width': 865, 'height': 408}, 'resolutions': [{'url': 'https://external-preview.redd.it/SwV5q5JDOSBx6I6AZzZTXDQq0geV9UqC8qUMRv1CVIo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e83aeab424fbd762e5e0120fe620d12a7c2b507', 'width': 108, 'height': 50}, {'url': 'https://external-preview.redd.it/SwV5q5JDOSBx6I6AZzZTXDQq0geV9UqC8qUMRv1CVIo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2051f642f41b2e5715b6a6f47fd088ce936fbfc', 'width': 216, 'height': 101}, {'url': 'https://external-preview.redd.it/SwV5q5JDOSBx6I6AZzZTXDQq0geV9UqC8qUMRv1CVIo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a651b0ce8e9ff8051e24fb3dcc25baa3aa2fbf08', 'width': 320, 'height': 150}, {'url': 'https://external-preview.redd.it/SwV5q5JDOSBx6I6AZzZTXDQq0geV9UqC8qUMRv1CVIo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c2884d86ad108ded2cca95f657dc4287ffe6e32b', 'width': 640, 'height': 301}], 'variants': {}, 'id': 'uaFVcSxyk158tcabg5wTzfnWzWvUtP8lgvl5I3W7I_k'}], 'enabled': False}",,,,,,
177,,tensorflow,,t2_ibs89,False,,0,False,TensorFlow Lite Support,[],r/tensorflow,False,6,,0,140.0,,False,t3_l4uvqv,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/4xiSpltDNPBLghbjwgPLvy1Pi2mQtVrWqwTZKxMJNhc.jpg,False,,[],{},,False,,1611630395.0,text,6,,,text,github.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l4uvqv,True,,nbortolotti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l4uvqv/tensorflow_lite_support/,all_ads,False,https://github.com/tensorflow/tflite-support,22217,1611601595.0,0,,False,link,https://github.com/tensorflow/tflite-support,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
178,,tensorflow,"Hello,

I am new to tensorflow and am trying to figure out what I think should be a rather simple task.  I have a model (.pb file) given to me and I need to use it to markup an image.

I have two classes that the model was trained on: background and burnish.

From this point on, I have literally no idea what I am doing. I tried searching online and there is a lot about how to train a model but I don't need to do be able to do that.

Any help pointing me in the right direction would be awesome!",t2_84vbl,False,,0,False,[Help Please] Applying an already trained model to an image,[],r/tensorflow,False,6,,0,,,False,t3_l4r0f5,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1611620000.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I am new to tensorflow and am trying to figure out what I think should be a rather simple task.  I have a model (.pb file) given to me and I need to use it to markup an image.&lt;/p&gt;

&lt;p&gt;I have two classes that the model was trained on: background and burnish.&lt;/p&gt;

&lt;p&gt;From this point on, I have literally no idea what I am doing. I tried searching online and there is a lot about how to train a model but I don&amp;#39;t need to do be able to do that.&lt;/p&gt;

&lt;p&gt;Any help pointing me in the right direction would be awesome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l4r0f5,True,,barrinmw,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l4r0f5/help_please_applying_an_already_trained_model_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l4r0f5/help_please_applying_an_already_trained_model_to/,22217,1611591200.0,0,,False,,,,,,,,,
179,,tensorflow,,t2_emsr9,False,,0,False,Create a TensorFlow sandpit environment and learn the basics in 5 minutes.,[],r/tensorflow,False,6,,0,117.0,,False,t3_l4mh18,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/PMRThW5hT7k-ur8jyA8MXrQjhYpBxGnDQ5JPIcPQESw.jpg,False,,[],{},,False,,1611604718.0,text,6,,,text,fiveminute.cloud,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l4mh18,True,,PeteWood,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l4mh18/create_a_tensorflow_sandpit_environment_and_learn/,all_ads,False,https://fiveminute.cloud/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow.html,22217,1611575918.0,0,,False,,https://fiveminute.cloud/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow.html,,,,,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': '', 'author_fullname': 't2_emsr9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Create a TensorFlow sandpit environment and learn the basics in 5 minutes.', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_l4me93', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'author_premium': False, 'thumbnail': 'default', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1611604380.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'fiveminute.cloud', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://fiveminute.cloud/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow.html', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '8aeee882-d289-11ea-b4f0-0ed750cbd99b', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'l4me93', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'PeteWood', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/l4me93/create_a_tensorflow_sandpit_environment_and_learn/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://fiveminute.cloud/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow.html', 'subreddit_subscribers': 217922, 'created_utc': 1611575580.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_l4me93,
180,,tensorflow,"I am have searched a lot of tutorials and courses, most start with a BERT model or some variation of it.  I want to watch/ learn how a transformer/ attention is trainned from scratch. 

I want to try to build a attention/ transformer model for solved games like chess, (ie I will have generate-able data)",t2_6kwe4fb6,False,,0,False,Anyone have a good example/ tutorial for TF attention/ transformers from scratch?,[],r/tensorflow,False,6,,0,,,False,t3_l46gbq,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1611547154.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am have searched a lot of tutorials and courses, most start with a BERT model or some variation of it.  I want to watch/ learn how a transformer/ attention is trainned from scratch. &lt;/p&gt;

&lt;p&gt;I want to try to build a attention/ transformer model for solved games like chess, (ie I will have generate-able data)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l46gbq,True,,Ok_Cryptographer2209,,11,True,all_ads,False,[],False,,/r/tensorflow/comments/l46gbq/anyone_have_a_good_example_tutorial_for_tf/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l46gbq/anyone_have_a_good_example_tutorial_for_tf/,22217,1611518354.0,0,,False,,,,,,,,,
181,,tensorflow,"I'm looking at reducing the costs of EfficientNet for a task that only deals with greyscale data.

To do this, I need to reduce the number of filters across the network by 1/3rd (RGB -&gt; (B/W)), and train on COCO in greyscale.

The [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) has [a link of training configs](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2) if you want to train from scratch.  

However, I can't seem to find how I would edit the architecture to reduce the number of channels.  

I can see there's an [official definition in Keras](https://github.com/keras-team/keras-applications/blob/master/keras_applications/efficientnet.py), however I'm unsure if this is what's used by the config.

If there was some way to load the saved model, and then edit it's structure that way, that could work.  But I'm unsure if there's a better way to do this.",t2_85simod,False,,0,False,Training custom EfficientNet from scratch (greyscale),[],r/tensorflow,False,6,,0,,,False,t3_l4097t,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1611526673.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking at reducing the costs of EfficientNet for a task that only deals with greyscale data.&lt;/p&gt;

&lt;p&gt;To do this, I need to reduce the number of filters across the network by 1/3rd (RGB -&amp;gt; (B/W)), and train on COCO in greyscale.&lt;/p&gt;

&lt;p&gt;The &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md""&gt;TensorFlow 2 Detection Model Zoo&lt;/a&gt; has &lt;a href=""https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2""&gt;a link of training configs&lt;/a&gt; if you want to train from scratch.  &lt;/p&gt;

&lt;p&gt;However, I can&amp;#39;t seem to find how I would edit the architecture to reduce the number of channels.  &lt;/p&gt;

&lt;p&gt;I can see there&amp;#39;s an &lt;a href=""https://github.com/keras-team/keras-applications/blob/master/keras_applications/efficientnet.py""&gt;official definition in Keras&lt;/a&gt;, however I&amp;#39;m unsure if this is what&amp;#39;s used by the config.&lt;/p&gt;

&lt;p&gt;If there was some way to load the saved model, and then edit it&amp;#39;s structure that way, that could work.  But I&amp;#39;m unsure if there&amp;#39;s a better way to do this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l4097t,True,,pram-ila,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/l4097t/training_custom_efficientnet_from_scratch/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l4097t/training_custom_efficientnet_from_scratch/,22217,1611497873.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
182,,tensorflow,So at this point I've managed to get ahold of my checkpoint file which is of type \`DATA-00000-OF-00001\` and there is also a similar one that is of type \`INDEX\` and this file is significantly smaller in terms of size. I would like to convert these two into a single \`\*.pb\` file. Is that possible?,t2_y2aw2,False,,0,False,How do I convert my checkpoint file to a pb file,[],r/tensorflow,False,6,,0,,,False,t3_l3q66k,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1611482962.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So at this point I&amp;#39;ve managed to get ahold of my checkpoint file which is of type `DATA-00000-OF-00001` and there is also a similar one that is of type `INDEX` and this file is significantly smaller in terms of size. I would like to convert these two into a single `*.pb` file. Is that possible?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l3q66k,True,,SilentWolfDev,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/l3q66k/how_do_i_convert_my_checkpoint_file_to_a_pb_file/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l3q66k/how_do_i_convert_my_checkpoint_file_to_a_pb_file/,22217,1611454162.0,0,,False,,,,,,,,,
183,,tensorflow,"Sorry for asking a question that's not a direct TensorFlow issue but 2.4 supports the 3000-series GPUs, so a lot of us are waiting on Anaconda support, and was thinking maybe someone here can remember how long it took Anaconda to support 2.3 after its release, to give others an approximate timeframe on 2.4.  Thanks. )",t2_bdhhv,False,,0,False,Any idea when Anaconda Cloud will carry TensorFlow 2.4?,[],r/tensorflow,False,6,,0,,,False,t3_l3fl26,False,dark,0.92,,public,9,0,{},,,False,[],,False,False,,{},,False,9,,False,self,False,,[],{},,True,,1611449241.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sorry for asking a question that&amp;#39;s not a direct TensorFlow issue but 2.4 supports the 3000-series GPUs, so a lot of us are waiting on Anaconda support, and was thinking maybe someone here can remember how long it took Anaconda to support 2.3 after its release, to give others an approximate timeframe on 2.4.  Thanks. )&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l3fl26,True,,venture70,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l3fl26/any_idea_when_anaconda_cloud_will_carry/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l3fl26/any_idea_when_anaconda_cloud_will_carry/,22217,1611420441.0,0,,False,,,,,,,,,
184,,tensorflow,"https://reddit-username-generator.herokuapp.com/

Trained on ~400k usernames, this LSTM based approach can generate pretty realistic looking reddit usernames. You can even provide a start string like ""PM_ME"" (warning: lotta profanity).

At first I deployed with TensorFlow.js in React, but to learn more I rewrote the backend with Flask instead.

Here's the GitHub: https://github.com/dchen327/reddit-username-generator

Have fun!",t2_2upf6ses,False,,0,False,I made and deployed a Reddit username generator!,[],r/tensorflow,False,6,,0,,,False,t3_l3evs3,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Project,False,3,,False,self,False,,[],{},,True,,1611447105.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://reddit-username-generator.herokuapp.com/""&gt;https://reddit-username-generator.herokuapp.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Trained on ~400k usernames, this LSTM based approach can generate pretty realistic looking reddit usernames. You can even provide a start string like &amp;quot;PM_ME&amp;quot; (warning: lotta profanity).&lt;/p&gt;

&lt;p&gt;At first I deployed with TensorFlow.js in React, but to learn more I rewrote the backend with Flask instead.&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s the GitHub: &lt;a href=""https://github.com/dchen327/reddit-username-generator""&gt;https://github.com/dchen327/reddit-username-generator&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Have fun!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l3evs3,True,,lambda5x5,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l3evs3/i_made_and_deployed_a_reddit_username_generator/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l3evs3/i_made_and_deployed_a_reddit_username_generator/,22217,1611418305.0,0,,False,,,,,,,,,
185,,tensorflow,,t2_3dwzospl,False,,0,False,My First Project was creating Pokemon Names using Tensorflow and Python [Youtube video in description],[],r/tensorflow,False,6,,0,86.0,,False,t3_l2kh2t,False,dark,0.88,,public,29,0,{},140.0,,False,[],,True,False,,{},Project,False,29,,False,https://b.thumbs.redditmedia.com/gxTRRVmJqKZHRv7GJJSyQx4AYnVvj1SjbeNop2CZitQ.jpg,False,,[],{},,False,,1611337599.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l2kh2t,True,,yogibiceps,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/l2kh2t/my_first_project_was_creating_pokemon_names_using/,all_ads,False,https://i.redd.it/oxzjx9rouuc61.png,22217,1611308799.0,0,,False,image,https://i.redd.it/oxzjx9rouuc61.png,"{'images': [{'source': {'url': 'https://preview.redd.it/oxzjx9rouuc61.png?auto=webp&amp;s=0c9660c36285826c28cc01e1fa0210fb9288dc89', 'width': 1597, 'height': 988}, 'resolutions': [{'url': 'https://preview.redd.it/oxzjx9rouuc61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e4a7071814fb733849b202933eeb779c180a1bc', 'width': 108, 'height': 66}, {'url': 'https://preview.redd.it/oxzjx9rouuc61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d87f41aeb2f30f4531b2d8cc145ba4e5152e6ca', 'width': 216, 'height': 133}, {'url': 'https://preview.redd.it/oxzjx9rouuc61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bbd4767a521d961e2bdc4619a5a3671ffce6009', 'width': 320, 'height': 197}, {'url': 'https://preview.redd.it/oxzjx9rouuc61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef87d3a391b6ac934446ad56c6c0c32f134a61c6', 'width': 640, 'height': 395}, {'url': 'https://preview.redd.it/oxzjx9rouuc61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4296e8b08ba797776678dbe98048561195f32c90', 'width': 960, 'height': 593}, {'url': 'https://preview.redd.it/oxzjx9rouuc61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e59327945a1b47444fc9765b9920f6d351bb10a', 'width': 1080, 'height': 668}], 'variants': {}, 'id': 'vA9lZXfh2soBe0z2NxpI670nMv8rc8r9ObAsLDjb4Cs'}], 'enabled': True}",,,,,,True
186,,tensorflow,"I built an AI that generates rap music lyrics using TensorFlow and Keras actually posted this project a while ago but since then lots of improvements have done also at that time servers are not capable of running the tf model. you can check the website(live demo you can give it a seed and I generates rap based on the seed) and the GitHub repos all links down below if you star or fork the repo I would be so happy thanks.

Github: [https://github.com/YigitGunduc/Spectrum](https://github.com/YigitGunduc/Spectrum)

Website: [https://spectrumapp.herokuapp.com/](https://spectrumapp.herokuapp.com/)",t2_70tvn3l8,False,,0,False,AI that generates rap lyrics (Open-Source + Live Demo),[],r/tensorflow,False,6,,0,,,False,t3_l2qko8,False,dark,0.91,,public,8,0,{},,,False,[],,False,False,,{},Project,False,8,,False,self,False,,[],{},,True,,1611359946.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I built an AI that generates rap music lyrics using TensorFlow and Keras actually posted this project a while ago but since then lots of improvements have done also at that time servers are not capable of running the tf model. you can check the website(live demo you can give it a seed and I generates rap based on the seed) and the GitHub repos all links down below if you star or fork the repo I would be so happy thanks.&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/YigitGunduc/Spectrum""&gt;https://github.com/YigitGunduc/Spectrum&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Website: &lt;a href=""https://spectrumapp.herokuapp.com/""&gt;https://spectrumapp.herokuapp.com/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l2qko8,True,,_Xeon__,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/l2qko8/ai_that_generates_rap_lyrics_opensource_live_demo/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2qko8/ai_that_generates_rap_lyrics_opensource_live_demo/,22217,1611331146.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?auto=webp&amp;s=95976682426bdc4bc0a7d1f9a830014b2594cc62', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=575db71fe99b03f846d413b42fafbc0250c8000f', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=681d15c1d40b573baab0166065df0157cba2939f', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7be3a8e936983353f0163be0e69ed10178f5039a', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'IXMU2IHAflclO88ngV0NR-B0Zju3TH48jgQPZsfD7Uo'}], 'enabled': False}",,,,,,
187,,tensorflow,Git link https://github.com/ArimaValanImmanuel/posenet-python,t2_6ongi8yt,False,,0,False,Can anybody help me with running posenet python version of posenet tensorflowjs by rwightman?,[],r/tensorflow,False,6,,0,,,False,t3_l2upr6,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1611371606.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Git link &lt;a href=""https://github.com/ArimaValanImmanuel/posenet-python""&gt;https://github.com/ArimaValanImmanuel/posenet-python&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l2upr6,True,,Section_Disastrous,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l2upr6/can_anybody_help_me_with_running_posenet_python/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2upr6/can_anybody_help_me_with_running_posenet_python/,22217,1611342806.0,1,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Q9xN0_je_IZGSp8YKJH5J68oP3a_B6mNkpFClT-O1Dw.jpg?auto=webp&amp;s=06a709ef736035d9efec4a3fb087865ee96fcdaa', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/Q9xN0_je_IZGSp8YKJH5J68oP3a_B6mNkpFClT-O1Dw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cab8c0efae46158b45fd0eed8d23143f5838aa10', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/Q9xN0_je_IZGSp8YKJH5J68oP3a_B6mNkpFClT-O1Dw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4897a996df147d5aeebd1db810fefdae5f55ed5', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/Q9xN0_je_IZGSp8YKJH5J68oP3a_B6mNkpFClT-O1Dw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a1c2e46832e3cf37e1ef1676d96b551fb1f6024', 'width': 320, 'height': 320}], 'variants': {}, 'id': '48IxQKjU0Af64g3PKg-tomFVXwc6uxLhoHtKdy8mRe0'}], 'enabled': False}",,,,,,
188,,tensorflow,"I'm upgrading my tensorflow version and using their tf\_upgrade\_v2 script. I don't run into any issues but all my python files register as ""modified"" in git, even when there are no changes? I poked around google and some people mention that my file permissions may be changing, so I set the core.filemode to false in my .git/config and then retry to to the upgrade, but I am still seeing file changes. I diffed the files and I see zero changes. I believe it could be the EOL, but I tried setting core.autcrlf to false as well and that still gives me all these files as modified. Has anyone encountered this? Running ubuntu 20.04.1.",t2_8wz65,False,,0,False,Upgrading to tf2 modifies all my .py files,[],r/tensorflow,False,6,,0,,,False,t3_l2rhw3,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1611362553.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m upgrading my tensorflow version and using their tf_upgrade_v2 script. I don&amp;#39;t run into any issues but all my python files register as &amp;quot;modified&amp;quot; in git, even when there are no changes? I poked around google and some people mention that my file permissions may be changing, so I set the core.filemode to false in my .git/config and then retry to to the upgrade, but I am still seeing file changes. I diffed the files and I see zero changes. I believe it could be the EOL, but I tried setting core.autcrlf to false as well and that still gives me all these files as modified. Has anyone encountered this? Running ubuntu 20.04.1.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l2rhw3,True,,Woodhouse_20,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l2rhw3/upgrading_to_tf2_modifies_all_my_py_files/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2rhw3/upgrading_to_tf2_modifies_all_my_py_files/,22217,1611333753.0,0,,False,,,,,,,,,
189,,tensorflow,"I have tf dataset with images and labels and want to convert it to a Pandas DataFrame, since that's the object required in an AzureML pipeline designer. 

I'm a beginner working with tensorflow and after googling for a couple of hours I haven't found anything. 

I'd appreciate any tips on how to do this.",t2_btwm0,False,,0,False,How can I convert a TensorFlow Dataset into a Pandas DataFrame?,[],r/tensorflow,False,6,,0,,,False,t3_l2l9vm,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1611341298.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have tf dataset with images and labels and want to convert it to a Pandas DataFrame, since that&amp;#39;s the object required in an AzureML pipeline designer. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m a beginner working with tensorflow and after googling for a couple of hours I haven&amp;#39;t found anything. &lt;/p&gt;

&lt;p&gt;I&amp;#39;d appreciate any tips on how to do this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l2l9vm,True,,juliansorel,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l2l9vm/how_can_i_convert_a_tensorflow_dataset_into_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2l9vm/how_can_i_convert_a_tensorflow_dataset_into_a/,22217,1611312498.0,0,,False,,,,,,,,,
190,,tensorflow,"Hi all, I'm training a model which has two separate branches with different inputs, which after two layers are concatenated for a final layer. Upon being concatenated, they are equal sizes and the number of samples is equal to the number of labels, however initially one set is double the size of the other. See the code below.

[`model.fit`](https://model.fit)`({""R1_input"": R1_padded_train_tensor, ""R2_input"": R2_padded_train_tensor},{""U"": R2_labels_train_tensor}, epochs=10,verbose=1, steps_per_epoch=500, batch_size=8)`

where `R1_padded_train_tensor` has 492456 samples and `R2_padded_train_tensor` has 246228 samples. The `R2_labels_train_tensor` has 246228 samples.

A layer of the model combines two samples, halving the number of samples in R1 and in the concatenated tensor, so when R1 and R2 are combined their length is 492456 which is subsequently halved to get to 246228 samples. The error given is:

`ValueError: Data cardinality is ambiguous:`

  `x sizes: 492456, 246228`

  `y sizes: 246228`

`Make sure all arrays contain the same number of samples.`

&amp;#x200B;

I don't understand why the same number of samples is necessary if the model isn't sequential?

This did work and suddenly stopped working (as far as I'm aware I didn't change any of the code). Any ideas would be greatly appreciated!",t2_app97,False,,0,False,Multiple input model using functional API is giving a dimension error?,[],r/tensorflow,False,6,,0,,,False,t3_l2n0ed,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1611348362.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m training a model which has two separate branches with different inputs, which after two layers are concatenated for a final layer. Upon being concatenated, they are equal sizes and the number of samples is equal to the number of labels, however initially one set is double the size of the other. See the code below.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://model.fit""&gt;&lt;code&gt;model.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;({&amp;quot;R1_input&amp;quot;: R1_padded_train_tensor, &amp;quot;R2_input&amp;quot;: R2_padded_train_tensor},{&amp;quot;U&amp;quot;: R2_labels_train_tensor}, epochs=10,verbose=1, steps_per_epoch=500, batch_size=8)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where &lt;code&gt;R1_padded_train_tensor&lt;/code&gt; has 492456 samples and &lt;code&gt;R2_padded_train_tensor&lt;/code&gt; has 246228 samples. The &lt;code&gt;R2_labels_train_tensor&lt;/code&gt; has 246228 samples.&lt;/p&gt;

&lt;p&gt;A layer of the model combines two samples, halving the number of samples in R1 and in the concatenated tensor, so when R1 and R2 are combined their length is 492456 which is subsequently halved to get to 246228 samples. The error given is:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ValueError: Data cardinality is ambiguous:&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x sizes: 492456, 246228&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;y sizes: 246228&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Make sure all arrays contain the same number of samples.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t understand why the same number of samples is necessary if the model isn&amp;#39;t sequential?&lt;/p&gt;

&lt;p&gt;This did work and suddenly stopped working (as far as I&amp;#39;m aware I didn&amp;#39;t change any of the code). Any ideas would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l2n0ed,True,,Ryvm,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/l2n0ed/multiple_input_model_using_functional_api_is/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2n0ed/multiple_input_model_using_functional_api_is/,22217,1611319562.0,0,,False,,,,,,,,,
191,,tensorflow,"Autoencoders have a number of limitations for generative tasks. That’s why they need a power-up to become Variational Autoencoders. In my new video, I explain the first step to transform an autoencoder into a VAE. Specifically, I discuss how VAEs use multivariate normal distributions to encode input data into a latent space and why this is awesome for generative tasks. Don’t worry - I also explain what multivariate normal distributions are! 

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

https://www.youtube.com/watch?v=b8AzCgY1gZI&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=9",t2_12ahau,False,,0,False,I published part 1 of a tutorial that shows how to transform vanilla autoencoders into variational autoencoders,[],r/tensorflow,False,6,,0,,,False,t3_l2kw6p,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Project,False,0,,False,self,False,,[],{},,True,,1611339551.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Autoencoders have a number of limitations for generative tasks. That’s why they need a power-up to become Variational Autoencoders. In my new video, I explain the first step to transform an autoencoder into a VAE. Specifically, I discuss how VAEs use multivariate normal distributions to encode input data into a latent space and why this is awesome for generative tasks. Don’t worry - I also explain what multivariate normal distributions are! &lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=b8AzCgY1gZI&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=9""&gt;https://www.youtube.com/watch?v=b8AzCgY1gZI&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=9&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,l2kw6p,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l2kw6p/i_published_part_1_of_a_tutorial_that_shows_how/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2kw6p/i_published_part_1_of_a_tutorial_that_shows_how/,22217,1611310751.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QMqzyVIUiun4vslu6qOcRbU_HhqZPkedIP7XzK6DMoc.jpg?auto=webp&amp;s=a2858b76b541b4392a60b337371e3b1a990e98e5', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/QMqzyVIUiun4vslu6qOcRbU_HhqZPkedIP7XzK6DMoc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b5209f15bd3e2fe8014eb3dab7f4cca57f586de', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/QMqzyVIUiun4vslu6qOcRbU_HhqZPkedIP7XzK6DMoc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=72a2fb07120b606059166b69a78776f49ce281aa', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/QMqzyVIUiun4vslu6qOcRbU_HhqZPkedIP7XzK6DMoc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8dfc38854f3026c962baf02e4bc2fd4c9230db73', 'width': 320, 'height': 240}], 'variants': {}, 'id': '45eCMqp-hdsS9VnVFjUkbVLODZE2TISRddMzKzli-qg'}], 'enabled': False}",,,,,,
192,,tensorflow,"If I have any other version of protobuf except for 3.6.0 I will get “ImportError: DLL load failed: The specified procedure could not be found” but if I use protobuf 3.6.0 I get “AttributeError: ‘google.protobuf.pyext._message.RepeatedCompositeCo’ object has no attribute ‘append’” this error occurs when I try to build the model.

I have tried every 2.x version of tensorflow have reinstalled python 3.6 I have made sure my path variables are correct.  I can find no useful information on the internet. I have tried countless versions of protobuf. Please help! I have no clue what the hell is going on.

Maybe upgrade python 3.6 to 3.7? as I have previously had tensorflow 2.x working on python 3.7 but I don’t know.",t2_3x1hf9b1,False,,0,False,Can’t use tensorflow 2 (I need tensorflow 2cant use 1) because of no protobuf version working for it.,[],r/tensorflow,False,6,,0,,,False,t3_l2ejzi,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1611289356.0,,[],{},,True,,1611313369.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I have any other version of protobuf except for 3.6.0 I will get “ImportError: DLL load failed: The specified procedure could not be found” but if I use protobuf 3.6.0 I get “AttributeError: ‘google.protobuf.pyext._message.RepeatedCompositeCo’ object has no attribute ‘append’” this error occurs when I try to build the model.&lt;/p&gt;

&lt;p&gt;I have tried every 2.x version of tensorflow have reinstalled python 3.6 I have made sure my path variables are correct.  I can find no useful information on the internet. I have tried countless versions of protobuf. Please help! I have no clue what the hell is going on.&lt;/p&gt;

&lt;p&gt;Maybe upgrade python 3.6 to 3.7? as I have previously had tensorflow 2.x working on python 3.7 but I don’t know.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l2ejzi,True,,FunnyForWrongReason,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l2ejzi/cant_use_tensorflow_2_i_need_tensorflow_2cant_use/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l2ejzi/cant_use_tensorflow_2_i_need_tensorflow_2cant_use/,22217,1611284569.0,0,,False,,,,,,,,,
193,,tensorflow,,t2_6yjbbips,False,,0,False,What does the shape of a spectrogram really mean?,[],r/tensorflow,False,6,,0,140.0,,False,t3_l2dowd,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/CDHwqtnYHyvioPurRCdjVK76PCZKJIKZjSAOCXGLdKY.jpg,False,,[],{},,False,,1611310437.0,text,6,,,text,stackoverflow.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l2dowd,True,,Metecko,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l2dowd/what_does_the_shape_of_a_spectrogram_really_mean/,all_ads,False,https://stackoverflow.com/questions/65838342/what-does-the-shape-of-a-spectrogram-really-mean,22217,1611281637.0,0,,False,link,https://stackoverflow.com/questions/65838342/what-does-the-shape-of-a-spectrogram-really-mean,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
194,,tensorflow,"So I understood the attention mechanism ( Bahdanau Attention, 2017 paper) and I was looking for the implementation of the paper and then I landed on the tensorflow website which has a tutorial on attention mechanism. Nut Frankly speaking, I found it very hard to understand the code. Are there any tutorials that you can share that will help me to understand the code of the attention mechanism.",t2_7uvqkxdb,False,,0,False,Any tutorials that you can recommend?,[],r/tensorflow,False,6,,0,,,False,t3_l25yc5,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1611286830.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I understood the attention mechanism ( Bahdanau Attention, 2017 paper) and I was looking for the implementation of the paper and then I landed on the tensorflow website which has a tutorial on attention mechanism. Nut Frankly speaking, I found it very hard to understand the code. Are there any tutorials that you can share that will help me to understand the code of the attention mechanism.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l25yc5,True,,Consistent_Ad767,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/l25yc5/any_tutorials_that_you_can_recommend/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l25yc5/any_tutorials_that_you_can_recommend/,22217,1611258030.0,0,,False,,,,,,,,,
195,,tensorflow,"Messing around with transformers and images and I can patch the images together, and display them as a grid with matplotlib, but can't wrap my head around putting the image back together into a single tensor. I saw on StackExchange someone recommended tf.space\_to\_dense and tf.dense\_to\_space, but the how wasn't straightforward for me.

Anyone have any tips or insight?",t2_w6j04,False,,0,False,Go from tf.image.extract_patches back to a stitched together image?,[],r/tensorflow,False,6,,0,,,False,t3_l29udh,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1611298073.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Messing around with transformers and images and I can patch the images together, and display them as a grid with matplotlib, but can&amp;#39;t wrap my head around putting the image back together into a single tensor. I saw on StackExchange someone recommended tf.space_to_dense and tf.dense_to_space, but the how wasn&amp;#39;t straightforward for me.&lt;/p&gt;

&lt;p&gt;Anyone have any tips or insight?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l29udh,True,,bahwi,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/l29udh/go_from_tfimageextract_patches_back_to_a_stitched/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l29udh/go_from_tfimageextract_patches_back_to_a_stitched/,22217,1611269273.0,0,,False,,,,,,,,,
196,,tensorflow,"I'm a Python web developer, so I have some professional coding experience, but I'm a complete novice when it comes to machine learning.

In short, I have a dataset (csv form) with 65,000 sentences in two languages. One of the languages is real, the other is not. I'd live to quickly dive into an RNN example online so that I can train a model based on this dataset, but all of the examples seem to prefer that I use existing, binary datasets (that I can't read).

My laptop is relatively old, and processing a dataset properly can take a week, so every example I've attempted to adapt to my needs has cost lots of time and lots of heartache when I discover that I can't use it.

Is there an RNN translation tutorial that anyone would recommend for the purpose of translating between an existing corpus and a constructed language? I can do research on any terms listed below, but the topic of machine learning has so regularly stumped me that, even though I know easy examples for what I want to do probably already exist, I don't even know where to start.

Thank you for your time!",t2_3tfrqi8u,False,,0,False,Fastest way to develop a custom translation model with RNN?,[],r/tensorflow,False,6,,0,,,False,t3_l24ol6,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1611283391.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a Python web developer, so I have some professional coding experience, but I&amp;#39;m a complete novice when it comes to machine learning.&lt;/p&gt;

&lt;p&gt;In short, I have a dataset (csv form) with 65,000 sentences in two languages. One of the languages is real, the other is not. I&amp;#39;d live to quickly dive into an RNN example online so that I can train a model based on this dataset, but all of the examples seem to prefer that I use existing, binary datasets (that I can&amp;#39;t read).&lt;/p&gt;

&lt;p&gt;My laptop is relatively old, and processing a dataset properly can take a week, so every example I&amp;#39;ve attempted to adapt to my needs has cost lots of time and lots of heartache when I discover that I can&amp;#39;t use it.&lt;/p&gt;

&lt;p&gt;Is there an RNN translation tutorial that anyone would recommend for the purpose of translating between an existing corpus and a constructed language? I can do research on any terms listed below, but the topic of machine learning has so regularly stumped me that, even though I know easy examples for what I want to do probably already exist, I don&amp;#39;t even know where to start.&lt;/p&gt;

&lt;p&gt;Thank you for your time!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l24ol6,True,,ehowardhill,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/l24ol6/fastest_way_to_develop_a_custom_translation_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l24ol6/fastest_way_to_develop_a_custom_translation_model/,22217,1611254591.0,0,,False,,,,,,,,,
197,,tensorflow,"When performing custom batch training in the training loop, which one should be used? 

tf.gradient_tape or train_on_batch? 

What is the difference?",t2_4ih25pre,False,,0,False,Batch training in tf 2.0,[],r/tensorflow,False,6,,0,,,False,t3_l1tnqn,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},,False,8,,False,self,False,,[],{},,True,,1611243252.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When performing custom batch training in the training loop, which one should be used? &lt;/p&gt;

&lt;p&gt;tf.gradient_tape or train_on_batch? &lt;/p&gt;

&lt;p&gt;What is the difference?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l1tnqn,True,,SuccMyStrangerThings,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/l1tnqn/batch_training_in_tf_20/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l1tnqn/batch_training_in_tf_20/,22217,1611214452.0,0,,False,,,,,,,,,
198,,tensorflow,"I got this error/warning while trying to run the webcam\_demo.py example in Posenet library from Tensorflow. how to resolve this?

&amp;#x200B;

This is the **Git Repo** from where I forked this code : [posenet-python](https://github.com/rwightman/posenet-python)

&amp;#x200B;

and This is my **Output Screen** :

&amp;#x200B;

`&gt;&gt;&gt;` 

 `RESTART: A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py` 

`Cannot find model file ./_models\model-mobilenet_v1_101.pb, converting from tfjs...`

`WARNING:tensorflow:From A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.`

`Instructions for updating:`

`Use standard file APIs to check for files with this prefix.`

`Traceback (most recent call last):`

  `File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py"", line 66, in &lt;module&gt;`

`main()`

  `File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py"", line 20, in main`

`model_cfg, model_outputs = posenet.load_model(args.model, sess)`

  `File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\posenet\`[`model.py`](https://model.py)`"", line 42, in load_model`

`convert(model_ord, model_dir, check=False)`

  `File ""A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\posenet\converter\`[`tfjs2python.py`](https://tfjs2python.py)`"", line 198, in convert`

`initializer_nodes="""")`

  `File ""A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py"", line 361, in freeze_graph`

`checkpoint_version=checkpoint_version)`

  `File ""A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py"", line 190, in freeze_graph_with_def_protos`

`var_list=var_list, write_version=checkpoint_version)`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\`[`saver.py`](https://saver.py)`"", line 835, in __init__`

[`self.build`](https://self.build)`()`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\`[`saver.py`](https://saver.py)`"", line 847, in build`

`self._build(self._filename, build_save=True, build_restore=True)`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\`[`saver.py`](https://saver.py)`"", line 885, in _build`

`build_restore=build_restore)`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\`[`saver.py`](https://saver.py)`"", line 489, in _build_internal`

`names_to_saveables)`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py"", line 362, in validate_and_slice_inputs`

`for converted_saveable_object in saveable_objects_for_op(op, name):`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py"", line 223, in saveable_objects_for_op`

`yield ResourceVariableSaveable(variable, """", name)`

  `File ""A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py"", line 95, in __init__`

`self.handle_op = var.op.inputs[0]`

`IndexError: tuple index out of range`

`&gt;&gt;&gt;` 

&amp;#x200B;

[My Git Issue Link](https://github.com/tensorflow/tensorflow/issues/46575)",t2_6ongi8yt,False,,0,False,I got this error while trying to run the webcam_demo.py example in Posenet library from tensorflow. how to resolve this? #46575,[],r/tensorflow,False,6,,0,,,False,t3_l1xolh,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1611261597.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I got this error/warning while trying to run the webcam_demo.py example in Posenet library from Tensorflow. how to resolve this?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;This is the &lt;strong&gt;Git Repo&lt;/strong&gt; from where I forked this code : &lt;a href=""https://github.com/rwightman/posenet-python""&gt;posenet-python&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;and This is my &lt;strong&gt;Output Screen&lt;/strong&gt; :&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; &lt;/p&gt;

&lt;p&gt;&lt;code&gt;RESTART: A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py&lt;/code&gt; &lt;/p&gt;

&lt;p&gt;&lt;code&gt;Cannot find model file ./_models\model-mobilenet_v1_101.pb, converting from tfjs...&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;WARNING:tensorflow:From A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Instructions for updating:&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Use standard file APIs to check for files with this prefix.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Traceback (most recent call last):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py&amp;quot;, line 66, in &amp;lt;module&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;main()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\webcam_demo.py&amp;quot;, line 20, in main&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model_cfg, model_outputs = posenet.load_model(args.model, sess)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\posenet\&lt;/code&gt;&lt;a href=""https://model.py""&gt;&lt;code&gt;model.py&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;, line 42, in load_model&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;convert(model_ord, model_dir, check=False)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\Scripts\Posenet-Forked -- OGCode\posenet-python-master\posenet\converter\&lt;/code&gt;&lt;a href=""https://tfjs2python.py""&gt;&lt;code&gt;tfjs2python.py&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;, line 198, in convert&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;initializer_nodes=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py&amp;quot;, line 361, in freeze_graph&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;checkpoint_version=checkpoint_version)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\tools\freeze_graph.py&amp;quot;, line 190, in freeze_graph_with_def_protos&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;var_list=var_list, write_version=checkpoint_version)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\&lt;/code&gt;&lt;a href=""https://saver.py""&gt;&lt;code&gt;saver.py&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;, line 835, in __init__&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://self.build""&gt;&lt;code&gt;self.build&lt;/code&gt;&lt;/a&gt;&lt;code&gt;()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\&lt;/code&gt;&lt;a href=""https://saver.py""&gt;&lt;code&gt;saver.py&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;, line 847, in build&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;self._build(self._filename, build_save=True, build_restore=True)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\&lt;/code&gt;&lt;a href=""https://saver.py""&gt;&lt;code&gt;saver.py&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;, line 885, in _build&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;build_restore=build_restore)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\&lt;/code&gt;&lt;a href=""https://saver.py""&gt;&lt;code&gt;saver.py&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;, line 489, in _build_internal&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;names_to_saveables)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py&amp;quot;, line 362, in validate_and_slice_inputs&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for converted_saveable_object in saveable_objects_for_op(op, name):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py&amp;quot;, line 223, in saveable_objects_for_op&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;yield ResourceVariableSaveable(variable, &amp;quot;&amp;quot;, name)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;File &amp;quot;A:\Python\lib\site-packages\tensorflow\python\training\saving\saveable_object_util.py&amp;quot;, line 95, in __init__&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;self.handle_op = var.op.inputs[0]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;IndexError: tuple index out of range&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/tensorflow/tensorflow/issues/46575""&gt;My Git Issue Link&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,l1xolh,True,,Section_Disastrous,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l1xolh/i_got_this_error_while_trying_to_run_the_webcam/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l1xolh/i_got_this_error_while_trying_to_run_the_webcam/,22217,1611232797.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/0NSOWVRQ6zi0k8qio3AtoCmzD3KfWNhAGsxq6xAvIi8.jpg?auto=webp&amp;s=ad42500150e14660b759ca9025ee34bf9bdade8a', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/0NSOWVRQ6zi0k8qio3AtoCmzD3KfWNhAGsxq6xAvIi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=55a6da8e4bfbfd94d6c0942bc7187a632c70ac0b', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/0NSOWVRQ6zi0k8qio3AtoCmzD3KfWNhAGsxq6xAvIi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42101e9b1038dd86845d8edad13e60d2e2fee6d0', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/0NSOWVRQ6zi0k8qio3AtoCmzD3KfWNhAGsxq6xAvIi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5afeace7984619a85f41ffd27e66e87da9466a03', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'py77FUxNmOuLwumtDMSpV2x6AatTcP5_xQBZLtOrSTM'}], 'enabled': False}",,,,,,
199,,tensorflow,"TF 2.0 data API is so difficult to work with. I want to create a simple pipeline that loads image from the folder, preprocess and do batch training. 

Is there a good article on the same to follow?",t2_4ih25pre,False,,0,False,Tf 2.0 data API help,[],r/tensorflow,False,6,,0,,,False,t3_l1svoz,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1611239807.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TF 2.0 data API is so difficult to work with. I want to create a simple pipeline that loads image from the folder, preprocess and do batch training. &lt;/p&gt;

&lt;p&gt;Is there a good article on the same to follow?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l1svoz,True,,SuccMyStrangerThings,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/l1svoz/tf_20_data_api_help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l1svoz/tf_20_data_api_help/,22217,1611211007.0,0,,False,,,,,,,,,
200,,tensorflow,,t2_4u798if4,False,,0,False,"Use your AMD GPUs with DirectML, the catch is you are with TF 1.15...",[],r/tensorflow,False,6,,0,105.0,,False,t3_l1fd9s,False,dark,0.79,,public,10,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gjVFH7NHB9s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tensorflow on AMD GPU with Windows 10', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gjVFH7NHB9s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Computing Hangout', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/gjVFH7NHB9s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCAOBAMyMnTlJbGsws-an62A'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gjVFH7NHB9s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/l1fd9s', 'height': 200}",Discussion,False,10,,False,https://b.thumbs.redditmedia.com/eQRMaagEL3tUyaTvllS8OGHh3WHFmcztAnd5IbA1ySk.jpg,False,,[],{},,False,,1611196708.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,l1fd9s,True,,computing_hangout,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/l1fd9s/use_your_amd_gpus_with_directml_the_catch_is_you/,all_ads,False,https://www.youtube.com/watch?v=gjVFH7NHB9s,22217,1611167908.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tensorflow on AMD GPU with Windows 10', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gjVFH7NHB9s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Computing Hangout', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/gjVFH7NHB9s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCAOBAMyMnTlJbGsws-an62A'}}",False,rich:video,https://www.youtube.com/watch?v=gjVFH7NHB9s,"{'images': [{'source': {'url': 'https://external-preview.redd.it/KKRP2MnvL-pHS6lvjvuuDapDUA_EKdZlam5Tj-ldjCY.jpg?auto=webp&amp;s=d39cc58e82b6666d8475940d478d8b4a7c71cdd7', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/KKRP2MnvL-pHS6lvjvuuDapDUA_EKdZlam5Tj-ldjCY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=212c939ba4a06bd5ac5af6b1b22b98841d266e05', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/KKRP2MnvL-pHS6lvjvuuDapDUA_EKdZlam5Tj-ldjCY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6fef679680dc16a59833f553173d8643f30f63d', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/KKRP2MnvL-pHS6lvjvuuDapDUA_EKdZlam5Tj-ldjCY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b3c48716308dd5bdb3c27d99136181e017c947c6', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'WaZ-Sn2Y5StDSN-2ULo3ngHFAojr3a2KugBptEoPH_M'}], 'enabled': False}",,,,,,
201,,tensorflow,"The log at the bottom of this post is the output from an EfficientNet model I am trying to train. I am using tensorflow 2.2.0, with tf_nightly installed so I can use EfficientNet with keras. As you can see, it clearly detects the GPU (GeForce RTX 2070 Super) at the start, but at the end it states ""Skipping registering GPU devices"". I'm confused as to whether the GPU is being used or not?

    2021-01-20 13:32:30.312706: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
    2021-01-20 13:32:30.312730: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
    Found 40951 images belonging to 2 classes.
    Found 0 images belonging to 2 classes.
    Found 11700 images belonging to 2 classes.
    2021-01-20 13:32:32.670790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
    2021-01-20 13:32:32.707238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2021-01-20 13:32:32.707673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1760] Found device 0 with properties: 
    pciBusID: 0000:01:00.0 name: GeForce RTX 2070 Super with Max-Q Design computeCapability: 7.5
    coreClock: 1.155GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s
    2021-01-20 13:32:32.707752: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
    2021-01-20 13:32:32.707823: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
    2021-01-20 13:32:32.707880: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
    2021-01-20 13:32:32.708974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
    2021-01-20 13:32:32.709189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
    2021-01-20 13:32:32.710388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
    2021-01-20 13:32:32.710458: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
    2021-01-20 13:32:32.710517: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
    2021-01-20 13:32:32.710529: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1793] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
    Skipping registering GPU devices...
    2021-01-20 13:32:32.710737: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2021-01-20 13:32:32.710997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Device interconnect StreamExecutor with strength 1 edge matrix:
    2021-01-20 13:32:32.711008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306]",t2_toruh,False,,0,False,Is Tensorflow using my GPU or not?,[],r/tensorflow,False,6,,0,,,False,t3_l19fpo,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,1611162751.0,,[],{},,True,,1611179099.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The log at the bottom of this post is the output from an EfficientNet model I am trying to train. I am using tensorflow 2.2.0, with tf_nightly installed so I can use EfficientNet with keras. As you can see, it clearly detects the GPU (GeForce RTX 2070 Super) at the start, but at the end it states &amp;quot;Skipping registering GPU devices&amp;quot;. I&amp;#39;m confused as to whether the GPU is being used or not?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2021-01-20 13:32:30.312706: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;libcudart.so.11.0&amp;#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2021-01-20 13:32:30.312730: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Found 40951 images belonging to 2 classes.
Found 0 images belonging to 2 classes.
Found 11700 images belonging to 2 classes.
2021-01-20 13:32:32.670790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-01-20 13:32:32.707238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 13:32:32.707673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1760] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2070 Super with Max-Q Design computeCapability: 7.5
coreClock: 1.155GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s
2021-01-20 13:32:32.707752: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;libcudart.so.11.0&amp;#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2021-01-20 13:32:32.707823: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;libcublas.so.11&amp;#39;; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2021-01-20 13:32:32.707880: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;libcublasLt.so.11&amp;#39;; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2021-01-20 13:32:32.708974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-20 13:32:32.709189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-20 13:32:32.710388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-20 13:32:32.710458: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;libcusparse.so.11&amp;#39;; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2021-01-20 13:32:32.710517: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;libcudnn.so.8&amp;#39;; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2021-01-20 13:32:32.710529: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1793] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-01-20 13:32:32.710737: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-20 13:32:32.710997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-20 13:32:32.711008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l19fpo,True,,bc_uk,,34,True,all_ads,False,[],False,,/r/tensorflow/comments/l19fpo/is_tensorflow_using_my_gpu_or_not/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l19fpo/is_tensorflow_using_my_gpu_or_not/,22217,1611150299.0,0,,False,,,,,,,,,
202,,tensorflow,"Hello all! I have spent some time working on my chatbot and it's working pretty well. I have a json file that stores all my intents, but I have come across a problem that I don't know how to solve. I want to have an ""other"" tag. This tag should be called whenever the input doesn't match any other patterns or tags. The goal of this is so that if no tags are matched, I have a separate set of instructions for my program to follow in such cases. Does anyone have any idea how I can go about this? Is there a certain pattern I should have or what? Also, another question I have is what if a certain pattern I have has variables in it, for example, ""Play Clocks by Coldplay"". In the case of ""Play {songName} by {artist}"" a constant pattern cannot be used since the user can come up with any combination of song names and artists. Any help is appreciated. Thank you in advance!",t2_895jo,False,,0,False,Need help with intent based personal assistant / chatbot,[],r/tensorflow,False,6,,0,,,False,t3_l0t1gv,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1611118601.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all! I have spent some time working on my chatbot and it&amp;#39;s working pretty well. I have a json file that stores all my intents, but I have come across a problem that I don&amp;#39;t know how to solve. I want to have an &amp;quot;other&amp;quot; tag. This tag should be called whenever the input doesn&amp;#39;t match any other patterns or tags. The goal of this is so that if no tags are matched, I have a separate set of instructions for my program to follow in such cases. Does anyone have any idea how I can go about this? Is there a certain pattern I should have or what? Also, another question I have is what if a certain pattern I have has variables in it, for example, &amp;quot;Play Clocks by Coldplay&amp;quot;. In the case of &amp;quot;Play {songName} by {artist}&amp;quot; a constant pattern cannot be used since the user can come up with any combination of song names and artists. Any help is appreciated. Thank you in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l0t1gv,True,,Rafhay101,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/l0t1gv/need_help_with_intent_based_personal_assistant/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l0t1gv/need_help_with_intent_based_personal_assistant/,22217,1611089801.0,0,,False,,,,,,,,,
203,,tensorflow,I'm looking for a tensorflow implementation of BLEU score similar to the nltk implementation. The reason I can't use nltk is because I need to calculate bleu score per each TPU replica result. I cannot append predictions across replicas and then use nltk to calculate BLEU for the entire corpus as I would prefer. The reason is described in this stackoverflow post [https://stackoverflow.com/questions/60842868/how-can-i-merge-the-results-from-strategy-in-tensorflow-2](https://stackoverflow.com/questions/60842868/how-can-i-merge-the-results-from-strategy-in-tensorflow-2),t2_83w9rbaf,False,,0,False,Tensorflow implementation of Bleu score,[],r/tensorflow,False,6,,0,,,False,t3_l11b9q,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1611144422.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for a tensorflow implementation of BLEU score similar to the nltk implementation. The reason I can&amp;#39;t use nltk is because I need to calculate bleu score per each TPU replica result. I cannot append predictions across replicas and then use nltk to calculate BLEU for the entire corpus as I would prefer. The reason is described in this stackoverflow post &lt;a href=""https://stackoverflow.com/questions/60842868/how-can-i-merge-the-results-from-strategy-in-tensorflow-2""&gt;https://stackoverflow.com/questions/60842868/how-can-i-merge-the-results-from-strategy-in-tensorflow-2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l11b9q,True,,International_Fix_94,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/l11b9q/tensorflow_implementation_of_bleu_score/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l11b9q/tensorflow_implementation_of_bleu_score/,22217,1611115622.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
204,,tensorflow,"I'm using Tensorflow 2.4.0 to build an autoencoder. I've noticed something odd that I'm hoping somebody can help share some light on.

Essentially, the val\_loss (MSE) appears quite static (I'm aware I'm overfitting) but when checking the MSE of the val data set after the training is complete, the value is completely different to what the loss shows mid training for the validation set. Does anyone know why this might be?

code here: https://imgur.com/ulOCe1D",t2_15r2mo,False,,0,False,Val loss appears incorrect,[],r/tensorflow,False,6,,0,,,False,t3_l0rm0i,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1611114574.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using Tensorflow 2.4.0 to build an autoencoder. I&amp;#39;ve noticed something odd that I&amp;#39;m hoping somebody can help share some light on.&lt;/p&gt;

&lt;p&gt;Essentially, the val_loss (MSE) appears quite static (I&amp;#39;m aware I&amp;#39;m overfitting) but when checking the MSE of the val data set after the training is complete, the value is completely different to what the loss shows mid training for the validation set. Does anyone know why this might be?&lt;/p&gt;

&lt;p&gt;code here: &lt;a href=""https://imgur.com/ulOCe1D""&gt;https://imgur.com/ulOCe1D&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l0rm0i,True,,snowdon9,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/l0rm0i/val_loss_appears_incorrect/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/l0rm0i/val_loss_appears_incorrect/,22217,1611085774.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/AavKlNveI2hTPW2XHhqCxk-O-vW-yY5Jet2dHPSXTuw.jpg?auto=webp&amp;s=6d93694d322deaca033c6c645edfc759544a5925', 'width': 600, 'height': 315}, 'resolutions': [{'url': 'https://external-preview.redd.it/AavKlNveI2hTPW2XHhqCxk-O-vW-yY5Jet2dHPSXTuw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8258dd76692d57599173b2b4657469b3709c9c33', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/AavKlNveI2hTPW2XHhqCxk-O-vW-yY5Jet2dHPSXTuw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab328267cbc7b336eab55d1e0c3201c7069cd617', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/AavKlNveI2hTPW2XHhqCxk-O-vW-yY5Jet2dHPSXTuw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1accb53a329ca67c3eb0eebcbe255c022638a86d', 'width': 320, 'height': 168}], 'variants': {}, 'id': 'PGSVtdAurn-2VtTp0sIUcYd-cQ2AZszrw4ciJo5XoRk'}], 'enabled': False}",,,,,,
205,,tensorflow,,t2_f6kbs,False,,0,False,Tensorflow: Confusion on how javascript bundling with rollup affects exports/namespaces/etc.,[],r/tensorflow,False,6,,0,,,False,t3_l0t3sa,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,default,False,,[],{},,False,,1611118791.0,text,6,,,text,self.learnjavascript,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l0t3sa,True,,ApproximateIdentity,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/l0t3sa/tensorflow_confusion_on_how_javascript_bundling/,all_ads,False,/r/learnjavascript/comments/l06cfq/confusion_on_how_javascript_bundling_affects/,22217,1611089991.0,0,,False,,/r/learnjavascript/comments/l06cfq/confusion_on_how_javascript_bundling_affects/,,,,,"[{'approved_at_utc': None, 'subreddit': 'learnjavascript', 'selftext': 'If my post title makes no sense it\'s because of my confusion. I\'ve put together explicit example code to try to explain it better. I start with the following `index.html` file:\n\n    &lt;!DOCTYPE html&gt;\n    &lt;html lang=""en""&gt;\n    &lt;head&gt;\n      &lt;meta charset=""UTF-8""&gt;\n      &lt;title&gt;Blank&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n      &lt;script src=""tf.js""&gt;&lt;/script&gt;\n      &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs""&gt;&lt;/script&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n\nAs you can see it does nothing except load in two separate scripts. One is the official tensorflow javascript release and the other is a file `tf.js` that I bundle myself. I build the file `tf.js` by first starting with a file `index.js` containing the following:\n\n    import * as tf from \'@tensorflow/tfjs\';\n    export default tf\n\nNext I install `rollup` (for me I just use a newly created node virtual environment with only that package installed). After that I create the config file `rollup.config.js`:\n\n    import resolve from \'rollup-plugin-node-resolve\';\n    export default {\n      input: \'index.js\',\n      output: [{\n        file: \'tf.js\',\n        format: \'umd\',\n        name: \'rolleduptf\',\n      }],\n      plugins: [resolve()]\n    }\n\nFinally I create the `tf.js` file by running `rollup -c`.\n\nAfter all of this has been done I open up the index file (by e.g. running `python3 -m http.server` in this folder and going to the page `http://localhost:8000`). Now here\'s the odd part. In the console, I see that `rolleduptf.loadFrozenModel` (coming from my custom bundling) is a defined object whereas `tf.loadFrozenModel` is not. My confusion is why this is the case. I mean I presume that it might have to do with the `resolve()` parameter in the `rollup.config.js` however I also notice that `tf.loadGraphModel` exists while `rolleduptf.loadGraphModel` does not so in that case I have the opposite situation.\n\nDoes anyone here know why this is happening? I\'m pretty new to javascript so I might simply be missing something extremely basic (e.g. I\'m simply accessing the incorrect tensorflow library). Let me know if my question doesn\'t make much sense...\n\nSystem info: This is being run on a Linux Debian 10 box with the default firefox installation (78.6.1esr (64-bit). I used a fresh node environment which gave me npm version 7.4.0 as well as node version 15.6.0.\n\nThanks for any help!\n\nedit: This issue was sorted out. See solution here: https://old.reddit.com/r/tensorflow/comments/l0t3sa/tensorflow_confusion_on_how_javascript_bundling/gk3f5ez/', 'author_fullname': 't2_f6kbs', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Confusion on how javascript bundling affects exports/namespaces/etc.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnjavascript', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_l06cfq', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': 1611258091.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1611040237.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnjavascript', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If my post title makes no sense it&amp;#39;s because of my confusion. I&amp;#39;ve put together explicit example code to try to explain it better. I start with the following &lt;code&gt;index.html&lt;/code&gt; file:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;\n&amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt;\n&amp;lt;head&amp;gt;\n  &amp;lt;meta charset=&amp;quot;UTF-8&amp;quot;&amp;gt;\n  &amp;lt;title&amp;gt;Blank&amp;lt;/title&amp;gt;\n&amp;lt;/head&amp;gt;\n&amp;lt;body&amp;gt;\n  &amp;lt;script src=&amp;quot;tf.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;\n  &amp;lt;script src=&amp;quot;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;\n&amp;lt;/body&amp;gt;\n&amp;lt;/html&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;As you can see it does nothing except load in two separate scripts. One is the official tensorflow javascript release and the other is a file &lt;code&gt;tf.js&lt;/code&gt; that I bundle myself. I build the file &lt;code&gt;tf.js&lt;/code&gt; by first starting with a file &lt;code&gt;index.js&lt;/code&gt; containing the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import * as tf from &amp;#39;@tensorflow/tfjs&amp;#39;;\nexport default tf\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Next I install &lt;code&gt;rollup&lt;/code&gt; (for me I just use a newly created node virtual environment with only that package installed). After that I create the config file &lt;code&gt;rollup.config.js&lt;/code&gt;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import resolve from &amp;#39;rollup-plugin-node-resolve&amp;#39;;\nexport default {\n  input: &amp;#39;index.js&amp;#39;,\n  output: [{\n    file: &amp;#39;tf.js&amp;#39;,\n    format: &amp;#39;umd&amp;#39;,\n    name: &amp;#39;rolleduptf&amp;#39;,\n  }],\n  plugins: [resolve()]\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Finally I create the &lt;code&gt;tf.js&lt;/code&gt; file by running &lt;code&gt;rollup -c&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;After all of this has been done I open up the index file (by e.g. running &lt;code&gt;python3 -m http.server&lt;/code&gt; in this folder and going to the page &lt;code&gt;http://localhost:8000&lt;/code&gt;). Now here&amp;#39;s the odd part. In the console, I see that &lt;code&gt;rolleduptf.loadFrozenModel&lt;/code&gt; (coming from my custom bundling) is a defined object whereas &lt;code&gt;tf.loadFrozenModel&lt;/code&gt; is not. My confusion is why this is the case. I mean I presume that it might have to do with the &lt;code&gt;resolve()&lt;/code&gt; parameter in the &lt;code&gt;rollup.config.js&lt;/code&gt; however I also notice that &lt;code&gt;tf.loadGraphModel&lt;/code&gt; exists while &lt;code&gt;rolleduptf.loadGraphModel&lt;/code&gt; does not so in that case I have the opposite situation.&lt;/p&gt;\n\n&lt;p&gt;Does anyone here know why this is happening? I&amp;#39;m pretty new to javascript so I might simply be missing something extremely basic (e.g. I&amp;#39;m simply accessing the incorrect tensorflow library). Let me know if my question doesn&amp;#39;t make much sense...&lt;/p&gt;\n\n&lt;p&gt;System info: This is being run on a Linux Debian 10 box with the default firefox installation (78.6.1esr (64-bit). I used a fresh node environment which gave me npm version 7.4.0 as well as node version 15.6.0.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n\n&lt;p&gt;edit: This issue was sorted out. See solution here: &lt;a href=""https://old.reddit.com/r/tensorflow/comments/l0t3sa/tensorflow_confusion_on_how_javascript_bundling/gk3f5ez/""&gt;https://old.reddit.com/r/tensorflow/comments/l0t3sa/tensorflow_confusion_on_how_javascript_bundling/gk3f5ez/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2tugi', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'l06cfq', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ApproximateIdentity', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnjavascript/comments/l06cfq/confusion_on_how_javascript_bundling_affects/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnjavascript/comments/l06cfq/confusion_on_how_javascript_bundling_affects/', 'subreddit_subscribers': 155717, 'created_utc': 1611011437.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_l06cfq,
206,,tensorflow,,t2_9j2qngiq,False,,0,False,Need help building a classification model in TensorFlow,[],r/tensorflow,False,6,,0,83.0,,False,t3_l05wcu,False,dark,0.6,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://a.thumbs.redditmedia.com/08H5_pSvt4aaTrzLqgfoMM5hMTahGdpGQDvRWrN8Y94.jpg,False,,[],{},,False,,1611038899.0,text,6,,,text,self.learnmachinelearning,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,l05wcu,True,,Sunkiller_902,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/l05wcu/need_help_building_a_classification_model_in/,all_ads,False,/r/learnmachinelearning/comments/l02qia/need_help_building_a_classification_model_in/,22217,1611010099.0,0,,False,link,/r/learnmachinelearning/comments/l02qia/need_help_building_a_classification_model_in/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Xvj60gTVX8iWDX846SKNk_O03g1j5upTu_-mJl-cdOI.jpg?auto=webp&amp;s=feacb86b811c5b09f5f58a95d0495fe166a0c0e1', 'width': 210, 'height': 125}, 'resolutions': [{'url': 'https://external-preview.redd.it/Xvj60gTVX8iWDX846SKNk_O03g1j5upTu_-mJl-cdOI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=528a658f35629d0f46a862908da745dfa1b19259', 'width': 108, 'height': 64}], 'variants': {}, 'id': 'tSwegkHUJ59ZoUC1g6qDNUJwvsOXztEQ1eZXAEglGAs'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': ""Hello everyone. I need help building a classification model. Basically what I want to do is take a dataset that contains crimes commited in chicago from 2001 to the present and, using the date and the crime type, predict the district in which a crime might occur. This is the dataset [https://catalog.data.gov/dataset/crimes-2001-to-present-398a4](https://catalog.data.gov/dataset/crimes-2001-to-present-398a4). At first I wanted to predict the coordinates, but decided to predict just the district for simplicity's sake (that's why you will see a bunch of columns dropped in my code, in the end I am just using the date and the crime type). Here is the code:\n\n            dataset = self.load_data()\n            dataset = dataset.drop(labels=['case_number','block', 'iucr', 'id','x_coordinate','y_coordinate', 'community_area'], axis=1)\n    \n            #Transform date to integer\n            dataset['date'] = pd.to_datetime(dataset['date'])\n            dataset['date']=dataset['date'].map(dt.datetime.toordinal)\n    \n            dataset = pd.get_dummies(dataset,columns=['primary_type'])\n    \n            dataset = dataset.dropna()\n    \n            train_dataset = dataset.sample(frac=0.66, random_state= 1)\n            test_dataset = dataset.drop(train_dataset.index)\n    \n            #Vfeatures\n            train_features = train_dataset.copy()\n            test_features = test_dataset.copy()\n    \n            #labels\n            train_labels = pd.get_dummies(train_features.pop('district'),columns=['district'])\n            test_labels = pd.get_dummies(test_features.pop('district'),columns=['district'])\n    \n            FEATURES = len(train_features.columns)\n            LABELS = len(train_labels.columns)\n    \n            #Normalizar\n            normalizer = preprocessing.Normalization()\n            normalizer.adapt(np.array(train_features))\n    \n            model = keras.Sequential([\n                normalizer,\n                layers.Dense(FEATURES ,activation='relu', input_shape=(FEATURES,)),\n                layers.Dense(25,activation='relu'),\n                layers.Dense(LABELS, activation='softmax')\n            ])\n    \n            model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                            optimizer=tf.keras.optimizers.Adam())\n            \n            print(model.summary())\n    \n            history = model.fit(\n            train_features, train_labels,\n            steps_per_epoch = 500,\n            validation_split=0.3,\n            verbose=1, epochs=100)\n    \n            test_results = model.evaluate(test_features, test_labels, verbose=0)\n            print(test_results)\n    \n            model.save('models/model')\n    \n            result = model.predict(test_features)\n            print(result)\n\n&amp;#x200B;\n\nHere's the output:\n\n&amp;#x200B;\n\n[The loss always stays around that number, no matter how many layers, neurons, epochs, steps per epochs or datapoints I use](https://preview.redd.it/ikm4yg8tc5c61.png?width=733&amp;format=png&amp;auto=webp&amp;s=942098a2acb7968f8704ae075d2954f1a0fb3f3e)\n\n&amp;#x200B;\n\n[And this is the prediction, it always predict the same value, only changing with different training cycles.](https://preview.redd.it/2j246pibd5c61.png?width=599&amp;format=png&amp;auto=webp&amp;s=a31b58c1c11e1ef2826b4de303a50d3ae28b65ae)\n\n&amp;#x200B;\n\nI want to know what I am doing wrong, what I am not understanding and what can I do to get an usable prediction out of the dataset.\n\n&amp;#x200B;\n\nThanks in advance for everyone who can help me, and if this is not the right place to ask this kind of questions, I would apreciate if you told me where is appropriate.\n\n&amp;#x200B;\n\nEDIT: This is using TensorFlow 2"", 'author_fullname': 't2_9j2qngiq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Need help building a classification model in TensorFlow', 'link_flair_richtext': [{'e': 'text', 't': 'Question'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 83, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'ikm4yg8tc5c61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 48, 'x': 108, 'u': 'https://preview.redd.it/ikm4yg8tc5c61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a3b3eadb528d757f9cfe9e07117e341a96d195e'}, {'y': 97, 'x': 216, 'u': 'https://preview.redd.it/ikm4yg8tc5c61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e8171dceb0f3728c17e58a26f5a32f720ac44a83'}, {'y': 144, 'x': 320, 'u': 'https://preview.redd.it/ikm4yg8tc5c61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3480b0e71dab7149223f3c3f92b63d729c69b80'}, {'y': 289, 'x': 640, 'u': 'https://preview.redd.it/ikm4yg8tc5c61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cda0228e1924144c3da5fe2267f111ead5f967a0'}], 's': {'y': 331, 'x': 733, 'u': 'https://preview.redd.it/ikm4yg8tc5c61.png?width=733&amp;format=png&amp;auto=webp&amp;s=942098a2acb7968f8704ae075d2954f1a0fb3f3e'}, 'id': 'ikm4yg8tc5c61'}, '2j246pibd5c61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 78, 'x': 108, 'u': 'https://preview.redd.it/2j246pibd5c61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a28f9c55c42ac79f919ddd1a64399187417affb4'}, {'y': 156, 'x': 216, 'u': 'https://preview.redd.it/2j246pibd5c61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7af0d616ac2507aa6336718eb144ac29acad84aa'}, {'y': 231, 'x': 320, 'u': 'https://preview.redd.it/2j246pibd5c61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=048f4067c09130b898f405feeee997120305614e'}], 's': {'y': 434, 'x': 599, 'u': 'https://preview.redd.it/2j246pibd5c61.png?width=599&amp;format=png&amp;auto=webp&amp;s=a31b58c1c11e1ef2826b4de303a50d3ae28b65ae'}, 'id': '2j246pibd5c61'}}, 'name': 't3_l02qia', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Question', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/08H5_pSvt4aaTrzLqgfoMM5hMTahGdpGQDvRWrN8Y94.jpg', 'edited': 1611001138.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1611029692.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone. I need help building a classification model. Basically what I want to do is take a dataset that contains crimes commited in chicago from 2001 to the present and, using the date and the crime type, predict the district in which a crime might occur. This is the dataset &lt;a href=""https://catalog.data.gov/dataset/crimes-2001-to-present-398a4""&gt;https://catalog.data.gov/dataset/crimes-2001-to-present-398a4&lt;/a&gt;. At first I wanted to predict the coordinates, but decided to predict just the district for simplicity&amp;#39;s sake (that&amp;#39;s why you will see a bunch of columns dropped in my code, in the end I am just using the date and the crime type). Here is the code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;        dataset = self.load_data()\n        dataset = dataset.drop(labels=[&amp;#39;case_number&amp;#39;,&amp;#39;block&amp;#39;, &amp;#39;iucr&amp;#39;, &amp;#39;id&amp;#39;,&amp;#39;x_coordinate&amp;#39;,&amp;#39;y_coordinate&amp;#39;, &amp;#39;community_area&amp;#39;], axis=1)\n\n        #Transform date to integer\n        dataset[&amp;#39;date&amp;#39;] = pd.to_datetime(dataset[&amp;#39;date&amp;#39;])\n        dataset[&amp;#39;date&amp;#39;]=dataset[&amp;#39;date&amp;#39;].map(dt.datetime.toordinal)\n\n        dataset = pd.get_dummies(dataset,columns=[&amp;#39;primary_type&amp;#39;])\n\n        dataset = dataset.dropna()\n\n        train_dataset = dataset.sample(frac=0.66, random_state= 1)\n        test_dataset = dataset.drop(train_dataset.index)\n\n        #Vfeatures\n        train_features = train_dataset.copy()\n        test_features = test_dataset.copy()\n\n        #labels\n        train_labels = pd.get_dummies(train_features.pop(&amp;#39;district&amp;#39;),columns=[&amp;#39;district&amp;#39;])\n        test_labels = pd.get_dummies(test_features.pop(&amp;#39;district&amp;#39;),columns=[&amp;#39;district&amp;#39;])\n\n        FEATURES = len(train_features.columns)\n        LABELS = len(train_labels.columns)\n\n        #Normalizar\n        normalizer = preprocessing.Normalization()\n        normalizer.adapt(np.array(train_features))\n\n        model = keras.Sequential([\n            normalizer,\n            layers.Dense(FEATURES ,activation=&amp;#39;relu&amp;#39;, input_shape=(FEATURES,)),\n            layers.Dense(25,activation=&amp;#39;relu&amp;#39;),\n            layers.Dense(LABELS, activation=&amp;#39;softmax&amp;#39;)\n        ])\n\n        model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                        optimizer=tf.keras.optimizers.Adam())\n\n        print(model.summary())\n\n        history = model.fit(\n        train_features, train_labels,\n        steps_per_epoch = 500,\n        validation_split=0.3,\n        verbose=1, epochs=100)\n\n        test_results = model.evaluate(test_features, test_labels, verbose=0)\n        print(test_results)\n\n        model.save(&amp;#39;models/model&amp;#39;)\n\n        result = model.predict(test_features)\n        print(result)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the output:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/ikm4yg8tc5c61.png?width=733&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=942098a2acb7968f8704ae075d2954f1a0fb3f3e""&gt;The loss always stays around that number, no matter how many layers, neurons, epochs, steps per epochs or datapoints I use&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/2j246pibd5c61.png?width=599&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a31b58c1c11e1ef2826b4de303a50d3ae28b65ae""&gt;And this is the prediction, it always predict the same value, only changing with different training cycles.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to know what I am doing wrong, what I am not understanding and what can I do to get an usable prediction out of the dataset.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for everyone who can help me, and if this is not the right place to ask this kind of questions, I would apreciate if you told me where is appropriate.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: This is using TensorFlow 2&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/Xvj60gTVX8iWDX846SKNk_O03g1j5upTu_-mJl-cdOI.jpg?auto=webp&amp;s=feacb86b811c5b09f5f58a95d0495fe166a0c0e1', 'width': 210, 'height': 125}, 'resolutions': [{'url': 'https://external-preview.redd.it/Xvj60gTVX8iWDX846SKNk_O03g1j5upTu_-mJl-cdOI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=528a658f35629d0f46a862908da745dfa1b19259', 'width': 108, 'height': 64}], 'variants': {}, 'id': 'tSwegkHUJ59ZoUC1g6qDNUJwvsOXztEQ1eZXAEglGAs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'ec81b8ee-accf-11e9-b8f8-0ebea2df7d78', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ffb000', 'id': 'l02qia', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Sunkiller_902', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/l02qia/need_help_building_a_classification_model_in/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/l02qia/need_help_building_a_classification_model_in/', 'subreddit_subscribers': 217922, 'created_utc': 1611000892.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_l02qia,
207,,tensorflow,"I'm using tensorflow 2.4 and 3070 for fast inference task. Recently I was able to profile inference and notice that a lot of time is spent on host operations. 

[Here is one prediction trace viewer screenshot](http://imgur.com/a/J6JYYHN), as you can see there are two parts before and after prediction. I see memory copy operations and that's not them. The left one has three different tf.function-graph_building (there are different dataset calls, do they really necessary to be called 3 times every inference?), and the right one (hole) has nothing in profiler, but definitely scale up with batch size. I get up to 4 pictures at once and I need to predict them in real time as fast as I can, so this host operations take a lot of processing time because prediction has to be called multiple times. 

I tried to use model(data, training =false) instead of prediction call but got the same time with different profiler trace view.

Is there any way to decrease the time this operations take? My target program uses C API but it has almost same inference time, so I think I have to do something with global default settings but can't understand where to move from this point.",t2_3du8jurt,False,,0,False,Any way to speed up inference prepare operations on host (CPU)?,[],r/tensorflow,False,6,,0,,,False,t3_kzt41g,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1610998968.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using tensorflow 2.4 and 3070 for fast inference task. Recently I was able to profile inference and notice that a lot of time is spent on host operations. &lt;/p&gt;

&lt;p&gt;&lt;a href=""http://imgur.com/a/J6JYYHN""&gt;Here is one prediction trace viewer screenshot&lt;/a&gt;, as you can see there are two parts before and after prediction. I see memory copy operations and that&amp;#39;s not them. The left one has three different tf.function-graph_building (there are different dataset calls, do they really necessary to be called 3 times every inference?), and the right one (hole) has nothing in profiler, but definitely scale up with batch size. I get up to 4 pictures at once and I need to predict them in real time as fast as I can, so this host operations take a lot of processing time because prediction has to be called multiple times. &lt;/p&gt;

&lt;p&gt;I tried to use model(data, training =false) instead of prediction call but got the same time with different profiler trace view.&lt;/p&gt;

&lt;p&gt;Is there any way to decrease the time this operations take? My target program uses C API but it has almost same inference time, so I think I have to do something with global default settings but can&amp;#39;t understand where to move from this point.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kzt41g,True,,gogasius,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kzt41g/any_way_to_speed_up_inference_prepare_operations/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kzt41g/any_way_to_speed_up_inference_prepare_operations/,22217,1610970168.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?auto=webp&amp;s=2b35a89b8a6c379e9d42ca5afc3c948228f1d889', 'width': 1556, 'height': 595}, 'resolutions': [{'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eef9874ee347c4f7260b502d3679e82a9c0a293c', 'width': 108, 'height': 41}, {'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=30b92d9c5384439f45f62a4278cd0b996678a764', 'width': 216, 'height': 82}, {'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1532c2ae51f5705701a51d2be994f8527ba38956', 'width': 320, 'height': 122}, {'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3a96ae23777999b99f540751ce5c8fc4d7482cb5', 'width': 640, 'height': 244}, {'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8122480a0c55e7066d9c21a25087bd3e691cdf63', 'width': 960, 'height': 367}, {'url': 'https://external-preview.redd.it/zi2zSN15LJAQFjbSLbXa7_n_dlKRXWhAwttugPYrb1s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7318e3f20795629c94f52783adf90ac2a686dc83', 'width': 1080, 'height': 412}], 'variants': {}, 'id': 'OMBSMmp621nUzdYhg46_3O8KFp-mSOlYjfO5GR1cL1o'}], 'enabled': False}",,,,,,True
208,,tensorflow,,t2_73xuvz9s,False,,0,False,A WebAssembly Powered Augmented Reality Sudoku Solver,[],r/tensorflow,False,6,,0,103.0,,False,t3_kz4xlp,False,dark,1.0,,public,194,0,{},140.0,,False,[],,True,False,,{},Project,False,194,,False,https://b.thumbs.redditmedia.com/ZHmworg_EFbcIlqeP_TTg3S-yj2TWZFmjoddklJr02M.jpg,False,,[],{},,False,,1610912124.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kz4xlp,True,,SpatialComputing,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kz4xlp/a_webassembly_powered_augmented_reality_sudoku/,all_ads,False,https://i.redd.it/t58n48vs5pb61.gif,22217,1610883324.0,0,,False,image,https://i.redd.it/t58n48vs5pb61.gif,"{'images': [{'source': {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?format=png8&amp;s=b25c49020bc5484f1db3eca6b85e3a08cd0601fe', 'width': 400, 'height': 295}, 'resolutions': [{'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=3d1fb976304c72fc68a2324b0ccc098c654f515d', 'width': 108, 'height': 79}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=93f93cc41c5d2699aaf5a97da1fa03a07d22a4f7', 'width': 216, 'height': 159}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=465032554b4280353e09634c929b6dcbf03ce495', 'width': 320, 'height': 236}], 'variants': {'gif': {'source': {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?s=9428864d9eeb546a07eafce5ff066db7dd21adc5', 'width': 400, 'height': 295}, 'resolutions': [{'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=108&amp;crop=smart&amp;s=66cd66ec78f37a42a1da631ef92e1b4314dae9ca', 'width': 108, 'height': 79}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=216&amp;crop=smart&amp;s=251bbc38e286ce1aec90fa2cdd8a4d6a2a3053a1', 'width': 216, 'height': 159}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=320&amp;crop=smart&amp;s=1ceeba6bd1e4431f205eacea8f30fc5ebb3745e2', 'width': 320, 'height': 236}]}, 'mp4': {'source': {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?format=mp4&amp;s=7218ecdd837fb992d28e691b2c9ea794d2aeae0b', 'width': 400, 'height': 295}, 'resolutions': [{'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=108&amp;format=mp4&amp;s=3190648d439456dddc6910004b7947e2090d412f', 'width': 108, 'height': 79}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=216&amp;format=mp4&amp;s=e65bc25b93f97c87a92246cb0e68c8421021f2e9', 'width': 216, 'height': 159}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=320&amp;format=mp4&amp;s=bda6f99c052d8b1d503972e0f454d1c798072fb0', 'width': 320, 'height': 236}]}}, 'id': '0_TWGzK-BOD_lIaUWJIkEHgXBap6Bfj3yw193rUH8_8'}], 'enabled': True}",,,,"[{'approved_at_utc': None, 'subreddit': 'AR_MR_XR', 'selftext': '', 'author_fullname': 't2_2vsjwr3g', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'A WebAssembly Powered Augmented Reality Sudoku Solver', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/AR_MR_XR', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 103, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_kyj051', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'restricted', 'ups': 208, 'total_awards_received': 2, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Software', 'can_mod_post': False, 'score': 208, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/ZHmworg_EFbcIlqeP_TTg3S-yj2TWZFmjoddklJr02M.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 1}, 'post_hint': 'image', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1610832825.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': True, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/t58n48vs5pb61.gif', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?format=png8&amp;s=b25c49020bc5484f1db3eca6b85e3a08cd0601fe', 'width': 400, 'height': 295}, 'resolutions': [{'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=3d1fb976304c72fc68a2324b0ccc098c654f515d', 'width': 108, 'height': 79}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=93f93cc41c5d2699aaf5a97da1fa03a07d22a4f7', 'width': 216, 'height': 159}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=465032554b4280353e09634c929b6dcbf03ce495', 'width': 320, 'height': 236}], 'variants': {'gif': {'source': {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?s=9428864d9eeb546a07eafce5ff066db7dd21adc5', 'width': 400, 'height': 295}, 'resolutions': [{'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=108&amp;crop=smart&amp;s=66cd66ec78f37a42a1da631ef92e1b4314dae9ca', 'width': 108, 'height': 79}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=216&amp;crop=smart&amp;s=251bbc38e286ce1aec90fa2cdd8a4d6a2a3053a1', 'width': 216, 'height': 159}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=320&amp;crop=smart&amp;s=1ceeba6bd1e4431f205eacea8f30fc5ebb3745e2', 'width': 320, 'height': 236}]}, 'mp4': {'source': {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?format=mp4&amp;s=7218ecdd837fb992d28e691b2c9ea794d2aeae0b', 'width': 400, 'height': 295}, 'resolutions': [{'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=108&amp;format=mp4&amp;s=3190648d439456dddc6910004b7947e2090d412f', 'width': 108, 'height': 79}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=216&amp;format=mp4&amp;s=e65bc25b93f97c87a92246cb0e68c8421021f2e9', 'width': 216, 'height': 159}, {'url': 'https://preview.redd.it/t58n48vs5pb61.gif?width=320&amp;format=mp4&amp;s=bda6f99c052d8b1d503972e0f454d1c798072fb0', 'width': 320, 'height': 236}]}}, 'id': '0_TWGzK-BOD_lIaUWJIkEHgXBap6Bfj3yw193rUH8_8'}], 'enabled': True}, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'c05d4abe-0700-11e9-bf42-0e081c054816', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_t9z3q', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#e8e8e8', 'id': 'kyj051', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AR_MR_XR', 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/AR_MR_XR/comments/kyj051/a_webassembly_powered_augmented_reality_sudoku/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://i.redd.it/t58n48vs5pb61.gif', 'subreddit_subscribers': 6064, 'created_utc': 1610804025.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_kyj051,
209,,tensorflow,,t2_jj0fjpa,False,,0,False,"I used TensorFlow's text generation tutorial, to create an ML-powered Trump twitter bot!",[],r/tensorflow,False,6,,0,105.0,,False,t3_kzh4jq,False,dark,0.75,,public,6,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UZvW7uD0g44?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'A.I. Learns to Write Trump Tweets', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UZvW7uD0g44?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Jarrod Watts', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/UZvW7uD0g44/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCJae_agpt9S3qwWNED0KHcQ'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UZvW7uD0g44?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kzh4jq', 'height': 200}",Project,False,6,,False,https://b.thumbs.redditmedia.com/Zh58LuTIfPF4293FcYQKKV0SNgCvBbkewzhYh6bauSc.jpg,False,,[],{},,False,,1610952836.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kzh4jq,True,,cumcopter,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kzh4jq/i_used_tensorflows_text_generation_tutorial_to/,all_ads,False,https://youtu.be/UZvW7uD0g44,22217,1610924036.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'A.I. Learns to Write Trump Tweets', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UZvW7uD0g44?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Jarrod Watts', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/UZvW7uD0g44/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCJae_agpt9S3qwWNED0KHcQ'}}",False,rich:video,https://youtu.be/UZvW7uD0g44,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IsoY0bIBvjpCDgHtfvIM4WHN_RDpKCxmQGgvlK7KN1Y.jpg?auto=webp&amp;s=cf342f0b1e0d3c798fcf78b77b08e8f886462d58', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/IsoY0bIBvjpCDgHtfvIM4WHN_RDpKCxmQGgvlK7KN1Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8403a07caba0a1f4b1cf7336a4f1c1d9fdab10d', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/IsoY0bIBvjpCDgHtfvIM4WHN_RDpKCxmQGgvlK7KN1Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=958a3e6d0eb4221fddc29a8b487261ed52a9e60f', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/IsoY0bIBvjpCDgHtfvIM4WHN_RDpKCxmQGgvlK7KN1Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b11d2d2866b5ebda9311267d6d445ac8149674e4', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'ASTn6CHDE9h9L8NaAn93eWqRTkIHI6zbzWk9OaE17wE'}], 'enabled': False}",,,,,,
210,,tensorflow,"What would be a tensorflow friendly way to split an input tensor by row (dim 0) according to column values (dim 1). \*with a built graph, not eager execution\*

    ie, split this tensor such that the resulting tensors all have the same value in the 1st column:
    
    [ 1 , 3, 7
      1 , 5, 2
      2 , 4, 6]
    
    split to 
    
    [ 1 , 3, 7
      1 , 5, 2]
    
    and 

\[2  ,  4,  6\]",t2_c1gng65,False,,0,False,How to tf.split() tensor according to column values?,[],r/tensorflow,False,6,,0,,,False,t3_kzmwl7,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1610972208.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What would be a tensorflow friendly way to split an input tensor by row (dim 0) according to column values (dim 1). *with a built graph, not eager execution*&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ie, split this tensor such that the resulting tensors all have the same value in the 1st column:

[ 1 , 3, 7
  1 , 5, 2
  2 , 4, 6]

split to 

[ 1 , 3, 7
  1 , 5, 2]

and 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[2  ,  4,  6]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kzmwl7,True,,joltunit,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kzmwl7/how_to_tfsplit_tensor_according_to_column_values/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kzmwl7/how_to_tfsplit_tensor_according_to_column_values/,22217,1610943408.0,0,,False,,,,,,,,,
211,,tensorflow,"Hi All, I am new to tensorflow and I'm trying it out on my rtx3070 fe. i have installed   
\-latest gpu drivers  
\-CUDA 11  
\-CUDNN 8.0.4 (in C://tools/cuda)  
\-Python 3.8.7  


I have set all the environment variables correctly.  


When I run -  

    device_lib.list_local_devices()
    

I get-

    [name: ""/device:CPU:0""
    device_type: ""CPU""
    memory_limit: 268435456
    locality {
    }
    incarnation: 3560111549067631038
    , name: ""/device:GPU:0""
    device_type: ""GPU""
    memory_limit: 6686530832
    locality {
      bus_id: 1
      links {
      }
    }
    incarnation: 12476054709360192724
    physical_device_desc: ""device: 0, name: GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6""
    ]
    

Hence, I am assuming that my installations are correct. As a trial example, I treid the image classifier example on tensorflow website. And it ran successfully (task manager showed around 7% GPU usage  while training)  


ISSUE -   


I am building a text classifier (sentiment analysis) - ran the sample code from tensorflow website - while training ([model.fit](https://model.fit)()), it ran 2 epochs then failed with an error ( RecvAsync is cancelled ). And it never ran after that ever again. Its failing with this error-   
 

&amp;#x200B;

     CancelledError:  [_Derived_]RecvAsync is cancelled. 	 [[{{node Adam/Adam/update/AssignSubVariableOp/_57}}]] 	 [[gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape/_54]] [Op:__inference_train_function_34190] 
 

I also sometimes  get the error - couldn't find the implementation for cudnnrnnv3 

Can somebody please help me out over here?  
I tried googling, I only saw people suggesting installing the correct version of cuda drivers. No other solution.   
If it were an issue with the CUDA driver version, it should not have run in the first time. Also, the image classifier example should not have run.  
Thank you!",t2_1s1kbo84,False,,0,False,Intermittent RecvAsync is cancelled error - Keras Text classifier,[],r/tensorflow,False,6,,0,,,False,t3_kzpbt0,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610981439.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All, I am new to tensorflow and I&amp;#39;m trying it out on my rtx3070 fe. i have installed&lt;br/&gt;
-latest gpu drivers&lt;br/&gt;
-CUDA 11&lt;br/&gt;
-CUDNN 8.0.4 (in C://tools/cuda)&lt;br/&gt;
-Python 3.8.7  &lt;/p&gt;

&lt;p&gt;I have set all the environment variables correctly.  &lt;/p&gt;

&lt;p&gt;When I run -  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;device_lib.list_local_devices()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I get-&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[name: &amp;quot;/device:CPU:0&amp;quot;
device_type: &amp;quot;CPU&amp;quot;
memory_limit: 268435456
locality {
}
incarnation: 3560111549067631038
, name: &amp;quot;/device:GPU:0&amp;quot;
device_type: &amp;quot;GPU&amp;quot;
memory_limit: 6686530832
locality {
  bus_id: 1
  links {
  }
}
incarnation: 12476054709360192724
physical_device_desc: &amp;quot;device: 0, name: GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6&amp;quot;
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hence, I am assuming that my installations are correct. As a trial example, I treid the image classifier example on tensorflow website. And it ran successfully (task manager showed around 7% GPU usage  while training)  &lt;/p&gt;

&lt;p&gt;ISSUE -   &lt;/p&gt;

&lt;p&gt;I am building a text classifier (sentiment analysis) - ran the sample code from tensorflow website - while training (&lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;()), it ran 2 epochs then failed with an error ( RecvAsync is cancelled ). And it never ran after that ever again. Its failing with this error-   &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; CancelledError:  [_Derived_]RecvAsync is cancelled.     [[{{node Adam/Adam/update/AssignSubVariableOp/_57}}]]   [[gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape/_54]] [Op:__inference_train_function_34190] 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also sometimes  get the error - couldn&amp;#39;t find the implementation for cudnnrnnv3 &lt;/p&gt;

&lt;p&gt;Can somebody please help me out over here?&lt;br/&gt;
I tried googling, I only saw people suggesting installing the correct version of cuda drivers. No other solution.&lt;br/&gt;
If it were an issue with the CUDA driver version, it should not have run in the first time. Also, the image classifier example should not have run.&lt;br/&gt;
Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kzpbt0,True,,chiranshu14,,16,True,all_ads,False,[],False,,/r/tensorflow/comments/kzpbt0/intermittent_recvasync_is_cancelled_error_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kzpbt0/intermittent_recvasync_is_cancelled_error_keras/,22217,1610952639.0,0,,False,,,,,,,,,
212,,tensorflow,,t2_9qs8o917,False,,0,False,YouTube Comments Sentiment Analysis Chrome Extension with TFJS,[],r/tensorflow,False,6,,0,140.0,,False,t3_kzo8da,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Project,False,1,,False,https://b.thumbs.redditmedia.com/8Da7ei7EfOjWr0rMycoO0eoghCYoCNFQqYbhfqzGehs.jpg,False,,[],{},,False,,1610977062.0,text,6,,,text,github.com,False,,,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kzo8da,True,,codercj,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kzo8da/youtube_comments_sentiment_analysis_chrome/,all_ads,False,https://github.com/charlie-jones/YouTube-Comments-Analyzer,22217,1610948262.0,0,,False,link,https://github.com/charlie-jones/YouTube-Comments-Analyzer,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yN7fnJAI7RVwtX72n3gDo4KdU5AfrxrFXbODua7xWcc.jpg?auto=webp&amp;s=ed63bef3b4703108125581aa7a4e9b3dd5639ade', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/yN7fnJAI7RVwtX72n3gDo4KdU5AfrxrFXbODua7xWcc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d687b1f512ed29d0c361f8a39e45caff61010672', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/yN7fnJAI7RVwtX72n3gDo4KdU5AfrxrFXbODua7xWcc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4dce887aea15d0550198ec4d29d3e94f79e105ac', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/yN7fnJAI7RVwtX72n3gDo4KdU5AfrxrFXbODua7xWcc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66cd8e0b4bc909702ff13aaccdc17f717206ab30', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'NlGsmNBbSLOUVODYGdrK2FWZstBjJXErGju9T8tgwkc'}], 'enabled': False}",,,,,,
213,,tensorflow,"According to Ai benchmarks my 2080 should be 3x faster than my Quadro but when training the exact same models with the same settings my Quadro is 3x faster???
Does anyone have a solution or explanation for this?",t2_2fosmx29,False,,0,False,Why is my RTX 2080 3x slower than my Quadro P4000?,[],r/tensorflow,False,6,,0,,,False,t3_kzffnh,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1610947671.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;According to Ai benchmarks my 2080 should be 3x faster than my Quadro but when training the exact same models with the same settings my Quadro is 3x faster???
Does anyone have a solution or explanation for this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kzffnh,True,,danang1986,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kzffnh/why_is_my_rtx_2080_3x_slower_than_my_quadro_p4000/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kzffnh/why_is_my_rtx_2080_3x_slower_than_my_quadro_p4000/,22217,1610918871.0,0,,False,,,,,,,,,
214,,tensorflow,"Hey guys,

I have been looking everywhere for this issue: I followed a google tutorial for image classification to get  model that I converted to tf.js format. I used node at the front end to upload images to see which class it belong; the issues is that I am getting 100% accuracy at inference on any images (sometimes, even incorrect images get 100%. What could be the cause here? here are some code:

Model with softmax:

`model = Sequential([`  
  `layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 120, 3)),`  
  `layers.MaxPooling2D((2, 2)),`  
  `layers.Conv2D(64, (3, 3), activation='relu'),`  
  `layers.MaxPooling2D((2, 2)),`  
  `layers.Conv2D(128, (3, 3), activation='relu'),`  
  `layers.MaxPooling2D((2, 2)),`  
  `layers.Conv2D(128, (3, 3), activation='relu'),`  
  `layers.Dropout(0.2),`  
  `layers.Flatten(),`  
  `layers.Dense(512, activation='relu'),`  
  `layers.Dense(num_classes, activation='softmax')`  
`])`

On the JavaScript file, server side, I have this:

`$(""#predict-button"").click(async function() {`  
 `let image = $('#selected-image').get(0);`  
 `let tensor = tf.browser.fromPixels(image)`  
 `//.div( 255 ).sub( 1 )`  
`.resizeNearestNeighbor([120,120])`  
`.reshape([120, 120, 3])`  
`.toFloat()`  
`.expandDims()`  
`;`

`let predictions = await model.predict(tensor).data();`  
 `let top5 = Array.from(predictions)`  
`.map(function (p, i) {`  
 `return {`  
 `probability: p,`  
 `className: IMAGENET_CLASSES[i]`  
`};`  
`}).sort(function (a, b) {`  
 `return b.probability - a.probability;`  
`}).slice(0, 5);`  
 `$(""#prediction-list"").empty();`  
 `top5.forEach(function (p) {`  
 `$('#prediction-list').append(\`&lt;li&gt;${p.className}: ${p.probability.toFixed(4)}&lt;/li&gt;\`);`  
`});`

&amp;#x200B;

And the result of a test:

1. SujeDendi-Niger\_RP\_SO: 1.0000
2. Dadjo\_LP\_SO: 0.0000
3. PeulGurmance\_LP\_SO: 0.0000
4. PeulGurmance\_P\_SO: 0.0000
5. PeulGurmance\_RP\_SO: 0.0000

What I am doing wrong guys?",t2_tdhq6,False,,0,False,Softmax prediction Always 100%,[],r/tensorflow,False,6,,0,,,False,t3_kzfbrr,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1610947343.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys,&lt;/p&gt;

&lt;p&gt;I have been looking everywhere for this issue: I followed a google tutorial for image classification to get  model that I converted to tf.js format. I used node at the front end to upload images to see which class it belong; the issues is that I am getting 100% accuracy at inference on any images (sometimes, even incorrect images get 100%. What could be the cause here? here are some code:&lt;/p&gt;

&lt;p&gt;Model with softmax:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model = Sequential([&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Conv2D(32, (3, 3), activation=&amp;#39;relu&amp;#39;, input_shape=(120, 120, 3)),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.MaxPooling2D((2, 2)),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Conv2D(64, (3, 3), activation=&amp;#39;relu&amp;#39;),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.MaxPooling2D((2, 2)),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Conv2D(128, (3, 3), activation=&amp;#39;relu&amp;#39;),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.MaxPooling2D((2, 2)),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Conv2D(128, (3, 3), activation=&amp;#39;relu&amp;#39;),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Dropout(0.2),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Flatten(),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Dense(512, activation=&amp;#39;relu&amp;#39;),&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;layers.Dense(num_classes, activation=&amp;#39;softmax&amp;#39;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;On the JavaScript file, server side, I have this:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$(&amp;quot;#predict-button&amp;quot;).click(async function() {&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;let image = $(&amp;#39;#selected-image&amp;#39;).get(0);&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;let tensor = tf.browser.fromPixels(image)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;//.div( 255 ).sub( 1 )&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.resizeNearestNeighbor([120,120])&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.reshape([120, 120, 3])&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.toFloat()&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.expandDims()&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;let predictions = await model.predict(tensor).data();&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;let top5 = Array.from(predictions)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.map(function (p, i) {&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return {&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;probability: p,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;className: IMAGENET_CLASSES[i]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;};&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;}).sort(function (a, b) {&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return b.probability - a.probability;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;}).slice(0, 5);&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;$(&amp;quot;#prediction-list&amp;quot;).empty();&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;top5.forEach(function (p) {&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;$(&amp;#39;#prediction-list&amp;#39;).append(\&lt;/code&gt;&amp;lt;li&amp;gt;${p.className}: ${p.probability.toFixed(4)}&amp;lt;/li&amp;gt;`);&lt;code&gt;
&lt;/code&gt;});`&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;And the result of a test:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;SujeDendi-Niger_RP_SO: 1.0000&lt;/li&gt;
&lt;li&gt;Dadjo_LP_SO: 0.0000&lt;/li&gt;
&lt;li&gt;PeulGurmance_LP_SO: 0.0000&lt;/li&gt;
&lt;li&gt;PeulGurmance_P_SO: 0.0000&lt;/li&gt;
&lt;li&gt;PeulGurmance_RP_SO: 0.0000&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;What I am doing wrong guys?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kzfbrr,True,,wymco,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kzfbrr/softmax_prediction_always_100/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kzfbrr/softmax_prediction_always_100/,22217,1610918543.0,0,,False,,,,,,,,,
215,,tensorflow,"I am trying to implement a very basic recursive neural network into my linear regression analysis project in Tensorflow that takes two inputs passed to it and then a third value of what it previously calculated. So, my project is trying to calculate something across the next *x* number of years, and after the first year I want it to keep taking the value of the last year. Currently, my training data has two inputs, not three, predicting one output, so how could I make it recursive, so it keeps on passing in the value from the last year, to calculate the next? To explain slightly further, if it were to calculate across the next 5 years:

1st year:

Input 1: 10

Input 2: 20

(Maybe need input 3, but a value that has no affect on the linear regression model)

Output: 30

2nd year:

Input 1: 11

Input 2: 22

Input 3: 30 (1st year output)

Output: 35

3rd Year:

Input 1:12

Input 2: 24

Input 3: 35 (2nd year output)

Output: 40",t2_5bhqr9nu,False,,0,False,How to implement recursive neural networks in Tensorflow?,[],r/tensorflow,False,6,,0,,,False,t3_kz91kf,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610928357.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to implement a very basic recursive neural network into my linear regression analysis project in Tensorflow that takes two inputs passed to it and then a third value of what it previously calculated. So, my project is trying to calculate something across the next &lt;em&gt;x&lt;/em&gt; number of years, and after the first year I want it to keep taking the value of the last year. Currently, my training data has two inputs, not three, predicting one output, so how could I make it recursive, so it keeps on passing in the value from the last year, to calculate the next? To explain slightly further, if it were to calculate across the next 5 years:&lt;/p&gt;

&lt;p&gt;1st year:&lt;/p&gt;

&lt;p&gt;Input 1: 10&lt;/p&gt;

&lt;p&gt;Input 2: 20&lt;/p&gt;

&lt;p&gt;(Maybe need input 3, but a value that has no affect on the linear regression model)&lt;/p&gt;

&lt;p&gt;Output: 30&lt;/p&gt;

&lt;p&gt;2nd year:&lt;/p&gt;

&lt;p&gt;Input 1: 11&lt;/p&gt;

&lt;p&gt;Input 2: 22&lt;/p&gt;

&lt;p&gt;Input 3: 30 (1st year output)&lt;/p&gt;

&lt;p&gt;Output: 35&lt;/p&gt;

&lt;p&gt;3rd Year:&lt;/p&gt;

&lt;p&gt;Input 1:12&lt;/p&gt;

&lt;p&gt;Input 2: 24&lt;/p&gt;

&lt;p&gt;Input 3: 35 (2nd year output)&lt;/p&gt;

&lt;p&gt;Output: 40&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kz91kf,True,,HexadecimalHero,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kz91kf/how_to_implement_recursive_neural_networks_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kz91kf/how_to_implement_recursive_neural_networks_in/,22217,1610899557.0,0,,False,,,,,,,,,
216,,tensorflow,"I need to train several hundred individual models. Right now I'm training models on a single GPU, does anyone know if it's possible to run multiple studio codes/CMDs to train, multiple models, simultaneously on multiple GPUs? 

Thanks, just wanted to be sure it's possible before plunking down the money.",t2_2fosmx29,False,,0,False,Multi GPU PC Build Advice,[],r/tensorflow,False,6,,0,,,False,t3_kz1ahx,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1610894190.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need to train several hundred individual models. Right now I&amp;#39;m training models on a single GPU, does anyone know if it&amp;#39;s possible to run multiple studio codes/CMDs to train, multiple models, simultaneously on multiple GPUs? &lt;/p&gt;

&lt;p&gt;Thanks, just wanted to be sure it&amp;#39;s possible before plunking down the money.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kz1ahx,True,,danang1986,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kz1ahx/multi_gpu_pc_build_advice/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kz1ahx/multi_gpu_pc_build_advice/,22217,1610865390.0,0,,False,,,,,,,,,
217,,tensorflow,"I have tried to download tensorflow through pip install tensorflow but only get ERROR: Could not find a version that satisfies the required tensorflow and ERROR: No matching distribution found for tensorflow. I have updated pip to 20.3.3 and I have python 3.9.1. I’m running it in pycharm, cmd, and visual studio. How can I fix this?",t2_5xm9blrm,False,,0,False,I have a problem downloading tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_kyr78c,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1610859273.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have tried to download tensorflow through pip install tensorflow but only get ERROR: Could not find a version that satisfies the required tensorflow and ERROR: No matching distribution found for tensorflow. I have updated pip to 20.3.3 and I have python 3.9.1. I’m running it in pycharm, cmd, and visual studio. How can I fix this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kyr78c,True,,Creeperhaten1,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kyr78c/i_have_a_problem_downloading_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kyr78c/i_have_a_problem_downloading_tensorflow/,22217,1610830473.0,0,,False,,,,,,,,,
218,,tensorflow,,t2_lxi49m,False,,1,False,I made a website that animates real time facial expressions onto characters with TFJS,[],r/tensorflow,False,6,,0,140.0,,False,t3_ky3mp8,False,dark,0.98,,public,128,1,{},140.0,,False,[],"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/nympy7cc5kb61/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/nympy7cc5kb61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/nympy7cc5kb61/DASHPlaylist.mpd?a=1618044694%2CMDg2OGVlNTg1MzMwOTcxYjQ0ZjgwY2VmMWFjY2U2ZGNjMThlOTU4NWNjZGNlOTYxZDI1M2RlNTJmZjcwZWQwZA%3D%3D&amp;v=1&amp;f=sd', 'duration': 28, 'hls_url': 'https://v.redd.it/nympy7cc5kb61/HLSPlaylist.m3u8?a=1618044694%2CMTEzZmRjMGY1NzQ3M2NmOTNkM2UwZmNiYzI2NjAzOTM5ZmU2YTg2MjkyNmMxYTI1NDVjNzBmNjE4NTRjZDMzMw%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},Project,False,128,,False,https://b.thumbs.redditmedia.com/whKtFFMqaRUzyTeqMjo7aJLDD-luYzPisq8u0_1gmXs.jpg,False,,[],{'gid_2': 1},,False,,1610772917.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 500, 'id': 'gid_2', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 100, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/gold_512.png', 'days_of_premium': 7, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/gold_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Gold', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/gold_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/gold_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/gold_512.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,ky3mp8,True,,YeeMachineDev,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/ky3mp8/i_made_a_website_that_animates_real_time_facial/,all_ads,False,https://v.redd.it/nympy7cc5kb61,22217,1610744117.0,0,"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/nympy7cc5kb61/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/nympy7cc5kb61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/nympy7cc5kb61/DASHPlaylist.mpd?a=1618044694%2CMDg2OGVlNTg1MzMwOTcxYjQ0ZjgwY2VmMWFjY2U2ZGNjMThlOTU4NWNjZGNlOTYxZDI1M2RlNTJmZjcwZWQwZA%3D%3D&amp;v=1&amp;f=sd', 'duration': 28, 'hls_url': 'https://v.redd.it/nympy7cc5kb61/HLSPlaylist.m3u8?a=1618044694%2CMTEzZmRjMGY1NzQ3M2NmOTNkM2UwZmNiYzI2NjAzOTM5ZmU2YTg2MjkyNmMxYTI1NDVjNzBmNjE4NTRjZDMzMw%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/nympy7cc5kb61,"{'images': [{'source': {'url': 'https://external-preview.redd.it/shB3CgCzlEWNo6f3MEKp9FZVvw8gkb7eajbiagQWw7M.png?format=pjpg&amp;auto=webp&amp;s=998c0861229b8c7b3cd7f5e64d7158e7e0ddf06d', 'width': 640, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/shB3CgCzlEWNo6f3MEKp9FZVvw8gkb7eajbiagQWw7M.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=276ae7d23e307849b54740e34d8e711a1f36761d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/shB3CgCzlEWNo6f3MEKp9FZVvw8gkb7eajbiagQWw7M.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=eaf5f1f347b2bad1baf63e6f0e576287d39150fe', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/shB3CgCzlEWNo6f3MEKp9FZVvw8gkb7eajbiagQWw7M.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=507ba0269db1851ff822a42e1875bdbe6ba4c8a7', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/shB3CgCzlEWNo6f3MEKp9FZVvw8gkb7eajbiagQWw7M.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=14d88bb44468b6e85e35914b286bbe2f095f5528', 'width': 640, 'height': 640}], 'variants': {}, 'id': 'VikXdPCmHm3YdafW263HC-x2brt1DX1w25QFJRWKv5Q'}], 'enabled': False}",,,,,,
219,,tensorflow,"I'm trying to create my own model to classify a face as either wearing a mask or not, and by what ratio. [This is my Colab notebook](https://gist.github.com/lgariv/284d811d184db3ced09ce571ea9716d4), with predictions output at the end.



The question is:

How do I make the model predict with confidence, for example: `[0.966 0.034]`?



Note:
I didn't use `binary_crossentropy` with one neuron dense layer on purpose for this model, as I am planning on adding a 3rd class (mask worn incorrectley) as soon as I have a better dataset.",t2_sv8epzg,False,,0,False,"Keras model predicts correctly, but always at 100% confidence",[],r/tensorflow,False,6,,0,,,False,t3_kygnim,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,True,self,1610793473.0,,[],{},,True,,1610821813.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to create my own model to classify a face as either wearing a mask or not, and by what ratio. &lt;a href=""https://gist.github.com/lgariv/284d811d184db3ced09ce571ea9716d4""&gt;This is my Colab notebook&lt;/a&gt;, with predictions output at the end.&lt;/p&gt;

&lt;p&gt;The question is:&lt;/p&gt;

&lt;p&gt;How do I make the model predict with confidence, for example: &lt;code&gt;[0.966 0.034]&lt;/code&gt;?&lt;/p&gt;

&lt;p&gt;Note:
I didn&amp;#39;t use &lt;code&gt;binary_crossentropy&lt;/code&gt; with one neuron dense layer on purpose for this model, as I am planning on adding a 3rd class (mask worn incorrectley) as soon as I have a better dataset.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kygnim,True,,LGariv,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/kygnim/keras_model_predicts_correctly_but_always_at_100/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kygnim/keras_model_predicts_correctly_but_always_at_100/,22217,1610793013.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?auto=webp&amp;s=079a7260ec149880c73263d64811698adb22760a', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d5811c5bda5fece1040636a6af8702ba790f0fd4', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eee576fd4da7535eb53ceb88dd8b52f073048441', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=72872d880460efa723918c000adca0ed259cf775', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3545b9335d763c9da9c16bf7bf9a3f907dbd6f6', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d241ace0f1c07088fac3f8469dbad3b05d2d419', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9055f11bdc00beb0b3589e1cae5817d6070d83bc', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'OAXSl8SY6T3JK9MGQyKxkoYbqZ71HQRYXLeB8CV0NXg'}], 'enabled': False}",,,,,,
220,,tensorflow,"Hi guys, I have 2 separate models. First one is a normal dense neural network where the inputs are 8 features vectors. Second model is a univariate lstm model (sliding window size 4), input is time series data. Both models are predicting the same target. Is there a way I can combine both of the models into a single model? Will it make sense mathematically?",t2_2lkqhkad,False,,0,False,Combining 2 models with different inputs,[],r/tensorflow,False,6,,0,,,False,t3_kyd2mb,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1610804594.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I have 2 separate models. First one is a normal dense neural network where the inputs are 8 features vectors. Second model is a univariate lstm model (sliding window size 4), input is time series data. Both models are predicting the same target. Is there a way I can combine both of the models into a single model? Will it make sense mathematically?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kyd2mb,True,,dogcat0035,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kyd2mb/combining_2_models_with_different_inputs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kyd2mb/combining_2_models_with_different_inputs/,22217,1610775794.0,0,,False,,,,,,,,,
221,,tensorflow,Recently I was browsing through TFHub and found that only 1 pretrained model was present for Masked_R_CNN which was using a Resnet as the base feature extractor. What should be my steps if I want to use Masked_R_CNN with VGG or some other as the base feature extractor? Is there a way I can get pretrained models for transfer learning with such specifications?,t2_am2n61g,False,,0,False,How can I use models not present in tfhub?,[],r/tensorflow,False,6,,0,,,False,t3_kyesl0,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610812305.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Recently I was browsing through TFHub and found that only 1 pretrained model was present for Masked_R_CNN which was using a Resnet as the base feature extractor. What should be my steps if I want to use Masked_R_CNN with VGG or some other as the base feature extractor? Is there a way I can get pretrained models for transfer learning with such specifications?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kyesl0,True,,sbjr47,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kyesl0/how_can_i_use_models_not_present_in_tfhub/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kyesl0/how_can_i_use_models_not_present_in_tfhub/,22217,1610783505.0,0,,False,,,,,,,,,
222,,tensorflow,"I'm trying to make a DCGAN with Keras, but I'm running into an error when I try to train a combined model: 

&amp;#x200B;

     Traceback (most recent call last):
      File ""D:\Projects\DCGAN\train.py"", line 95, in &lt;module&gt;
        gan.fit(x = noise, y = misleading_labels, batch_size=BATCH_SIZE)
      File ""C:\Python\lib\site-packages\keras\engine\training.py"", line 1239, in fit
        validation_freq=validation_freq)
      File ""C:\Python\lib\site-packages\keras\engine\training_arrays.py"", line 175, in fit_loop
        np.random.shuffle(index_array)
    UnboundLocalError: local variable 'index_array' referenced before assignment 

&amp;#x200B;

My code: 

&amp;#x200B;

    def get_data(path):
        files = os.listdir(path)
        dat = []
        for j,file in enumerate(files):
            image = cv2.imread(path + '/' + file)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = image / 255
            #print(image[:10, :10])
            image = image.reshape(tuple([1] + list(image.shape)))
            
            dat.append(image)
    
        return np.concatenate(tuple(dat))
    
    def produce_samples(examples, epoch, n_samples):
        examples = (examples * 255)
        for i in range(n * n):
            pyplot.subplot(n, n, i+1)
            pyplot.axis(""off"")
            pyplot.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))
        filename = f""samples/generated_plot_epoch-{epoch+1}.png""
        pyplot.savefig(filename)
        pyplot.close()
        
    
    LATENT_DIM = 100
    IMG_H = 128
    IMG_W = 128
    IMG_C = 3
    LR = 1e-4
    EPOCHS = 1000
    BATCH_SIZE = 32
    path = 'cropped'
    n_samples = 25
    
    real_images = get_data(path)
    print(real_images.shape)
    
    gen = generator(LATENT_DIM, IMG_H, IMG_W, IMG_C, LR)
    disc = discriminator(IMG_H, IMG_W, IMG_C, LR)
    gan = get_gan(gen, disc, LR)
    
    
    test_noise = np.random.normal(size=(n_samples, LATENT_DIM))
    
    for epoch in range(EPOCHS):
        print(f'Epoch {epoch + 1} of {EPOCHS}')
        for BATCH in range(0, real_images.shape[0], BATCH_SIZE):
            batch = real_images[BATCH:BATCH+BATCH_SIZE]
            
            noise = np.random.normal(size=(batch.shape[0], LATENT_DIM))
    
            fake_images = gen.predict(noise) #get image from random noise
    
            fake_labels = np.array([random.uniform(0.0, 0.1) for i in range(batch.shape[0])]) #create fake labels
            real_labels = np.array([random.uniform(0.9, 1.0) for i in range(batch.shape[0])]) #create real labels
    
            #TRAIN DISCRIMINATOR
    
            disc_X = np.concatenate((batch, fake_images), axis=0) #combine both
            disc_Y = np.concatenate((real_labels, fake_labels), axis=0)
            disc_X, disc_y = shuffle(disc_X, disc_Y) #shuffle
            print('Discriminator')
            res = disc.train_on_batch(disc_X, disc_Y)
            print(res)
    
    
            #TRAIN GENERATOR
    
            noise = tf.random.normal(shape=(batch.shape[0], LATENT_DIM))
    
            misleading_labels = tf.ones((batch.shape[0], 1))
    
            print(noise.shape, misleading_labels.shape)
    
            print('Generator')
    
            
            gan.fit(x = noise, y = misleading_labels, batch_size=BATCH_SIZE)
    
            produce_examples(gen.predict(test_noise), epoch, n_samples)

&amp;#x200B;

My models: 

&amp;#x200B;

    def discriminator(IMG_H, IMG_W, IMG_C, lr):
        model = Sequential()
    
    
    
        f = [2**i for i in range(4)]
        
        filters = 64
        output_strides = 16
        h_output = IMG_H // output_strides
        w_output = IMG_W // output_strides
    
        model.add(InputLayer(input_shape = (IMG_H, IMG_W, IMG_C)))
        
        for i in range(0, 4):
            model.add(Conv2D(filters=f[i] * filters, kernel_size=5, padding='same', strides=2))
            model.add(LeakyReLU(alpha=0.2))
            model.add(Dropout(0.3))
                      
        model.add(Flatten())
        model.add(Dense(1, activation = 'sigmoid'))
    
        optimizer = Adam(lr = lr)
    
        model.summary()
        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    
        return model
    
    
    
    def generator(latent_dim, IMG_H, IMG_W, IMG_C, lr):
    
    
        
        model = Sequential()
    
    
        
        model.add(InputLayer((latent_dim,)))
        f = [2**i for i in range(5)][::-1]
        filters = 32
        output_strides = 16
        h_output = IMG_H // output_strides
        w_output = IMG_W // output_strides
    
        model.add(Dense(f[0] * filters * h_output * w_output))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.2))
    
        model.add(Reshape((h_output, w_output, 16 * filters)))
    
        
        for i in range(1,5):
            model.add(Conv2DTranspose(filters = f[i] * filters, kernel_size = 5, strides = 2, padding='same', use_bias = False))
            model.add(LeakyReLU(alpha=0.2))
            model.add(Dropout(0.3))
    
    
        model.add(Conv2D(filters=IMG_C, kernel_size=5, padding='same', strides=1, activation = 'sigmoid'))

I've tried Tensorflow 2.1.0, 2.2.0 and the most recent 2.4.0, all to no avail. Is the way I'm creating the GAN model (in get\_gan) incorrect such that it breaks, or is this a Keras/Tensorflow issue?",t2_yqlkc,False,,0,False,Keras “index_array” referenced before assignment,[],r/tensorflow,False,6,,0,,,False,t3_ky5vgs,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question (error),False,2,,False,self,False,,[],{},,True,,1610779485.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to make a DCGAN with Keras, but I&amp;#39;m running into an error when I try to train a combined model: &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; Traceback (most recent call last):
  File &amp;quot;D:\Projects\DCGAN\train.py&amp;quot;, line 95, in &amp;lt;module&amp;gt;
    gan.fit(x = noise, y = misleading_labels, batch_size=BATCH_SIZE)
  File &amp;quot;C:\Python\lib\site-packages\keras\engine\training.py&amp;quot;, line 1239, in fit
    validation_freq=validation_freq)
  File &amp;quot;C:\Python\lib\site-packages\keras\engine\training_arrays.py&amp;quot;, line 175, in fit_loop
    np.random.shuffle(index_array)
UnboundLocalError: local variable &amp;#39;index_array&amp;#39; referenced before assignment 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My code: &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_data(path):
    files = os.listdir(path)
    dat = []
    for j,file in enumerate(files):
        image = cv2.imread(path + &amp;#39;/&amp;#39; + file)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = image / 255
        #print(image[:10, :10])
        image = image.reshape(tuple([1] + list(image.shape)))

        dat.append(image)

    return np.concatenate(tuple(dat))

def produce_samples(examples, epoch, n_samples):
    examples = (examples * 255)
    for i in range(n * n):
        pyplot.subplot(n, n, i+1)
        pyplot.axis(&amp;quot;off&amp;quot;)
        pyplot.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))
    filename = f&amp;quot;samples/generated_plot_epoch-{epoch+1}.png&amp;quot;
    pyplot.savefig(filename)
    pyplot.close()


LATENT_DIM = 100
IMG_H = 128
IMG_W = 128
IMG_C = 3
LR = 1e-4
EPOCHS = 1000
BATCH_SIZE = 32
path = &amp;#39;cropped&amp;#39;
n_samples = 25

real_images = get_data(path)
print(real_images.shape)

gen = generator(LATENT_DIM, IMG_H, IMG_W, IMG_C, LR)
disc = discriminator(IMG_H, IMG_W, IMG_C, LR)
gan = get_gan(gen, disc, LR)


test_noise = np.random.normal(size=(n_samples, LATENT_DIM))

for epoch in range(EPOCHS):
    print(f&amp;#39;Epoch {epoch + 1} of {EPOCHS}&amp;#39;)
    for BATCH in range(0, real_images.shape[0], BATCH_SIZE):
        batch = real_images[BATCH:BATCH+BATCH_SIZE]

        noise = np.random.normal(size=(batch.shape[0], LATENT_DIM))

        fake_images = gen.predict(noise) #get image from random noise

        fake_labels = np.array([random.uniform(0.0, 0.1) for i in range(batch.shape[0])]) #create fake labels
        real_labels = np.array([random.uniform(0.9, 1.0) for i in range(batch.shape[0])]) #create real labels

        #TRAIN DISCRIMINATOR

        disc_X = np.concatenate((batch, fake_images), axis=0) #combine both
        disc_Y = np.concatenate((real_labels, fake_labels), axis=0)
        disc_X, disc_y = shuffle(disc_X, disc_Y) #shuffle
        print(&amp;#39;Discriminator&amp;#39;)
        res = disc.train_on_batch(disc_X, disc_Y)
        print(res)


        #TRAIN GENERATOR

        noise = tf.random.normal(shape=(batch.shape[0], LATENT_DIM))

        misleading_labels = tf.ones((batch.shape[0], 1))

        print(noise.shape, misleading_labels.shape)

        print(&amp;#39;Generator&amp;#39;)


        gan.fit(x = noise, y = misleading_labels, batch_size=BATCH_SIZE)

        produce_examples(gen.predict(test_noise), epoch, n_samples)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My models: &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def discriminator(IMG_H, IMG_W, IMG_C, lr):
    model = Sequential()



    f = [2**i for i in range(4)]

    filters = 64
    output_strides = 16
    h_output = IMG_H // output_strides
    w_output = IMG_W // output_strides

    model.add(InputLayer(input_shape = (IMG_H, IMG_W, IMG_C)))

    for i in range(0, 4):
        model.add(Conv2D(filters=f[i] * filters, kernel_size=5, padding=&amp;#39;same&amp;#39;, strides=2))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.3))

    model.add(Flatten())
    model.add(Dense(1, activation = &amp;#39;sigmoid&amp;#39;))

    optimizer = Adam(lr = lr)

    model.summary()
    model.compile(loss=&amp;#39;binary_crossentropy&amp;#39;, optimizer=optimizer, metrics=[&amp;#39;accuracy&amp;#39;])

    return model



def generator(latent_dim, IMG_H, IMG_W, IMG_C, lr):



    model = Sequential()



    model.add(InputLayer((latent_dim,)))
    f = [2**i for i in range(5)][::-1]
    filters = 32
    output_strides = 16
    h_output = IMG_H // output_strides
    w_output = IMG_W // output_strides

    model.add(Dense(f[0] * filters * h_output * w_output))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Reshape((h_output, w_output, 16 * filters)))


    for i in range(1,5):
        model.add(Conv2DTranspose(filters = f[i] * filters, kernel_size = 5, strides = 2, padding=&amp;#39;same&amp;#39;, use_bias = False))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.3))


    model.add(Conv2D(filters=IMG_C, kernel_size=5, padding=&amp;#39;same&amp;#39;, strides=1, activation = &amp;#39;sigmoid&amp;#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;#39;ve tried Tensorflow 2.1.0, 2.2.0 and the most recent 2.4.0, all to no avail. Is the way I&amp;#39;m creating the GAN model (in get_gan) incorrect such that it breaks, or is this a Keras/Tensorflow issue?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ky5vgs,True,,Anomalix,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ky5vgs/keras_index_array_referenced_before_assignment/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ky5vgs/keras_index_array_referenced_before_assignment/,22217,1610750685.0,0,,False,,,,,,,,,
223,,tensorflow,"[Left and Right images](https://preview.redd.it/zwhj6mx7lhb61.png?width=1770&amp;format=png&amp;auto=webp&amp;s=51b5d0c36728d05d3cee8f7c167c302d50684d66)

So, for instance, I have a pair of stereo images (as an example, here I have duplicated the photo to represent left and right images) of certain objects (in this case dogs and cats). I want to match the dogs in the 2 images, i.e the network should identify that if there's a 'Dog 1' in the left image, then which dog in the right image is the corresponding match for 'Dog 1'. And similarly for other objects as well.

I can perform instance segmentation on the images and get the object boundaries and the masks for both left and right images, but how do match the objects in the stereo image pair?

I was thinking of using Siamese Networks to get a similarity score, but pretty clueless on how to proceed with that.

Any help would be great! TIA!

&amp;#x200B;",t2_3s0qrm4z,False,,0,False,How do I identify matching objects in a pair of stereo images?,[],r/tensorflow,False,6,,0,55.0,,False,t3_kxtcza,False,dark,0.67,,public,2,0,{},140.0,,False,[],,False,False,,{},Question,False,2,,False,https://a.thumbs.redditmedia.com/W67_IuZGfPaWjH7jFRCq-goeeDoAL3wHhuS2FJ4P9e0.jpg,1610713047.0,,[],{},,True,,1610741532.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://preview.redd.it/zwhj6mx7lhb61.png?width=1770&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=51b5d0c36728d05d3cee8f7c167c302d50684d66""&gt;Left and Right images&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So, for instance, I have a pair of stereo images (as an example, here I have duplicated the photo to represent left and right images) of certain objects (in this case dogs and cats). I want to match the dogs in the 2 images, i.e the network should identify that if there&amp;#39;s a &amp;#39;Dog 1&amp;#39; in the left image, then which dog in the right image is the corresponding match for &amp;#39;Dog 1&amp;#39;. And similarly for other objects as well.&lt;/p&gt;

&lt;p&gt;I can perform instance segmentation on the images and get the object boundaries and the masks for both left and right images, but how do match the objects in the stereo image pair?&lt;/p&gt;

&lt;p&gt;I was thinking of using Siamese Networks to get a similarity score, but pretty clueless on how to proceed with that.&lt;/p&gt;

&lt;p&gt;Any help would be great! TIA!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kxtcza,True,,chinmaygrg,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kxtcza/how_do_i_identify_matching_objects_in_a_pair_of/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kxtcza/how_do_i_identify_matching_objects_in_a_pair_of/,22217,1610712732.0,0,,False,,,,,"{'zwhj6mx7lhb61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 42, 'x': 108, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ceba4528ae76762674ed5a51646e117f4ecf301'}, {'y': 85, 'x': 216, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e1674c07834e8114dc45e7c661a0ef353a3cdf22'}, {'y': 126, 'x': 320, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9844ae0bdc33b129cdf3bba811229ad51416e473'}, {'y': 253, 'x': 640, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=16cc9de006c215890cd61b7e8a3510f5c72c8541'}, {'y': 380, 'x': 960, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4d2be406ffa184369c910c7ff76187477c9e7d73'}, {'y': 428, 'x': 1080, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=03a188a6da0a9cb8aed44325878f188231755257'}], 's': {'y': 702, 'x': 1770, 'u': 'https://preview.redd.it/zwhj6mx7lhb61.png?width=1770&amp;format=png&amp;auto=webp&amp;s=51b5d0c36728d05d3cee8f7c167c302d50684d66'}, 'id': 'zwhj6mx7lhb61'}}",,,,
224,,tensorflow,"I made a chatbot using TensorFlow, from [Tech With Tim's tutorial](https://youtu.be/wypVcNIH6D4). I changed it for a discord bot and flask. But for my project I want to somehow show ANY DATA, but in visual form, graphs, pie charts, bars. I don't know how to use TensorBoard to visualize my chatbot data. 

This is my code: [https://github.com/hootloot/Tensorflow-Question/blob/main/main.py](https://github.com/hootloot/Tensorflow-Question/blob/main/main.py)

Thank you",t2_28ivtfdu,False,,0,False,How do I visualize data from my Chat Bot?,[],r/tensorflow,False,6,,0,,,False,t3_kxgahy,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1610691623.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I made a chatbot using TensorFlow, from &lt;a href=""https://youtu.be/wypVcNIH6D4""&gt;Tech With Tim&amp;#39;s tutorial&lt;/a&gt;. I changed it for a discord bot and flask. But for my project I want to somehow show ANY DATA, but in visual form, graphs, pie charts, bars. I don&amp;#39;t know how to use TensorBoard to visualize my chatbot data. &lt;/p&gt;

&lt;p&gt;This is my code: &lt;a href=""https://github.com/hootloot/Tensorflow-Question/blob/main/main.py""&gt;https://github.com/hootloot/Tensorflow-Question/blob/main/main.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kxgahy,True,,chopchopstiicks,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kxgahy/how_do_i_visualize_data_from_my_chat_bot/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kxgahy/how_do_i_visualize_data_from_my_chat_bot/,22217,1610662823.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/0c_Gd2pDPvK4T_1PJMMVfIwOosJ7IN1fqR7I9xpNPTE.jpg?auto=webp&amp;s=66fae544fbde010f1c1e2e78188d001acaf2d45d', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/0c_Gd2pDPvK4T_1PJMMVfIwOosJ7IN1fqR7I9xpNPTE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6fcf46b45e22d62fab7582b821ef3914f3b791cf', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/0c_Gd2pDPvK4T_1PJMMVfIwOosJ7IN1fqR7I9xpNPTE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17400e3a663dd2d65f4fa0c31a3ef4b9486a0818', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/0c_Gd2pDPvK4T_1PJMMVfIwOosJ7IN1fqR7I9xpNPTE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4595192a911601edbfe9d0ee808c57bf059df8ff', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'w_fr-jauhR8851PfUr-jdw_vgewZYYhFUs8rAv5MRaU'}], 'enabled': False}",,,,,,
225,,tensorflow,"Putting your ML model development work inside a (docker) container can really help with managing the process and keeping your environments clean.

You'll read about:

- machine learning iterative processes and dependency
- similarities and differences between MLOps vs DevOps
- essentials of Containers (meaning, scope, docker file and docker-compose etc.)
- jupyter notebook in containers 
- application development with TensorFlow in containers as microservice
- Use of GPUs in Docker 

[intro to ML with containers](https://neptune.ai/blog/data-science-machine-learning-in-containers?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-data-science-machine-learning-in-containers&amp;utm_content=tensorflow)",t2_5hfacnnv,False,,0,False,[Tutorial] Intro to ML with Containers,[],r/tensorflow,False,6,,0,,,False,t3_kx14zg,False,dark,0.94,,public,14,0,{},,,False,[],,False,False,,{},,False,14,,False,self,1611066099.0,,[],{},,True,,1610639028.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Putting your ML model development work inside a (docker) container can really help with managing the process and keeping your environments clean.&lt;/p&gt;

&lt;p&gt;You&amp;#39;ll read about:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;machine learning iterative processes and dependency&lt;/li&gt;
&lt;li&gt;similarities and differences between MLOps vs DevOps&lt;/li&gt;
&lt;li&gt;essentials of Containers (meaning, scope, docker file and docker-compose etc.)&lt;/li&gt;
&lt;li&gt;jupyter notebook in containers &lt;/li&gt;
&lt;li&gt;application development with TensorFlow in containers as microservice&lt;/li&gt;
&lt;li&gt;Use of GPUs in Docker &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/data-science-machine-learning-in-containers?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-data-science-machine-learning-in-containers&amp;amp;utm_content=tensorflow""&gt;intro to ML with containers&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kx14zg,True,,kk_ai,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kx14zg/tutorial_intro_to_ml_with_containers/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kx14zg/tutorial_intro_to_ml_with_containers/,22217,1610610228.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?auto=webp&amp;s=9df39e8619a398911ce5e70334e1b6c3452643cb', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=be7e8f4896fea2ae9cc09b8ff39035ba75e3cd0b', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=de840836ef684303bc7c51f8e22b3cde54448e26', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e208e2ddabbc143be85f60bd751873bd54de20a2', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fd16a20a459906e5a20a41d152dac9f740484aa', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=99aa7d118a89369174659af63c85153b83a0aee6', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/vbDGTSIXJjFfRDWW4k2kP8umZK5_zi1fAb0mjJrB1LA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3f5bc2e30dbbf7062c52d7c464aaa3bba38abbb6', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'Bt-n7gkgdufb7AHJ16Nd5MDjN1YZiI_9Lr9huszlm1Q'}], 'enabled': False}",,,,,,
226,,tensorflow,,t2_6qfe15s8,False,,0,False,Generating Beatles-like lyrics with Tensorflow RNNs,[],r/tensorflow,False,6,,0,137.0,,False,t3_kx6riq,False,dark,0.75,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/CKUZCPhmMl5U5NC67tVJprMaQkzeWCFXBzq6KxWk3Dk.jpg,False,,[],{},,False,,1610663693.0,text,6,,,text,medium.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kx6riq,True,,petrandeme,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kx6riq/generating_beatleslike_lyrics_with_tensorflow_rnns/,all_ads,False,https://medium.com/swlh/generating-beatles-like-lyrics-with-rnns-914186c66dbe,22217,1610634893.0,0,,False,link,https://medium.com/swlh/generating-beatles-like-lyrics-with-rnns-914186c66dbe,"{'images': [{'source': {'url': 'https://external-preview.redd.it/W65DQ8liqmX82qohGdQMbciqakVg3XpJOhASv3aNnro.jpg?auto=webp&amp;s=5bc01f202f2296806fa1ca71e635163edd9f3be5', 'width': 510, 'height': 500}, 'resolutions': [{'url': 'https://external-preview.redd.it/W65DQ8liqmX82qohGdQMbciqakVg3XpJOhASv3aNnro.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=89daed8dcdfee7f10edfa4790eea9fb41d5ac9ef', 'width': 108, 'height': 105}, {'url': 'https://external-preview.redd.it/W65DQ8liqmX82qohGdQMbciqakVg3XpJOhASv3aNnro.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7a7e39d0b1fc31f981cd3bedab0fd9547a1503b', 'width': 216, 'height': 211}, {'url': 'https://external-preview.redd.it/W65DQ8liqmX82qohGdQMbciqakVg3XpJOhASv3aNnro.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=90de8358046f3869ba9d8c0f1a790774d672fc46', 'width': 320, 'height': 313}], 'variants': {}, 'id': 'f1vfyT1-u-tvw0nN4wdqJDGN5cxA-CLOoOW-lUApqYc'}], 'enabled': False}",,,,,,
227,,tensorflow,"I published a tutorial where I explain how to save an AutoEncoder with Python + Keras. In particular, in this video you’ll learn how to save/load the Autoencoder class parameters with pickle and the model weights with methods native to the Keras API.

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

https://www.youtube.com/watch?v=UIC0Irq-Eok&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=7",t2_12ahau,False,,0,False,I published a step-by-step tutorial on how to save autoencoders with Python/Keras,[],r/tensorflow,False,6,,0,,,False,t3_kx8ezp,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Project,False,1,,False,self,False,,[],{},,True,,1610668808.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I published a tutorial where I explain how to save an AutoEncoder with Python + Keras. In particular, in this video you’ll learn how to save/load the Autoencoder class parameters with pickle and the model weights with methods native to the Keras API.&lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=UIC0Irq-Eok&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=7""&gt;https://www.youtube.com/watch?v=UIC0Irq-Eok&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=7&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kx8ezp,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kx8ezp/i_published_a_stepbystep_tutorial_on_how_to_save/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kx8ezp/i_published_a_stepbystep_tutorial_on_how_to_save/,22217,1610640008.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/zpp66XTurJrTSz3rCPBMSkzvUPfRWjzCvbPMqk6PYW0.jpg?auto=webp&amp;s=b337534fc27922bddc5a51ea87fce455ac4e92d8', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/zpp66XTurJrTSz3rCPBMSkzvUPfRWjzCvbPMqk6PYW0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=126640705a57ee400ec2205fababd68940a59077', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/zpp66XTurJrTSz3rCPBMSkzvUPfRWjzCvbPMqk6PYW0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=09111954102dab263f342bc7d9b4590b29415254', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/zpp66XTurJrTSz3rCPBMSkzvUPfRWjzCvbPMqk6PYW0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f7e8056cca7bcefb10488a311461e687a598f88', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'HZ49vmpZxJM_mt014PWnHCdulcSX-tH6kx5hC8Cwo-I'}], 'enabled': False}",,,,,,
228,,tensorflow,"Hello everyone,
This question is for people who deploy Tflite models on mobile devices.

Me and my friends working on one project and interested to understand the needs for measuring the speed of your Tflite models on mobile devices.

1. How often do you benchmark Tflite models?
2. What is the average time you spend?
3. How difficult is to analyze the speed and compare your models?
4. If we can provide easy to measure tool with full of mobiles device infrastructure and speed visualization dashboard, would you be interested?

Please let me know your opinion. Thank you.",t2_19ih2aow,False,,0,False,Benchmark on real mobile devices?,[],r/tensorflow,False,6,,0,,,False,t3_kx3zxv,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1610652915.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,
This question is for people who deploy Tflite models on mobile devices.&lt;/p&gt;

&lt;p&gt;Me and my friends working on one project and interested to understand the needs for measuring the speed of your Tflite models on mobile devices.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How often do you benchmark Tflite models?&lt;/li&gt;
&lt;li&gt;What is the average time you spend?&lt;/li&gt;
&lt;li&gt;How difficult is to analyze the speed and compare your models?&lt;/li&gt;
&lt;li&gt;If we can provide easy to measure tool with full of mobiles device infrastructure and speed visualization dashboard, would you be interested?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Please let me know your opinion. Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kx3zxv,True,,kg_unist,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kx3zxv/benchmark_on_real_mobile_devices/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kx3zxv/benchmark_on_real_mobile_devices/,22217,1610624115.0,0,,False,,,,,,,,,
229,,tensorflow,"In an object detection task, there's a variable number of boxes that can be present in an image, often with no upper bound. How do you handle this in tensorflow? One option that comes to mind is a fixed size upper bound, but that has the potential to discard some scenes that might have many objects. Would you use ragged tensors or is the performance hit too high? Curious how this is handled",t2_1hg7w5iv,False,,0,False,Handling labels with various sizes?,[],r/tensorflow,False,6,,0,,,False,t3_kwwgdo,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610620899.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In an object detection task, there&amp;#39;s a variable number of boxes that can be present in an image, often with no upper bound. How do you handle this in tensorflow? One option that comes to mind is a fixed size upper bound, but that has the potential to discard some scenes that might have many objects. Would you use ragged tensors or is the performance hit too high? Curious how this is handled&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kwwgdo,True,,atyshka,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kwwgdo/handling_labels_with_various_sizes/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kwwgdo/handling_labels_with_various_sizes/,22217,1610592099.0,0,,False,,,,,,,,,
230,,tensorflow,"Version control is used to keep track of modifications made in a software code. Similarly, when building machine learning (ML) systems, it is essential to track things, such as the datasets used to train the model, the hyperparameters and pipeline used, the version of tensorflow used to create the model, and many more.

ML artifacts’ history and lineage are very complicated than a simple, linear log. Git can be used to track the code to one extent, but we need something to track your models, datasets, and more. The complexity of ML code and artifacts like models, datasets, and much more requires a similar approach.

Article: [https://www.marktechpost.com/2021/01/12/machine-learning-metadata-mlmd-a-library-to-track-full-lineage-of-machine-learning-workflow/](https://www.marktechpost.com/2021/01/12/machine-learning-metadata-mlmd-a-library-to-track-full-lineage-of-machine-learning-workflow/) 

Github: https://github.com/google/ml-metadata",t2_2wsvqwhg,False,,0,False,Machine Learning Metadata (MLMD) : A Library To Track Full Lineage Of Machine Learning Workflow,[],r/tensorflow,False,6,,0,,,False,t3_kw7kxp,False,dark,0.92,,public,10,0,{},,,False,[],,False,False,,{},Project,False,10,,False,self,False,,[],{},,True,,1610536096.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Version control is used to keep track of modifications made in a software code. Similarly, when building machine learning (ML) systems, it is essential to track things, such as the datasets used to train the model, the hyperparameters and pipeline used, the version of tensorflow used to create the model, and many more.&lt;/p&gt;

&lt;p&gt;ML artifacts’ history and lineage are very complicated than a simple, linear log. Git can be used to track the code to one extent, but we need something to track your models, datasets, and more. The complexity of ML code and artifacts like models, datasets, and much more requires a similar approach.&lt;/p&gt;

&lt;p&gt;Article: &lt;a href=""https://www.marktechpost.com/2021/01/12/machine-learning-metadata-mlmd-a-library-to-track-full-lineage-of-machine-learning-workflow/""&gt;https://www.marktechpost.com/2021/01/12/machine-learning-metadata-mlmd-a-library-to-track-full-lineage-of-machine-learning-workflow/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/google/ml-metadata""&gt;https://github.com/google/ml-metadata&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kw7kxp,True,,ai-lover,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kw7kxp/machine_learning_metadata_mlmd_a_library_to_track/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kw7kxp/machine_learning_metadata_mlmd_a_library_to_track/,22217,1610507296.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IM9vAJpUWFFCa5V8UDYwSoaohuvUKI4KzKRscdECuyo.jpg?auto=webp&amp;s=b375a2db762dd43f2b19070b586bf667296f4838', 'width': 944, 'height': 481}, 'resolutions': [{'url': 'https://external-preview.redd.it/IM9vAJpUWFFCa5V8UDYwSoaohuvUKI4KzKRscdECuyo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85b119761f9b683e09d404918cdd4e7fe6ef5b2f', 'width': 108, 'height': 55}, {'url': 'https://external-preview.redd.it/IM9vAJpUWFFCa5V8UDYwSoaohuvUKI4KzKRscdECuyo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a1a37d4bf6600221f8f669e85ffc8a0456e95ec', 'width': 216, 'height': 110}, {'url': 'https://external-preview.redd.it/IM9vAJpUWFFCa5V8UDYwSoaohuvUKI4KzKRscdECuyo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=593c0d87758ddbe6be01bb0d18b7cc66591914c3', 'width': 320, 'height': 163}, {'url': 'https://external-preview.redd.it/IM9vAJpUWFFCa5V8UDYwSoaohuvUKI4KzKRscdECuyo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db1b5bac6448246848ca2e83715aa6455d139543', 'width': 640, 'height': 326}], 'variants': {}, 'id': 'VVgq03H3-kluBTMgFVPbsvuq_w73ygvRWCWnlWY_8L8'}], 'enabled': False}",,,,,,
231,,tensorflow,,t2_52hj835v,False,,0,False,I need some interpretations of these 3 highlighted sentence codes. Pardon me for being a newbie,[],r/tensorflow,False,6,,0,78.0,,False,t3_kwf99g,False,dark,0.33,,public,0,0,{},140.0,,False,[],,True,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/cp8VjX9W8HjLD1f-stP3yl_DbTWaNGf6STLw6uJT3Ec.jpg,False,,[],{},,False,,1610568857.0,text,6,,,text,i.redd.it,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kwf99g,True,,edmondoh001,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/kwf99g/i_need_some_interpretations_of_these_3/,all_ads,False,https://i.redd.it/h9fmv1hwc3b61.png,22217,1610540057.0,0,,False,image,https://i.redd.it/h9fmv1hwc3b61.png,"{'images': [{'source': {'url': 'https://preview.redd.it/h9fmv1hwc3b61.png?auto=webp&amp;s=9bde4f6de748cede8092452a621e2bb9b5c4416b', 'width': 814, 'height': 459}, 'resolutions': [{'url': 'https://preview.redd.it/h9fmv1hwc3b61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dcbb234f8fe25adbe166b32e9b00f99f2f920194', 'width': 108, 'height': 60}, {'url': 'https://preview.redd.it/h9fmv1hwc3b61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1e6afadb9bc30282472f4f9da572b3f01646e8f', 'width': 216, 'height': 121}, {'url': 'https://preview.redd.it/h9fmv1hwc3b61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a43747f3fb0da9f4f9880853afac5eb79ee45f53', 'width': 320, 'height': 180}, {'url': 'https://preview.redd.it/h9fmv1hwc3b61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6496b013546f822d84b41173f7df430cb7cc23f7', 'width': 640, 'height': 360}], 'variants': {}, 'id': 'qjP8TvA1wZlJC37rPozbLT7ao-I2SIoEEXbQaMC_gOc'}], 'enabled': True}",,,,,,
232,,tensorflow,"`def load_data(dir_list, image_size):`

`X = []`

`Y = []`

`image_width, image_height = image_size`

`for directory in dir_list:`

`for filename in listdir(directory):`

`image = cv2.imread(directory + '//' + filename)`

`imgres = resize(image, (240,240,3))`

`img_resized = cv2.resize(imgres, dsize = (image_width, image_height),interpolation=cv2.INTER_CUBIC)`

`X.append(image)`

`if directory[-3:] == 'yes':`

`Y.append([1])`

`else:`

`Y.append([0])`

`X = np.array(X)`

`Y = np.array(Y)`

`X, Y = shuffle(X, Y)`

`print(f'Number of examples is: {len(X)}')`

`print(f'X shape is: {X.shape}')`

`print(f'y shape is: {Y.shape}')`

`return X, Y`

\-----------------------------------------------

`yes = 'yes'`

`no =  'no'`

&amp;#x200B;

`IMG_WIDTH, IMG_HEIGHT = (240, 240)`

&amp;#x200B;

`X, Y = load_data([yes, no], (IMG_WIDTH, IMG_HEIGHT))`

\--------------------------------------------------------

&amp;#x200B;

OUTPUT:

Number of examples is: 253

X shape is: (253,)

Y shape is: (253, 1)

&amp;#x200B;

\-------------------------------------------------------

&amp;#x200B;

The X-Shape should be (253,240,240,3), however, I do not know why it is missing the other numbers. Thank you for helping.",t2_18w6l0tw,False,,0,False,Question regarding an error in my NumPy array.,[],r/tensorflow,False,6,,0,,,False,t3_kw6ibh,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1610532420.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;code&gt;def load_data(dir_list, image_size):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;X = []&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Y = []&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;image_width, image_height = image_size&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for directory in dir_list:&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for filename in listdir(directory):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;image = cv2.imread(directory + &amp;#39;//&amp;#39; + filename)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;imgres = resize(image, (240,240,3))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;img_resized = cv2.resize(imgres, dsize = (image_width, image_height),interpolation=cv2.INTER_CUBIC)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;X.append(image)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;if directory[-3:] == &amp;#39;yes&amp;#39;:&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Y.append([1])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;else:&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Y.append([0])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;X = np.array(X)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Y = np.array(Y)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;X, Y = shuffle(X, Y)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;print(f&amp;#39;Number of examples is: {len(X)}&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;print(f&amp;#39;X shape is: {X.shape}&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;print(f&amp;#39;y shape is: {Y.shape}&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;return X, Y&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------&lt;/p&gt;

&lt;p&gt;&lt;code&gt;yes = &amp;#39;yes&amp;#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;no =  &amp;#39;no&amp;#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;IMG_WIDTH, IMG_HEIGHT = (240, 240)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;X, Y = load_data([yes, no], (IMG_WIDTH, IMG_HEIGHT))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;--------------------------------------------------------&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;OUTPUT:&lt;/p&gt;

&lt;p&gt;Number of examples is: 253&lt;/p&gt;

&lt;p&gt;X shape is: (253,)&lt;/p&gt;

&lt;p&gt;Y shape is: (253, 1)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;-------------------------------------------------------&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The X-Shape should be (253,240,240,3), however, I do not know why it is missing the other numbers. Thank you for helping.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kw6ibh,True,,-KingKrazy-,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kw6ibh/question_regarding_an_error_in_my_numpy_array/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kw6ibh/question_regarding_an_error_in_my_numpy_array/,22217,1610503620.0,0,,False,,,,,,,,,
233,,tensorflow,"Quick question, so, i've got some model (an autoencoder to be exact) written in a sequential manner and let's say it looks something like this

    input = keras.Input()
    conv = layers.Conv2D()(input)
    flatten = layers.Flatten()(conv)
    dense = layers.Dense()(flatten)
    out = layers.Dense()(dense)
    model = keras.Model(inputs=input, outputs=out)
    model.compile()

and let's say i've trained that model. If i then use some layers of that model to make another one like this

    new_model = keras.Model(inputs=input, outputs=conv)

will that new model be already trained? I guess it poses more global question, does keras.Model() create separate object which uses those layers vairables you've written just to know the structure, like a Class description or does it actually acts upon those variables during actions like .fit()?",t2_wn450,False,,0,False,"When you acess layers of the trained model by name, do you also get the weights?",[],r/tensorflow,False,6,,0,,,False,t3_kvta7d,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1610492558.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Quick question, so, i&amp;#39;ve got some model (an autoencoder to be exact) written in a sequential manner and let&amp;#39;s say it looks something like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;input = keras.Input()
conv = layers.Conv2D()(input)
flatten = layers.Flatten()(conv)
dense = layers.Dense()(flatten)
out = layers.Dense()(dense)
model = keras.Model(inputs=input, outputs=out)
model.compile()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and let&amp;#39;s say i&amp;#39;ve trained that model. If i then use some layers of that model to make another one like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new_model = keras.Model(inputs=input, outputs=conv)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will that new model be already trained? I guess it poses more global question, does keras.Model() create separate object which uses those layers vairables you&amp;#39;ve written just to know the structure, like a Class description or does it actually acts upon those variables during actions like .fit()?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kvta7d,True,,Spectator696,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kvta7d/when_you_acess_layers_of_the_trained_model_by/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvta7d/when_you_acess_layers_of_the_trained_model_by/,22217,1610463758.0,0,,False,,,,,,,,,
234,,tensorflow,"!python {'/content/generate\_tfrecord.py'} -x {'/content/Training'} -l {'/content/label\_map.pbtxt'} -o {ANNOTATION\_PATH + '/train.record'} !python {'/content/generate\_tfrecord.py'} -x{'/content/Testing'} -l {'/content/label\_map.pbtxt'} -o {ANNOTATION\_PATH + '/test.record'}

running which I get error:

Traceback (most recent call last):   File ""/content/generate\_tfrecord.py"", line 29, in &lt;module&gt;     from object\_detection.utils import dataset\_util, label\_map\_util ModuleNotFoundError: No module named 'object\_detection' Traceback (most recent call last):   File ""/content/generate\_tfrecord.py"", line 29, in &lt;module&gt;     from object\_detection.utils import dataset\_util, label\_map\_util ModuleNotFoundError: No module named 'object\_detection' 

MacOS Catalina 10.15.2, Tensorflow (latest version)

I have already installed all dependencies through pip. (object-detection api, exported the path in terminal, ran the command ""python setup.py install in the same path)

Can someone please help?",t2_3xoqbe3x,False,,0,False,MacOS: ModuleNotFoundError: No module named 'object_detection',[],r/tensorflow,False,6,,0,,,False,t3_kvopmm,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1610473844.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;!python {&amp;#39;/content/generate_tfrecord.py&amp;#39;} -x {&amp;#39;/content/Training&amp;#39;} -l {&amp;#39;/content/label_map.pbtxt&amp;#39;} -o {ANNOTATION_PATH + &amp;#39;/train.record&amp;#39;} !python {&amp;#39;/content/generate_tfrecord.py&amp;#39;} -x{&amp;#39;/content/Testing&amp;#39;} -l {&amp;#39;/content/label_map.pbtxt&amp;#39;} -o {ANNOTATION_PATH + &amp;#39;/test.record&amp;#39;}&lt;/p&gt;

&lt;p&gt;running which I get error:&lt;/p&gt;

&lt;p&gt;Traceback (most recent call last):   File &amp;quot;/content/generate_tfrecord.py&amp;quot;, line 29, in &amp;lt;module&amp;gt;     from object_detection.utils import dataset_util, label_map_util ModuleNotFoundError: No module named &amp;#39;object_detection&amp;#39; Traceback (most recent call last):   File &amp;quot;/content/generate_tfrecord.py&amp;quot;, line 29, in &amp;lt;module&amp;gt;     from object_detection.utils import dataset_util, label_map_util ModuleNotFoundError: No module named &amp;#39;object_detection&amp;#39; &lt;/p&gt;

&lt;p&gt;MacOS Catalina 10.15.2, Tensorflow (latest version)&lt;/p&gt;

&lt;p&gt;I have already installed all dependencies through pip. (object-detection api, exported the path in terminal, ran the command &amp;quot;python setup.py install in the same path)&lt;/p&gt;

&lt;p&gt;Can someone please help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kvopmm,True,,Ghostly_Beast,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kvopmm/macos_modulenotfounderror_no_module_named_object/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvopmm/macos_modulenotfounderror_no_module_named_object/,22217,1610445044.0,0,,False,,,,,,,,,
235,,tensorflow,"I'm sorry if this has been asked before, or if it's obvious but:

I'm trying to make a deep learning model that can recommend items to users based on the rating that they've given other items.

And I kind of understand how to do this.

But now comes the part that confuses me, let's say I deploy this model on my website. But then an existing user rates some new items or what if it's an entirely new user that is not known by the model? Do I then need to retrain my entire model?

Or is there some way to make a recommender model that can make recommendations for users without retraining the entire model again?

I've tried googling this, but I can't seem to find an answer anywhere(or I'm not searching for the right words)

Anyone have a suggestion that can push me in the right direction?

Thanks in advance!",t2_812xilv1,False,,0,False,Recommendations for new users,[],r/tensorflow,False,6,,0,,,False,t3_kvpezp,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1610477222.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m sorry if this has been asked before, or if it&amp;#39;s obvious but:&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to make a deep learning model that can recommend items to users based on the rating that they&amp;#39;ve given other items.&lt;/p&gt;

&lt;p&gt;And I kind of understand how to do this.&lt;/p&gt;

&lt;p&gt;But now comes the part that confuses me, let&amp;#39;s say I deploy this model on my website. But then an existing user rates some new items or what if it&amp;#39;s an entirely new user that is not known by the model? Do I then need to retrain my entire model?&lt;/p&gt;

&lt;p&gt;Or is there some way to make a recommender model that can make recommendations for users without retraining the entire model again?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve tried googling this, but I can&amp;#39;t seem to find an answer anywhere(or I&amp;#39;m not searching for the right words)&lt;/p&gt;

&lt;p&gt;Anyone have a suggestion that can push me in the right direction?&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kvpezp,True,,EntrepreneurAmazing4,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kvpezp/recommendations_for_new_users/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvpezp/recommendations_for_new_users/,22217,1610448422.0,0,,False,,,,,,,,,
236,,tensorflow,,t2_107m07,False,,0,False,Help! Using keras Cnn with sklearn handwritten digits dataset,[],r/tensorflow,False,6,,0,140.0,,False,t3_kvutzd,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/Oy-O2C2j7SnpvE3X3jRWIlixyEiGW-r0gjso8Ox7cEY.jpg,False,,[],{},,False,,1610497440.0,text,6,,,text,reddit.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kvutzd,True,,Lucster12,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kvutzd/help_using_keras_cnn_with_sklearn_handwritten/,all_ads,False,https://www.reddit.com/gallery/kvutzd,22217,1610468640.0,0,,False,,https://www.reddit.com/gallery/kvutzd,,True,"{'4u3vti5kgxa61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 34, 'x': 108, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=16b1d2b29fa5c8c0b9147313e80431324dbfb4d7'}, {'y': 68, 'x': 216, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9fa0b4fada537aa9b9aca206bef44401bdf028f8'}, {'y': 101, 'x': 320, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=97c07e2e093df15f11e6f0da396f829d0cba110d'}, {'y': 202, 'x': 640, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=754c5e790c6c31b95e47bf0bb163cf0592387b4a'}, {'y': 303, 'x': 960, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7a255bc5168346921590db61958b446a210ab3c'}, {'y': 340, 'x': 1080, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77026f9e2190941b68e1a6d1f7a3bf1c5decb378'}], 's': {'y': 411, 'x': 1302, 'u': 'https://preview.redd.it/4u3vti5kgxa61.jpg?width=1302&amp;format=pjpg&amp;auto=webp&amp;s=fdc8578e5cc8a29df58b4f0c49abe1366ed8d1cf'}, 'id': '4u3vti5kgxa61'}, '1t3bf8fegxa61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 111, 'x': 108, 'u': 'https://preview.redd.it/1t3bf8fegxa61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2ce4cc5c51fcab5e8f5cd957dfdad3ed544183b'}, {'y': 222, 'x': 216, 'u': 'https://preview.redd.it/1t3bf8fegxa61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc52ba0ae098f7fc8d604148d40f510d0439e614'}, {'y': 329, 'x': 320, 'u': 'https://preview.redd.it/1t3bf8fegxa61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=776ee20e4a67d8de080816b0fe52ebf01ba619e9'}, {'y': 658, 'x': 640, 'u': 'https://preview.redd.it/1t3bf8fegxa61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=215afee48d91dc9503e213a39ce3f694c88b1adb'}], 's': {'y': 681, 'x': 662, 'u': 'https://preview.redd.it/1t3bf8fegxa61.jpg?width=662&amp;format=pjpg&amp;auto=webp&amp;s=0aab1d7a6a0a1afb55f63b146eeb29acad6305a3'}, 'id': '1t3bf8fegxa61'}}","{'items': [{'media_id': '1t3bf8fegxa61', 'id': 22026291}, {'media_id': '4u3vti5kgxa61', 'id': 22026292}]}",,,
237,,tensorflow,"So I'm completely new to Machine Learning and Tensorflow. I'm looking to run through a Tensorflow tutorial to ""build my first Neural network"" ([https://www.tensorflow.org/tutorials/quickstart/beginner](https://www.tensorflow.org/tutorials/quickstart/beginner)) but I want to start working on something myself pretty soon after.

Being from a Web Developer background I have tried to look into this myself but I am finding it hard to work out the specific roles that Anaconda/Jupyter Notebook/PyCharm etc would play and if there is some crossover between their use-cases?

If someone summarise what I will need to set up locally to be able to follow the above tutorial and to get started with some stuff of my own afterwards it would be hugely appreciated! (also, apologies if the terminology I'm using is totally wrong here - and please let me know if so)",t2_5b3oq2i6,False,,0,False,Tensorflow newbie local setup,[],r/tensorflow,False,6,,0,,,False,t3_kvqjlt,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1610482437.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;m completely new to Machine Learning and Tensorflow. I&amp;#39;m looking to run through a Tensorflow tutorial to &amp;quot;build my first Neural network&amp;quot; (&lt;a href=""https://www.tensorflow.org/tutorials/quickstart/beginner""&gt;https://www.tensorflow.org/tutorials/quickstart/beginner&lt;/a&gt;) but I want to start working on something myself pretty soon after.&lt;/p&gt;

&lt;p&gt;Being from a Web Developer background I have tried to look into this myself but I am finding it hard to work out the specific roles that Anaconda/Jupyter Notebook/PyCharm etc would play and if there is some crossover between their use-cases?&lt;/p&gt;

&lt;p&gt;If someone summarise what I will need to set up locally to be able to follow the above tutorial and to get started with some stuff of my own afterwards it would be hugely appreciated! (also, apologies if the terminology I&amp;#39;m using is totally wrong here - and please let me know if so)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kvqjlt,True,,eggywhipple,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kvqjlt/tensorflow_newbie_local_setup/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvqjlt/tensorflow_newbie_local_setup/,22217,1610453637.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
238,,tensorflow,"While using  tf.gradientTape for training a custom model with custom loss function. In tape.gradient(loss, trainablevalues)

 
Does the loss has to be total loss of the batch or should be an array of losses of batch size.",t2_61xce2yo,False,,0,False,Tensorflow tf.gradient doubt about custom loss function,[],r/tensorflow,False,6,,0,,,False,t3_kvpujk,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1610479222.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;While using  tf.gradientTape for training a custom model with custom loss function. In tape.gradient(loss, trainablevalues)&lt;/p&gt;

&lt;p&gt;Does the loss has to be total loss of the batch or should be an array of losses of batch size.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kvpujk,True,,MBR105,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kvpujk/tensorflow_tfgradient_doubt_about_custom_loss/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvpujk/tensorflow_tfgradient_doubt_about_custom_loss/,22217,1610450422.0,0,,False,,,,,,,,,
239,,tensorflow,"Hello everyone,

For the past few months I've been attempting to set up a custom object detector with Tensorflow 2, without succes.

I followed this guide to train a model: [https://www.youtube.com/watch?v=cvyDYdI2nEI](https://www.youtube.com/watch?v=cvyDYdI2nEI)

I tried to load this model and run inference on it by modifying this file: [https://github.com/TannerGilbert/Tensorflow-Object-Detection-with-Tensorflow-2.0/blob/master/live\_object\_detection.ipynb](https://github.com/TannerGilbert/Tensorflow-Object-Detection-with-Tensorflow-2.0/blob/master/live_object_detection.ipynb)

However, I've been unsuccessful in doing that, I always run into an unknown error that I can't seem to fix.

Does anyone happen to have an example file or tutorial that they're willing to share with me? It doesn't necessarily have to be with video stream, I would just like to see how to properly train and load a custom model and run inference on something. Doesn't matter if it's images, video or stream.

It feels like I've been stuck on this for ages and I can't seem to find the info I need online.

Thanks in advance!",t2_14tmdx,False,,0,False,Tensorflow 2 object detection(video stream) with custom model,[],r/tensorflow,False,6,,0,,,False,t3_kvri1e,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610486335.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;For the past few months I&amp;#39;ve been attempting to set up a custom object detector with Tensorflow 2, without succes.&lt;/p&gt;

&lt;p&gt;I followed this guide to train a model: &lt;a href=""https://www.youtube.com/watch?v=cvyDYdI2nEI""&gt;https://www.youtube.com/watch?v=cvyDYdI2nEI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I tried to load this model and run inference on it by modifying this file: &lt;a href=""https://github.com/TannerGilbert/Tensorflow-Object-Detection-with-Tensorflow-2.0/blob/master/live_object_detection.ipynb""&gt;https://github.com/TannerGilbert/Tensorflow-Object-Detection-with-Tensorflow-2.0/blob/master/live_object_detection.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, I&amp;#39;ve been unsuccessful in doing that, I always run into an unknown error that I can&amp;#39;t seem to fix.&lt;/p&gt;

&lt;p&gt;Does anyone happen to have an example file or tutorial that they&amp;#39;re willing to share with me? It doesn&amp;#39;t necessarily have to be with video stream, I would just like to see how to properly train and load a custom model and run inference on something. Doesn&amp;#39;t matter if it&amp;#39;s images, video or stream.&lt;/p&gt;

&lt;p&gt;It feels like I&amp;#39;ve been stuck on this for ages and I can&amp;#39;t seem to find the info I need online.&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kvri1e,True,,007Nick700,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kvri1e/tensorflow_2_object_detectionvideo_stream_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvri1e/tensorflow_2_object_detectionvideo_stream_with/,22217,1610457535.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?auto=webp&amp;s=dc4543d85718840fe61064d95252b5e4e849a011', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c860d6659775a902cb2c1e09d86cab25d124dd4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3df8fecc8ce7bd4502912064322431c09f60be87', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d8b6508d3c6737132c1252e272a13b266b96955', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'ADIqgKOaM8izkrToP2DHSC1LoPPLKoeG599X_jYuifA'}], 'enabled': False}",,,,,,
240,,tensorflow,"I published a tutorial where I explain how to build AutoEncoders with Python + Keras. In particular, in this video you’ll learn how to chain encoder + decoder architectures I already implemented in previous videos to create an autoencoder. You’ll also learn to train an autoencoder with the MNIST dataset.

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

[https://www.youtube.com/watch?v=6fZdJKm-fSk&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=6](https://www.youtube.com/watch?v=6fZdJKm-fSk&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=6)",t2_12ahau,False,,0,False,I published a tutorial that shows how to create and train an autoencoder with Keras,[],r/tensorflow,False,6,,0,,,False,t3_kv2o41,False,dark,0.93,,public,25,0,{},,,False,[],,False,False,,{},Project,False,25,,False,self,False,,[],{},,True,,1610400640.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I published a tutorial where I explain how to build AutoEncoders with Python + Keras. In particular, in this video you’ll learn how to chain encoder + decoder architectures I already implemented in previous videos to create an autoencoder. You’ll also learn to train an autoencoder with the MNIST dataset.&lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files and spectrograms 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=6fZdJKm-fSk&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=6""&gt;https://www.youtube.com/watch?v=6fZdJKm-fSk&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=6&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kv2o41,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kv2o41/i_published_a_tutorial_that_shows_how_to_create/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kv2o41/i_published_a_tutorial_that_shows_how_to_create/,22217,1610371840.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/l7l-V8hqwCX4OpyDpcwOytghQquavXtMlwaDiUn1Ie0.jpg?auto=webp&amp;s=abb145830fcbd1014c4cc34403771555517a8209', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/l7l-V8hqwCX4OpyDpcwOytghQquavXtMlwaDiUn1Ie0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=947971cec3d2d68c20eccc973f5ab8a8c4658ce5', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/l7l-V8hqwCX4OpyDpcwOytghQquavXtMlwaDiUn1Ie0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4409b053ef08facc7ffb8868ff5fd3204390d6eb', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/l7l-V8hqwCX4OpyDpcwOytghQquavXtMlwaDiUn1Ie0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=484d9e6e995151c06876a2b7c27d3e8e053c961d', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'SfN1Qlrts1ZYn-BWCKdYHmeexqJEY3hgydCoAlJlgKk'}], 'enabled': False}",,,,,,
241,,tensorflow,,t2_rpyiu,False,,0,False,"get_vocabulary() not reading some characters (ç), I need help!",[],r/tensorflow,False,6,,0,140.0,,False,t3_kvioi4,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},Question,False,2,,False,https://b.thumbs.redditmedia.com/IE6JK9SaAPz1hkmQdZFI0slQ6iS9GEKX2ScTzVWU7vo.jpg,False,,[],{},,False,,1610448831.0,text,6,,,text,stackoverflow.com,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kvioi4,True,,TobiaF,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kvioi4/get_vocabulary_not_reading_some_characters_ç_i/,all_ads,False,https://stackoverflow.com/questions/65660192/tf-keras-layers-experimental-preprocessing-textvectorization-get-vocabulary,22217,1610420031.0,0,,False,link,https://stackoverflow.com/questions/65660192/tf-keras-layers-experimental-preprocessing-textvectorization-get-vocabulary,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
242,,tensorflow,"I created **Kerod** a pure tensorflow 2 implementation of object detection algorithms (Faster R-CNN, DeTr) aiming production. It stands for Keras Object Detection.

It aims to build a clear, reusable, tested, simple and documented codebase for tensorflow 2.X.

You'll be able to train models on COCO, Pascal VOC just by launching the notebooks.

Here a link of the project: [https://github.com/EmGarr/kerod](https://github.com/EmGarr/kerod).

Hope it will helps!",t2_8w1s22sa,False,,0,False,Object detection in tensorflow 2.X,[],r/tensorflow,False,6,,0,,,False,t3_kvalla,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Project,False,5,,False,self,False,,[],{},,True,,1610423822.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I created &lt;strong&gt;Kerod&lt;/strong&gt; a pure tensorflow 2 implementation of object detection algorithms (Faster R-CNN, DeTr) aiming production. It stands for Keras Object Detection.&lt;/p&gt;

&lt;p&gt;It aims to build a clear, reusable, tested, simple and documented codebase for tensorflow 2.X.&lt;/p&gt;

&lt;p&gt;You&amp;#39;ll be able to train models on COCO, Pascal VOC just by launching the notebooks.&lt;/p&gt;

&lt;p&gt;Here a link of the project: &lt;a href=""https://github.com/EmGarr/kerod""&gt;https://github.com/EmGarr/kerod&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Hope it will helps!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kvalla,True,,Em_Garr,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kvalla/object_detection_in_tensorflow_2x/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvalla/object_detection_in_tensorflow_2x/,22217,1610395022.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WVCIAFpWYxFNdj7hbxdWb1WlrE0W1uVDgBXOGihspQg.jpg?auto=webp&amp;s=f2419f0f4833b5e387d9d41c000604a50bf0f0ea', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/WVCIAFpWYxFNdj7hbxdWb1WlrE0W1uVDgBXOGihspQg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7175dce70734444bee00dbb4d1dbc0a7b749602d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/WVCIAFpWYxFNdj7hbxdWb1WlrE0W1uVDgBXOGihspQg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a4ea6e18afdb39d2f273e603ea52bd7562f85d8', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/WVCIAFpWYxFNdj7hbxdWb1WlrE0W1uVDgBXOGihspQg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3fac852c8828421ca9353dc08a8be9a7546a575', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'u56imD8G45O_UzkyB_NETKiEqAs-dX8oq9niB2wbKLk'}], 'enabled': False}",,,,,,
243,,tensorflow,"I'm trying to train an object detector with TensorFlow. I downloaded the pre-trained model ssd\_mobilenet\_v2\_coco\_2018\_01\_28, created my .pbtxt file, my train and test records.

I'm using the model\_main.py which is in TensorFlow / models / research / object-detection

When I try to start training ""python model\_main.py --logtostderr model\_dir = results / --pipeline\_config\_path = training / ssd\_mobilenet\_v1\_pets.config --model\_dir = ssd\_mobilenet\_v1\_coco\_2018\_01\_28 /""

the following appears:

INFO:tensorflow:Skipping training since max\_steps has already saved.

I0111 23:57:18.103509 139762259621696 [estimator.py:360](https://estimator.py:360)\] Skipping training since max\_steps has already saved.

Does anyone know how to fix it ?",t2_6dk8qe5z,False,,0,False,Training not working.,[],r/tensorflow,False,6,,0,,,False,t3_kvktp8,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610456320.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to train an object detector with TensorFlow. I downloaded the pre-trained model ssd_mobilenet_v2_coco_2018_01_28, created my .pbtxt file, my train and test records.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using the model_main.py which is in TensorFlow / models / research / object-detection&lt;/p&gt;

&lt;p&gt;When I try to start training &amp;quot;python model_main.py --logtostderr model_dir = results / --pipeline_config_path = training / ssd_mobilenet_v1_pets.config --model_dir = ssd_mobilenet_v1_coco_2018_01_28 /&amp;quot;&lt;/p&gt;

&lt;p&gt;the following appears:&lt;/p&gt;

&lt;p&gt;INFO:tensorflow:Skipping training since max_steps has already saved.&lt;/p&gt;

&lt;p&gt;I0111 23:57:18.103509 139762259621696 &lt;a href=""https://estimator.py:360""&gt;estimator.py:360&lt;/a&gt;] Skipping training since max_steps has already saved.&lt;/p&gt;

&lt;p&gt;Does anyone know how to fix it ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kvktp8,True,,legendarypegasus,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kvktp8/training_not_working/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvktp8/training_not_working/,22217,1610427520.0,0,,False,,,,,,,,,
244,,tensorflow,"Hi /r/tensorflow,  


I am deeply learning a lot about steep learning curves! (hopefully the curve has a trend downward like a nice tensorboard loss graph...) Learning on my own can be tough sometimes.   


I am wondering if anyone has experience deploying TensorFlow models to nvidia's platforms and if they could help me out with some tips on how to get from a to b to c all the way to output tensor of a beautiful object detection deployment on my jetson.",t2_9ctqwmw9,False,,0,False,Question on portability to nvidia deepstream and tensorrt,[],r/tensorflow,False,6,,0,,,False,t3_kvhpwt,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1610445514.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/tensorflow""&gt;/r/tensorflow&lt;/a&gt;,  &lt;/p&gt;

&lt;p&gt;I am deeply learning a lot about steep learning curves! (hopefully the curve has a trend downward like a nice tensorboard loss graph...) Learning on my own can be tough sometimes.   &lt;/p&gt;

&lt;p&gt;I am wondering if anyone has experience deploying TensorFlow models to nvidia&amp;#39;s platforms and if they could help me out with some tips on how to get from a to b to c all the way to output tensor of a beautiful object detection deployment on my jetson.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kvhpwt,True,,BeatUpStudent,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kvhpwt/question_on_portability_to_nvidia_deepstream_and/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kvhpwt/question_on_portability_to_nvidia_deepstream_and/,22217,1610416714.0,0,,False,,,,,,,,,
245,,tensorflow,"Hey guys, so I also made this stackoverflow post if you want to see it: https://stackoverflow.com/questions/65662127/what-is-the-equivalent-of-get-collection-for-the-frozen-inference-model

So when testing my predictions are correct on the model, normally I write get_collection(""logits""). 

However, for a .pb/inference model I can't do this anymore because the saver.restore only works for checkpoints, not .pb, so even though I can get tensors, I'm not sure how to get this.

What is the equivalent action for the inference model?",t2_kplhh,False,,0,False,"get_collection doesn't work unless I use a checkpoint, what's the equivalent for a .pb?",[],r/tensorflow,False,6,,0,,,False,t3_kux20s,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1610375366.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, so I also made this stackoverflow post if you want to see it: &lt;a href=""https://stackoverflow.com/questions/65662127/what-is-the-equivalent-of-get-collection-for-the-frozen-inference-model""&gt;https://stackoverflow.com/questions/65662127/what-is-the-equivalent-of-get-collection-for-the-frozen-inference-model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So when testing my predictions are correct on the model, normally I write get_collection(&amp;quot;logits&amp;quot;). &lt;/p&gt;

&lt;p&gt;However, for a .pb/inference model I can&amp;#39;t do this anymore because the saver.restore only works for checkpoints, not .pb, so even though I can get tensors, I&amp;#39;m not sure how to get this.&lt;/p&gt;

&lt;p&gt;What is the equivalent action for the inference model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kux20s,True,,Vendredi46,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kux20s/get_collection_doesnt_work_unless_i_use_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kux20s/get_collection_doesnt_work_unless_i_use_a/,22217,1610346566.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
246,,tensorflow,"So we bought two 3070 GPU to replace our 2070 SUPER awaiting increase in inference performance, but instead the results are worse in almost 2 times.

We are using Unet with mobilenetv2 backbone and quite big input image (1024x320x3). I measured inference time with 2070s and it was around 50ms. Then I installed tf 2.4 with new cuda and cudnn, switched GPU to 3070, switched cuda path, solved several tensorflow issues copying and renaming some CUDA libs and ran the same code. The result time is around 90ms. I tried different cuda versions but seems like 11.1 is the one I need, but still results remain the same. Target application requires tensorflow.dll because it uses C API and results are the same as python.

Has anyone encountered poor inference performance with 30xx series? It has almost twice more cuda cores then 2070s so I thought that inference performance would be better. What else I can try to do to improve inference time with C API libs (I'm not compiling it myself, I download them from tensorflow site)? Maybe my models need to be somehow optimized for new cuda?",t2_3du8jurt,False,,0,False,3070 tf 2.4 poor inference performance compared to 2070s tf 2.3,[],r/tensorflow,False,6,,0,,,False,t3_kuenlx,False,dark,0.95,,public,16,0,{},,,False,[],,False,False,,{},Question,False,16,,False,self,False,,[],{},,True,,1610314934.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So we bought two 3070 GPU to replace our 2070 SUPER awaiting increase in inference performance, but instead the results are worse in almost 2 times.&lt;/p&gt;

&lt;p&gt;We are using Unet with mobilenetv2 backbone and quite big input image (1024x320x3). I measured inference time with 2070s and it was around 50ms. Then I installed tf 2.4 with new cuda and cudnn, switched GPU to 3070, switched cuda path, solved several tensorflow issues copying and renaming some CUDA libs and ran the same code. The result time is around 90ms. I tried different cuda versions but seems like 11.1 is the one I need, but still results remain the same. Target application requires tensorflow.dll because it uses C API and results are the same as python.&lt;/p&gt;

&lt;p&gt;Has anyone encountered poor inference performance with 30xx series? It has almost twice more cuda cores then 2070s so I thought that inference performance would be better. What else I can try to do to improve inference time with C API libs (I&amp;#39;m not compiling it myself, I download them from tensorflow site)? Maybe my models need to be somehow optimized for new cuda?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kuenlx,True,,gogasius,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kuenlx/3070_tf_24_poor_inference_performance_compared_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kuenlx/3070_tf_24_poor_inference_performance_compared_to/,22217,1610286134.0,0,,False,,,,,,,,,True
247,,tensorflow,"Here's the code: 

https://preview.redd.it/javwfv2vmja61.png?width=1614&amp;format=png&amp;auto=webp&amp;s=7845b10d1c6ee562c17addded5507aee493b8fa1",t2_52hj835v,False,,0,False,Can someone help to explain the written code? The code is correct but I don't understand a single thing. I am not really strong in python coding. I am sincerely grateful to anyone who could decipher the code for me. I'm a bit clueless about it.,[],r/tensorflow,False,6,,0,49.0,,False,t3_kuj7au,False,dark,0.78,,public,5,0,{},140.0,,False,[],,False,False,,{},,False,5,,False,https://b.thumbs.redditmedia.com/D6fwNknL2C_Yq_uGAoD-8ClMa3BHa4dWnp9yfOare2c.jpg,False,,[],{},,True,,1610330089.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Here&amp;#39;s the code: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/javwfv2vmja61.png?width=1614&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7845b10d1c6ee562c17addded5507aee493b8fa1""&gt;https://preview.redd.it/javwfv2vmja61.png?width=1614&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7845b10d1c6ee562c17addded5507aee493b8fa1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kuj7au,True,,edmondoh001,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/kuj7au/can_someone_help_to_explain_the_written_code_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kuj7au/can_someone_help_to_explain_the_written_code_the/,22217,1610301289.0,0,,False,,,,,"{'javwfv2vmja61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 38, 'x': 108, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6885d2d0bdda5c12e69cfc396190acf6c15d09af'}, {'y': 76, 'x': 216, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=49e551201b4488e71084897a29f5e95867e4100e'}, {'y': 113, 'x': 320, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b152ce43cc464348114b91de6fda758b631593a'}, {'y': 227, 'x': 640, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=90d49a1d8f53a9e9753aa3ac8e9aedb6aad503ec'}, {'y': 340, 'x': 960, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=92bb89dde81d1ef6e8f0d7296468cd7efa789a78'}, {'y': 383, 'x': 1080, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=36b5f181d06d6c50e4e2bfafb6de3d680e150607'}], 's': {'y': 573, 'x': 1614, 'u': 'https://preview.redd.it/javwfv2vmja61.png?width=1614&amp;format=png&amp;auto=webp&amp;s=7845b10d1c6ee562c17addded5507aee493b8fa1'}, 'id': 'javwfv2vmja61'}}",,,,
248,,tensorflow,"I'm training models with various hyperparameters iteratively in a for loop and I want to use a keras callback to save multiple models in a folder. I have been able to save the model number in each model but now I would also like to include variables such as epoch number (and to save the model every 5 epochs). In the following code, I add 1 to counter each time my for loop runs to denote the model number.

    filepath = root_path + ""/saved_models/model_number_{}.h5"".format(counter) history = final_model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_train, y_train),shuffle=True,callbacks= tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_accuracy', verbose=0, save_weights_only=True, mode='auto', save_freq='epoch'),) 

I can also make this filepath  
to save the epoch number and accuracy in the file name but I can't join it with my model. Is there a way to do so?

    filepath = s3_root_path + ""/saved_models/weights.{epoch:02d}-{val_loss:.2f}.h5""",t2_9rd000zm,False,,0,False,Including variables in filenames,[],r/tensorflow,False,6,,0,,,False,t3_kuoj80,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1610345953.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m training models with various hyperparameters iteratively in a for loop and I want to use a keras callback to save multiple models in a folder. I have been able to save the model number in each model but now I would also like to include variables such as epoch number (and to save the model every 5 epochs). In the following code, I add 1 to counter each time my for loop runs to denote the model number.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;filepath = root_path + &amp;quot;/saved_models/model_number_{}.h5&amp;quot;.format(counter) history = final_model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_train, y_train),shuffle=True,callbacks= tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor=&amp;#39;val_accuracy&amp;#39;, verbose=0, save_weights_only=True, mode=&amp;#39;auto&amp;#39;, save_freq=&amp;#39;epoch&amp;#39;),) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I can also make this filepath&lt;br/&gt;
to save the epoch number and accuracy in the file name but I can&amp;#39;t join it with my model. Is there a way to do so?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;filepath = s3_root_path + &amp;quot;/saved_models/weights.{epoch:02d}-{val_loss:.2f}.h5&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kuoj80,True,,Zealousideal-Bat-863,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kuoj80/including_variables_in_filenames/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kuoj80/including_variables_in_filenames/,22217,1610317153.0,0,,False,,,,,,,,,
249,,tensorflow,"Hello guys :)

I have a problem regarding CUDA GPU support on my laptop. I described the problem in detail here:  
[https://www.reddit.com/r/learnmachinelearning/comments/ktxjth/gpu\_support\_not\_working\_correctly/](https://www.reddit.com/r/learnmachinelearning/comments/ktxjth/gpu_support_not_working_correctly/)

I used `tf.config.experimental.set_memory_growth(physical_devices[0], True)` and my GPU memory usage is only at \~25%, so that's not the problem.

If  there is anything important I forgot to mention, please tell me, I'm  happy to provide more information if I am able to give it to you.

I appreciate your help very much! :)",t2_857yddhe,False,,0,False,GPU Support not working correctly,[],r/tensorflow,False,6,,0,,,False,t3_kud4q3,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610308091.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys :)&lt;/p&gt;

&lt;p&gt;I have a problem regarding CUDA GPU support on my laptop. I described the problem in detail here:&lt;br/&gt;
&lt;a href=""https://www.reddit.com/r/learnmachinelearning/comments/ktxjth/gpu_support_not_working_correctly/""&gt;https://www.reddit.com/r/learnmachinelearning/comments/ktxjth/gpu_support_not_working_correctly/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I used &lt;code&gt;tf.config.experimental.set_memory_growth(physical_devices[0], True)&lt;/code&gt; and my GPU memory usage is only at ~25%, so that&amp;#39;s not the problem.&lt;/p&gt;

&lt;p&gt;If  there is anything important I forgot to mention, please tell me, I&amp;#39;m  happy to provide more information if I am able to give it to you.&lt;/p&gt;

&lt;p&gt;I appreciate your help very much! :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kud4q3,True,,pm3esa91t8nm,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kud4q3/gpu_support_not_working_correctly/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kud4q3/gpu_support_not_working_correctly/,22217,1610279291.0,0,,False,,,,,,,,,
250,,tensorflow,,t2_1krqyfrs,False,,0,False,Pan Tilt Camera Project using the Raspberry Pi and OpenCV AI Kit in real-time,[],r/tensorflow,False,6,,0,140.0,,False,t3_ktpbzp,False,dark,0.89,,public,85,0,{},140.0,,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/ufen6evllaa61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1080, 'scrubber_media_url': 'https://v.redd.it/ufen6evllaa61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/ufen6evllaa61/DASHPlaylist.mpd?a=1618044698%2CODFiYzIxNDIyMTljMmNhM2EzOGQ1MjFmODdlNGEyMjViYjU5ZjQ5N2EwZDhiZmQzOTcyOTg5MmM3MWE3Y2EyNw%3D%3D&amp;v=1&amp;f=sd', 'duration': 51, 'hls_url': 'https://v.redd.it/ufen6evllaa61/HLSPlaylist.m3u8?a=1618044698%2CMzY3Y2I4ZjdlZGViNDg2YTAzMThmZGM0YmRkODVkNmQwYjE0MWFkNmY1Y2ZkODVlZGU5MTFjODQxMmQ5OWNjYQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},Project,False,85,,False,https://a.thumbs.redditmedia.com/KasY9QaLUWPlMx0hnvbvc-BRE2s9fqbJaOVfcLEf2y8.jpg,False,,[],{},,False,,1610220696.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,ktpbzp,True,,AugmentedStartups,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/ktpbzp/pan_tilt_camera_project_using_the_raspberry_pi/,all_ads,False,https://v.redd.it/ufen6evllaa61,22217,1610191896.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/ufen6evllaa61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1080, 'scrubber_media_url': 'https://v.redd.it/ufen6evllaa61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/ufen6evllaa61/DASHPlaylist.mpd?a=1618044698%2CODFiYzIxNDIyMTljMmNhM2EzOGQ1MjFmODdlNGEyMjViYjU5ZjQ5N2EwZDhiZmQzOTcyOTg5MmM3MWE3Y2EyNw%3D%3D&amp;v=1&amp;f=sd', 'duration': 51, 'hls_url': 'https://v.redd.it/ufen6evllaa61/HLSPlaylist.m3u8?a=1618044698%2CMzY3Y2I4ZjdlZGViNDg2YTAzMThmZGM0YmRkODVkNmQwYjE0MWFkNmY1Y2ZkODVlZGU5MTFjODQxMmQ5OWNjYQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/ufen6evllaa61,"{'images': [{'source': {'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?format=pjpg&amp;auto=webp&amp;s=14b2186fdd0c7040c079d0d951ca71a486a46506', 'width': 1080, 'height': 1080}, 'resolutions': [{'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b1e4f86eb0670bc9b2dd69287493ddbddd941a72', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=11fb6439a4ab3edee603e04e5db851dc0718ff0d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a78aa4aaf116b651cde0d6f1821bce294966a544', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b824013e17d824fc5fdd3702270fbf233ca3e1a4', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3072c0bfd7f91ca89d7905a52d6e94830823c66f', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/uJwftRUKolLLCnUqicZlSpE1tpQBAqD3z5ESKyIWltE.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d10ba2fe7df320824b255ef11c79e7a012996521', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': '9vSXFodRqPfRZP1J2r6TsvP7-aIyPcZeZ7jBPuEmx_k'}], 'enabled': False}",,,,,,
251,,tensorflow,"Hello everyone, I am starting to use tensorflow and I would like to know if you can recommend an updated tutorial on how to create my own object detector using the tensorflow api (learning transfer), thanks !!",t2_6dk8qe5z,False,,0,False,train model with tensorflow api,[],r/tensorflow,False,6,,0,,,False,t3_ku33b2,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Project,False,4,,False,self,False,,[],{},,True,,1610266746.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, I am starting to use tensorflow and I would like to know if you can recommend an updated tutorial on how to create my own object detector using the tensorflow api (learning transfer), thanks !!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,ku33b2,True,,legendarypegasus,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ku33b2/train_model_with_tensorflow_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ku33b2/train_model_with_tensorflow_api/,22217,1610237946.0,0,,False,,,,,,,,,
252,,tensorflow,"Hey,

I want to split my custom model e.g:  `class MyModel(keras.Model):`over multiply GPUs. and anything I've tried to do cause OOM exception.

what and how should I do it?

thanks in advanced!

&amp;#x200B;

some background:

I'm trying to implement the followed paper:

Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders  -[https://arxiv.org/abs/1704.01279](https://arxiv.org/abs/1704.01279)

but the large input (64K vector) with the deep WaveNet decoder cause OOM exception.

&amp;#x200B;

I have multiply GPUs and when creating a layer I'm doing it under a specific GPU but when I'm applying the gradients they all located on the same GPU (the default one, GPU0) and that causes OOM.

the train step is a custom one as well as the model.",t2_53w2juhn,False,,0,False,how to implement: Model parallelism in TF2,[],r/tensorflow,False,6,,0,,,False,t3_ktxjr8,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1610249312.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey,&lt;/p&gt;

&lt;p&gt;I want to split my custom model e.g:  &lt;code&gt;class MyModel(keras.Model):&lt;/code&gt;over multiply GPUs. and anything I&amp;#39;ve tried to do cause OOM exception.&lt;/p&gt;

&lt;p&gt;what and how should I do it?&lt;/p&gt;

&lt;p&gt;thanks in advanced!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;some background:&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to implement the followed paper:&lt;/p&gt;

&lt;p&gt;Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders  -&lt;a href=""https://arxiv.org/abs/1704.01279""&gt;https://arxiv.org/abs/1704.01279&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but the large input (64K vector) with the deep WaveNet decoder cause OOM exception.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have multiply GPUs and when creating a layer I&amp;#39;m doing it under a specific GPU but when I&amp;#39;m applying the gradients they all located on the same GPU (the default one, GPU0) and that causes OOM.&lt;/p&gt;

&lt;p&gt;the train step is a custom one as well as the model.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ktxjr8,True,,ori_yt,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/ktxjr8/how_to_implement_model_parallelism_in_tf2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ktxjr8/how_to_implement_model_parallelism_in_tf2/,22217,1610220512.0,0,,False,,,,,,,,,
253,,tensorflow,"My X_train has 316175 samples and I am trying to fit it on a sequential model. But after running fit method, the number of samples shows up to be 1236 during each epoch. Here's how I am fitting the model.

    model.fit(x=X_train, y=y_train, epochs=25, batch_size=256, validation_data=(X_test,y_test))

I cannot understand why it is not using all the samples. Can someone please help?",t2_y91om,False,,0,False,Number of training samples during fit is less than the original number of training samples,[],r/tensorflow,False,6,,0,,,False,t3_ktwxtz,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610247461.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My X_train has 316175 samples and I am trying to fit it on a sequential model. But after running fit method, the number of samples shows up to be 1236 during each epoch. Here&amp;#39;s how I am fitting the model.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.fit(x=X_train, y=y_train, epochs=25, batch_size=256, validation_data=(X_test,y_test))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I cannot understand why it is not using all the samples. Can someone please help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ktwxtz,True,,protokoul,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ktwxtz/number_of_training_samples_during_fit_is_less/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ktwxtz/number_of_training_samples_during_fit_is_less/,22217,1610218661.0,0,,False,,,,,,,,,
254,,tensorflow,,t2_5z1hrtz2,False,,0,False,Model Compression with TensorFlow Lite: A Look into Reducing Model Size,[],r/tensorflow,False,6,,0,140.0,,False,t3_ktvv28,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Project,False,1,,False,https://b.thumbs.redditmedia.com/6JadJmbBkfsy84EQtNNHedBDUAzD8_iwL76MjXKZNIU.jpg,False,,[],{},,False,,1610244232.0,text,6,,,text,towardsdatascience.com,False,,,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,ktvv28,True,,beta_lasagna,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ktvv28/model_compression_with_tensorflow_lite_a_look/,all_ads,False,https://towardsdatascience.com/model-compression-a-look-into-reducing-model-size-8251683c338e,22217,1610215432.0,0,,False,link,https://towardsdatascience.com/model-compression-a-look-into-reducing-model-size-8251683c338e,"{'images': [{'source': {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?auto=webp&amp;s=8817994f3bb7958a1d0c9e19ec140e0ecbb235dc', 'width': 1200, 'height': 1250}, 'resolutions': [{'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9be5a4a2b0155ecfafdc6131b9bb323431d29932', 'width': 108, 'height': 112}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe797dd999067194ca2bb0ce61df57d901920a3c', 'width': 216, 'height': 225}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ff2e4cd7f3f8a92bb23d5b663a746e580ab8943', 'width': 320, 'height': 333}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4f50988a30c194e7b696cac7a077c95693d4dd15', 'width': 640, 'height': 666}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c51eae44e87a2729505edd99508c1fbe4da13768', 'width': 960, 'height': 1000}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=df49cfd82dcdd05b954585271053d17e77730427', 'width': 1080, 'height': 1125}], 'variants': {}, 'id': 'qIc50ZTCH8_msySKz5Vm-Ks6gisZiuI4d5wkdav8b5A'}], 'enabled': False}",,,,,,
255,,tensorflow,I know the Tensorflow discord is pretty dead. Stackoverflow keeps downvoting me. Is there any way I can please get help on my problem \*error\*. Is there a community of some sort!?,t2_6cpgks1a,False,,0,False,Tensorflow Support,[],r/tensorflow,False,6,,0,,,False,t3_ktv9r5,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1610242481.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know the Tensorflow discord is pretty dead. Stackoverflow keeps downvoting me. Is there any way I can please get help on my problem *error*. Is there a community of some sort!?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ktv9r5,True,,RicardoCarlos55,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/ktv9r5/tensorflow_support/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ktv9r5/tensorflow_support/,22217,1610213681.0,0,,False,,,,,,,,,
256,,tensorflow,"I am getting this error when trying to set up distributed learning and disabling autoshard.  To do this I need to make TensorSlices and when I set the model up, I get this error:
``ValueError: `y` argument is not supported when using dataset as input.``  What can I do to my model.fit to make this work?",t2_71dtn57o,False,,0,False,"How to turn X_train, y_train into one dataset for distributed learning?",[],r/tensorflow,False,6,,0,,,False,t3_ktu9od,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610239537.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am getting this error when trying to set up distributed learning and disabling autoshard.  To do this I need to make TensorSlices and when I set the model up, I get this error:
&lt;code&gt;ValueError: `y` argument is not supported when using dataset as input.&lt;/code&gt;  What can I do to my model.fit to make this work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ktu9od,True,,zukocodes,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ktu9od/how_to_turn_x_train_y_train_into_one_dataset_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ktu9od/how_to_turn_x_train_y_train_into_one_dataset_for/,22217,1610210737.0,0,,False,,,,,,,,,
257,,tensorflow,"In short:

Is there a true low-level manual with details on the working of TF 2.0 so I can learn WTF tf.cond, tf.where and all other stuff which is used in tf source code. I don't need high level api manuals with keras.Layers Sequential Model etc... High level is not what I need. 

In long:

Hi, I know c#, js, php, python etc. but my progress in TF api is stale. TF api is like **a bird** language to me.

I can make some Sequential models, build some data pipeline using pure python etc. ..

but making anything non-standard which is not covered by manuals is impossible to me. I've spend a week in vein trying to convert string to onehot vector the way I need it for my model (there were some minor impementation non-standard requirements).   


I need a book/blog where details like: 

&gt;where if-then statments are not allowed  
where they are allowed  
what to do if you can't use if-then  
all the basic stuff for tf2.0

I need low-level tf2.0 api manual for complete idiots which can make me into ""**a bird**"" with native knowledge of this God forsaken api!. :",t2_10z1pk,False,,0,False,an Advice for a novice. Please.,[],r/tensorflow,False,6,,0,,,False,t3_ktslx9,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1610234102.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In short:&lt;/p&gt;

&lt;p&gt;Is there a true low-level manual with details on the working of TF 2.0 so I can learn WTF tf.cond, tf.where and all other stuff which is used in tf source code. I don&amp;#39;t need high level api manuals with keras.Layers Sequential Model etc... High level is not what I need. &lt;/p&gt;

&lt;p&gt;In long:&lt;/p&gt;

&lt;p&gt;Hi, I know c#, js, php, python etc. but my progress in TF api is stale. TF api is like &lt;strong&gt;a bird&lt;/strong&gt; language to me.&lt;/p&gt;

&lt;p&gt;I can make some Sequential models, build some data pipeline using pure python etc. ..&lt;/p&gt;

&lt;p&gt;but making anything non-standard which is not covered by manuals is impossible to me. I&amp;#39;ve spend a week in vein trying to convert string to onehot vector the way I need it for my model (there were some minor impementation non-standard requirements).   &lt;/p&gt;

&lt;p&gt;I need a book/blog where details like: &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;where if-then statments are not allowed&lt;br/&gt;
where they are allowed&lt;br/&gt;
what to do if you can&amp;#39;t use if-then&lt;br/&gt;
all the basic stuff for tf2.0&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I need low-level tf2.0 api manual for complete idiots which can make me into &amp;quot;&lt;strong&gt;a bird&lt;/strong&gt;&amp;quot; with native knowledge of this God forsaken api!. :&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ktslx9,True,,coobit,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/ktslx9/an_advice_for_a_novice_please/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ktslx9/an_advice_for_a_novice_please/,22217,1610205302.0,0,,False,,,,,,,,,
258,,tensorflow,"So, i've made an autoencoder for the purpose of exracting useful features from the images, a common task as far as i know, but this is my first time actually doing this so i'm not sure how exactly can i do it. I've fit a convolutional autoencoder on the set of images, now i need to extract the output of a bottleneck layer for each image i've got to construct a feature set of interest, how should i do this? I used keras sequential way of writing the code for the network",t2_wn450,False,,0,False,Extracting latent features from an autoencoder with keras,[],r/tensorflow,False,6,,0,,,False,t3_ktjpje,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1610194725.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So, i&amp;#39;ve made an autoencoder for the purpose of exracting useful features from the images, a common task as far as i know, but this is my first time actually doing this so i&amp;#39;m not sure how exactly can i do it. I&amp;#39;ve fit a convolutional autoencoder on the set of images, now i need to extract the output of a bottleneck layer for each image i&amp;#39;ve got to construct a feature set of interest, how should i do this? I used keras sequential way of writing the code for the network&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ktjpje,True,,Spectator696,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ktjpje/extracting_latent_features_from_an_autoencoder/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ktjpje/extracting_latent_features_from_an_autoencoder/,22217,1610165925.0,0,,False,,,,,,,,,
259,,tensorflow,,t2_ibs89,False,,0,False,ML Metadata: Version Control for ML,[],r/tensorflow,False,6,,0,73.0,,False,t3_kt8pkj,False,dark,1.0,,public,5,0,{},140.0,,False,[],,False,False,,{},,False,5,,False,https://a.thumbs.redditmedia.com/A5cyEmXSzCK3ySjBOFWixGMU_wdODvFHli2knmyX1i0.jpg,False,,[],{},,False,,1610160058.0,text,6,,,text,blog.tensorflow.org,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kt8pkj,True,,nbortolotti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kt8pkj/ml_metadata_version_control_for_ml/,all_ads,False,https://blog.tensorflow.org/2021/01/ml-metadata-version-control-for-ml.html,22217,1610131258.0,0,,False,link,https://blog.tensorflow.org/2021/01/ml-metadata-version-control-for-ml.html,"{'images': [{'source': {'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?auto=webp&amp;s=80c300dfc4be7aa42fc9dabaef8e4d36fb76c6ed', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a1b744388b4d2e11527d6b94a85c94cdeb53a727', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a55fbed9df6dadfee83551972426302b5ddee5cb', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3742d214d8daef3502cb3676874bd822de922162', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4e0d66b71de610437fc86980b8dc963947464f3', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bdda7651c9fc822cd898a8c66b2f0211fa78b7c9', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/1Nb2QDm727I9tC0N85-O5aKe1CMAKhA1xfd4cQBbZ4A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=08d4a9cfec1eb52156367b69a5fc86f714176f0e', 'width': 1080, 'height': 567}], 'variants': {}, 'id': '2cdqVHFLRwPlhwjCWaJyVPi-3Wl4lHoBExagYUEnf78'}], 'enabled': False}",,,,,,
260,,tensorflow,,t2_3v9pkzti,False,,0,False,How To Create your own Sign Language Translation App,[],r/tensorflow,False,6,,0,78.0,,False,t3_ktbz8z,False,dark,0.75,,public,4,0,{},140.0,,False,[],,False,False,,{},Discussion,False,4,,False,https://b.thumbs.redditmedia.com/qBES-qdU_oiMjepEcmSXHWoiLR87WkHx8epdpALhL0g.jpg,False,,[],{},,False,,1610169331.0,text,6,,,text,arian-alavi.medium.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,ktbz8z,True,,_Ari___,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ktbz8z/how_to_create_your_own_sign_language_translation/,all_ads,False,https://arian-alavi.medium.com/how-to-create-your-own-sign-language-translation-app-by-extending-signn-172b8beafbad,22217,1610140531.0,0,,False,link,https://arian-alavi.medium.com/how-to-create-your-own-sign-language-translation-app-by-extending-signn-172b8beafbad,"{'images': [{'source': {'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?auto=webp&amp;s=b32f6c0fbb8c467760f3797821fbd7bc48a6a0b8', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=676a7f07e47c8b3821dd57c61e9c9439209553c9', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3c885967f338678ed3ba204a9a3799a163d4124', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=76cc2579c5a74e82193192e9bbe460948f2d4a69', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b393b9c3c9804c2c60d02ed8b60cb1505cbb7e73', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=67d47c4a13ae959aff86d760efc382d86dc6f148', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/vMDGpqstKi38adGzXqq_20u3CE60f6gq0tzlPdLjDmE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3626f07768c8f0921e3bc03b66cb080111dfb274', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'zgnEvbRp5q78EzEmhdveu63-ndUq6l6QlOy7dSvRyN0'}], 'enabled': False}",,,,,,
261,,tensorflow,"While working on my TinyML project, I made several discoveries that I would like to share.

 I hope that with this it would be make it easier to integrate model compression into pre-existing models! 

[https://cawin-chan.medium.com/model-compression-a-look-into-reducing-model-size-8251683c338e](https://cawin-chan.medium.com/model-compression-a-look-into-reducing-model-size-8251683c338e)

[ Photo by John Cameron on Unsplash ](https://preview.redd.it/bene00f8v5a61.jpg?width=700&amp;format=pjpg&amp;auto=webp&amp;s=065d83a47749a16f59df308e5c1726955d449cf6)",t2_5z1hrtz2,False,,0,False,Model Compression with TensorFlow Lite: A Look into Reducing Model Size,[],r/tensorflow,False,6,,0,140.0,,False,t3_kt9x40,False,dark,0.6,,public,1,0,{},140.0,,False,[],,False,False,,{},Project,False,1,,False,https://b.thumbs.redditmedia.com/Ui8M5BbwDPeC2ugX1TcdaUoDWXfw-8toyblikyr6w5k.jpg,False,,[],{},,True,,1610163436.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;While working on my TinyML project, I made several discoveries that I would like to share.&lt;/p&gt;

&lt;p&gt;I hope that with this it would be make it easier to integrate model compression into pre-existing models! &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://cawin-chan.medium.com/model-compression-a-look-into-reducing-model-size-8251683c338e""&gt;https://cawin-chan.medium.com/model-compression-a-look-into-reducing-model-size-8251683c338e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/bene00f8v5a61.jpg?width=700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=065d83a47749a16f59df308e5c1726955d449cf6""&gt; Photo by John Cameron on Unsplash &lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kt9x40,True,,beta_lasagna,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kt9x40/model_compression_with_tensorflow_lite_a_look/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kt9x40/model_compression_with_tensorflow_lite_a_look/,22217,1610134636.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?auto=webp&amp;s=8817994f3bb7958a1d0c9e19ec140e0ecbb235dc', 'width': 1200, 'height': 1250}, 'resolutions': [{'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9be5a4a2b0155ecfafdc6131b9bb323431d29932', 'width': 108, 'height': 112}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe797dd999067194ca2bb0ce61df57d901920a3c', 'width': 216, 'height': 225}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ff2e4cd7f3f8a92bb23d5b663a746e580ab8943', 'width': 320, 'height': 333}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4f50988a30c194e7b696cac7a077c95693d4dd15', 'width': 640, 'height': 666}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c51eae44e87a2729505edd99508c1fbe4da13768', 'width': 960, 'height': 1000}, {'url': 'https://external-preview.redd.it/R-NS-NWcQanAagJfIIr_FIT3COKVAxlfOusqJcCmTpc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=df49cfd82dcdd05b954585271053d17e77730427', 'width': 1080, 'height': 1125}], 'variants': {}, 'id': 'qIc50ZTCH8_msySKz5Vm-Ks6gisZiuI4d5wkdav8b5A'}], 'enabled': False}",,"{'bene00f8v5a61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 112, 'x': 108, 'u': 'https://preview.redd.it/bene00f8v5a61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb695d5ca9bf9c2f126e0bf721b356bacaae58e0'}, {'y': 224, 'x': 216, 'u': 'https://preview.redd.it/bene00f8v5a61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a312efa894a3438ac64a75d936f2f0b612e1587'}, {'y': 333, 'x': 320, 'u': 'https://preview.redd.it/bene00f8v5a61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4c3bd0422a79e88a98ac8764b8679ce926e5a92'}, {'y': 666, 'x': 640, 'u': 'https://preview.redd.it/bene00f8v5a61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36f6ca59730b432227482587a05f13d68ae96d5e'}], 's': {'y': 729, 'x': 700, 'u': 'https://preview.redd.it/bene00f8v5a61.jpg?width=700&amp;format=pjpg&amp;auto=webp&amp;s=065d83a47749a16f59df308e5c1726955d449cf6'}, 'id': 'bene00f8v5a61'}}",,,,
262,,tensorflow,"I hooked up two GPUs and set up my model to run as distributed with 


``mirrored_strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:0"", ""/gpu:1""])``



``with mirrored_strategy.scope():``



``layer``



``layer``



``layer``



``output``



``compile``



and then outside of the strategy I fit the model.  I keep getting [this error](https://pastebin.com/jXFwaMg0). Can anyone help me on what to do?",t2_71dtn57o,False,,0,False,"Tensorflow aborted, core dumped? Trying to run two GPUs.",[],r/tensorflow,False,6,,0,,,False,t3_ksvrgn,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1610111434.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I hooked up two GPUs and set up my model to run as distributed with &lt;/p&gt;

&lt;p&gt;&lt;code&gt;mirrored_strategy = tf.distribute.MirroredStrategy(devices=[&amp;quot;/gpu:0&amp;quot;, &amp;quot;/gpu:1&amp;quot;])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;with mirrored_strategy.scope():&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;layer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;layer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;layer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;output&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;compile&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and then outside of the strategy I fit the model.  I keep getting &lt;a href=""https://pastebin.com/jXFwaMg0""&gt;this error&lt;/a&gt;. Can anyone help me on what to do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ksvrgn,True,,zukocodes,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/ksvrgn/tensorflow_aborted_core_dumped_trying_to_run_two/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ksvrgn/tensorflow_aborted_core_dumped_trying_to_run_two/,22217,1610082634.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;s=07c121a0180003f7373863af66192b6ff6a937da', 'width': 150, 'height': 150}, 'resolutions': [{'url': 'https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9c6a296446d05d873c629a30253398c4d29c1b', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs'}], 'enabled': False}",,,,,,
263,,tensorflow,"Im a beginner in this field and I have just gone through the following tutorial for Fashion MNIST [https://www.tensorflow.org/tutorials/keras/classification](https://www.tensorflow.org/tutorials/keras/classification)

I had a few doubts about things that weren't clearly explained in it.

When we compile the model we do:

`
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
`

I understand why the input shape is (28,28) but I don't understand what 128 means for the first Dense layer. Is it output shape? And if so why did we choose 128?

Also how does the model know that it's predicting correctly?  I'm guessing the second Dense layer outputs an array of 10 floats each of which corresponds to the probability of an input belonging to one of 10 categories. How does the model know that it has to take the maximum of this array and compare it with the train label for it to be correct?",t2_2l48bxrf,False,,0,False,Need help understand tensorflow Fashion MNIST tutorial,[],r/tensorflow,False,6,,0,,,False,t3_kszpm2,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1610103503.0,,[],{},,True,,1610129612.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im a beginner in this field and I have just gone through the following tutorial for Fashion MNIST &lt;a href=""https://www.tensorflow.org/tutorials/keras/classification""&gt;https://www.tensorflow.org/tutorials/keras/classification&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I had a few doubts about things that weren&amp;#39;t clearly explained in it.&lt;/p&gt;

&lt;p&gt;When we compile the model we do:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation=&amp;#39;relu&amp;#39;),
    tf.keras.layers.Dense(10)
])
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;I understand why the input shape is (28,28) but I don&amp;#39;t understand what 128 means for the first Dense layer. Is it output shape? And if so why did we choose 128?&lt;/p&gt;

&lt;p&gt;Also how does the model know that it&amp;#39;s predicting correctly?  I&amp;#39;m guessing the second Dense layer outputs an array of 10 floats each of which corresponds to the probability of an input belonging to one of 10 categories. How does the model know that it has to take the maximum of this array and compare it with the train label for it to be correct?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kszpm2,True,,GamerWael,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kszpm2/need_help_understand_tensorflow_fashion_mnist/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kszpm2/need_help_understand_tensorflow_fashion_mnist/,22217,1610100812.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
264,,tensorflow,"My pc has 32G Ram with Quadro M1200, I'm training on external SSD installed with Ubuntu 16.04, but it keeps giving me resourceExhaustedError. 

    $ free -h
                  total        used        free      shared  buff/cache   available
    Mem:            31G        5.6G        273M        1.2G         25G         23G
    Swap:           15G        9.0M         15G

&amp;#x200B;

    $ nvidia-smi
    Fri Jan  8 17:56:32 2021       
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |                               |                      |               MIG M. |
    |===============================+======================+======================|
    |   0  Quadro M1200        Off  | 00000000:01:00.0 Off |                  N/A |
    | N/A   52C    P0    N/A /  N/A |   3875MiB /  4046MiB |      0%      Default |
    |                               |                      |                  N/A |
    +-------------------------------+----------------------+----------------------+
                                                                                   
    +-----------------------------------------------------------------------------+
    | Processes:                                                                  |
    |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
    |        ID   ID                                                   Usage      |
    |=============================================================================|
    |    0   N/A  N/A      1060      G   /usr/lib/xorg/Xorg                171MiB |
    |    0   N/A  N/A      1816      G   compiz                            145MiB |
    |    0   N/A  N/A     11572      C   python                           3538MiB |
    |    0   N/A  N/A     22318      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     22352      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     22532      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     27511      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     27686      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     27773      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     27917      G   /usr/lib/firefox/firefox            1MiB |
    |    0   N/A  N/A     28780      G   /usr/lib/firefox/firefox            1MiB |
    +-----------------------------------------------------------------------------+

Here is the training output,  batch size is only 1 !! How much gpu memory does it need ?!!!

    --- Get training operator
    learning_rate:  Tensor(""lr:0"", shape=(), dtype=float32, device=/device:GPU:0)
    optimizer:  &lt;tensorflow.python.training.adam.AdamOptimizer object at 0x7fe527d60f60&gt;
    2021-01-08 17:04:23.922771: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
    2021-01-08 17:04:23.998743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2021-01-08 17:04:23.999030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
    name: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148
    pciBusID: 0000:01:00.0
    totalMemory: 3.95GiB freeMemory: 3.60GiB
    2021-01-08 17:04:23.999047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
    
    2021-01-08 17:07:23.662259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
    2021-01-08 17:07:23.662310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
    2021-01-08 17:07:23.662320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
    2021-01-08 17:07:23.662431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3349 MB memory) -&gt; physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)
    
    
    ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4096,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
    	 [[node vgg_16/fc6/Conv2D (defined at /home/jun/anaconda3/envs/tf_1.12_trimesh/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1057)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](vgg_16/pool5/MaxPool, vgg_16/fc6/weights/read)]]
    Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
    
    	 [[{{node Mean_6/_109}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_2473_Mean_6"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
    Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.",t2_2qvu206d,False,,0,False,ResourceExhaustedError,[],r/tensorflow,False,6,,0,,,False,t3_kszm1i,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1610129106.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My pc has 32G Ram with Quadro M1200, I&amp;#39;m training on external SSD installed with Ubuntu 16.04, but it keeps giving me resourceExhaustedError. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ free -h
              total        used        free      shared  buff/cache   available
Mem:            31G        5.6G        273M        1.2G         25G         23G
Swap:           15G        9.0M         15G
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nvidia-smi
Fri Jan  8 17:56:32 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro M1200        Off  | 00000000:01:00.0 Off |                  N/A |
| N/A   52C    P0    N/A /  N/A |   3875MiB /  4046MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1060      G   /usr/lib/xorg/Xorg                171MiB |
|    0   N/A  N/A      1816      G   compiz                            145MiB |
|    0   N/A  N/A     11572      C   python                           3538MiB |
|    0   N/A  N/A     22318      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     22352      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     22532      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     27511      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     27686      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     27773      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     27917      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A     28780      G   /usr/lib/firefox/firefox            1MiB |
+-----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is the training output,  batch size is only 1 !! How much gpu memory does it need ?!!!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;--- Get training operator
learning_rate:  Tensor(&amp;quot;lr:0&amp;quot;, shape=(), dtype=float32, device=/device:GPU:0)
optimizer:  &amp;lt;tensorflow.python.training.adam.AdamOptimizer object at 0x7fe527d60f60&amp;gt;
2021-01-08 17:04:23.922771: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-01-08 17:04:23.998743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-08 17:04:23.999030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.60GiB
2021-01-08 17:04:23.999047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0

2021-01-08 17:07:23.662259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-08 17:07:23.662310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2021-01-08 17:07:23.662320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2021-01-08 17:07:23.662431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3349 MB memory) -&amp;gt; physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)


ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4096,512,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
     [[node vgg_16/fc6/Conv2D (defined at /home/jun/anaconda3/envs/tf_1.12_trimesh/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1057)  = Conv2D[T=DT_FLOAT, data_format=&amp;quot;NCHW&amp;quot;, dilations=[1, 1, 1, 1], padding=&amp;quot;VALID&amp;quot;, strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=&amp;quot;/job:localhost/replica:0/task:0/device:GPU:0&amp;quot;](vgg_16/pool5/MaxPool, vgg_16/fc6/weights/read)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

     [[{{node Mean_6/_109}} = _Recv[client_terminated=false, recv_device=&amp;quot;/job:localhost/replica:0/task:0/device:CPU:0&amp;quot;, send_device=&amp;quot;/job:localhost/replica:0/task:0/device:GPU:0&amp;quot;, send_device_incarnation=1, tensor_name=&amp;quot;edge_2473_Mean_6&amp;quot;, tensor_type=DT_FLOAT, _device=&amp;quot;/job:localhost/replica:0/task:0/device:CPU:0&amp;quot;]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kszm1i,True,,HistoricalTouch0,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kszm1i/resourceexhaustederror/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kszm1i/resourceexhaustederror/,22217,1610100306.0,0,,False,,,,,,,,,
265,,tensorflow,"Got a \_brand new\_ machine from Falcon NW with 2 Titan RTX Gpus.  It literally arrived on Monday.

I follow the instructions exactly on install tensorflow 2.4 for windows 10.  What happens?  NOTHING!  IT DOESNT WORK! The damn thing hangs when I go to call [model.fit](https://model.fit)(). 

I then went back to tensorflow 2.3, installed all the appropriate cuda and cudnn libs and voila, everything works fine.  

I feel like every other version of tensorflow sucks.  I'm getting so tired of this crap.",t2_9pegj54y,False,,0,False,[D] Why is Tensorflow getting worse on windows as the versions roll by?,[],r/tensorflow,False,6,,0,,,False,t3_ksdew0,False,dark,0.82,,public,11,0,{},,,False,[],,False,False,,{},,False,11,,False,self,False,,[],{},,True,,1610055458.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Got a _brand new_ machine from Falcon NW with 2 Titan RTX Gpus.  It literally arrived on Monday.&lt;/p&gt;

&lt;p&gt;I follow the instructions exactly on install tensorflow 2.4 for windows 10.  What happens?  NOTHING!  IT DOESNT WORK! The damn thing hangs when I go to call &lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;(). &lt;/p&gt;

&lt;p&gt;I then went back to tensorflow 2.3, installed all the appropriate cuda and cudnn libs and voila, everything works fine.  &lt;/p&gt;

&lt;p&gt;I feel like every other version of tensorflow sucks.  I&amp;#39;m getting so tired of this crap.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ksdew0,True,,wtf_tensorflow,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/ksdew0/d_why_is_tensorflow_getting_worse_on_windows_as/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ksdew0/d_why_is_tensorflow_getting_worse_on_windows_as/,22217,1610026658.0,0,,False,,,,,,,,,
266,,tensorflow,"&amp;#x200B;

[Image from the training](https://preview.redd.it/2bkeglw6rx961.png?width=672&amp;format=png&amp;auto=webp&amp;s=adc68cb64b580f383febebc33f6b0d4ec8c80f54)

* ✍ [How to load a dataset.ipynb](https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/How%20to%20load%20a%20dataset.ipynb)
* ✍ [DETR Tensorflow - Finetuning tutorial.ipynb](https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/DETR%20Tensorflow%20-%20%20Finetuning%20tutorial.ipynb)
* ✍ [DETR Tensorflow - How to setup a custom dataset.ipynb](https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/DETR%20Tensorflow%20-%20%20How%20to%20setup%20a%20custom%20dataset.ipynb)

Since the paper Attention is all you need, published in 2017, the landscape of NLP completely shifts towards transformers  based architecture.

In 2020, most computer vision models still rely solely on convolutional neural networks to detect and segments images. We predict that 2021 will be an important milestone for detection and segmentation algorithms. Convolution mixed with transformers will become the default choice for most practitioners.

Therefore, few weeks ago, we decided to open-source a DETR (Object Detection with Transformers) Tensorflow implementation, including code for inference, finetuning, and training ! Today we released some tutorials to help you getting started and train on your dataset.

Also, to get started with the logging system, we released a wandb report of the training performance on the hard hat workers dataset:

\- 🚀 Wandb : [Finetuning DETR on Tensorflow - A step by step guide](https://wandb.ai/thibault-neveu/detr-tensorflow-log/reports/Finetuning-DETR-on-Tensorflow-A-step-by-step-tutorial--VmlldzozOTYyNzQ)",t2_g75w4q,False,,0,False,Finetuning DETR on Tensorflow - Step by step tutorials,[],r/tensorflow,False,6,,0,78.0,,False,t3_ksgkl1,False,dark,1.0,,public,5,0,{},140.0,,False,[],,False,False,,{},,False,5,,False,https://b.thumbs.redditmedia.com/n7TKmq_nhIj_QdAJ7CfFzG5xE_NHK5X_UPPtHvpOK8A.jpg,1610036821.0,,[],{},,True,,1610065226.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/2bkeglw6rx961.png?width=672&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=adc68cb64b580f383febebc33f6b0d4ec8c80f54""&gt;Image from the training&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;✍ &lt;a href=""https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/How%20to%20load%20a%20dataset.ipynb""&gt;How to load a dataset.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;✍ &lt;a href=""https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/DETR%20Tensorflow%20-%20%20Finetuning%20tutorial.ipynb""&gt;DETR Tensorflow - Finetuning tutorial.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;✍ &lt;a href=""https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/DETR%20Tensorflow%20-%20%20How%20to%20setup%20a%20custom%20dataset.ipynb""&gt;DETR Tensorflow - How to setup a custom dataset.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the paper Attention is all you need, published in 2017, the landscape of NLP completely shifts towards transformers  based architecture.&lt;/p&gt;

&lt;p&gt;In 2020, most computer vision models still rely solely on convolutional neural networks to detect and segments images. We predict that 2021 will be an important milestone for detection and segmentation algorithms. Convolution mixed with transformers will become the default choice for most practitioners.&lt;/p&gt;

&lt;p&gt;Therefore, few weeks ago, we decided to open-source a DETR (Object Detection with Transformers) Tensorflow implementation, including code for inference, finetuning, and training ! Today we released some tutorials to help you getting started and train on your dataset.&lt;/p&gt;

&lt;p&gt;Also, to get started with the logging system, we released a wandb report of the training performance on the hard hat workers dataset:&lt;/p&gt;

&lt;p&gt;- 🚀 Wandb : &lt;a href=""https://wandb.ai/thibault-neveu/detr-tensorflow-log/reports/Finetuning-DETR-on-Tensorflow-A-step-by-step-tutorial--VmlldzozOTYyNzQ""&gt;Finetuning DETR on Tensorflow - A step by step guide&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ksgkl1,True,,thibo73800,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ksgkl1/finetuning_detr_on_tensorflow_step_by_step/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ksgkl1/finetuning_detr_on_tensorflow_step_by_step/,22217,1610036426.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?auto=webp&amp;s=e8bf1acd163eb615c53f1d6a9f330b726b2b0121', 'width': 672, 'height': 376}, 'resolutions': [{'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b5615afab664f36830b3648ba7cd230f971ebc', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=693c4dc93bd31aea8a1c38f069331a96ef045a67', 'width': 216, 'height': 120}, {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac73c8b117b5f609773d76fafab20a7ae30dd2b8', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f88b39da685f9051e60075efaa0e89615c8e6a60', 'width': 640, 'height': 358}], 'variants': {}, 'id': 'qJzQFqiKV3LJwboWk2lyoTrrXoCLYLrNdfcNfmqAye8'}], 'enabled': False}",,"{'2bkeglw6rx961': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/2bkeglw6rx961.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cffa03955f5a8f013d430bc9f64b0cab2b7447d1'}, {'y': 120, 'x': 216, 'u': 'https://preview.redd.it/2bkeglw6rx961.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f25f48d0be915bed61906bc346bcbb6d7d6896b9'}, {'y': 179, 'x': 320, 'u': 'https://preview.redd.it/2bkeglw6rx961.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=808de53336f6bacf727542f3366f74baf1763f0f'}, {'y': 358, 'x': 640, 'u': 'https://preview.redd.it/2bkeglw6rx961.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1c69270198dcb52a636a52287b687c6df8ad4f5'}], 's': {'y': 376, 'x': 672, 'u': 'https://preview.redd.it/2bkeglw6rx961.png?width=672&amp;format=png&amp;auto=webp&amp;s=adc68cb64b580f383febebc33f6b0d4ec8c80f54'}, 'id': '2bkeglw6rx961'}}",,,,
267,,tensorflow,"Currently, I'm focusing on continual learning, which requires on-device training when the model is deployed. Unfortunately, there doesn't seem to be any concrete support for on-device training by TensorFlow Lite (transfer learning option only).

1. Is there an official roadmap for TF lite implementation in 2021?
2. Will TF lite support true on-device training anytime soon?
3. Is there any workaround for the moment?

Thank you everyone",t2_167nx2qq,False,,0,False,Will TensorFlow Lite support true on-device training anytime soon? [2021 roadmap?],[],r/tensorflow,False,6,,0,,,False,t3_ks9lrl,False,dark,0.91,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1610039261.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently, I&amp;#39;m focusing on continual learning, which requires on-device training when the model is deployed. Unfortunately, there doesn&amp;#39;t seem to be any concrete support for on-device training by TensorFlow Lite (transfer learning option only).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is there an official roadmap for TF lite implementation in 2021?&lt;/li&gt;
&lt;li&gt;Will TF lite support true on-device training anytime soon?&lt;/li&gt;
&lt;li&gt;Is there any workaround for the moment?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thank you everyone&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ks9lrl,True,,mrsailor23,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ks9lrl/will_tensorflow_lite_support_true_ondevice/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ks9lrl/will_tensorflow_lite_support_true_ondevice/,22217,1610010461.0,0,,False,,,,,,,,,
268,,tensorflow,"Does anyone know where to get Tensorflow help. I tried posting in tensorflow github and stackoverflow but I keep getting ignored.

Thanks",t2_6cpgks1a,False,,0,False,Tensorflow Help,[],r/tensorflow,False,6,,0,,,False,t3_ksi7k5,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1610069821.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone know where to get Tensorflow help. I tried posting in tensorflow github and stackoverflow but I keep getting ignored.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ksi7k5,True,,RicardoCarlos55,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/ksi7k5/tensorflow_help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ksi7k5/tensorflow_help/,22217,1610041021.0,0,,False,,,,,,,,,
269,,tensorflow,"I'm complete newbie in machine learning. Currently I'm training a dataset of 10k samples(6601/4000 trainig /test, each sample size is about 600Kb-30Mb), `batch size 100, learning rate 1e-4`.During the past couple days, each step was taking 90min, loss was zigzaging between the highest of 376697090 and lowest of 7000. Right now I'm close to the end of the first epoch, but loss is still ranging from 630000 to 7000. What is it telling me?",t2_2qvu206d,False,,0,False,Training loss too high,[],r/tensorflow,False,6,,0,,,False,t3_ks9sgg,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1610040082.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m complete newbie in machine learning. Currently I&amp;#39;m training a dataset of 10k samples(6601/4000 trainig /test, each sample size is about 600Kb-30Mb), &lt;code&gt;batch size 100, learning rate 1e-4&lt;/code&gt;.During the past couple days, each step was taking 90min, loss was zigzaging between the highest of 376697090 and lowest of 7000. Right now I&amp;#39;m close to the end of the first epoch, but loss is still ranging from 630000 to 7000. What is it telling me?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ks9sgg,True,,HistoricalTouch0,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ks9sgg/training_loss_too_high/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ks9sgg/training_loss_too_high/,22217,1610011282.0,0,,False,,,,,,,,,
270,,tensorflow,"Hello there,

I came here to see if anybody can help me and my friends solve some problems and doubts about tensorflow

for context, we are depeloping a mask detector with raspberry pi and tensorflow (normal ver.) however the fps outcome is really low and we would like to switch to tensorflow LITE to make it smoother

we already have a code created and works fine except the fps problem, and it uses tensorflow, how can we start using tensorflow in our code, and get rid of the normal version?

we thought we could just modify the lines in our code to LITE version (in case they were different) or if we had to do something else in order for it to work

i apologise if my explanation was confusing, i'll provide more information adn details if needed",t2_3h3c7c3z,False,,0,False,Switching to TensorFlow LITE on an existing program,[],r/tensorflow,False,6,,0,,,False,t3_ksbake,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1610046937.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello there,&lt;/p&gt;

&lt;p&gt;I came here to see if anybody can help me and my friends solve some problems and doubts about tensorflow&lt;/p&gt;

&lt;p&gt;for context, we are depeloping a mask detector with raspberry pi and tensorflow (normal ver.) however the fps outcome is really low and we would like to switch to tensorflow LITE to make it smoother&lt;/p&gt;

&lt;p&gt;we already have a code created and works fine except the fps problem, and it uses tensorflow, how can we start using tensorflow in our code, and get rid of the normal version?&lt;/p&gt;

&lt;p&gt;we thought we could just modify the lines in our code to LITE version (in case they were different) or if we had to do something else in order for it to work&lt;/p&gt;

&lt;p&gt;i apologise if my explanation was confusing, i&amp;#39;ll provide more information adn details if needed&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ksbake,True,,UnrealNine,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ksbake/switching_to_tensorflow_lite_on_an_existing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ksbake/switching_to_tensorflow_lite_on_an_existing/,22217,1610018137.0,0,,False,,,,,,,,,
271,,tensorflow,,t2_1krqyfrs,False,,0,False,A Prototype of YOLOv4 Object Detection fused with Siam Mask Object Tracking with Segmentation. Works really great if objects are not occluded. Like and comment below if you would like to see a tutorial on this. #opencv #yolov4 #computervision - Only on Augmented Startups,[],r/tensorflow,False,6,,0,78.0,,False,t3_krkqhp,False,dark,0.93,,public,51,0,{},140.0,,False,[],,True,False,,{},Project,False,51,,False,https://b.thumbs.redditmedia.com/_Xmi529Lp29pTD4kj0IYOklhp0dGk4h7Ru54049d82M.jpg,False,,[],{},,False,,1609954859.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,krkqhp,True,,AugmentedStartups,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/krkqhp/a_prototype_of_yolov4_object_detection_fused_with/,all_ads,False,https://i.redd.it/no4nktq6no961.gif,22217,1609926059.0,0,,False,image,https://i.redd.it/no4nktq6no961.gif,"{'images': [{'source': {'url': 'https://preview.redd.it/no4nktq6no961.gif?format=png8&amp;s=4c49101fb54910ce2d3b428eb8c4c7d8236b7fb8', 'width': 600, 'height': 336}, 'resolutions': [{'url': 'https://preview.redd.it/no4nktq6no961.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=ede0f9671ef9c07b7a3a15c2f633aa17323b5edf', 'width': 108, 'height': 60}, {'url': 'https://preview.redd.it/no4nktq6no961.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=c1eafdd6c01a28a4419013994b539c1e2b0d1828', 'width': 216, 'height': 120}, {'url': 'https://preview.redd.it/no4nktq6no961.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=79ad3d9adab497f88ab362bc1a4c1baf81657621', 'width': 320, 'height': 179}], 'variants': {'gif': {'source': {'url': 'https://preview.redd.it/no4nktq6no961.gif?s=77d6f842156d38ee739f949cdd228d1e6cfb9db5', 'width': 600, 'height': 336}, 'resolutions': [{'url': 'https://preview.redd.it/no4nktq6no961.gif?width=108&amp;crop=smart&amp;s=fe62ec79b65851a81039a59f96ed86d67b114adb', 'width': 108, 'height': 60}, {'url': 'https://preview.redd.it/no4nktq6no961.gif?width=216&amp;crop=smart&amp;s=dc7745a4bc6bfb4bda7d92dad7da4b89f6c5dcc8', 'width': 216, 'height': 120}, {'url': 'https://preview.redd.it/no4nktq6no961.gif?width=320&amp;crop=smart&amp;s=0dbeff689825180801ba8ed930da6cd2e1dcce24', 'width': 320, 'height': 179}]}, 'mp4': {'source': {'url': 'https://preview.redd.it/no4nktq6no961.gif?format=mp4&amp;s=1494d7fa2be55a3e526f2b5d07993d1c9303ab12', 'width': 600, 'height': 336}, 'resolutions': [{'url': 'https://preview.redd.it/no4nktq6no961.gif?width=108&amp;format=mp4&amp;s=6868a6b33b59de18434b46a8362cbcb10580f82c', 'width': 108, 'height': 60}, {'url': 'https://preview.redd.it/no4nktq6no961.gif?width=216&amp;format=mp4&amp;s=07d781547e2b6287a6cfe2759e793f08e0d3723b', 'width': 216, 'height': 120}, {'url': 'https://preview.redd.it/no4nktq6no961.gif?width=320&amp;format=mp4&amp;s=4b5f05b178658b5e4b6c0ece1347ebb523fd39ed', 'width': 320, 'height': 179}]}}, 'id': 'G6QVl3n_BWjibXKDMMI9uu37rcFMBY813ikj_j2dirw'}], 'enabled': True}",,,,,,
272,,tensorflow,"EDIT: ALL SET NOW. THANKS TEAM 🙏 
I'm working on a project that will perform skeletal tracking using pose, ideally over a web app. Looking to start prototyping soon. If anyone here has experience (ideally with a portfolio or repo profile you can share) and would want to look at the project I'm actively looking for contractors. Just a short term project for now and will have budget. DM me for more info. Thanks all!",t2_kwdb8fa,False,,0,False,Anyone looking to prototype web apps with pose estimation?,[],r/tensorflow,False,6,,0,,,False,t3_krqv37,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,1610061155.0,,[],{},,True,,1609978267.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;EDIT: ALL SET NOW. THANKS TEAM 🙏 
I&amp;#39;m working on a project that will perform skeletal tracking using pose, ideally over a web app. Looking to start prototyping soon. If anyone here has experience (ideally with a portfolio or repo profile you can share) and would want to look at the project I&amp;#39;m actively looking for contractors. Just a short term project for now and will have budget. DM me for more info. Thanks all!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,krqv37,True,,yoozernamed,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/krqv37/anyone_looking_to_prototype_web_apps_with_pose/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/krqv37/anyone_looking_to_prototype_web_apps_with_pose/,22217,1609949467.0,0,,False,,,,,,,,,
273,,tensorflow,,t2_1knw9sib,False,,0,False,Coding a Framework for Language Understaning with Python and Tensorflow,[],r/tensorflow,False,6,,0,105.0,,False,t3_krtto4,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'How to Create Your Virtual Assistant with Python 2021- #6', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Código Logo', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IdNs4sDnzjs/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/CódigoLogo'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/krtto4', 'height': 200}",Project,False,0,,False,https://a.thumbs.redditmedia.com/tkt2246J8KpNrPNIz326S17Bc7jvNVllyLwFh4F2924.jpg,False,,[],{},,False,,1609986436.0,text,6,,,text,youtube.com,False,,,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,krtto4,True,,limapedro,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/krtto4/coding_a_framework_for_language_understaning_with/,all_ads,False,https://www.youtube.com/watch?v=IdNs4sDnzjs,22217,1609957636.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'How to Create Your Virtual Assistant with Python 2021- #6', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Código Logo', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IdNs4sDnzjs/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/CódigoLogo'}, 'type': 'youtube.com'}",False,rich:video,https://www.youtube.com/watch?v=IdNs4sDnzjs,"{'images': [{'source': {'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?auto=webp&amp;s=20147cfc3600e6f0a671cdc347c5c7d164354da8', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28844a862c342281c8876ec57509675a6a06b33d', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8219b0337b38d167c6ca4a7f4c5eaf28da6ac54d', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99ccb31d427d15d10fbc2bb467ee672d1b19d152', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Qeub3haSYbiJbNJAtA39NXRloUVzazuKfb5Wfc-yqkk'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'coding', 'selftext': '', 'author_fullname': 't2_1knw9sib', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Coding a Framework for Language Understaning with Python and Tensorflow', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/coding', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 105, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_krtqyt', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'How to Create Your Virtual Assistant with Python 2021- #6', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Código Logo', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IdNs4sDnzjs/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/CódigoLogo'}, 'type': 'youtube.com'}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/krtqyt', 'height': 200}, 'link_flair_text': None, 'can_mod_post': False, 'score': 3, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/tkt2246J8KpNrPNIz326S17Bc7jvNVllyLwFh4F2924.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'rich:video', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1609986222.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=IdNs4sDnzjs', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?auto=webp&amp;s=20147cfc3600e6f0a671cdc347c5c7d164354da8', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28844a862c342281c8876ec57509675a6a06b33d', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8219b0337b38d167c6ca4a7f4c5eaf28da6ac54d', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/DnWTCdP-LubRqHESBGyZUXJcUxFYqrHtgwtl8HZEs4w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99ccb31d427d15d10fbc2bb467ee672d1b19d152', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Qeub3haSYbiJbNJAtA39NXRloUVzazuKfb5Wfc-yqkk'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2rb2y', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'krtqyt', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'limapedro', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/coding/comments/krtqyt/coding_a_framework_for_language_understaning_with/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.youtube.com/watch?v=IdNs4sDnzjs', 'subreddit_subscribers': 276395, 'created_utc': 1609957422.0, 'num_crossposts': 4, 'media': {'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'How to Create Your Virtual Assistant with Python 2021- #6', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IdNs4sDnzjs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Código Logo', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IdNs4sDnzjs/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/CódigoLogo'}, 'type': 'youtube.com'}, 'is_video': False}]",t3_krtqyt,
274,,tensorflow,Qualcomm has released a lot of drivers and I signed up to work with them. Need any guidance on how to speed up the performance or how to setup the drivers LIKE in case of CUDA. If I just directly use my tensorflow lite model would that give me the best performance?,t2_12bo13,False,,0,False,[HELP] I am looking to run tensorflow inference on my mobile but I want to use the internal GPU (Adreno 650). The processor is Snapdragon 865+ with 12GB of RAM on board,[],r/tensorflow,False,6,,0,,,False,t3_krhi72,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1609940650.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Qualcomm has released a lot of drivers and I signed up to work with them. Need any guidance on how to speed up the performance or how to setup the drivers LIKE in case of CUDA. If I just directly use my tensorflow lite model would that give me the best performance?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,krhi72,True,,chhab798,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/krhi72/help_i_am_looking_to_run_tensorflow_inference_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/krhi72/help_i_am_looking_to_run_tensorflow_inference_on/,22217,1609911850.0,0,,False,,,,,,,,,
275,,tensorflow,"It's standard practice to finetune an object detection model for a given task.  Finetuning is part of the workflow of the [Tensorflow Object Detection workflow tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest).

However, I have been tasked by a sceptical supervisor to show that using a pretrained model actually improves performance.  So I need a way to reinitialise the parameters of [one of the pretrained TF Object detection models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md), so I can train and convince the supervisor that finetuning is actually best practice.

However, I haven't found a way to do this - finetuning seems to be baked in.  Is there a way I can reinitalise the weights of the network, following the Tensorflow Object Detection workflow tutorial?",t2_85simod,False,,0,False,Running Tensorflow Object Detection API from scratch (no finetuning - with randomly initialised model),[],r/tensorflow,False,6,,0,,,False,t3_kqzhzu,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1609885916.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It&amp;#39;s standard practice to finetune an object detection model for a given task.  Finetuning is part of the workflow of the &lt;a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest""&gt;Tensorflow Object Detection workflow tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, I have been tasked by a sceptical supervisor to show that using a pretrained model actually improves performance.  So I need a way to reinitialise the parameters of &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md""&gt;one of the pretrained TF Object detection models&lt;/a&gt;, so I can train and convince the supervisor that finetuning is actually best practice.&lt;/p&gt;

&lt;p&gt;However, I haven&amp;#39;t found a way to do this - finetuning seems to be baked in.  Is there a way I can reinitalise the weights of the network, following the Tensorflow Object Detection workflow tutorial?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kqzhzu,True,,pram-ila,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kqzhzu/running_tensorflow_object_detection_api_from/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kqzhzu/running_tensorflow_object_detection_api_from/,22217,1609857116.0,0,,False,,,,,,,,,
276,,tensorflow,"I want to add some new augmentations to the TF2 Object Detection API. Seems straight forward, add a new function to [https://github.com/tensorflow/models/blob/master/research/object\_detection/core/preprocessor.py](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py)

However, there is also the proto file here: [https://github.com/tensorflow/models/blob/master/research/object\_detection/protos/preprocessor.proto](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto)

What do I have to do with the proto file? Anything? (TBH I've never really worked out what they are used for)",t2_7zjscnsq,False,,0,False,Adding augmentations to Tensorflow Object Detection API,[],r/tensorflow,False,6,,0,,,False,t3_kqox4g,False,dark,0.91,,public,8,0,{},,,False,[],,False,False,,{},,False,8,,False,self,False,,[],{},,True,,1609844351.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to add some new augmentations to the TF2 Object Detection API. Seems straight forward, add a new function to &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py""&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, there is also the proto file here: &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto""&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What do I have to do with the proto file? Anything? (TBH I&amp;#39;ve never really worked out what they are used for)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kqox4g,True,,everytime_nothing,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kqox4g/adding_augmentations_to_tensorflow_object/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kqox4g/adding_augmentations_to_tensorflow_object/,22217,1609815551.0,0,,False,,,,,,,,,
277,,tensorflow,"So I found a pre-trained model that greatly interested me:
https://github.com/OMR-Research/tf-end-to-end

Probably irrelevant but I found it from this article and maybe you'd like to read it too:
https://heartbeat.fritz.ai/play-sheet-music-with-python-opencv-and-an-optical-music-recognition-model-a55a3bea8fe

I wanted to play around with it in the context of an android phone and I found out that tensorflow can support this easily if I can just convert it into TFLite format. Problem is, I've been having so much trouble getting the model into it, but it's likely my lack of experience in dealing with such a complex model.

This is the model I've been tooling with
https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip

So in order to get it into TFLite format, I needed to get its
.meta / .index / .data files into a frozen graph, however, to do this you would need to know the input and output nodes which I had trouble understanding, even with tensorboard summaries. Another method I found was through the savedmodel format, however I was getting all sorts of errors detailed in my stack overflow post that you can maybe help with: https://stackoverflow.com/questions/65572476/how-do-i-convert-a-meta-index-and-data-file-into-savedmodel-pb-format-with

So basically, I just want to convert my checkpoint file into a usable file for inference and getting really lost and need some advice.",t2_kplhh,False,,0,False,"Beginner here wanting to use a pre-trained model, confused trying to do simple things",[],r/tensorflow,False,6,,0,,,False,t3_kqtfo7,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1609861225.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I found a pre-trained model that greatly interested me:
&lt;a href=""https://github.com/OMR-Research/tf-end-to-end""&gt;https://github.com/OMR-Research/tf-end-to-end&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Probably irrelevant but I found it from this article and maybe you&amp;#39;d like to read it too:
&lt;a href=""https://heartbeat.fritz.ai/play-sheet-music-with-python-opencv-and-an-optical-music-recognition-model-a55a3bea8fe""&gt;https://heartbeat.fritz.ai/play-sheet-music-with-python-opencv-and-an-optical-music-recognition-model-a55a3bea8fe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I wanted to play around with it in the context of an android phone and I found out that tensorflow can support this easily if I can just convert it into TFLite format. Problem is, I&amp;#39;ve been having so much trouble getting the model into it, but it&amp;#39;s likely my lack of experience in dealing with such a complex model.&lt;/p&gt;

&lt;p&gt;This is the model I&amp;#39;ve been tooling with
&lt;a href=""https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip""&gt;https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So in order to get it into TFLite format, I needed to get its
.meta / .index / .data files into a frozen graph, however, to do this you would need to know the input and output nodes which I had trouble understanding, even with tensorboard summaries. Another method I found was through the savedmodel format, however I was getting all sorts of errors detailed in my stack overflow post that you can maybe help with: &lt;a href=""https://stackoverflow.com/questions/65572476/how-do-i-convert-a-meta-index-and-data-file-into-savedmodel-pb-format-with""&gt;https://stackoverflow.com/questions/65572476/how-do-i-convert-a-meta-index-and-data-file-into-savedmodel-pb-format-with&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So basically, I just want to convert my checkpoint file into a usable file for inference and getting really lost and need some advice.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kqtfo7,True,,Vendredi46,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kqtfo7/beginner_here_wanting_to_use_a_pretrained_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kqtfo7/beginner_here_wanting_to_use_a_pretrained_model/,22217,1609832425.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/v54NOI0a1OVi0M254tr9584sJaBCha_MnkCNCN3hC0A.jpg?auto=webp&amp;s=e6efa9ceef0990d0d68d0d55b8332605ad61885e', 'width': 219, 'height': 219}, 'resolutions': [{'url': 'https://external-preview.redd.it/v54NOI0a1OVi0M254tr9584sJaBCha_MnkCNCN3hC0A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0db2a892e76e7756e7241ca2564c91bdd468520c', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/v54NOI0a1OVi0M254tr9584sJaBCha_MnkCNCN3hC0A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=26eb5c19808910ff1e543d00c1f0a5ee1dbf6b0a', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'R2TCUcF9dceD5YQSIatPVOcqQLrJ8iNc3L74kHuGuDk'}], 'enabled': False}",,,,,,
278,,tensorflow,"I'm a little confused by what I'm getting vs. what I'm expecting. I'm using Tensorflow 2.1 in Python 3.7  in Anaconda 3-2020.07

Here's my problem:

1. I want my output to be the next value in an hour-by-hour time series.
2. My input has 99 features.
3. I have 24,444 data points for training. Some of the data was corrupted/reserved for validation.

&amp;#x200B;

I'm trying to build a 2 layer deep neural network using LSTM layers:

`model = Sequential() model.add(tensorflow.keras.layers.LSTM(64, return\_sequences=True, input\_dim=99))` 

`model.add(tensorflow.keras.layers.LSTM(32, return\_sequences=True))` 

`model.add(tensorflow.keras.layers.Dense(1)`

&amp;#x200B;

I plan to give it sets of data with 72 hours (3 days) of sequential training.

&amp;#x200B;

So when I give my model training data:

[`model.fit`](https://model.fit)`(X_data, Y_data, ...)`

&amp;#x200B;

I planned on giving X\_data with dimensions of size \[24444, 72, 99\], where the first dimension 24444 describes the data points, the 72 describes the 72 hours of history, and the 99 describes my training features.

My Y\_data has dimensions of size \[24444, 72, 1\] where first dimension 24444 describes my training points, 72 describes the history, and 1 is my output feature.

&amp;#x200B;

My question is, when training is done, and I'm actively using my model for predictions, what should my production input size be?

`prediction = model.predict(production_data)`

Should my production size be \[1, 72, 99\]? Where 1 is the number of output points I expect, 72 is my history, and 99 my feature size? 

When I do this, I get an output size of \[72, 1\]. That feels... weird?

What is the difference between feeding my model input of \[72, 1, 99\] vs \[1, 72, 99\]? Does the first case not proprogate the internal state forward?

If I give my model \[1, 1, 99\] do I need to loop my model predictions? And how would I do this?",t2_12pfvk,False,,0,False,LSTM Tensorflow Input/Output Dimensions,[],r/tensorflow,False,6,,0,,,False,t3_kqqkiy,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609849881.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a little confused by what I&amp;#39;m getting vs. what I&amp;#39;m expecting. I&amp;#39;m using Tensorflow 2.1 in Python 3.7  in Anaconda 3-2020.07&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s my problem:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I want my output to be the next value in an hour-by-hour time series.&lt;/li&gt;
&lt;li&gt;My input has 99 features.&lt;/li&gt;
&lt;li&gt;I have 24,444 data points for training. Some of the data was corrupted/reserved for validation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to build a 2 layer deep neural network using LSTM layers:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model = Sequential() model.add(tensorflow.keras.layers.LSTM(64, return\_sequences=True, input\_dim=99))&lt;/code&gt; &lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(tensorflow.keras.layers.LSTM(32, return\_sequences=True))&lt;/code&gt; &lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(tensorflow.keras.layers.Dense(1)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I plan to give it sets of data with 72 hours (3 days) of sequential training.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;So when I give my model training data:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://model.fit""&gt;&lt;code&gt;model.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(X_data, Y_data, ...)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I planned on giving X_data with dimensions of size [24444, 72, 99], where the first dimension 24444 describes the data points, the 72 describes the 72 hours of history, and the 99 describes my training features.&lt;/p&gt;

&lt;p&gt;My Y_data has dimensions of size [24444, 72, 1] where first dimension 24444 describes my training points, 72 describes the history, and 1 is my output feature.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My question is, when training is done, and I&amp;#39;m actively using my model for predictions, what should my production input size be?&lt;/p&gt;

&lt;p&gt;&lt;code&gt;prediction = model.predict(production_data)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Should my production size be [1, 72, 99]? Where 1 is the number of output points I expect, 72 is my history, and 99 my feature size? &lt;/p&gt;

&lt;p&gt;When I do this, I get an output size of [72, 1]. That feels... weird?&lt;/p&gt;

&lt;p&gt;What is the difference between feeding my model input of [72, 1, 99] vs [1, 72, 99]? Does the first case not proprogate the internal state forward?&lt;/p&gt;

&lt;p&gt;If I give my model [1, 1, 99] do I need to loop my model predictions? And how would I do this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kqqkiy,True,,jyliu86,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kqqkiy/lstm_tensorflow_inputoutput_dimensions/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kqqkiy/lstm_tensorflow_inputoutput_dimensions/,22217,1609821081.0,0,,False,,,,,,,,,
279,,tensorflow,"hello, guys I recently build a deep learning project with python, Keras, and TensorFlow that uses LSTMs text generating method to generate rap and hip hop music lyrics. All the code and the models are in the Github repo([https://github.com/YigitGunduc/Spectrum](https://github.com/YigitGunduc/Spectrum)) if you want to train the model with your own dataset, the project is flexible enough to do it by only changing the data folder. I also build a website([https://spectrumapp.herokuapp.com/](https://spectrumapp.herokuapp.com/)) if you guys check it out I would be so happy.",t2_70tvn3l8,False,,0,False,AI that generates rap music lyrics (ml/dl) (Open-Source),[],r/tensorflow,False,6,,0,,,False,t3_kqdg5n,False,dark,0.77,,public,7,0,{},,,False,[],,False,False,,{},Project,False,7,,False,self,False,,[],{},,True,,1609810515.0,text,6,,,text,self.tensorflow,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hello, guys I recently build a deep learning project with python, Keras, and TensorFlow that uses LSTMs text generating method to generate rap and hip hop music lyrics. All the code and the models are in the Github repo(&lt;a href=""https://github.com/YigitGunduc/Spectrum""&gt;https://github.com/YigitGunduc/Spectrum&lt;/a&gt;) if you want to train the model with your own dataset, the project is flexible enough to do it by only changing the data folder. I also build a website(&lt;a href=""https://spectrumapp.herokuapp.com/""&gt;https://spectrumapp.herokuapp.com/&lt;/a&gt;) if you guys check it out I would be so happy.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kqdg5n,True,,_Xeon__,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kqdg5n/ai_that_generates_rap_music_lyrics_mldl_opensource/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kqdg5n/ai_that_generates_rap_music_lyrics_mldl_opensource/,22217,1609781715.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?auto=webp&amp;s=95976682426bdc4bc0a7d1f9a830014b2594cc62', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=575db71fe99b03f846d413b42fafbc0250c8000f', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=681d15c1d40b573baab0166065df0157cba2939f', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/5KLf9eIdls8sJb0AcTkx0BozDX_UOfM96I_qka87dCw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7be3a8e936983353f0163be0e69ed10178f5039a', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'IXMU2IHAflclO88ngV0NR-B0Zju3TH48jgQPZsfD7Uo'}], 'enabled': False}",,,,,,
280,,tensorflow,,t2_v7nu2,False,,0,False,"Release John Snow Labs Spark-NLP 2.7.0: New T5 and MarianMT seq2seq transformers, detect up to 375 languages, word segmentation, over 720+ models and pipelines, support for 192+ languages, and many more! · JohnSnowLabs/spark-nlp",[],r/tensorflow,False,6,,0,70.0,,False,t3_kqfaga,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/F_ci5ZfxCxPLffusV83D8BKb_8aGMDDg1Tk21J16tZk.jpg,False,,[],{},,False,,1609815740.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kqfaga,True,,dark-night-rises,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kqfaga/release_john_snow_labs_sparknlp_270_new_t5_and/,all_ads,False,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.0,22217,1609786940.0,0,,False,link,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.0,"{'images': [{'source': {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?auto=webp&amp;s=26d4e2ccac57601a99f4cf45d17f0e00f92fead8', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d55caafe011d4551ac15197e82b07dc37606c085', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e16ade26c248b8f9dfe83d12e5a437af7764697', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6301bc373904ebf9e06640d72df79738f466d080', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c3eadd9c1d9a2e41e1b423431c1666469d533309', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d59956f28b0a75b5571510adebb6a47c3dff02e2', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cd7fba8bfcb78eb50ebaa2190e9d66a954f7bf8', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'jMsd8PwIcNruRH9ONi-X0NcTUSJ4CHYE0cb1s8qw_TI'}], 'enabled': False}",,,,,,
281,,tensorflow,,t2_1krqyfrs,False,,0,False,Mask Detection on Raspberry Pi with Stepper Motor Access Control Tutorial,[],r/tensorflow,False,6,,0,105.0,,False,t3_kq4b94,False,dark,0.87,,public,11,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DU8Ze-ATVRg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Mask Detection on Raspberry Pi with Stepper Motor Access Control | App 3', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DU8Ze-ATVRg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Augmented Startups', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/DU8Ze-ATVRg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ArduinoStartups'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DU8Ze-ATVRg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kq4b94', 'height': 200}",Project,False,11,,False,https://b.thumbs.redditmedia.com/66EuRfKRQBZX_sK4LNgNdUmHMh2BtdGD4SLqDBZUchU.jpg,False,,[],{},,False,,1609776282.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kq4b94,True,,AugmentedStartups,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kq4b94/mask_detection_on_raspberry_pi_with_stepper_motor/,all_ads,False,https://www.youtube.com/watch?v=DU8Ze-ATVRg&amp;ab_channel=AugmentedStartups,22217,1609747482.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Mask Detection on Raspberry Pi with Stepper Motor Access Control | App 3', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DU8Ze-ATVRg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Augmented Startups', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/DU8Ze-ATVRg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ArduinoStartups'}}",False,rich:video,https://www.youtube.com/watch?v=DU8Ze-ATVRg&amp;ab_channel=AugmentedStartups,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VUWK7_30slEp2-zS1CdPA4M6k3xioqdz__PkmfFB0BM.jpg?auto=webp&amp;s=7127ae7a1c4103c223b81f966ff7519ee532b534', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/VUWK7_30slEp2-zS1CdPA4M6k3xioqdz__PkmfFB0BM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=541b9b624d705062c12d8e2ebe4bf855d497ceb2', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/VUWK7_30slEp2-zS1CdPA4M6k3xioqdz__PkmfFB0BM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2dbe18bc278b99587be8c87ad63214814c8529ae', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/VUWK7_30slEp2-zS1CdPA4M6k3xioqdz__PkmfFB0BM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89ebbf63125b6e83429311e5fdfb5ade928254fd', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'PUo_0tf5rt9uxXPopNAdGNY67_2oxqh5zHXPioHN3T0'}], 'enabled': False}",,,,,,
282,,tensorflow,,t2_yo11a,False,,0,False,Qt TensorFlow Lite example,[],r/tensorflow,False,6,,0,140.0,,False,t3_kq9wk5,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://a.thumbs.redditmedia.com/c15S6zQh81C-rHTLn_w2ZhReFnJW1e7mZ7sgDJJIzB0.jpg,False,,[],{},,False,,1609799803.0,text,6,,,text,github.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kq9wk5,True,,IvanSafonov,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kq9wk5/qt_tensorflow_lite_example/,all_ads,False,https://github.com/IvanSafonov/qt-tf-lite-example,22217,1609771003.0,0,,False,link,https://github.com/IvanSafonov/qt-tf-lite-example,"{'images': [{'source': {'url': 'https://external-preview.redd.it/PMMGLLKXvXeCcOMx0QfDKOtagGS-k-bA75EFViVtDho.jpg?auto=webp&amp;s=ee54ed9bafdf3a03c2dbbfe685018a80249c1027', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/PMMGLLKXvXeCcOMx0QfDKOtagGS-k-bA75EFViVtDho.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff7728716b1c963656642e2d5f14a51f057de0a5', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/PMMGLLKXvXeCcOMx0QfDKOtagGS-k-bA75EFViVtDho.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d0f6ea21e9531da063d0e9745daf6809634ae76a', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/PMMGLLKXvXeCcOMx0QfDKOtagGS-k-bA75EFViVtDho.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cd46d15ddbead2630776b283bad39580c1816ec', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'R67BO7VnI-KDPB1bY3INHFiLQWnwzx-lOeoZYrRr_WY'}], 'enabled': False}",,,,,,
283,,tensorflow,"**Abstract.**

The project aims to simulate language acquisition. We simulate language acquisition by a virtual agent from a native speaker. The demonstrated principles for acquisition are suitable for any language. These are the initial principles of the Folks’Talks game project:

1. Acquisition starts from scratch. There is no preliminary data.
2. The collected data is vocal (wave files) and not connected to any writing system.
3. In the virtual interaction areas of the Folks’Talks game objects are placed in specific ways, within specific scenes, and with specific relations. These objects represent the inner world of the Folks’Talks game, which is a small reflection of the real world with its three main components: space, time, and society.
4. This inner world must be described vocally by a human speaker in phrases with definite patterns.
5. These phrases are marked by the speaker. The markers are:

a. Phrase pattern

b. Object within the phrase

c. Phrase intonation (question, imperative, statement, etc.)

d. Number of words in the phrase

e. Function of each word in the phrase

f. Some others markers.

Initially, the speaker records and marks an acceptable amount of all variations of the phrase patterns (about 5 repetitions for each tested phrase). We then extract sound features from all recordings. We extract 53 features for each recording frame using the Essentia library. For training and subsequent recognition, we use the TensorFlow C-API. The trained virtual agent can:

1. Name an object the human speaker points at
2. Find a requested object
3. Give a suitable answer for a trained question-answer pair
4. Give an answer about an object’s size and color
5. Execute requested vocal commands
6. Recognize different speaking intonations (command, question, story, etc.)",t2_6zjod2ey,False,,0,False,Language acquisition by virtual agent (The Folks’Talks game project),[],r/tensorflow,False,6,,0,,,False,t3_kqb3ug,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609803578.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Abstract.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The project aims to simulate language acquisition. We simulate language acquisition by a virtual agent from a native speaker. The demonstrated principles for acquisition are suitable for any language. These are the initial principles of the Folks’Talks game project:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Acquisition starts from scratch. There is no preliminary data.&lt;/li&gt;
&lt;li&gt;The collected data is vocal (wave files) and not connected to any writing system.&lt;/li&gt;
&lt;li&gt;In the virtual interaction areas of the Folks’Talks game objects are placed in specific ways, within specific scenes, and with specific relations. These objects represent the inner world of the Folks’Talks game, which is a small reflection of the real world with its three main components: space, time, and society.&lt;/li&gt;
&lt;li&gt;This inner world must be described vocally by a human speaker in phrases with definite patterns.&lt;/li&gt;
&lt;li&gt;These phrases are marked by the speaker. The markers are:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;a. Phrase pattern&lt;/p&gt;

&lt;p&gt;b. Object within the phrase&lt;/p&gt;

&lt;p&gt;c. Phrase intonation (question, imperative, statement, etc.)&lt;/p&gt;

&lt;p&gt;d. Number of words in the phrase&lt;/p&gt;

&lt;p&gt;e. Function of each word in the phrase&lt;/p&gt;

&lt;p&gt;f. Some others markers.&lt;/p&gt;

&lt;p&gt;Initially, the speaker records and marks an acceptable amount of all variations of the phrase patterns (about 5 repetitions for each tested phrase). We then extract sound features from all recordings. We extract 53 features for each recording frame using the Essentia library. For training and subsequent recognition, we use the TensorFlow C-API. The trained virtual agent can:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Name an object the human speaker points at&lt;/li&gt;
&lt;li&gt;Find a requested object&lt;/li&gt;
&lt;li&gt;Give a suitable answer for a trained question-answer pair&lt;/li&gt;
&lt;li&gt;Give an answer about an object’s size and color&lt;/li&gt;
&lt;li&gt;Execute requested vocal commands&lt;/li&gt;
&lt;li&gt;Recognize different speaking intonations (command, question, story, etc.)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kqb3ug,True,,FolksTalksGame,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kqb3ug/language_acquisition_by_virtual_agent_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kqb3ug/language_acquisition_by_virtual_agent_the/,22217,1609774778.0,0,,False,,,,,,,,,
284,,tensorflow,"Hi,

I posted a question in [stackoverflow](https://stackoverflow.com/questions/65514470/how-to-pass-big-sparse-tensors-to-a-function-to-be-used-via-dataset-map-without) and filed an issue in [github](https://github.com/tensorflow/tensorflow/issues/46089) for this. Maybe I get an answer here. 

I am using a constant big sparse tensor of size 16777216 by 5416537 with 335548396 entries (this is the tfidf matrix in DrQA) I want to ultimately multiply this by a sparse vector of size 16777216 and get another sparse vector of size 5416537 (the similarity scores.)

I have tried this in three different ways:

1) Having the constant being loaded before a function f uses it (not as an argument) and use `ds.map(f, num_parallel_calls=32)` this ends up in adding the constant to the graph and hitting the 2GB limit. I honestly don't know why, since I though it was only one operation the full single matrix, it has to be that the constant entries are being unfolded and added as single ops in the graph. I really don't get if the limit on number of ops or the memory required to store the graph. I tried to turn the folding off following this [guide](https://www.tensorflow.org/guide/graph_optimization) without any positive result.

2) Passing the components of the sparse matrix as arguments (indices and values) and use `Dataset.zip ((ds, Dataset.from_tensor(indices).repeat(), ...` I use here the operations `sparse_csr_matrix_ops.sparse_matrix_sparse_mat_mul` to multiply to sparse tensors in csr format. It all ends up being extremely slow, I doubt it has to do with the implementation of the sparse product, since it's around 160 times slower than the following solution. I know that if I use a lot of parallel_calls the sparse matrix has to be generated several times per each parallel call, and this creates a memory bottleneck, I have to use a quarter of my cpu count to get a decent (still slow) speed.

3) I use a `py_function` and keep the constant matrix as a python constant and use scipy sparse products in csr format as well, this gives me good performance. Since the constant is never in the TF graph it does not hit the 2GB limit. I was hoping to get something similar with TF but it was impossible.

Does anyone knows how to use a constant this large (to be use together with Datasets) without overpopulating the graph? Or can you confirm if the sparse multiplication has such a big performance hit?

Best.",t2_5ovgt,False,,0,False,How to use big and constant sparse tensors with Datasets.,[],r/tensorflow,False,6,,0,,,False,t3_kq7vr5,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609792378.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I posted a question in &lt;a href=""https://stackoverflow.com/questions/65514470/how-to-pass-big-sparse-tensors-to-a-function-to-be-used-via-dataset-map-without""&gt;stackoverflow&lt;/a&gt; and filed an issue in &lt;a href=""https://github.com/tensorflow/tensorflow/issues/46089""&gt;github&lt;/a&gt; for this. Maybe I get an answer here. &lt;/p&gt;

&lt;p&gt;I am using a constant big sparse tensor of size 16777216 by 5416537 with 335548396 entries (this is the tfidf matrix in DrQA) I want to ultimately multiply this by a sparse vector of size 16777216 and get another sparse vector of size 5416537 (the similarity scores.)&lt;/p&gt;

&lt;p&gt;I have tried this in three different ways:&lt;/p&gt;

&lt;p&gt;1) Having the constant being loaded before a function f uses it (not as an argument) and use &lt;code&gt;ds.map(f, num_parallel_calls=32)&lt;/code&gt; this ends up in adding the constant to the graph and hitting the 2GB limit. I honestly don&amp;#39;t know why, since I though it was only one operation the full single matrix, it has to be that the constant entries are being unfolded and added as single ops in the graph. I really don&amp;#39;t get if the limit on number of ops or the memory required to store the graph. I tried to turn the folding off following this &lt;a href=""https://www.tensorflow.org/guide/graph_optimization""&gt;guide&lt;/a&gt; without any positive result.&lt;/p&gt;

&lt;p&gt;2) Passing the components of the sparse matrix as arguments (indices and values) and use &lt;code&gt;Dataset.zip ((ds, Dataset.from_tensor(indices).repeat(), ...&lt;/code&gt; I use here the operations &lt;code&gt;sparse_csr_matrix_ops.sparse_matrix_sparse_mat_mul&lt;/code&gt; to multiply to sparse tensors in csr format. It all ends up being extremely slow, I doubt it has to do with the implementation of the sparse product, since it&amp;#39;s around 160 times slower than the following solution. I know that if I use a lot of parallel_calls the sparse matrix has to be generated several times per each parallel call, and this creates a memory bottleneck, I have to use a quarter of my cpu count to get a decent (still slow) speed.&lt;/p&gt;

&lt;p&gt;3) I use a &lt;code&gt;py_function&lt;/code&gt; and keep the constant matrix as a python constant and use scipy sparse products in csr format as well, this gives me good performance. Since the constant is never in the TF graph it does not hit the 2GB limit. I was hoping to get something similar with TF but it was impossible.&lt;/p&gt;

&lt;p&gt;Does anyone knows how to use a constant this large (to be use together with Datasets) without overpopulating the graph? Or can you confirm if the sparse multiplication has such a big performance hit?&lt;/p&gt;

&lt;p&gt;Best.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kq7vr5,True,,jorgeecardona,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kq7vr5/how_to_use_big_and_constant_sparse_tensors_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kq7vr5/how_to_use_big_and_constant_sparse_tensors_with/,22217,1609763578.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
285,,tensorflow,,t2_p3jl6tq,False,,0,False,Top 20 Data Science Platforms &amp; Their Most Common Uses,[],r/tensorflow,False,6,,0,,,False,t3_kq6z4s,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Project,False,1,,False,default,False,,[],{},,False,,1609788762.0,text,6,,,text,dasca.org,False,,,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kq6z4s,True,,sharmaniti437,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kq6z4s/top_20_data_science_platforms_their_most_common/,all_ads,False,https://www.dasca.org/world-of-big-data/article/top-20-data-science-platforms-and-their-most-common-uses,22217,1609759962.0,0,,False,,https://www.dasca.org/world-of-big-data/article/top-20-data-science-platforms-and-their-most-common-uses,,,,,,,
286,,tensorflow,"I already have experience with python, but I am not sure where to learn tensorflow",t2_61taps64,False,,0,False,"Beginner: Just starting to learn tensorflow, any tips?",[],r/tensorflow,False,6,,0,,,False,t3_kpx0f2,False,dark,0.8,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1609749319.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I already have experience with python, but I am not sure where to learn tensorflow&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kpx0f2,True,,Real_Scholar2762,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/kpx0f2/beginner_just_starting_to_learn_tensorflow_any/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kpx0f2/beginner_just_starting_to_learn_tensorflow_any/,22217,1609720519.0,0,,False,,,,,,,,,
287,,tensorflow,"How do I make an image classifier with size (200,200,1) perform well I am only getting 30% accuracy is it due to my hardware I dont have a gpu",t2_5q4igchx,False,,0,False,Help!,[],r/tensorflow,False,6,,0,,,False,t3_kq3uym,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1609774225.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How do I make an image classifier with size (200,200,1) perform well I am only getting 30% accuracy is it due to my hardware I dont have a gpu&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kq3uym,True,,c0d3r_,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kq3uym/help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kq3uym/help/,22217,1609745425.0,0,,False,,,,,,,,,
288,,tensorflow," 

    plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()",t2_61taps64,False,,0,False,"I am new to tensorflow, and I am confused abt this section of the code. Can someone briefly explain this to me, I appreciate it.",[],r/tensorflow,False,6,,0,,,False,t3_kq1807,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609763438.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;plt.figure(figsize=(10,10))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kq1807,True,,Real_Scholar2762,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kq1807/i_am_new_to_tensorflow_and_i_am_confused_abt_this/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kq1807/i_am_new_to_tensorflow_and_i_am_confused_abt_this/,22217,1609734638.0,0,,False,,,,,,,,,
289,,tensorflow,"Hello everyone, sos

I am following an online tutorial on how to run gesture recognition using react and tensor flow. However, I am always seeing this error whenever I play around with the webcam in chrome.

Here is my github for what I am working on btw. And here is the tutorial video I'm watching. I got stuck right around minute 10

[ https://github.com/riccrdo5/handpose-help ] (https://github.com/riccrdo5/handpose-help)

[https://youtu.be/f7uBsb-0sGQ](https://youtu.be/f7uBsb-0sGQ)

Ty and happy holidays

&amp;#x200B;

&amp;#x200B;

https://preview.redd.it/3y923uvvc6961.png?width=1366&amp;format=png&amp;auto=webp&amp;s=557aed6e1faac7e38150189582dba9796f4a044c

https://preview.redd.it/ateyqtvvc6961.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;s=ffed821126f1e56f9d2ae1b9562e37a2de85f7a4",t2_6cpgks1a,False,,0,False,"""Unhandled Rejection Error, The Implicit Shape can not be a fractional number """,[],r/tensorflow,False,6,,0,140.0,,False,t3_kprnao,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},Question,False,2,,False,https://b.thumbs.redditmedia.com/6jWmEwtiQLKolDBzusIb_O2iaAPOpt8v-LRBnTP8zik.jpg,1610254901.0,,[],{},,True,,1609732600.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, sos&lt;/p&gt;

&lt;p&gt;I am following an online tutorial on how to run gesture recognition using react and tensor flow. However, I am always seeing this error whenever I play around with the webcam in chrome.&lt;/p&gt;

&lt;p&gt;Here is my github for what I am working on btw. And here is the tutorial video I&amp;#39;m watching. I got stuck right around minute 10&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/riccrdo5/handpose-help""&gt; https://github.com/riccrdo5/handpose-help &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://youtu.be/f7uBsb-0sGQ""&gt;https://youtu.be/f7uBsb-0sGQ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ty and happy holidays&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3y923uvvc6961.png?width=1366&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=557aed6e1faac7e38150189582dba9796f4a044c""&gt;https://preview.redd.it/3y923uvvc6961.png?width=1366&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=557aed6e1faac7e38150189582dba9796f4a044c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ateyqtvvc6961.jpg?width=960&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ffed821126f1e56f9d2ae1b9562e37a2de85f7a4""&gt;https://preview.redd.it/ateyqtvvc6961.jpg?width=960&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ffed821126f1e56f9d2ae1b9562e37a2de85f7a4&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kprnao,True,,RicardoCarlos55,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kprnao/unhandled_rejection_error_the_implicit_shape_can/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kprnao/unhandled_rejection_error_the_implicit_shape_can/,22217,1609703800.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?auto=webp&amp;s=d42cf97dab3541d0c043b8f6f0345c22e443b5a0', 'width': 1366, 'height': 768}, 'resolutions': [{'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ff20e1f09867cd7229a18edaf746cbc25e148fc', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cfb420716a64fd42364d89c641ce23d871ce316', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=07487415e1ebe6f408fe852c2fc74a7e1906ce04', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=356579a30067ff8e7f6949f31647faaa9778e51b', 'width': 640, 'height': 359}, {'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=33f981fab144798098ae4a0f87828bdc2ab6fb61', 'width': 960, 'height': 539}, {'url': 'https://external-preview.redd.it/BuUOEXFlj5Uf-iqIckWCptYu-5cedgEk23whJAn2GMA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6d3c6cf82c78a3fedd7dd113380835dee7e29307', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '5lh15SUWXFtRt5fO35OEeV05Nqzuogu-6_zV29KoFvI'}], 'enabled': False}",,"{'ateyqtvvc6961': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/ateyqtvvc6961.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b43f2011b1d95affccd0b9354b75bcee3cced522'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/ateyqtvvc6961.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c166ce26de9b58ac81a66edeb0549f13f2b31954'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/ateyqtvvc6961.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7258f7cdeb7779255c81a94111afe0c4a568f056'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/ateyqtvvc6961.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=250327a888d0e55cb03d6c2971e1d95b55877d45'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/ateyqtvvc6961.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4d0187a4023068e7457b8dcff11fdc4ce1165a9'}], 's': {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/ateyqtvvc6961.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;s=ffed821126f1e56f9d2ae1b9562e37a2de85f7a4'}, 'id': 'ateyqtvvc6961'}, '3y923uvvc6961': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=67b69e746d088f350c35e66b060158623f16550a'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e12c9a7879d80945a6ff1dfa75c25c363c66bb87'}, {'y': 179, 'x': 320, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=88cc2500019c8b7459760c01eb328ba5c9b8af3c'}, {'y': 359, 'x': 640, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=80d55cf139a445111b680bf45dd84e592356e951'}, {'y': 539, 'x': 960, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa506e761f55aa1758acc8a79801da48f2764255'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8bef8bbb140e1833172df02db0a7192db0c45956'}], 's': {'y': 768, 'x': 1366, 'u': 'https://preview.redd.it/3y923uvvc6961.png?width=1366&amp;format=png&amp;auto=webp&amp;s=557aed6e1faac7e38150189582dba9796f4a044c'}, 'id': '3y923uvvc6961'}}",,,,
290,,tensorflow,,t2_jj0fjpa,False,,0,False,I made an A.I. create Drake lyrics in my first ML project!,[],r/tensorflow,False,6,,0,105.0,,False,t3_kowxxz,False,dark,0.92,,public,49,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lU6JFuduCac?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'I made an A.I. read Drake lyrics for over 1000 Hours...', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lU6JFuduCac?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Jarrod Watts', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/lU6JFuduCac/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCJae_agpt9S3qwWNED0KHcQ'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lU6JFuduCac?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kowxxz', 'height': 200}",Project,False,49,,False,https://b.thumbs.redditmedia.com/WRAH43DNOk2xhg20xm_iBnz99hHlgEEbuFr_5dyZt_A.jpg,False,,[],{},,False,,1609620384.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kowxxz,True,,cumcopter,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kowxxz/i_made_an_ai_create_drake_lyrics_in_my_first_ml/,all_ads,False,https://www.youtube.com/watch?v=lU6JFuduCac,22217,1609591584.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'I made an A.I. read Drake lyrics for over 1000 Hours...', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lU6JFuduCac?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Jarrod Watts', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/lU6JFuduCac/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCJae_agpt9S3qwWNED0KHcQ'}}",False,rich:video,https://www.youtube.com/watch?v=lU6JFuduCac,"{'images': [{'source': {'url': 'https://external-preview.redd.it/RsBjFTfdhTwvs0pzQOSrl9mMTcBagz64UEJnO5eLEQc.jpg?auto=webp&amp;s=383136e666466cef2233d1f8517ac63248b75322', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/RsBjFTfdhTwvs0pzQOSrl9mMTcBagz64UEJnO5eLEQc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bcd0d914ae5ac308394df8e78e5c1755d9e5da9b', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/RsBjFTfdhTwvs0pzQOSrl9mMTcBagz64UEJnO5eLEQc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff9ed3b016b1a6794b4731b46191ae5ef6087fca', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/RsBjFTfdhTwvs0pzQOSrl9mMTcBagz64UEJnO5eLEQc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7ccd75cb122bcd4d7e040121ffa6286bb6d3974', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'iVnYJAcfNR9RNBr5TomCqKMtNiWtQoqORBLk1nxiGKo'}], 'enabled': False}",,,,,,
291,,tensorflow,"Hi everyone, I did a post 3 days ago about compiling tensorflow on rocm [here the post](https://www.reddit.com/r/tensorflow/comments/kn0rgu/compiling_tensorflow_with_rocm_support/?utm_source=share&amp;utm_medium=web2x&amp;context=3). I did not precised that I was on arch linux at the time and now I am trying to build on fedora. Following [those instructions](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/blob/develop-upstream/rocm_docs/tensorflow-build-from-source.md) I end up with bazel saying me that some rocm included libs are not declared as dependencies. How can I solve that ? I tried to understand the bazel syntax of the file concerned but I am a bit pissed by old the suffering (I also suffered to try to install pytorch on arch before achieving to do it on fedora)

Here is the error message :
```log
ERROR: /home/matteo/sources/tensorflow/tensorflow/stream_executor/rocm/BUILD:297:1: undeclared inclusion(s) in rule '//tensorflow/stream_executor/rocm:rocm_helpers':
this rule is missing dependency declarations for the following files included by 'tensorflow/stream_executor/rocm/rocm_helpers.cu.cc':
  '/opt/rocm-4.0.0/hip/include/hip/hip_runtime.h'
  '/opt/rocm-4.0.0/hip/include/hip/hip_version.h'
  '/opt/rocm-4.0.0/hip/include/hip/hip_common.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_runtime.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_common.h'
  '/opt/rocm-4.0.0/hip/include/hip/hip_runtime_api.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_runtime_api.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/host_defines.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/driver_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_texture_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/channel_descriptor.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_vector_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/texture_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_surface_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_ldg.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_atomic.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/device_functions.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/math_fwd.h'
  '/opt/rocm-4.0.0/hip/include/hip/hip_vector_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/device_library_decls.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/llvm_intrinsics.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/surface_functions.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/texture_fetch_functions.h'
  '/opt/rocm-4.0.0/hip/include/hip/texture_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/ockl_image.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/texture_indirect_functions.h'
  '/opt/rocm-4.0.0/hip/include/hip/hip_texture_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/math_functions.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_fp16_math_fwd.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_memory.h'
  '/opt/rocm-4.0.0/hip/include/hip/library_types.h'
  '/opt/rocm-4.0.0/hip/include/hip/hcc_detail/library_types.h'
```

and here is the section of the BUILD file:
```
 297   │ cc_library(
 298   │         name = ""rocm_helpers"",
 299   │         srcs = [""rocm_helpers.cu.cc""],
 300   │         deps =
 301   │         [""@local_config_rocm//rocm:rocm_headers"",
 302   │         ],
 303   │         copts = rocm_copts(),
 304   │         alwayslink = True,
 305   │     )

```",t2_3p9011e2,False,,0,False,Compiling tensorflow on rocm,[],r/tensorflow,False,6,,0,,,False,t3_koxwik,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1609624819.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I did a post 3 days ago about compiling tensorflow on rocm &lt;a href=""https://www.reddit.com/r/tensorflow/comments/kn0rgu/compiling_tensorflow_with_rocm_support/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3""&gt;here the post&lt;/a&gt;. I did not precised that I was on arch linux at the time and now I am trying to build on fedora. Following &lt;a href=""https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/blob/develop-upstream/rocm_docs/tensorflow-build-from-source.md""&gt;those instructions&lt;/a&gt; I end up with bazel saying me that some rocm included libs are not declared as dependencies. How can I solve that ? I tried to understand the bazel syntax of the file concerned but I am a bit pissed by old the suffering (I also suffered to try to install pytorch on arch before achieving to do it on fedora)&lt;/p&gt;

&lt;p&gt;Here is the error message :
&lt;code&gt;log
ERROR: /home/matteo/sources/tensorflow/tensorflow/stream_executor/rocm/BUILD:297:1: undeclared inclusion(s) in rule &amp;#39;//tensorflow/stream_executor/rocm:rocm_helpers&amp;#39;:
this rule is missing dependency declarations for the following files included by &amp;#39;tensorflow/stream_executor/rocm/rocm_helpers.cu.cc&amp;#39;:
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hip_runtime.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hip_version.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hip_common.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_runtime.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_common.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hip_runtime_api.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_runtime_api.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/host_defines.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/driver_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_texture_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/channel_descriptor.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_vector_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/texture_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_surface_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_ldg.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_atomic.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/device_functions.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/math_fwd.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hip_vector_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/device_library_decls.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/llvm_intrinsics.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/surface_functions.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/texture_fetch_functions.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/texture_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/ockl_image.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/texture_indirect_functions.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hip_texture_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/math_functions.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_fp16_math_fwd.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/hip_memory.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/library_types.h&amp;#39;
  &amp;#39;/opt/rocm-4.0.0/hip/include/hip/hcc_detail/library_types.h&amp;#39;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and here is the section of the BUILD file:
```
 297   │ cc_library(
 298   │         name = &amp;quot;rocm_helpers&amp;quot;,
 299   │         srcs = [&amp;quot;rocm_helpers.cu.cc&amp;quot;],
 300   │         deps =
 301   │         [&amp;quot;@local_config_rocm//rocm:rocm_headers&amp;quot;,
 302   │         ],
 303   │         copts = rocm_copts(),
 304   │         alwayslink = True,
 305   │     )&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,koxwik,True,,baalroga,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/koxwik/compiling_tensorflow_on_rocm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/koxwik/compiling_tensorflow_on_rocm/,22217,1609596019.0,1,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/D3yz96Ip6ydyRzILGSAUm6DlhqkZgpFbcK9caw7QAsk.jpg?auto=webp&amp;s=dc3b527035778042da156efa2786d5b3840420d1', 'width': 192, 'height': 192}, 'resolutions': [{'url': 'https://external-preview.redd.it/D3yz96Ip6ydyRzILGSAUm6DlhqkZgpFbcK9caw7QAsk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c101285d9fbfbebfe14e6dab5a85ee322abfb6f8', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'NiyuT7RYkVwIZq_tU5hmFJpfOxp-12Ko-51PuLfwBgo'}], 'enabled': False}",,,,,,
292,,tensorflow,,t2_4pnrhe50,False,,0,False,Intro to Tensorflow Lite,[],r/tensorflow,False,6,,0,105.0,,False,t3_koth2b,False,dark,0.92,,public,10,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/jCO0Fh70rZw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Intro to Tensorflow Lite', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/jCO0Fh70rZw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/jCO0Fh70rZw/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/jCO0Fh70rZw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/koth2b', 'height': 200}",,False,10,,False,https://a.thumbs.redditmedia.com/QdxRu-Hk7uGM49DnPCT3Vi_2_AjJ8jggm6V8P2uMPL8.jpg,False,,[],{},,False,,1609602318.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,koth2b,True,,hacknomus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/koth2b/intro_to_tensorflow_lite/,all_ads,False,https://youtu.be/jCO0Fh70rZw,22217,1609573518.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Intro to Tensorflow Lite', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/jCO0Fh70rZw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/jCO0Fh70rZw/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}, 'type': 'youtube.com'}",False,rich:video,https://youtu.be/jCO0Fh70rZw,"{'images': [{'source': {'url': 'https://external-preview.redd.it/FPENPJpGhu7BOAnrCo7TBgszO_pfwUQZqgWTXxf1D7s.jpg?auto=webp&amp;s=0404fafc9c8081ac38c5e8288ef4b2117e34adda', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/FPENPJpGhu7BOAnrCo7TBgszO_pfwUQZqgWTXxf1D7s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2173bffdf7f008c11d0183a548e458bea11e51f1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/FPENPJpGhu7BOAnrCo7TBgszO_pfwUQZqgWTXxf1D7s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cab6dd91fd9f994ff5c1e5b9d18eaaf4ed493d8', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/FPENPJpGhu7BOAnrCo7TBgszO_pfwUQZqgWTXxf1D7s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff312054c31c3f2b3cdcbd333dddef38ddfd3e58', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'X4CCW1a1BKRJBASwFJTbWUdMTOSM08llo9vLRzOPiLs'}], 'enabled': False}",,,,,,
293,,tensorflow,,t2_4pnrhe50,False,,0,False,"Building Dense, Dropout, and Readout Layers",[],r/tensorflow,False,6,,0,105.0,,False,t3_kovhoi,False,dark,1.0,,public,3,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qp_aoF8XrV0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Building Dense, Dropout, and Readout Layers', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qp_aoF8XrV0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/qp_aoF8XrV0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qp_aoF8XrV0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kovhoi', 'height': 200}",,False,3,,False,https://a.thumbs.redditmedia.com/b8F-fOXXkS5IhkjOpmyVKWZ2iIHvfPdpdavpylPMjL8.jpg,False,,[],{},,False,,1609612834.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kovhoi,True,,hacknomus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kovhoi/building_dense_dropout_and_readout_layers/,all_ads,False,https://youtu.be/qp_aoF8XrV0,22217,1609584034.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Building Dense, Dropout, and Readout Layers', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qp_aoF8XrV0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/qp_aoF8XrV0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}}",False,rich:video,https://youtu.be/qp_aoF8XrV0,"{'images': [{'source': {'url': 'https://external-preview.redd.it/p8PaBhWscUtgZ_iqd0bYOTQECcnZM_wedxx-Q14i658.jpg?auto=webp&amp;s=854b98160ce1868358a236891d06e371e054f70b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/p8PaBhWscUtgZ_iqd0bYOTQECcnZM_wedxx-Q14i658.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99b669448c671c52fa2104bd7e29efcba2f2bc8b', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/p8PaBhWscUtgZ_iqd0bYOTQECcnZM_wedxx-Q14i658.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1a81b2741524e1253b546e3bd991c275f12364c', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/p8PaBhWscUtgZ_iqd0bYOTQECcnZM_wedxx-Q14i658.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=951d7b5fe90a6eb28ba8980c5775f8f8233616b3', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'bC3z2Vk-BIgdVTtip2iLxZuEwOdim-tRAbi0B2zeKTI'}], 'enabled': False}",,,,,,
294,,tensorflow,"    def get_model_2(input_shape):
        model = Sequential()
        model.add(Conv2D(64, (5, 5), activation='relu', input_shape=input_shape))
        model.add(MaxPooling2D(pool_size=(3, 3)))
        model.add(Conv2D(128, (4, 4), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Conv2D(512, (3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Conv2D(512, (3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
    
        # model.add(Conv2D(512, (3, 3), activation='relu'))
        # model.add(MaxPooling2D(pool_size=(2, 2)))
    
        model.add(Conv2D(512, (2, 2), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Flatten())
        model.add(Dense(512, activation='relu'))
        # model.add(Dropout(0.5))
        model.add(Dense(1, activation='sigmoid'))
    
        return model

Why do I get the following error when I un-comment that middle layer?

&amp;#x200B;

&gt;ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max\_pooling2d\_4/MaxPool}} = MaxPool\[T=DT\_FLOAT, data\_format=""NHWC"", explicit\_paddings=\[\], ksize=\[1, 2, 2, 1\], padding=""VALID"", strides=\[1, 2, 2, 1\]\](Placeholder)' with input shapes: \[?,1,1,512\].",t2_621he0r0,False,,0,False,ValueError: Negative dimension size caused by subtracting 2 from 1,[],r/tensorflow,False,6,,0,,,False,t3_kp044h,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1609632837.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;def get_model_2(input_shape):
    model = Sequential()
    model.add(Conv2D(64, (5, 5), activation=&amp;#39;relu&amp;#39;, input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=(3, 3)))
    model.add(Conv2D(128, (4, 4), activation=&amp;#39;relu&amp;#39;))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(512, (3, 3), activation=&amp;#39;relu&amp;#39;))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(512, (3, 3), activation=&amp;#39;relu&amp;#39;))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # model.add(Conv2D(512, (3, 3), activation=&amp;#39;relu&amp;#39;))
    # model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(512, (2, 2), activation=&amp;#39;relu&amp;#39;))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(512, activation=&amp;#39;relu&amp;#39;))
    # model.add(Dropout(0.5))
    model.add(Dense(1, activation=&amp;#39;sigmoid&amp;#39;))

    return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Why do I get the following error when I un-comment that middle layer?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ValueError: Negative dimension size caused by subtracting 2 from 1 for &amp;#39;{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=&amp;quot;NHWC&amp;quot;, explicit_paddings=[], ksize=[1, 2, 2, 1], padding=&amp;quot;VALID&amp;quot;, strides=[1, 2, 2, 1]](Placeholder)&amp;#39; with input shapes: [?,1,1,512].&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kp044h,True,,BananaCharmer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kp044h/valueerror_negative_dimension_size_caused_by/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kp044h/valueerror_negative_dimension_size_caused_by/,22217,1609604037.0,0,,False,,,,,,,,,
295,,tensorflow,I wrote a custom model using a custom loss function.  The layers are all basic keras layers but the loss function is a custom.  How do I move this to a high performance serving scenario?  I don't need to do training - just prediction.   Suggestions? Tutorials?,t2_15wsdd,False,,0,False,Trained a model w. Keras in Python w. custom loss function. How can I deploy it for inference with Tensorflow Serving - aka how to define a custom loss function or just disable that part?,[],r/tensorflow,False,6,,0,,,False,t3_koyrai,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609628213.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wrote a custom model using a custom loss function.  The layers are all basic keras layers but the loss function is a custom.  How do I move this to a high performance serving scenario?  I don&amp;#39;t need to do training - just prediction.   Suggestions? Tutorials?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,koyrai,True,,i8code,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/koyrai/trained_a_model_w_keras_in_python_w_custom_loss/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/koyrai/trained_a_model_w_keras_in_python_w_custom_loss/,22217,1609599413.0,0,,False,,,,,,,,,
296,,tensorflow,I mean different number of gradient updates to generator and discriminator,t2_zv1tm5,False,,0,False,How to perform different gradient updates for generator and discriminator while training GAN's ?? A small snippet or pseudo code will help !,[],r/tensorflow,False,6,,0,,,False,t3_koxhxx,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1609623028.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I mean different number of gradient updates to generator and discriminator&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,koxhxx,True,,DynoKool,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/koxhxx/how_to_perform_different_gradient_updates_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/koxhxx/how_to_perform_different_gradient_updates_for/,22217,1609594228.0,0,,False,,,,,,,,,
297,,tensorflow,,t2_4pnrhe50,False,,0,False,Testing on Mobile Device,[],r/tensorflow,False,6,,0,105.0,,False,t3_kouxse,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QkrveE6jX4M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Testing on Mobile Device', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QkrveE6jX4M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QkrveE6jX4M/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QkrveE6jX4M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kouxse', 'height': 200}",,False,1,,False,https://a.thumbs.redditmedia.com/DJ8ZWEOwEPgo_RptyckNRR6xR6ZaHRsAi1POxf0GF84.jpg,False,,[],{},,False,,1609609920.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kouxse,True,,hacknomus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kouxse/testing_on_mobile_device/,all_ads,False,https://youtu.be/QkrveE6jX4M,22217,1609581120.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Testing on Mobile Device', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QkrveE6jX4M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QkrveE6jX4M/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}}",False,rich:video,https://youtu.be/QkrveE6jX4M,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IcmR9HFd3eYB4I73S5nyilq93_Sw36wcfCOewQzJ1lc.jpg?auto=webp&amp;s=6d0bc5e33ed7723b7691321a3055bcf17a3c332b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/IcmR9HFd3eYB4I73S5nyilq93_Sw36wcfCOewQzJ1lc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f797ce22434ff5cf36e3f9d75fea279cc4dfac6b', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/IcmR9HFd3eYB4I73S5nyilq93_Sw36wcfCOewQzJ1lc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=750ae246dd1afec2bafe662c1e18e3aeea26b2d8', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/IcmR9HFd3eYB4I73S5nyilq93_Sw36wcfCOewQzJ1lc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e2e3c09ee2dfd779a17b2791ff2bfa29eacb3df', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'e6GNNt8a2z9g76u2tN3mFVReaddmsjTvMe70S3c9o4E'}], 'enabled': False}",,,,,,
298,,tensorflow,"I'm trying to build a 'Car Classifier' using TensorFlow.

I have 1000 labelled JPG images, 800x800, complete with bounding boxes and associated annotations.coco.json; split into train/validate/test folders.

I've managed to load the TFRecordDataset's using the code below:

**TFRecord Data Set Loading Steps**

    # Load TfRecord data sets
    raw_train = tf.data.TFRecordDataset([training_file])
    raw_validation = tf.data.TFRecordDataset([validation_file])
    raw_test = tf.data.TFRecordDataset([testing_file])
    
    # Load label map
    category_index = label_map_util.create_category_index_from_labelmap(label_map_file, use_display_name=True)
    
    --------------------------------------------------------------------------------
    def extract_features(tfrecord):
        # Extract features using the keys set during creation
        features = {
            'image/object/bbox/xmin': tf.io.VarLenFeature(dtype=tf.float32),
            'image/object/bbox/ymin': tf.io.VarLenFeature(dtype=tf.float32),
            'image/object/bbox/xmax': tf.io.VarLenFeature(dtype=tf.float32),
            'image/object/bbox/ymax': tf.io.VarLenFeature(dtype=tf.float32),        
            'image/object/class/label': tf.io.VarLenFeature(dtype=tf.int64),        
            'image/width': tf.io.FixedLenFeature([], tf.int64),
            'image/height': tf.io.FixedLenFeature([], tf.int64),
            'image/encoded': tf.io.FixedLenFeature([], tf.string)
        }
    
        # Extract the data record
        sample = tf.io.parse_single_example(tfrecord, features)
    
        image = tf.io.decode_image(sample['image/encoded'])        
        label = sample['image/object/class/label']
            
        return [image, label]
    
    raw_train = raw_train.map(extract_features)
    raw_validation = raw_validation.map(extract_features)
    raw_test = raw_test.map(extract_features)

**Transform/Resize images for Training**

    ORIGINAL_IMG_SIZE = 800
    RESIZE_IMG_SIZE = 160 # All images will be resized to 160x160 or 614x614 maybe for Yolo?
    
    def format_example(image, label):
        #https://stackoverflow.com/questions/62957726/i-got-value-error-that-image-has-no-shape-while-converting-image-to-tensor-for-p
        image.set_shape([ORIGINAL_IMG_SIZE, ORIGINAL_IMG_SIZE, 3])
        image = tf.cast(image, tf.float32)
        image = (image/127.5) - 1
        image = tf.image.resize(image, (RESIZE_IMG_SIZE, RESIZE_IMG_SIZE))
        return image, label

* Tensorflow examples only seem to talk about resizing the whole image and not about how to handle resizing of bounding boxes within the image, and bounding box labels.
* **Does anyone have any examples of how to handle the resizing of images together with bounding boxes contained within the image?**

**Training Pipeline**

* Again Tensorflow examples only seem to train with whole images, not with images with bounding boxes and associated bounding box labels.
* **Does anyone have any examples of TensorFlow Transfer Learning training with images with bounding boxes and associated bounding box labels?**",t2_9jorpzzk,False,,0,False,TensorFlow - TFRecords load and transform images with bounding boxes,[],r/tensorflow,False,6,,0,,,False,t3_kollrj,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,1609543946.0,,[],{},,True,,1609572129.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to build a &amp;#39;Car Classifier&amp;#39; using TensorFlow.&lt;/p&gt;

&lt;p&gt;I have 1000 labelled JPG images, 800x800, complete with bounding boxes and associated annotations.coco.json; split into train/validate/test folders.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve managed to load the TFRecordDataset&amp;#39;s using the code below:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TFRecord Data Set Loading Steps&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Load TfRecord data sets
raw_train = tf.data.TFRecordDataset([training_file])
raw_validation = tf.data.TFRecordDataset([validation_file])
raw_test = tf.data.TFRecordDataset([testing_file])

# Load label map
category_index = label_map_util.create_category_index_from_labelmap(label_map_file, use_display_name=True)

--------------------------------------------------------------------------------
def extract_features(tfrecord):
    # Extract features using the keys set during creation
    features = {
        &amp;#39;image/object/bbox/xmin&amp;#39;: tf.io.VarLenFeature(dtype=tf.float32),
        &amp;#39;image/object/bbox/ymin&amp;#39;: tf.io.VarLenFeature(dtype=tf.float32),
        &amp;#39;image/object/bbox/xmax&amp;#39;: tf.io.VarLenFeature(dtype=tf.float32),
        &amp;#39;image/object/bbox/ymax&amp;#39;: tf.io.VarLenFeature(dtype=tf.float32),        
        &amp;#39;image/object/class/label&amp;#39;: tf.io.VarLenFeature(dtype=tf.int64),        
        &amp;#39;image/width&amp;#39;: tf.io.FixedLenFeature([], tf.int64),
        &amp;#39;image/height&amp;#39;: tf.io.FixedLenFeature([], tf.int64),
        &amp;#39;image/encoded&amp;#39;: tf.io.FixedLenFeature([], tf.string)
    }

    # Extract the data record
    sample = tf.io.parse_single_example(tfrecord, features)

    image = tf.io.decode_image(sample[&amp;#39;image/encoded&amp;#39;])        
    label = sample[&amp;#39;image/object/class/label&amp;#39;]

    return [image, label]

raw_train = raw_train.map(extract_features)
raw_validation = raw_validation.map(extract_features)
raw_test = raw_test.map(extract_features)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Transform/Resize images for Training&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ORIGINAL_IMG_SIZE = 800
RESIZE_IMG_SIZE = 160 # All images will be resized to 160x160 or 614x614 maybe for Yolo?

def format_example(image, label):
    #https://stackoverflow.com/questions/62957726/i-got-value-error-that-image-has-no-shape-while-converting-image-to-tensor-for-p
    image.set_shape([ORIGINAL_IMG_SIZE, ORIGINAL_IMG_SIZE, 3])
    image = tf.cast(image, tf.float32)
    image = (image/127.5) - 1
    image = tf.image.resize(image, (RESIZE_IMG_SIZE, RESIZE_IMG_SIZE))
    return image, label
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Tensorflow examples only seem to talk about resizing the whole image and not about how to handle resizing of bounding boxes within the image, and bounding box labels.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Does anyone have any examples of how to handle the resizing of images together with bounding boxes contained within the image?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Training Pipeline&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Again Tensorflow examples only seem to train with whole images, not with images with bounding boxes and associated bounding box labels.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Does anyone have any examples of TensorFlow Transfer Learning training with images with bounding boxes and associated bounding box labels?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kollrj,True,,Worldly-Guest8115,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kollrj/tensorflow_tfrecords_load_and_transform_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kollrj/tensorflow_tfrecords_load_and_transform_images/,22217,1609543329.0,0,,False,,,,,,,,,
299,,tensorflow,"Im Training a vq-vae on audio data (spectrograms), but the posterior always collapses. Anyone an idea how to avoid that?",t2_2u65sj2v,False,,0,False,How to fix VQ-VAE postirior collapse?,[],r/tensorflow,False,6,,0,,,False,t3_koob47,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1609581424.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im Training a vq-vae on audio data (spectrograms), but the posterior always collapses. Anyone an idea how to avoid that?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,koob47,True,,Ramox_Phersu,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/koob47/how_to_fix_vqvae_postirior_collapse/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/koob47/how_to_fix_vqvae_postirior_collapse/,22217,1609552624.0,0,,False,,,,,,,,,
300,,tensorflow,"I have a tflite model which is quite big in size, around 80mb, I want to use it for on-device inference in an app. Though the size of the model is not an issue, the inference time is.

What i plan to do is:
split the model at one node and get two half models of it.
i will calculate the inference of 1st half at app launch and the inference of next half when needed. Is it possible to split in such way ?",t2_1wkfq5ws,False,,0,False,Splitting TFLite model into two,[],r/tensorflow,False,6,,0,,,False,t3_ko8ih2,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1609521708.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a tflite model which is quite big in size, around 80mb, I want to use it for on-device inference in an app. Though the size of the model is not an issue, the inference time is.&lt;/p&gt;

&lt;p&gt;What i plan to do is:
split the model at one node and get two half models of it.
i will calculate the inference of 1st half at app launch and the inference of next half when needed. Is it possible to split in such way ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ko8ih2,True,,scocoyash,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ko8ih2/splitting_tflite_model_into_two/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ko8ih2/splitting_tflite_model_into_two/,22217,1609492908.0,0,,False,,,,,,,,,
301,,tensorflow,,t2_4pnrhe50,False,,0,False,Loading and Display Images,[],r/tensorflow,False,6,,0,105.0,,False,t3_kob3mq,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/bqzZpvbbQvY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Loading and Display Images', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/bqzZpvbbQvY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/bqzZpvbbQvY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/bqzZpvbbQvY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kob3mq', 'height': 200}",,False,1,,False,https://b.thumbs.redditmedia.com/tPaXllxKsrOrvCW3ODfaySUWIFKzs4Mvjj0jo_tI7hg.jpg,False,,[],{},,False,,1609535632.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kob3mq,True,,hacknomus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kob3mq/loading_and_display_images/,all_ads,False,https://youtu.be/bqzZpvbbQvY,22217,1609506832.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Loading and Display Images', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/bqzZpvbbQvY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BinaryWeb Technologies', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/bqzZpvbbQvY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BinaryWebTechnologies'}}",False,rich:video,https://youtu.be/bqzZpvbbQvY,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kAjPSPJR68idDRgxj22xta59SUsBKUeGOdIyPQf7BB4.jpg?auto=webp&amp;s=07241174c0d1229fe15af8d0176c35a05d53d9d4', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/kAjPSPJR68idDRgxj22xta59SUsBKUeGOdIyPQf7BB4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d974dabb1698cba2997fb099d42aae374d027eae', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/kAjPSPJR68idDRgxj22xta59SUsBKUeGOdIyPQf7BB4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f5a13128bb8a388e76cb9723ae59ab432d15d6f', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/kAjPSPJR68idDRgxj22xta59SUsBKUeGOdIyPQf7BB4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a93a73354012ab0c287ef8a406fa2199451025a8', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'kkY5rhKdyEi0fYAzTIoFDWsuyE5ZH2VeI2OgKPTXw3w'}], 'enabled': False}",,,,,,
302,,tensorflow,"Hi, All, 

&amp;#x200B;

I have written a script to export a pre-trained TensorFlow model for inference. The inference code is for the code present at this directory -[https://github.com/sabarim/itis](https://github.com/sabarim/itis).

I took a reference from the Deeplab export\_model.py script to write a similar one for this model. 

Reference script link: [https://github.com/tensorflow/models/blob/master/research/deeplab/export\_model.py](https://github.com/tensorflow/models/blob/master/research/deeplab/export_model.py)

My script: 

[https://projectcode1.s3-us-west-1.amazonaws.com/export\_model.py](https://projectcode1.s3-us-west-1.amazonaws.com/export_model.py)

&amp;#x200B;

I am getting an error, when I try to run inference from the saved model.

FailedPreconditionError: 2 root error(s) found.   

(0) Failed precondition: Attempting to use uninitialized value decoder/feature\_projection0/BatchNorm/moving\_variance 	 \[\[{{node decoder/feature\_projection0/BatchNorm/moving\_variance/read}}\]\] 	 \[\[SemanticPredictions/\_13\]\]   (1) Failed precondition: Attempting to use uninitialized value decoder/feature\_projection0/BatchNorm/moving\_variance 	 \[\[{{node decoder/feature\_projection0/BatchNorm/moving\_variance/read}}\]\] 0 successful operations. 0 derived errors ignored. 

&amp;#x200B;

Could anyone please take a look and help me understand the problem.",t2_3bs1yb28,False,,0,False,Export a model for inference.,[],r/tensorflow,False,6,,0,,,False,t3_knt7cx,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1609461548.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, All, &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have written a script to export a pre-trained TensorFlow model for inference. The inference code is for the code present at this directory -&lt;a href=""https://github.com/sabarim/itis""&gt;https://github.com/sabarim/itis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I took a reference from the Deeplab export_model.py script to write a similar one for this model. &lt;/p&gt;

&lt;p&gt;Reference script link: &lt;a href=""https://github.com/tensorflow/models/blob/master/research/deeplab/export_model.py""&gt;https://github.com/tensorflow/models/blob/master/research/deeplab/export_model.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My script: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://projectcode1.s3-us-west-1.amazonaws.com/export_model.py""&gt;https://projectcode1.s3-us-west-1.amazonaws.com/export_model.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am getting an error, when I try to run inference from the saved model.&lt;/p&gt;

&lt;p&gt;FailedPreconditionError: 2 root error(s) found.   &lt;/p&gt;

&lt;p&gt;(0) Failed precondition: Attempting to use uninitialized value decoder/feature_projection0/BatchNorm/moving_variance   [[{{node decoder/feature_projection0/BatchNorm/moving_variance/read}}]]   [[SemanticPredictions/_13]]   (1) Failed precondition: Attempting to use uninitialized value decoder/feature_projection0/BatchNorm/moving_variance   [[{{node decoder/feature_projection0/BatchNorm/moving_variance/read}}]] 0 successful operations. 0 derived errors ignored. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Could anyone please take a look and help me understand the problem.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,knt7cx,True,,DamanpKaur,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/knt7cx/export_a_model_for_inference/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/knt7cx/export_a_model_for_inference/,22217,1609432748.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/1B6_uOoUkZE68_4ebmxlfCMsV5Tvczl_7SsM9BYLQxE.jpg?auto=webp&amp;s=4fa78f89afc8314dd986a7426d7c79b8b2ae4384', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/1B6_uOoUkZE68_4ebmxlfCMsV5Tvczl_7SsM9BYLQxE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=62e28d7581b54c19fff5f29d0edaf863fc169ec1', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/1B6_uOoUkZE68_4ebmxlfCMsV5Tvczl_7SsM9BYLQxE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f17f270b162f3f79402d1f7eca954e53688c2a8', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/1B6_uOoUkZE68_4ebmxlfCMsV5Tvczl_7SsM9BYLQxE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e40a6747e704bd66791274d21ff5e8d3fe6dd275', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'DRj2fb2UkagE3MGzaVsNU-uGfte2Ep2cmyFi6df9XBI'}], 'enabled': False}",,,,,,
303,,tensorflow,"Hey everyone,

I'm using a Surface Pro X and wanted to get a little bit into Deep Learning and neural networks, and wanted to use Tensorflow. Is it possible/How is it possible to install Tensorflow on ARM devices? Seems to me like the first big hurdle is the one that I can't install Python as a 64-bit-version. Should I maybe use an emulation? Thanks for any help!",t2_900rdvz1,False,,0,False,Tensorflow on ARM Devices,[],r/tensorflow,False,6,,0,,,False,t3_knqok6,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1609452854.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using a Surface Pro X and wanted to get a little bit into Deep Learning and neural networks, and wanted to use Tensorflow. Is it possible/How is it possible to install Tensorflow on ARM devices? Seems to me like the first big hurdle is the one that I can&amp;#39;t install Python as a 64-bit-version. Should I maybe use an emulation? Thanks for any help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,knqok6,True,,Hot-Ad-3651,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/knqok6/tensorflow_on_arm_devices/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/knqok6/tensorflow_on_arm_devices/,22217,1609424054.0,0,,False,,,,,,,,,
304,,tensorflow,"I am training my top model like this and exporting the weights:

    model = Sequential()
    model.add(Flatten(input_shape=train_data.shape[1:]))
    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))
    model.add(Dropout(0.5))
    model.add(Dense(CLASSES, activation='sigmoid')) #num_classes
    
    model.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy', metrics=['accuracy'])
    
    history = model.fit(train_data, train_labels,
                        epochs=initial_epochs,
                        batch_size=BATCH_SIZE,
                        validation_data=(validation_data, validation_labels))
    
    model.save_weights('models/{}topmodel.h5'.format(pltid))

In anothe function, I want to re-create the model above, load in the weights I saved, then mount this on top of a VGG16 base model:

    base_model = applications.VGG16(include_top=False, weights='imagenet', input_shape=IMG_SHAPE)
    train_data = np.load('features/{}_bottleneck_train.npy'.format(pltid))
    
    top_model = Sequential()
    top_model.add(Flatten(input_shape=train_data.shape[1:]))
    top_model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))
    top_model.add(Dropout(0.5))
    top_model.add(Dense(CLASSES, activation='sigmoid'))
    
    top_model.load_weights('models/{}topmodel.h5'.format(pltid))
    
    model = Model(inputs=base_model.inputs, outputs=top_model)

The above doesn't work though (I've tried a few ways; I can't load the weights if my top model and base model are connected (wrong number of layers). But I can't seem to load weights to the top model then connect it to the base either... any ideas?",t2_621he0r0,False,,0,False,"How to load weights to a top model, then connect it to a base model?",[],r/tensorflow,False,6,,0,,,False,t3_knes54,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1609403634.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am training my top model like this and exporting the weights:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = Sequential()
model.add(Flatten(input_shape=train_data.shape[1:]))
model.add(Dense(256, activation=&amp;#39;relu&amp;#39;, kernel_initializer=&amp;#39;he_uniform&amp;#39;))
model.add(Dropout(0.5))
model.add(Dense(CLASSES, activation=&amp;#39;sigmoid&amp;#39;)) #num_classes

model.compile(optimizer=&amp;#39;rmsprop&amp;#39;,
              loss=&amp;#39;categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])

history = model.fit(train_data, train_labels,
                    epochs=initial_epochs,
                    batch_size=BATCH_SIZE,
                    validation_data=(validation_data, validation_labels))

model.save_weights(&amp;#39;models/{}topmodel.h5&amp;#39;.format(pltid))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In anothe function, I want to re-create the model above, load in the weights I saved, then mount this on top of a VGG16 base model:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;base_model = applications.VGG16(include_top=False, weights=&amp;#39;imagenet&amp;#39;, input_shape=IMG_SHAPE)
train_data = np.load(&amp;#39;features/{}_bottleneck_train.npy&amp;#39;.format(pltid))

top_model = Sequential()
top_model.add(Flatten(input_shape=train_data.shape[1:]))
top_model.add(Dense(256, activation=&amp;#39;relu&amp;#39;, kernel_initializer=&amp;#39;he_uniform&amp;#39;))
top_model.add(Dropout(0.5))
top_model.add(Dense(CLASSES, activation=&amp;#39;sigmoid&amp;#39;))

top_model.load_weights(&amp;#39;models/{}topmodel.h5&amp;#39;.format(pltid))

model = Model(inputs=base_model.inputs, outputs=top_model)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above doesn&amp;#39;t work though (I&amp;#39;ve tried a few ways; I can&amp;#39;t load the weights if my top model and base model are connected (wrong number of layers). But I can&amp;#39;t seem to load weights to the top model then connect it to the base either... any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,knes54,True,,BananaCharmer,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/knes54/how_to_load_weights_to_a_top_model_then_connect/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/knes54/how_to_load_weights_to_a_top_model_then_connect/,22217,1609374834.0,0,,False,,,,,,,,,
305,,tensorflow,"TL/DR

I am using keras with tf 2.3 to train a heatmap regression model for key point localisation and am getting some weird errors when resuming from previous checkpoints. I am looking for a simple script that can load weights from a tensorflow ""saved_model"", and use these weights to initialise my fine-tune model.

Some more details:
I am training an FCN to identify key points in an image using heatmap regression. After training 30/50 epochs on an open source dataset, i switch to a production dataset to fine-tune my predictions. While the open source dataset is 150k images, the production dataset is 5k.  I do this because, while the model at epoch 30 gives good results (using only the open source dataset), but I believe fine-tuning will help overcome the rough edges that I spot in the production dataset.

When I resume training after loading the new dataset, I see exceptions that the previous checkpoint could not be loaded filly, and it throws a bunch of error messages that all point to optimiser/Adam weights and biases. I think this issue is due to the difference in the count of the training datasets, but haven't been able to verify it yet. My reasoning is that the error doesn't surface if I use the open source dataset when resuming. Except the image set, there are no differences between the two datasets.

Since I already export my model using tensorflow saved_model format, I am looking for something that I can quickly implement to load weights only and copy them to the newly created model. Any help identifying the root cause of optimiser error or how to handle partial loading of weights in tf.keras is welcome 😄.",t2_2okxzsd7,False,,0,False,Easy way to load weights only from an existing saved_model,[],r/tensorflow,False,6,,0,,,False,t3_knhmjb,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1609413284.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TL/DR&lt;/p&gt;

&lt;p&gt;I am using keras with tf 2.3 to train a heatmap regression model for key point localisation and am getting some weird errors when resuming from previous checkpoints. I am looking for a simple script that can load weights from a tensorflow &amp;quot;saved_model&amp;quot;, and use these weights to initialise my fine-tune model.&lt;/p&gt;

&lt;p&gt;Some more details:
I am training an FCN to identify key points in an image using heatmap regression. After training 30/50 epochs on an open source dataset, i switch to a production dataset to fine-tune my predictions. While the open source dataset is 150k images, the production dataset is 5k.  I do this because, while the model at epoch 30 gives good results (using only the open source dataset), but I believe fine-tuning will help overcome the rough edges that I spot in the production dataset.&lt;/p&gt;

&lt;p&gt;When I resume training after loading the new dataset, I see exceptions that the previous checkpoint could not be loaded filly, and it throws a bunch of error messages that all point to optimiser/Adam weights and biases. I think this issue is due to the difference in the count of the training datasets, but haven&amp;#39;t been able to verify it yet. My reasoning is that the error doesn&amp;#39;t surface if I use the open source dataset when resuming. Except the image set, there are no differences between the two datasets.&lt;/p&gt;

&lt;p&gt;Since I already export my model using tensorflow saved_model format, I am looking for something that I can quickly implement to load weights only and copy them to the newly created model. Any help identifying the root cause of optimiser error or how to handle partial loading of weights in tf.keras is welcome 😄.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,knhmjb,True,,Deep_Quarter,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/knhmjb/easy_way_to_load_weights_only_from_an_existing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/knhmjb/easy_way_to_load_weights_only_from_an_existing/,22217,1609384484.0,0,,False,,,,,,,,,
306,,tensorflow,"Hello everyone, as stated in the title, I am trying to build tensorflow on rocm platform. I am compiling with numa, avx2, rocm, nonccl, noaws, nohdfs and nogcp, and I always end up with a gcc error and almost no informations on it. Even with the verbose_failures flag. Can someone help me ?",t2_3p9011e2,False,,0,False,Compiling tensorflow with rocm support,[],r/tensorflow,False,6,,0,,,False,t3_kn0rgu,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1609357119.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, as stated in the title, I am trying to build tensorflow on rocm platform. I am compiling with numa, avx2, rocm, nonccl, noaws, nohdfs and nogcp, and I always end up with a gcc error and almost no informations on it. Even with the verbose_failures flag. Can someone help me ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kn0rgu,True,,baalroga,,17,True,all_ads,False,[],False,,/r/tensorflow/comments/kn0rgu/compiling_tensorflow_with_rocm_support/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kn0rgu/compiling_tensorflow_with_rocm_support/,22217,1609328319.0,1,,False,,,,,,,,,
307,,tensorflow,"I am looking for resources for me and my team .  I am a data scientist and my team are web dev's.  I know stochasitc maths, python, r, c++ but my dev team knows javascript and cool web voodoo.  

I am having a difficult time trying to package up a tf model with some preprocessing so that we can all understand what's happening.  

I want to just build a prototype on google cloud gcp, just to have a end to end model as a road map.  I am sure they can handle the web api's and data pipelines.  

&amp;#x200B;

Question is: 

Does any one know of examples, courses, etc of end to end deployment of tf 2.x model.  I will need to package up some custom distribution function with requirements from scipy, numpy, pandas.  

&amp;#x200B;

Thanks for your time and help!",t2_6kwe4fb6,False,,0,False,Any recommended resources for deploying TF2.x to the cloud?,[],r/tensorflow,False,6,,0,,,False,t3_knbq2w,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609393969.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking for resources for me and my team .  I am a data scientist and my team are web dev&amp;#39;s.  I know stochasitc maths, python, r, c++ but my dev team knows javascript and cool web voodoo.  &lt;/p&gt;

&lt;p&gt;I am having a difficult time trying to package up a tf model with some preprocessing so that we can all understand what&amp;#39;s happening.  &lt;/p&gt;

&lt;p&gt;I want to just build a prototype on google cloud gcp, just to have a end to end model as a road map.  I am sure they can handle the web api&amp;#39;s and data pipelines.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Question is: &lt;/p&gt;

&lt;p&gt;Does any one know of examples, courses, etc of end to end deployment of tf 2.x model.  I will need to package up some custom distribution function with requirements from scipy, numpy, pandas.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for your time and help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,knbq2w,True,,Ok_Cryptographer2209,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/knbq2w/any_recommended_resources_for_deploying_tf2x_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/knbq2w/any_recommended_resources_for_deploying_tf2x_to/,22217,1609365169.0,0,,False,,,,,,,,,
308,,tensorflow,"Assuming, i have a for loop, that requires a predicted value of my AI each minute, but performance of the loop is important, how would i thread the prediction process? would the Threading library work?",t2_5sv8o3yi,False,,0,False,How can i Thread the prediction process of my AI?,[],r/tensorflow,False,6,,0,,,False,t3_knb448,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1609392072.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Assuming, i have a for loop, that requires a predicted value of my AI each minute, but performance of the loop is important, how would i thread the prediction process? would the Threading library work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,knb448,True,,Chris-hsr,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/knb448/how_can_i_thread_the_prediction_process_of_my_ai/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/knb448/how_can_i_thread_the_prediction_process_of_my_ai/,22217,1609363272.0,0,,False,,,,,,,,,
309,,tensorflow,"I'm using tf.split to split a tensor into multiple tensors of size 16000. I'm doing this inside a tf.data.Dataset map function and since tf.split either takes an iterator or an int as number of splits.  How do I pass a 0 rank tensor as number of splits? 

More information on my question here: https://stackoverflow.com/questions/65506121/split-an-audio-file-into-1-second-chunks-of-audio-tensors-using-tf-data-map

Thanks!",t2_90ds8b56,False,,0,False,How to split a tensor into multiples tensor of some constant length in graph?,[],r/tensorflow,False,6,,0,,,False,t3_kn14br,False,dark,0.72,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1609358760.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using tf.split to split a tensor into multiple tensors of size 16000. I&amp;#39;m doing this inside a tf.data.Dataset map function and since tf.split either takes an iterator or an int as number of splits.  How do I pass a 0 rank tensor as number of splits? &lt;/p&gt;

&lt;p&gt;More information on my question here: &lt;a href=""https://stackoverflow.com/questions/65506121/split-an-audio-file-into-1-second-chunks-of-audio-tensors-using-tf-data-map""&gt;https://stackoverflow.com/questions/65506121/split-an-audio-file-into-1-second-chunks-of-audio-tensors-using-tf-data-map&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kn14br,True,,_a_wandering_spirit,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kn14br/how_to_split_a_tensor_into_multiples_tensor_of/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kn14br/how_to_split_a_tensor_into_multiples_tensor_of/,22217,1609329960.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
310,,tensorflow,"Hi Everyone,

Pretty much in the title. I'm pretty sure that the smoothed values are some sort of exponential moving average.

When evaluating the accuracy of the model (say, the accuracy I want to tell people my model can achieve on the validation set, for some nth epoch), should I be using the smoothed value or the normal value? I take the accuracy every epoch. 

Of course, this is before the ultimate test on the test set, but before doing that, to kind of figure out what my max accuracy is, and to gauge if the hyperparamaters i'm choosing are working, should I be going by the smoothed or not smoothed values?

An example: 

On step no. 151 (epoch 8) 

smoothed accuracy (with smooth = 0.6) is 36.25% 

""real"" accuracy is 42.86%

&amp;#x200B;

Is my actual accuracy 36.25% or 42.86%? i

Thanks!

A",t2_3ke4xozp,False,,0,False,Tensorboard: Should I be using the smoothed or normal value for evaluating accuracy?,[],r/tensorflow,False,6,,0,,,False,t3_kmlc3o,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1609299841.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;

&lt;p&gt;Pretty much in the title. I&amp;#39;m pretty sure that the smoothed values are some sort of exponential moving average.&lt;/p&gt;

&lt;p&gt;When evaluating the accuracy of the model (say, the accuracy I want to tell people my model can achieve on the validation set, for some nth epoch), should I be using the smoothed value or the normal value? I take the accuracy every epoch. &lt;/p&gt;

&lt;p&gt;Of course, this is before the ultimate test on the test set, but before doing that, to kind of figure out what my max accuracy is, and to gauge if the hyperparamaters i&amp;#39;m choosing are working, should I be going by the smoothed or not smoothed values?&lt;/p&gt;

&lt;p&gt;An example: &lt;/p&gt;

&lt;p&gt;On step no. 151 (epoch 8) &lt;/p&gt;

&lt;p&gt;smoothed accuracy (with smooth = 0.6) is 36.25% &lt;/p&gt;

&lt;p&gt;&amp;quot;real&amp;quot; accuracy is 42.86%&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is my actual accuracy 36.25% or 42.86%? i&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;A&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kmlc3o,True,,kirbyburgers,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kmlc3o/tensorboard_should_i_be_using_the_smoothed_or/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kmlc3o/tensorboard_should_i_be_using_the_smoothed_or/,22217,1609271041.0,0,,False,,,,,,,,,
311,,tensorflow,"I have the weights and biases for both the normalizer and the Dense layer in my model, but I am unsure how to convert these values into 1 equation that the computer is using to predict values, which I would like to know. The model takes 2 independent values and predicts 1 value, so using the weights and biases below, how I could formulate an equation:

weights for normalizer layer: \[ 8.89 11.5 \]

biases for normalizer layer: \[321.69 357.53\]

(not even sure if the normalizer biases and weights matter as it is part of preprocessing)

weights for Dense layer: \[\[ 0.08\] \[19.3 \]\]

biases for Dense layer: \[11.54\]

Thank you very much and I would greatly appreciate any help! :)",t2_5bhqr9nu,False,,0,False,How to get equation that multiple linear regression model is using in Keras w/ Tensorflow:,[],r/tensorflow,False,6,,0,,,False,t3_kmc3z1,False,dark,0.92,,public,10,0,{},,,False,[],,False,False,,{},,False,10,,False,self,False,,[],{},,True,,1609267452.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have the weights and biases for both the normalizer and the Dense layer in my model, but I am unsure how to convert these values into 1 equation that the computer is using to predict values, which I would like to know. The model takes 2 independent values and predicts 1 value, so using the weights and biases below, how I could formulate an equation:&lt;/p&gt;

&lt;p&gt;weights for normalizer layer: [ 8.89 11.5 ]&lt;/p&gt;

&lt;p&gt;biases for normalizer layer: [321.69 357.53]&lt;/p&gt;

&lt;p&gt;(not even sure if the normalizer biases and weights matter as it is part of preprocessing)&lt;/p&gt;

&lt;p&gt;weights for Dense layer: [[ 0.08] [19.3 ]]&lt;/p&gt;

&lt;p&gt;biases for Dense layer: [11.54]&lt;/p&gt;

&lt;p&gt;Thank you very much and I would greatly appreciate any help! :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kmc3z1,True,,HexadecimalHero,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kmc3z1/how_to_get_equation_that_multiple_linear/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kmc3z1/how_to_get_equation_that_multiple_linear/,22217,1609238652.0,0,,False,,,,,,,,,
312,,tensorflow,"I have the weights and biases for both the normalizer and the Dense layer in my model, but I am unsure how to convert these values into 1 equation that the computer is using to predict values, which I would like to know. The model takes 2 independent values and predicts 1 value, so using the weights and biases below, how I could formulate an equation:

weights for normalizer layer: \[ 8.89 11.5 \]

biases for normalizer layer: \[321.69 357.53\]

(not even sure if the normalizer biases and weights matter as it is part of preprocessing)

weights for Dense layer: \[\[ 0.08\] \[19.3 \]\]

biases for Dense layer: \[11.54\]

Thank you very much and I would greatly appreciate any help! :)",t2_5bhqr9nu,False,,0,False,How to get the equation that a multiple linear regression model is using in Keras w/ Tensorflow?,[],r/tensorflow,False,6,,0,,,False,t3_kmc48i,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1609267485.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have the weights and biases for both the normalizer and the Dense layer in my model, but I am unsure how to convert these values into 1 equation that the computer is using to predict values, which I would like to know. The model takes 2 independent values and predicts 1 value, so using the weights and biases below, how I could formulate an equation:&lt;/p&gt;

&lt;p&gt;weights for normalizer layer: [ 8.89 11.5 ]&lt;/p&gt;

&lt;p&gt;biases for normalizer layer: [321.69 357.53]&lt;/p&gt;

&lt;p&gt;(not even sure if the normalizer biases and weights matter as it is part of preprocessing)&lt;/p&gt;

&lt;p&gt;weights for Dense layer: [[ 0.08] [19.3 ]]&lt;/p&gt;

&lt;p&gt;biases for Dense layer: [11.54]&lt;/p&gt;

&lt;p&gt;Thank you very much and I would greatly appreciate any help! :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kmc48i,True,,HexadecimalHero,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kmc48i/how_to_get_the_equation_that_a_multiple_linear/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kmc48i/how_to_get_the_equation_that_a_multiple_linear/,22217,1609238685.0,0,,False,,,,,,,,,
313,,tensorflow,"So many outdated guides, so many things to install, and whenever you get it wrong your computer is loaded with 10 GB of junk that you need to get rid of. 

Took me more than a day to set a whole thing up, did the same thing on a different computer and it doesn't work again!",t2_5x51xwu1,False,,0,False,Installing tensorflow with gpu makes me want to blow my brains out,[],r/tensorflow,False,6,,0,,,False,t3_kls13f,False,dark,0.92,,public,52,0,{},,,False,[],,False,False,,{},Question,False,52,,False,self,False,,[],{},,True,,1609196464.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So many outdated guides, so many things to install, and whenever you get it wrong your computer is loaded with 10 GB of junk that you need to get rid of. &lt;/p&gt;

&lt;p&gt;Took me more than a day to set a whole thing up, did the same thing on a different computer and it doesn&amp;#39;t work again!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kls13f,True,,neocoronalism,,26,True,all_ads,False,[],False,,/r/tensorflow/comments/kls13f/installing_tensorflow_with_gpu_makes_me_want_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kls13f/installing_tensorflow_with_gpu_makes_me_want_to/,22217,1609167664.0,0,,False,,,,,,,,,
314,,tensorflow,"I've built my first model and I've not very experienced so I'm unsure if it's structured correctly.

I have the VGG16 model on top (frozen) and I connect this to a dene layer that I train on categorical data (6 classes)

    _________________________________________________________________
    Model: ""model""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #
    =================================================================
    input_1 (InputLayer)         [(None, 150, 150, 3)]     0
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
    _________________________________________________________________
    flatten (Flatten)            (None, 8192)              0
    _________________________________________________________________
    dense (Dense)                (None, 128)               1048704
    _________________________________________________________________
    dense_1 (Dense)              (None, 6)                 774
    =================================================================
    Total params: 15,764,166
    Trainable params: 1,049,478
    Non-trainable params: 14,714,688
    _________________________________________________________________

I want to apply what the model has learnt thus far to a binary classification problem. So, once trained on my categorical data, I freeze \`dense\` and remove \`dense\_1\`, then I add in \`dense\_2\`, \`dense\_3\`, \`dense\_4\` (the latter having 1 output).

    continued from before....
    block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
    _________________________________________________________________
    flatten (Flatten)            (None, 8192)              0
    _________________________________________________________________
    dense (Dense)                (None, 128)               1048704
    _________________________________________________________________
    dense_2 (Dense)              (None, 128)               16512
    _________________________________________________________________
    dense_3 (Dense)              (None, 128)               16512
    _________________________________________________________________
    dense_4 (Dense)              (None, 1)                 129
    =================================================================
    Total params: 15,796,545
    Trainable params: 33,153
    Non-trainable params: 15,763,392

Then I train it on my binary data (I have setup augmentation and preprocessing, etc.)

Does this network make sense though? I don't have the deep understanding many people here do, so not really sure. Any input would be appreciated.",t2_621he0r0,False,,0,False,Does my model make sense? It's looking thicc but I don't know,[],r/tensorflow,False,6,,0,,,False,t3_kmcn32,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1609269926.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve built my first model and I&amp;#39;ve not very experienced so I&amp;#39;m unsure if it&amp;#39;s structured correctly.&lt;/p&gt;

&lt;p&gt;I have the VGG16 model on top (frozen) and I connect this to a dene layer that I train on categorical data (6 classes)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_________________________________________________________________
Model: &amp;quot;model&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 150, 150, 3)]     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
dense (Dense)                (None, 128)               1048704
_________________________________________________________________
dense_1 (Dense)              (None, 6)                 774
=================================================================
Total params: 15,764,166
Trainable params: 1,049,478
Non-trainable params: 14,714,688
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I want to apply what the model has learnt thus far to a binary classification problem. So, once trained on my categorical data, I freeze `dense` and remove `dense_1`, then I add in `dense_2`, `dense_3`, `dense_4` (the latter having 1 output).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;continued from before....
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0
_________________________________________________________________
dense (Dense)                (None, 128)               1048704
_________________________________________________________________
dense_2 (Dense)              (None, 128)               16512
_________________________________________________________________
dense_3 (Dense)              (None, 128)               16512
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 129
=================================================================
Total params: 15,796,545
Trainable params: 33,153
Non-trainable params: 15,763,392
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then I train it on my binary data (I have setup augmentation and preprocessing, etc.)&lt;/p&gt;

&lt;p&gt;Does this network make sense though? I don&amp;#39;t have the deep understanding many people here do, so not really sure. Any input would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kmcn32,True,,BananaCharmer,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kmcn32/does_my_model_make_sense_its_looking_thicc_but_i/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kmcn32/does_my_model_make_sense_its_looking_thicc_but_i/,22217,1609241126.0,0,,False,,,,,,,,,
315,,tensorflow,"Hi All,

I have been looking for TensorFlow models pre-trained on speech data, preferably in js/python. That I can use to extract embeddings for streaming/recorded audio up to 1 min long. 

I intend to use the embeddings as an input to my machine learning pipeline. 

So far, I have found only this:

[https://github.com/tensorflow/tfjs-models/tree/master/speech-commands](https://github.com/tensorflow/tfjs-models/tree/master/speech-commands)

This is trained to classify 20 voice commands. So, I feel the embeddings from this model may not have sufficient discriminative power to identify, let's say - phonemes, 1000 words each from English, French and a few other popular languages.

I am not worried about embedding-&gt;word mapping. At the current stage, I am happy to use the embeddings to evaluate similarity score of two different sound samples. E.g. I am not worried about resolving confusion between - 'red' and 'read(past tense)'. In fact - 'I read a red book' 'Eye red a read buk' should result to 95+% match.

Any hints/redirection are also greatly appreciated. Perhaps there are simpler ways to achieve the same.",t2_36dhy,False,,0,False,Any pre-trained TensorFlow models on speech/voice data?,[],r/tensorflow,False,6,,0,,,False,t3_km6svm,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1609243988.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;I have been looking for TensorFlow models pre-trained on speech data, preferably in js/python. That I can use to extract embeddings for streaming/recorded audio up to 1 min long. &lt;/p&gt;

&lt;p&gt;I intend to use the embeddings as an input to my machine learning pipeline. &lt;/p&gt;

&lt;p&gt;So far, I have found only this:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/tensorflow/tfjs-models/tree/master/speech-commands""&gt;https://github.com/tensorflow/tfjs-models/tree/master/speech-commands&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is trained to classify 20 voice commands. So, I feel the embeddings from this model may not have sufficient discriminative power to identify, let&amp;#39;s say - phonemes, 1000 words each from English, French and a few other popular languages.&lt;/p&gt;

&lt;p&gt;I am not worried about embedding-&amp;gt;word mapping. At the current stage, I am happy to use the embeddings to evaluate similarity score of two different sound samples. E.g. I am not worried about resolving confusion between - &amp;#39;red&amp;#39; and &amp;#39;read(past tense)&amp;#39;. In fact - &amp;#39;I read a red book&amp;#39; &amp;#39;Eye red a read buk&amp;#39; should result to 95+% match.&lt;/p&gt;

&lt;p&gt;Any hints/redirection are also greatly appreciated. Perhaps there are simpler ways to achieve the same.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,km6svm,True,,akshayxyz,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/km6svm/any_pretrained_tensorflow_models_on_speechvoice/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/km6svm/any_pretrained_tensorflow_models_on_speechvoice/,22217,1609215188.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
316,,tensorflow,"I've been learning machine learning from uni, but I haven't done as much practical stuff as I'd like so I decided to do some in the holidays. 

Most of the books I've looked at (Deep learning pipeline). These are pretty recent (2018ish) but mostly seem to either feature tensorflow 1, need a previous version of keras to be compatible, etc etc. Things like the Mnist dataset are also in different forms across different versions. 

For tensorflow I've been just using  

    tf.compat.v1.function()
    

To just keep compatibility with tensorflow 1 so I can follow along with the examples better, but should I just try to find something more recent than 2018? 

One of the tutorials also wanted me to run all code on an ubuntu google cloud machine? 

Are there any super good tensorflow books that are up to date that you'd recommend? I've literally just been searching for deep learning at the university online library. 

It seems kinda dumb that the way the framework operates changes so much in such a short period of time. I'm willing to put time in, but I don't want to go through a 500 page book to realize that everything is now obsolete. Also how the hell do people working in the industry deal with this, when half of the code they've written is now not compatible with the main version.",t2_3gmvv1b,False,,0,False,Most tutorials seem outdated,[],r/tensorflow,False,6,,0,,,False,t3_km2x2b,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609230694.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been learning machine learning from uni, but I haven&amp;#39;t done as much practical stuff as I&amp;#39;d like so I decided to do some in the holidays. &lt;/p&gt;

&lt;p&gt;Most of the books I&amp;#39;ve looked at (Deep learning pipeline). These are pretty recent (2018ish) but mostly seem to either feature tensorflow 1, need a previous version of keras to be compatible, etc etc. Things like the Mnist dataset are also in different forms across different versions. &lt;/p&gt;

&lt;p&gt;For tensorflow I&amp;#39;ve been just using  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tf.compat.v1.function()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To just keep compatibility with tensorflow 1 so I can follow along with the examples better, but should I just try to find something more recent than 2018? &lt;/p&gt;

&lt;p&gt;One of the tutorials also wanted me to run all code on an ubuntu google cloud machine? &lt;/p&gt;

&lt;p&gt;Are there any super good tensorflow books that are up to date that you&amp;#39;d recommend? I&amp;#39;ve literally just been searching for deep learning at the university online library. &lt;/p&gt;

&lt;p&gt;It seems kinda dumb that the way the framework operates changes so much in such a short period of time. I&amp;#39;m willing to put time in, but I don&amp;#39;t want to go through a 500 page book to realize that everything is now obsolete. Also how the hell do people working in the industry deal with this, when half of the code they&amp;#39;ve written is now not compatible with the main version.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,km2x2b,True,,eht_amgine_enihcam,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/km2x2b/most_tutorials_seem_outdated/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/km2x2b/most_tutorials_seem_outdated/,22217,1609201894.0,0,,False,,,,,,,,,
317,,tensorflow,"Yesterday, I installed the latest CUDA toolkit (11.2), but TensorFlow said there was no cudart64\_110.dll file. So, I then installed CUDA toolkit 11.0, which has this file, but TensorFlow still cannot find the file.

I am running Windows 10 Home Edition.",t2_5zg4jvtk,False,,0,False,(Windows) TensorFlow not detecting the cudart64_110.dll file,[],r/tensorflow,False,6,,0,,,False,t3_kle9k3,False,dark,0.82,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1609141162.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Yesterday, I installed the latest CUDA toolkit (11.2), but TensorFlow said there was no cudart64_110.dll file. So, I then installed CUDA toolkit 11.0, which has this file, but TensorFlow still cannot find the file.&lt;/p&gt;

&lt;p&gt;I am running Windows 10 Home Edition.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kle9k3,True,,Comprehensive-Ad3963,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/kle9k3/windows_tensorflow_not_detecting_the_cudart64/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kle9k3/windows_tensorflow_not_detecting_the_cudart64/,22217,1609112362.0,0,,False,,,,,,,,,
318,,tensorflow,"I'm rather quite embarrassed recently for flooding this forum thread with mostly novice questions. I'm still a newbie, still struggling to figure out how the code works in TensorFlow. Pardon me for doing that. Is there any template code where I can compute and display the loss and accuracy of the trained model on the test set?",t2_52hj835v,False,,0,False,How to write a code that can compute and display the loss and accuracy of the trained model on the test set?,[],r/tensorflow,False,6,,0,,,False,t3_kllw6y,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609169564.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m rather quite embarrassed recently for flooding this forum thread with mostly novice questions. I&amp;#39;m still a newbie, still struggling to figure out how the code works in TensorFlow. Pardon me for doing that. Is there any template code where I can compute and display the loss and accuracy of the trained model on the test set?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kllw6y,True,,edmondoh001,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kllw6y/how_to_write_a_code_that_can_compute_and_display/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kllw6y/how_to_write_a_code_that_can_compute_and_display/,22217,1609140764.0,0,,False,,,,,,,,,
319,,tensorflow,,t2_52hj835v,False,,0,False,"How do I write a proper code to plot the images for the SVHN dataset? I'm literally stuck, need some help for that.",[],r/tensorflow,False,6,,0,69.0,,False,t3_kl7m6s,False,dark,0.75,,public,2,0,{},140.0,,False,[],,True,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/Gex7rFUl8hNFJup6qDphj9mg0qdyixavGW-5yuNxhhM.jpg,False,,[],{},,False,,1609119357.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kl7m6s,True,,edmondoh001,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kl7m6s/how_do_i_write_a_proper_code_to_plot_the_images/,all_ads,False,https://i.redd.it/je3fwcarmr761.png,22217,1609090557.0,0,,False,image,https://i.redd.it/je3fwcarmr761.png,"{'images': [{'source': {'url': 'https://preview.redd.it/je3fwcarmr761.png?auto=webp&amp;s=7f4566bc2db5acd2bf193071e0f9fbfc2d06972c', 'width': 1262, 'height': 627}, 'resolutions': [{'url': 'https://preview.redd.it/je3fwcarmr761.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff246ed864245d1f03fc8dc8d60c6d2a9616e731', 'width': 108, 'height': 53}, {'url': 'https://preview.redd.it/je3fwcarmr761.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ad0dcbc1168d80d0362bec16f5424cf0706b22e', 'width': 216, 'height': 107}, {'url': 'https://preview.redd.it/je3fwcarmr761.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a21def00cc954e948a88ca0d5b924d0f08b435f3', 'width': 320, 'height': 158}, {'url': 'https://preview.redd.it/je3fwcarmr761.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=47bca4e0f622d1064f995accaa62710e84a8f762', 'width': 640, 'height': 317}, {'url': 'https://preview.redd.it/je3fwcarmr761.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3c70e45693854317176c8d0fedb99be1f9f6dfce', 'width': 960, 'height': 476}, {'url': 'https://preview.redd.it/je3fwcarmr761.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc1729fce8c15148c74e21d5caaa03dbb59d3eb5', 'width': 1080, 'height': 536}], 'variants': {}, 'id': 'fwQ0L0_aYuF9uQaJm3V0wtosZgEfsN8_LGHiMzTlvuw'}], 'enabled': True}",,,,,,
320,,tensorflow,"Is there an example somewhere of transfer learning using a model you've trained rather than MobileNetV2 or imagenet? I've read through the first 10 Google results and they all use these. I simply want to train model 1, then freeze model 1 layers and train model 2.

First model is straightforward:

&amp;#x200B;

    def main():
    
        ##################
        # TRAIN ON IDEAL #
        ##################
    
        ideal_dir = pathlib.Path('ideal')
    
        CLASSES = 2
        CHANNELS = 3
    
        ideal_epochs = 100
        batch_size = 32
        img_height_ideal = 301 #238
        img_width_ideal = 301 #363
    
        ideal_train = tf.keras.preprocessing.image_dataset_from_directory(
            ideal_dir,
            validation_split=0.2,
            subset=""training"",
            seed=123,
            image_size=(img_height_ideal, img_width_ideal),
            batch_size=batch_size,
        )
    
        ideal_val = tf.keras.preprocessing.image_dataset_from_directory(
            ideal_dir,
            validation_split=0.2,
            subset=""validation"",
            seed=123,
            image_size=(img_height_ideal, img_width_ideal),
            batch_size=batch_size,
        )
    
        AUTOTUNE = tf.data.experimental.AUTOTUNE
        ideal_train = ideal_train.prefetch(buffer_size=AUTOTUNE)
        ideal_val = ideal_val.prefetch(buffer_size=AUTOTUNE)
    
        ideal_augmentation0 = keras.Sequential([
            layers.experimental.preprocessing.RandomFlip(""horizontal""),
            layers.experimental.preprocessing.RandomFlip(""vertical""),
            layers.experimental.preprocessing.RandomRotation(1.0),
            layers.experimental.preprocessing.RandomZoom(0.3),
        ])
    
        ideal_model = Sequential([
            ideal_augmentation0,
            layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height_ideal, img_width_ideal, 3)),
            layers.Conv2D(128, (5, 5), activation='relu', input_shape=(img_height_ideal, img_width_ideal, 3)),
            layers.MaxPooling2D(2, 2),
            layers.Flatten(),
            layers.Dense(64, activation='relu'),
            layers.Dense(CLASSES, activation='softmax'),
        ])
    
        ideal_model.compile(
            optimizer='adam',
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=['accuracy']
        )
    
        ideal_history = ideal_model.fit(
            ideal_train,
            validation_data=ideal_val,
            epochs=ideal_epochs,
        )
    
        ideal_model.summary()

EDIT: Does this look right?

    ideal_model.trainable = False
    
    new_model = Sequential([
            ideal_augmentation0,
            layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height_ideal, img_width_ideal, 3)),
            ideal_model.layers[1], &lt;---------
            ideal_model.layers[2], &lt;---------
            ideal_model.layers[3], &lt;---------
            layers.Conv2D(128, (3, 3), activation='relu', input_shape=(img_height_ideal, img_width_ideal, 3)),
            layers.MaxPooling2D(2, 2),
            layers.Flatten(),
            layers.Dense(64, activation='relu'),
            layers.Dense(CLASSES, activation='softmax'),
        ])

It looks correct from the summary:

    Model: ""sequential_1""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #
    =================================================================
    sequential (Sequential)      (None, 150, 150, 3)       0
    _________________________________________________________________
    rescaling (Rescaling)        (None, 150, 150, 3)       0
    _________________________________________________________________
    conv2d (Conv2D)              (None, 148, 148, 128)     3584
    _________________________________________________________________
    max_pooling2d (MaxPooling2D) (None, 74, 74, 128)       0
    _________________________________________________________________
    flatten (Flatten)            (None, 700928)            0
    _________________________________________________________________
    dense (Dense)                (None, 64)                44859456
    _________________________________________________________________
    dense_1 (Dense)              (None, 2)                 130
    =================================================================
    Total params: 44,863,170
    Trainable params: 44,863,170
    Non-trainable params: 0
    
    _________________________________________________________________
    
    Model: ""sequential_2""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #
    =================================================================
    sequential (Sequential)      (None, 150, 150, 3)       0
    _________________________________________________________________
    rescaling_1 (Rescaling)      (None, 150, 150, 3)       0
    _________________________________________________________________
    rescaling (Rescaling)        (None, 150, 150, 3)       0
    _________________________________________________________________
    conv2d (Conv2D)              (None, 148, 148, 128)     3584
    _________________________________________________________________
    max_pooling2d (MaxPooling2D) (None, 74, 74, 128)       0
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 72, 72, 128)       147584
    _________________________________________________________________
    max_pooling2d_1 (MaxPooling2 (None, 36, 36, 128)       0
    _________________________________________________________________
    flatten_1 (Flatten)          (None, 165888)            0
    _________________________________________________________________
    dense_2 (Dense)              (None, 64)                10616896
    _________________________________________________________________
    dense_3 (Dense)              (None, 2)                 130
    =================================================================
    Total params: 10,768,194
    Trainable params: 10,764,610
    Non-trainable params: 3,584

&amp;#x200B;",t2_621he0r0,False,,0,False,I have a trained model. How do I use it for (transfer learning ) training another model?,[],r/tensorflow,False,6,,0,,,False,t3_kl3niv,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,1609094806.0,,[],{},,True,,1609104383.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there an example somewhere of transfer learning using a model you&amp;#39;ve trained rather than MobileNetV2 or imagenet? I&amp;#39;ve read through the first 10 Google results and they all use these. I simply want to train model 1, then freeze model 1 layers and train model 2.&lt;/p&gt;

&lt;p&gt;First model is straightforward:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def main():

    ##################
    # TRAIN ON IDEAL #
    ##################

    ideal_dir = pathlib.Path(&amp;#39;ideal&amp;#39;)

    CLASSES = 2
    CHANNELS = 3

    ideal_epochs = 100
    batch_size = 32
    img_height_ideal = 301 #238
    img_width_ideal = 301 #363

    ideal_train = tf.keras.preprocessing.image_dataset_from_directory(
        ideal_dir,
        validation_split=0.2,
        subset=&amp;quot;training&amp;quot;,
        seed=123,
        image_size=(img_height_ideal, img_width_ideal),
        batch_size=batch_size,
    )

    ideal_val = tf.keras.preprocessing.image_dataset_from_directory(
        ideal_dir,
        validation_split=0.2,
        subset=&amp;quot;validation&amp;quot;,
        seed=123,
        image_size=(img_height_ideal, img_width_ideal),
        batch_size=batch_size,
    )

    AUTOTUNE = tf.data.experimental.AUTOTUNE
    ideal_train = ideal_train.prefetch(buffer_size=AUTOTUNE)
    ideal_val = ideal_val.prefetch(buffer_size=AUTOTUNE)

    ideal_augmentation0 = keras.Sequential([
        layers.experimental.preprocessing.RandomFlip(&amp;quot;horizontal&amp;quot;),
        layers.experimental.preprocessing.RandomFlip(&amp;quot;vertical&amp;quot;),
        layers.experimental.preprocessing.RandomRotation(1.0),
        layers.experimental.preprocessing.RandomZoom(0.3),
    ])

    ideal_model = Sequential([
        ideal_augmentation0,
        layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height_ideal, img_width_ideal, 3)),
        layers.Conv2D(128, (5, 5), activation=&amp;#39;relu&amp;#39;, input_shape=(img_height_ideal, img_width_ideal, 3)),
        layers.MaxPooling2D(2, 2),
        layers.Flatten(),
        layers.Dense(64, activation=&amp;#39;relu&amp;#39;),
        layers.Dense(CLASSES, activation=&amp;#39;softmax&amp;#39;),
    ])

    ideal_model.compile(
        optimizer=&amp;#39;adam&amp;#39;,
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=[&amp;#39;accuracy&amp;#39;]
    )

    ideal_history = ideal_model.fit(
        ideal_train,
        validation_data=ideal_val,
        epochs=ideal_epochs,
    )

    ideal_model.summary()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EDIT: Does this look right?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ideal_model.trainable = False

new_model = Sequential([
        ideal_augmentation0,
        layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height_ideal, img_width_ideal, 3)),
        ideal_model.layers[1], &amp;lt;---------
        ideal_model.layers[2], &amp;lt;---------
        ideal_model.layers[3], &amp;lt;---------
        layers.Conv2D(128, (3, 3), activation=&amp;#39;relu&amp;#39;, input_shape=(img_height_ideal, img_width_ideal, 3)),
        layers.MaxPooling2D(2, 2),
        layers.Flatten(),
        layers.Dense(64, activation=&amp;#39;relu&amp;#39;),
        layers.Dense(CLASSES, activation=&amp;#39;softmax&amp;#39;),
    ])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks correct from the summary:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential_1&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
sequential (Sequential)      (None, 150, 150, 3)       0
_________________________________________________________________
rescaling (Rescaling)        (None, 150, 150, 3)       0
_________________________________________________________________
conv2d (Conv2D)              (None, 148, 148, 128)     3584
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 74, 74, 128)       0
_________________________________________________________________
flatten (Flatten)            (None, 700928)            0
_________________________________________________________________
dense (Dense)                (None, 64)                44859456
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 130
=================================================================
Total params: 44,863,170
Trainable params: 44,863,170
Non-trainable params: 0

_________________________________________________________________

Model: &amp;quot;sequential_2&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
sequential (Sequential)      (None, 150, 150, 3)       0
_________________________________________________________________
rescaling_1 (Rescaling)      (None, 150, 150, 3)       0
_________________________________________________________________
rescaling (Rescaling)        (None, 150, 150, 3)       0
_________________________________________________________________
conv2d (Conv2D)              (None, 148, 148, 128)     3584
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 74, 74, 128)       0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 72, 72, 128)       147584
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 36, 36, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 165888)            0
_________________________________________________________________
dense_2 (Dense)              (None, 64)                10616896
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 130
=================================================================
Total params: 10,768,194
Trainable params: 10,764,610
Non-trainable params: 3,584
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kl3niv,True,,BananaCharmer,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/kl3niv/i_have_a_trained_model_how_do_i_use_it_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kl3niv/i_have_a_trained_model_how_do_i_use_it_for/,22217,1609075583.0,0,,False,,,,,,,,,
321,,tensorflow,"I was implementing a MLP neural network architecture, just starting to work on the Flatten, Dense Layers, with the final layer having a 10-way softmax output. The problem cropped up even without using the to.categorical function

I run into the error when my loss function is 'categorical\_crossentropy'.

https://preview.redd.it/ai5jmj3qbs761.png?width=1148&amp;format=png&amp;auto=webp&amp;s=aec4e8667d7c7ca2a7fee41eec4e1616c0a38471

And then, I changed my loss function to 'sparse\_categorical\_crossentropy',

I was running into this problem, as shown below

&amp;#x200B;

https://preview.redd.it/ysedtfy4fs761.png?width=1094&amp;format=png&amp;auto=webp&amp;s=78e64df51c7cceb9eb9a4b9860d4ca46fc4ba056

I am stuck. I don't know where did the error come from? Can someone enlighten me. I really appreciated it. It's quite a tough journey for me in this TensorFlow journey.

&amp;#x200B;

Just some extra info: I'm currently working on the [SVHN dataset](http://ufldl.stanford.edu/housenumbers/), which has an image dataset of over 600,000 digit images in all, and is a harder dataset than MNIST as the numbers appear in the context of natural scene images. SVHN is obtained from house numbers in Google Street View images.

I set

X\_train = train\['X'\]

y\_train = train\['y'\]

X\_test = test\['X'\]

y\_test = test\['y'\]

&amp;#x200B;

The shape of X\_train is  (73257, 32, 32, 3)  and y\_train is  (73257, 1)

&amp;#x200B;

After which, I do this step,

X\_train= X\_train.mean(axis=-1,keepdims=True)

X\_test= X\_test.mean(axis=-1,keepdims=True)

&amp;#x200B;

So, the shape of X\_train will be  (73257, 32, 32, 1)  and X\_test is  (26032, 32, 32, 1)

&amp;#x200B;

Next, I did this

X\_train = X\_train.astype(np.float32)/255

X\_test= X\_test.astype(np.float32)/255

list\_labels= np.unique(y\_train)

list\_labels

This gives me an output of  : array(\[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10\], dtype=uint8)

&amp;#x200B;

Then, I did this

y\_train\_one\_hot = to\_categorical(y\_train-1, num\_classes=10)

y\_test\_one\_hot= to\_categorical(y\_test-1, num\_classes=10)

&amp;#x200B;

For my model architecture, it's quite simple:

&amp;#x200B;

https://preview.redd.it/f5q1274jds761.png?width=1028&amp;format=png&amp;auto=webp&amp;s=a1363d9ec7863f4a31c93e3d6f829dd0b9d69979

&amp;#x200B;

https://preview.redd.it/9xs6654les761.png?width=1218&amp;format=png&amp;auto=webp&amp;s=b269e6b4d467304881162580c7a1f73196e3e31b

&amp;#x200B;

That's where I get this error box:

&amp;#x200B;

    Train on 62268 samples, validate on 10989 samples
    Epoch 1/30
      128/62268 [..............................] - ETA: 44sWARNING:tensorflow:Can save best model only with loss available, skipping.
    WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: 
      128/62268 [..............................] - ETA: 1:29
    ---------------------------------------------------------------------------
    InvalidArgumentError                      Traceback (most recent call last)
    &lt;ipython-input-14-b1b279107f36&gt; in &lt;module&gt;
         10 early_stopping= tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
         11 
    ---&gt; 12 history= model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split= 0.15, callbacks=[checkpoint_best,early_stopping])
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
        726         max_queue_size=max_queue_size,
        727         workers=workers,
    --&gt; 728         use_multiprocessing=use_multiprocessing)
        729 
        730   def evaluate(self,
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
        322                 mode=ModeKeys.TRAIN,
        323                 training_context=training_context,
    --&gt; 324                 total_epochs=epochs)
        325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
        326 
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
        121         step=step, mode=mode, size=current_batch_size) as batch_logs:
        122       try:
    --&gt; 123         batch_outs = execution_function(iterator)
        124       except (StopIteration, errors.OutOfRangeError):
        125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
         84     # `numpy` translates Tensors to values in Eager mode.
         85     return nest.map_structure(_non_none_constant_value,
    ---&gt; 86                               distributed_function(input_fn))
         87 
         88   return execution_function
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
        455 
        456     tracing_count = self._get_tracing_count()
    --&gt; 457     result = self._call(*args, **kwds)
        458     if tracing_count == self._get_tracing_count():
        459       self._call_counter.called_without_tracing()
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
        485       # In this case we have created variables on the first call, so we run the
        486       # defunned version which is guaranteed to never create variables.
    --&gt; 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
        488     elif self._stateful_fn is not None:
        489       # Release the lock early so that multiple threads can perform the call
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
       1821     """"""Calls a graph function specialized to the inputs.""""""
       1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    -&gt; 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
       1824 
       1825   @property
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
       1139          if isinstance(t, (ops.Tensor,
       1140                            resource_variable_ops.BaseResourceVariable))),
    -&gt; 1141         self.captured_inputs)
       1142 
       1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
       1222     if executing_eagerly:
       1223       flat_outputs = forward_function.call(
    -&gt; 1224           ctx, args, cancellation_manager=cancellation_manager)
       1225     else:
       1226       gradient_name = self._delayed_rewrite_functions.register()
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
        509               inputs=args,
        510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
    --&gt; 511               ctx=ctx)
        512         else:
        513           outputs = execute.execute_with_cancellation(
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         65     else:
         66       message = e.message
    ---&gt; 67     six.raise_from(core._status_to_exception(e.code, message), None)
         68   except TypeError as e:
         69     keras_symbolic_tensors = [
    
    /opt/conda/lib/python3.7/site-packages/six.py in raise_from(value, from_value)
    
    InvalidArgumentError:  Received a label value of 10 which is outside the valid range of [0, 10).  Label values: 2 4 10 8 7 4 1 7 3 2 9 3 1 1 5 10 3 1 7 2 3 4 10 5 2 5 1 5 8 9 10 9 7 5 6 2 9 5 10 2 3 3 7 6 6 1 8 8 10 5 8 10 5 4 8 5 1 6 1 4 2 2 2 1 8 6 4 2 2 1 7 3 7 1 7 2 1 10 1 5 4 1 4 4 7 2 1 3 1 3 2 6 4 7 2 3 2 2 10 3 5 3 1 1 1 6 1 5 2 7 1 1 4 2 1 10 2 3 7 5 6 8 2 6 5 1 3 5
    	 [[node loss/dense_2_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_757]
    
    Function call stack:
    distributed_function

&amp;#x200B;

I have to really thank you guys for having to read my lengthy post. I feel sorry about that.",t2_52hj835v,False,,0,False,I have to say this is my biggest nightmare for this project.,[],r/tensorflow,False,6,,0,93.0,,False,t3_klafdw,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://a.thumbs.redditmedia.com/ZxuQZhUkK2Hh0wUP0L3WpeF-neFwjMNL-whTPiHxAt0.jpg,1609100076.0,,[],{},,True,,1609128454.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was implementing a MLP neural network architecture, just starting to work on the Flatten, Dense Layers, with the final layer having a 10-way softmax output. The problem cropped up even without using the to.categorical function&lt;/p&gt;

&lt;p&gt;I run into the error when my loss function is &amp;#39;categorical_crossentropy&amp;#39;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ai5jmj3qbs761.png?width=1148&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aec4e8667d7c7ca2a7fee41eec4e1616c0a38471""&gt;https://preview.redd.it/ai5jmj3qbs761.png?width=1148&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aec4e8667d7c7ca2a7fee41eec4e1616c0a38471&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And then, I changed my loss function to &amp;#39;sparse_categorical_crossentropy&amp;#39;,&lt;/p&gt;

&lt;p&gt;I was running into this problem, as shown below&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ysedtfy4fs761.png?width=1094&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=78e64df51c7cceb9eb9a4b9860d4ca46fc4ba056""&gt;https://preview.redd.it/ysedtfy4fs761.png?width=1094&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=78e64df51c7cceb9eb9a4b9860d4ca46fc4ba056&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am stuck. I don&amp;#39;t know where did the error come from? Can someone enlighten me. I really appreciated it. It&amp;#39;s quite a tough journey for me in this TensorFlow journey.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Just some extra info: I&amp;#39;m currently working on the &lt;a href=""http://ufldl.stanford.edu/housenumbers/""&gt;SVHN dataset&lt;/a&gt;, which has an image dataset of over 600,000 digit images in all, and is a harder dataset than MNIST as the numbers appear in the context of natural scene images. SVHN is obtained from house numbers in Google Street View images.&lt;/p&gt;

&lt;p&gt;I set&lt;/p&gt;

&lt;p&gt;X_train = train[&amp;#39;X&amp;#39;]&lt;/p&gt;

&lt;p&gt;y_train = train[&amp;#39;y&amp;#39;]&lt;/p&gt;

&lt;p&gt;X_test = test[&amp;#39;X&amp;#39;]&lt;/p&gt;

&lt;p&gt;y_test = test[&amp;#39;y&amp;#39;]&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The shape of X_train is  (73257, 32, 32, 3)  and y_train is  (73257, 1)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;After which, I do this step,&lt;/p&gt;

&lt;p&gt;X_train= X_train.mean(axis=-1,keepdims=True)&lt;/p&gt;

&lt;p&gt;X_test= X_test.mean(axis=-1,keepdims=True)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;So, the shape of X_train will be  (73257, 32, 32, 1)  and X_test is  (26032, 32, 32, 1)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Next, I did this&lt;/p&gt;

&lt;p&gt;X_train = X_train.astype(np.float32)/255&lt;/p&gt;

&lt;p&gt;X_test= X_test.astype(np.float32)/255&lt;/p&gt;

&lt;p&gt;list_labels= np.unique(y_train)&lt;/p&gt;

&lt;p&gt;list_labels&lt;/p&gt;

&lt;p&gt;This gives me an output of  : array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Then, I did this&lt;/p&gt;

&lt;p&gt;y_train_one_hot = to_categorical(y_train-1, num_classes=10)&lt;/p&gt;

&lt;p&gt;y_test_one_hot= to_categorical(y_test-1, num_classes=10)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;For my model architecture, it&amp;#39;s quite simple:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/f5q1274jds761.png?width=1028&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a1363d9ec7863f4a31c93e3d6f829dd0b9d69979""&gt;https://preview.redd.it/f5q1274jds761.png?width=1028&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a1363d9ec7863f4a31c93e3d6f829dd0b9d69979&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/9xs6654les761.png?width=1218&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b269e6b4d467304881162580c7a1f73196e3e31b""&gt;https://preview.redd.it/9xs6654les761.png?width=1218&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b269e6b4d467304881162580c7a1f73196e3e31b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;That&amp;#39;s where I get this error box:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Train on 62268 samples, validate on 10989 samples
Epoch 1/30
  128/62268 [..............................] - ETA: 44sWARNING:tensorflow:Can save best model only with loss available, skipping.
WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: 
  128/62268 [..............................] - ETA: 1:29
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
&amp;lt;ipython-input-14-b1b279107f36&amp;gt; in &amp;lt;module&amp;gt;
     10 early_stopping= tf.keras.callbacks.EarlyStopping(monitor=&amp;#39;loss&amp;#39;, patience=3)
     11 
---&amp;gt; 12 history= model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split= 0.15, callbacks=[checkpoint_best,early_stopping])

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--&amp;gt; 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--&amp;gt; 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--&amp;gt; 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---&amp;gt; 86                               distributed_function(input_fn))
     87 
     88   return execution_function

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--&amp;gt; 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    485       # In this case we have created variables on the first call, so we run the
    486       # defunned version which is guaranteed to never create variables.
--&amp;gt; 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    488     elif self._stateful_fn is not None:
    489       # Release the lock early so that multiple threads can perform the call

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1821     &amp;quot;&amp;quot;&amp;quot;Calls a graph function specialized to the inputs.&amp;quot;&amp;quot;&amp;quot;
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-&amp;gt; 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-&amp;gt; 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-&amp;gt; 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(&amp;quot;executor_type&amp;quot;, executor_type, &amp;quot;config_proto&amp;quot;, config),
--&amp;gt; 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---&amp;gt; 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

/opt/conda/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError:  Received a label value of 10 which is outside the valid range of [0, 10).  Label values: 2 4 10 8 7 4 1 7 3 2 9 3 1 1 5 10 3 1 7 2 3 4 10 5 2 5 1 5 8 9 10 9 7 5 6 2 9 5 10 2 3 3 7 6 6 1 8 8 10 5 8 10 5 4 8 5 1 6 1 4 2 2 2 1 8 6 4 2 2 1 7 3 7 1 7 2 1 10 1 5 4 1 4 4 7 2 1 3 1 3 2 6 4 7 2 3 2 2 10 3 5 3 1 1 1 6 1 5 2 7 1 1 4 2 1 10 2 3 7 5 6 8 2 6 5 1 3 5
     [[node loss/dense_2_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_757]

Function call stack:
distributed_function
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have to really thank you guys for having to read my lengthy post. I feel sorry about that.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,klafdw,True,,edmondoh001,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/klafdw/i_have_to_say_this_is_my_biggest_nightmare_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/klafdw/i_have_to_say_this_is_my_biggest_nightmare_for/,22217,1609099654.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?auto=webp&amp;s=27f818b7e3c51c131673994f8f46ce9c710d5fcb', 'width': 1091, 'height': 728}, 'resolutions': [{'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e998b968591131a2bfff9fad573d8afff75be3ba', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8a77f854394a3a793d6ef813cbd9097aba4e8ce', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d5db209324e238f8687f234209825a6d0c01f9bb', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7599f1e004e0c8b56c4e1c0d97327ef5dfd712d', 'width': 640, 'height': 427}, {'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=281a926464edb9f980bfb54fa42a41d28b4a67d3', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/rn-15n53m7FVDMOYbJ65vPnmvre_EvnbOa5XRxjVTwU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9c11d68ed141291c5eda6a1b7ab2a869de9d34a', 'width': 1080, 'height': 720}], 'variants': {}, 'id': '1qXEmLXAZDfwUl0aQb7XXWbUuDGv9-XmxyN5tabssL8'}], 'enabled': False}",,"{'ysedtfy4fs761': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 16, 'x': 108, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bb57bcc71f9acdb0a2b609addf2af644b62c82f'}, {'y': 33, 'x': 216, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5fe4a36bb2c76166c3930cca6f6832c8415ab3af'}, {'y': 50, 'x': 320, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ca7f78f86e12b7bd7a4c23d4c03acdfb6723474'}, {'y': 100, 'x': 640, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9ac3c6505bf813b1b5aad2fd18ed559da65e300'}, {'y': 150, 'x': 960, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9f674cf6ab7f5ba7f9f177d8eef242e07b6398a'}, {'y': 168, 'x': 1080, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=889c866b8d7b044c897d60727c24758b86866ec9'}], 's': {'y': 171, 'x': 1094, 'u': 'https://preview.redd.it/ysedtfy4fs761.png?width=1094&amp;format=png&amp;auto=webp&amp;s=78e64df51c7cceb9eb9a4b9860d4ca46fc4ba056'}, 'id': 'ysedtfy4fs761'}, '9xs6654les761': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 33, 'x': 108, 'u': 'https://preview.redd.it/9xs6654les761.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9665e5c7252677c9b01ee611f669b0c452a1c610'}, {'y': 66, 'x': 216, 'u': 'https://preview.redd.it/9xs6654les761.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=271463546bd7858bf462b9cfed0debac4e4aab37'}, {'y': 97, 'x': 320, 'u': 'https://preview.redd.it/9xs6654les761.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f24a073c25ed422a30973525e87c9aa720e5b0f'}, {'y': 195, 'x': 640, 'u': 'https://preview.redd.it/9xs6654les761.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c0c666c42e3d28e530cc0a69105fc943736c1904'}, {'y': 293, 'x': 960, 'u': 'https://preview.redd.it/9xs6654les761.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9cdb5185308f2dfd83f1bc63e62ae1d180e41164'}, {'y': 330, 'x': 1080, 'u': 'https://preview.redd.it/9xs6654les761.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3144bcacab394c7c18c225a1b66702d95c2f0e92'}], 's': {'y': 373, 'x': 1218, 'u': 'https://preview.redd.it/9xs6654les761.png?width=1218&amp;format=png&amp;auto=webp&amp;s=b269e6b4d467304881162580c7a1f73196e3e31b'}, 'id': '9xs6654les761'}, 'f5q1274jds761': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 58, 'x': 108, 'u': 'https://preview.redd.it/f5q1274jds761.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=89eb10936afa66a0637d0858a38a84dbb5ba07f1'}, {'y': 116, 'x': 216, 'u': 'https://preview.redd.it/f5q1274jds761.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1c4c7b908db50807181589464cbbe2d2584f356'}, {'y': 172, 'x': 320, 'u': 'https://preview.redd.it/f5q1274jds761.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd571f617f6ea3fe2dd84196c1447d7fde9126fb'}, {'y': 344, 'x': 640, 'u': 'https://preview.redd.it/f5q1274jds761.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea489dbfd32b20f2e4128a08c3018be917047a26'}, {'y': 516, 'x': 960, 'u': 'https://preview.redd.it/f5q1274jds761.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e61d9ff9d996b5dd6cc159ef62b932eae818ab67'}], 's': {'y': 553, 'x': 1028, 'u': 'https://preview.redd.it/f5q1274jds761.png?width=1028&amp;format=png&amp;auto=webp&amp;s=a1363d9ec7863f4a31c93e3d6f829dd0b9d69979'}, 'id': 'f5q1274jds761'}, 'ai5jmj3qbs761': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 17, 'x': 108, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=47bfb152dadc662374d6dc59b103a0f4e2cec09b'}, {'y': 35, 'x': 216, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4a2ff387cea39315ddd3f3a2ca937d87b35c8a7'}, {'y': 53, 'x': 320, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f082a750d71e9c636306dc10e2f349fd05ce983d'}, {'y': 106, 'x': 640, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=700ccafc31bd660319460c5b5895f9b7668d22dc'}, {'y': 159, 'x': 960, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=faffbd13641e169339eb6784049d877c71cfc074'}, {'y': 179, 'x': 1080, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=901a19999584f462d7649ee601fe117a10dec40e'}], 's': {'y': 191, 'x': 1148, 'u': 'https://preview.redd.it/ai5jmj3qbs761.png?width=1148&amp;format=png&amp;auto=webp&amp;s=aec4e8667d7c7ca2a7fee41eec4e1616c0a38471'}, 'id': 'ai5jmj3qbs761'}}",,,,
322,,tensorflow,"why google

&amp;#x200B;

Edit: after 3 days I got it to work with tf-nightly-gpu. even conda didn't work",t2_4ru495iw,False,,0,False,installing tensorflow gpu is making me want to cry,[],r/tensorflow,False,6,,0,,,False,t3_kkr3de,False,dark,0.91,,public,38,0,{},,,False,[],,False,False,,{},,False,38,,False,self,1609219935.0,,[],{},,True,,1609049528.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;why google&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit: after 3 days I got it to work with tf-nightly-gpu. even conda didn&amp;#39;t work&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kkr3de,True,,cereal_final,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/kkr3de/installing_tensorflow_gpu_is_making_me_want_to_cry/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kkr3de/installing_tensorflow_gpu_is_making_me_want_to_cry/,22217,1609020728.0,0,,False,,,,,,,,,
323,,tensorflow,"Hi. I am trying to train a model in VS code and have written this code (a part of it):

import tensorflow as tf

import tflearn'

....

tf.reset\_default\_graph()  
net = tflearn.input\_data(shape=\[None, len(trening\[0\])\])   
net = tflearn.fully\_connected(net, 8)   
net = tflearn.fully\_connected(net, 8)  
net = tflearn.fully\_connected(net, len(output\[0\]), activation=""softmax"")   
net = tflearn.regression(net)  
modell = tflearn.DNN(net)  
try:   
modell.load(""modell.tflearn"")  
except:  
modell.fit(trening, output, n\_epoch=1000, batch\_size=8, show\_metric=True)   
[modell.save](https://modell.save)(""modell.tflearn"")

...

output: raise RuntimeError('Attempted to use a closed Session.')

RuntimeError: Attempted to use a closed Session.

&amp;#x200B;

I don't understand what I am doing wrong, can someone help?",t2_1hbml4s9,False,,0,False,Error with Tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_kl2gh1,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},"Project, Question",False,0,,False,self,False,,[],{},,True,,1609098846.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I am trying to train a model in VS code and have written this code (a part of it):&lt;/p&gt;

&lt;p&gt;import tensorflow as tf&lt;/p&gt;

&lt;p&gt;import tflearn&amp;#39;&lt;/p&gt;

&lt;p&gt;....&lt;/p&gt;

&lt;p&gt;tf.reset_default_graph()&lt;br/&gt;
net = tflearn.input_data(shape=[None, len(trening[0])])&lt;br/&gt;
net = tflearn.fully_connected(net, 8)&lt;br/&gt;
net = tflearn.fully_connected(net, 8)&lt;br/&gt;
net = tflearn.fully_connected(net, len(output[0]), activation=&amp;quot;softmax&amp;quot;)&lt;br/&gt;
net = tflearn.regression(net)&lt;br/&gt;
modell = tflearn.DNN(net)&lt;br/&gt;
try:&lt;br/&gt;
modell.load(&amp;quot;modell.tflearn&amp;quot;)&lt;br/&gt;
except:&lt;br/&gt;
modell.fit(trening, output, n_epoch=1000, batch_size=8, show_metric=True)&lt;br/&gt;
&lt;a href=""https://modell.save""&gt;modell.save&lt;/a&gt;(&amp;quot;modell.tflearn&amp;quot;)&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;output: raise RuntimeError(&amp;#39;Attempted to use a closed Session.&amp;#39;)&lt;/p&gt;

&lt;p&gt;RuntimeError: Attempted to use a closed Session.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t understand what I am doing wrong, can someone help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kl2gh1,True,,SuprMarioo,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kl2gh1/error_with_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kl2gh1/error_with_tensorflow/,22217,1609070046.0,0,,False,,,,,,,,,
324,,tensorflow,"I am reading the advanced tutorials of TF 2.4, and I am confused about the need to use two instances of `GradientTape`. This is the case in the [Pix2Pix](https://www.tensorflow.org/tutorials/generative/pix2pix#training) and [Deep Convolutional GAN](https://www.tensorflow.org/tutorials/generative/dcgan#define_the_training_loop) examples, while the [CycleGAN](https://www.tensorflow.org/tutorials/generative/cyclegan#training) example uses a singe, persistent `GradientTape`.

It seems to me that the first approach makes both `GradientTape`s record the operations of both networks, which sounds wasteful. Intuitively, the second approach makes way more sense to me, should use half as much memory as the first.

When should one use the first and the second approaches?",t2_g9hx5,False,,0,False,Reading the tutorials -- When to use two `GradientTape`?,[],r/tensorflow,False,6,,0,,,False,t3_kkozig,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1609042242.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am reading the advanced tutorials of TF 2.4, and I am confused about the need to use two instances of &lt;code&gt;GradientTape&lt;/code&gt;. This is the case in the &lt;a href=""https://www.tensorflow.org/tutorials/generative/pix2pix#training""&gt;Pix2Pix&lt;/a&gt; and &lt;a href=""https://www.tensorflow.org/tutorials/generative/dcgan#define_the_training_loop""&gt;Deep Convolutional GAN&lt;/a&gt; examples, while the &lt;a href=""https://www.tensorflow.org/tutorials/generative/cyclegan#training""&gt;CycleGAN&lt;/a&gt; example uses a singe, persistent &lt;code&gt;GradientTape&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It seems to me that the first approach makes both &lt;code&gt;GradientTape&lt;/code&gt;s record the operations of both networks, which sounds wasteful. Intuitively, the second approach makes way more sense to me, should use half as much memory as the first.&lt;/p&gt;

&lt;p&gt;When should one use the first and the second approaches?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kkozig,True,,rmk236,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kkozig/reading_the_tutorials_when_to_use_two_gradienttape/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kkozig/reading_the_tutorials_when_to_use_two_gradienttape/,22217,1609013442.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
325,,tensorflow,"In tensorflow tutorial on neural machine translation [this](https://www.tensorflow.org/tutorials/text/nmt_with_attention)

In loss_function () function they have masked loss on padded tokken, but my question is won't crossenteopy function itself cancel out padded token loss term so why do masking",t2_8r7pae13,False,,0,False,Tensorflow tutorial on neural machine translation code understanding difficulty,[],r/tensorflow,False,6,,0,,,False,t3_kklibq,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1609030041.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In tensorflow tutorial on neural machine translation &lt;a href=""https://www.tensorflow.org/tutorials/text/nmt_with_attention""&gt;this&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In loss_function () function they have masked loss on padded tokken, but my question is won&amp;#39;t crossenteopy function itself cancel out padded token loss term so why do masking&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kklibq,True,,AI_Astronaut9852,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kklibq/tensorflow_tutorial_on_neural_machine_translation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kklibq/tensorflow_tutorial_on_neural_machine_translation/,22217,1609001241.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
326,,tensorflow,,t2_5yp2bwfr,False,,0,False,How to make a pretrained StyleGan model?,[],r/tensorflow,False,6,,0,,,False,t3_kkomn1,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1609041029.0,text,6,,,text,self.tensorflow,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kkomn1,True,,NegativeSector,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/kkomn1/how_to_make_a_pretrained_stylegan_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kkomn1/how_to_make_a_pretrained_stylegan_model/,22217,1609012229.0,0,,False,,,,,,,,,
327,,tensorflow,"So I am following a YouTube series here: [https://www.youtube.com/watch?v=CA0PQS1Rj\_4](https://www.youtube.com/watch?v=CA0PQS1Rj_4)

And this person also posted their code on GitHub: [https://github.com/musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment/tree/master/4-%20Making%20Predictions%20with%20the%20Speech%20Recognition%20System](https://github.com/musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment/tree/master/4-%20Making%20Predictions%20with%20the%20Speech%20Recognition%20System)

(I removed the model.h5 and data.json since I wanted to use a model generated on my own PC)

I run the train.py which trains the model and get this as a result: [https://pastebin.com/mZSXK25v](https://pastebin.com/mZSXK25v)

When i test the ""down.wav"", it predicts ""right"": [https://pastebin.com/Up8EvNyc](https://pastebin.com/Up8EvNyc)

When I tested ""left.wav"", it predicts ""down"": [https://pastebin.com/vzWzTV4X](https://pastebin.com/vzWzTV4X)

How come I get different results, in fact completely wrong results no matter what I test, despite getting a  0.9358 accuracy?",t2_5bnw38vl,False,,0,False,How Come I Get Different Results From a TF Tutorial on my Machine?,[],r/tensorflow,False,6,,0,,,False,t3_kke7zk,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1608993653.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I am following a YouTube series here: &lt;a href=""https://www.youtube.com/watch?v=CA0PQS1Rj_4""&gt;https://www.youtube.com/watch?v=CA0PQS1Rj_4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And this person also posted their code on GitHub: &lt;a href=""https://github.com/musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment/tree/master/4-%20Making%20Predictions%20with%20the%20Speech%20Recognition%20System""&gt;https://github.com/musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment/tree/master/4-%20Making%20Predictions%20with%20the%20Speech%20Recognition%20System&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(I removed the model.h5 and data.json since I wanted to use a model generated on my own PC)&lt;/p&gt;

&lt;p&gt;I run the train.py which trains the model and get this as a result: &lt;a href=""https://pastebin.com/mZSXK25v""&gt;https://pastebin.com/mZSXK25v&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When i test the &amp;quot;down.wav&amp;quot;, it predicts &amp;quot;right&amp;quot;: &lt;a href=""https://pastebin.com/Up8EvNyc""&gt;https://pastebin.com/Up8EvNyc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When I tested &amp;quot;left.wav&amp;quot;, it predicts &amp;quot;down&amp;quot;: &lt;a href=""https://pastebin.com/vzWzTV4X""&gt;https://pastebin.com/vzWzTV4X&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;How come I get different results, in fact completely wrong results no matter what I test, despite getting a  0.9358 accuracy?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kke7zk,True,,TuckleBuck88,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kke7zk/how_come_i_get_different_results_from_a_tf/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kke7zk/how_come_i_get_different_results_from_a_tf/,22217,1608964853.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/OvBKs9i8tf98kzzdIKo3RKG55ofiEkW7c8Qc3EPlS4A.jpg?auto=webp&amp;s=47b5cb5721e47e71a240b77ecd0d023a2e2b6638', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/OvBKs9i8tf98kzzdIKo3RKG55ofiEkW7c8Qc3EPlS4A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=644a612c2be71df551d226e6cd594bbababd1ec9', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/OvBKs9i8tf98kzzdIKo3RKG55ofiEkW7c8Qc3EPlS4A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a7d25e829ed9b17c43e3dca414d0cc13c9ad6b07', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/OvBKs9i8tf98kzzdIKo3RKG55ofiEkW7c8Qc3EPlS4A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e37c1d738312b698dabf18c5f4ce892db9faf64', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'feCkF1M9fWi9b-ZBlRM-DRaOhoJUHmD1pC-K2XqzgeM'}], 'enabled': False}",,,,,,
328,,tensorflow,"My code is 

    def get_checkpoint_every_epoch():
        checkpoint_every_epoch = 'model_checkpoints_every_epoch'
    
        checkpoints = ModelCheckpoint(filepath=checkpoint_every_epoch, 
    
                                      frequency= 'epoch', 
    
                                      save_weights_only=True, 
    
                                      verbose=1) 
        
        return checkpoints
    
    
    def get_checkpoint_best_only():
        checkpoint_best_path = 'model_checkpoints_best_only/checkpoint'
        
        checkpoint_best= ModelCheckpoint(filepath=checkpoint_best_path,
                                         save_weights_only= True,
                                         monitor= 'val_accuracy',
                                         save_best_only= True,
                                         verbose=1)
    
       
        return checkpoint_best
    
    def get_early_stopping():
    
        early_stopping= tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',         
    patience=3)
        
        
        return early_stopping
    
    
    checkpoint_every_epoch = get_checkpoint_every_epoch()
    checkpoint_best_only = get_checkpoint_best_only()
    early_stopping = get_early_stopping()
    

Followed by this,

        
    def get_model_last_epoch(model):
        model_last_epoch_file = tf.train.latest_checkpoint(""checkpoints_every_epoch"")
        model.load_weights(model_last_epoch_file)
    
        return model
    
    def get_model_best_epoch(model):
    
         model_best_epoch_file = tf.train.latest_checkpoint(""checkpoints_best_only"")
         model.load_weights(model_best_epoch_file)
    
         return model
    
    model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))
    model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))
    print('Model with last epoch weights:')
    get_test_accuracy(model_last_epoch, x_test, y_test)
    print('')
    print('Model with best epoch weights:')
    get_test_accuracy(model_best_epoch, x_test, y_test)

This is where, I get this error:

&amp;#x200B;

    AttributeError                            Traceback (most recent call last)
    &lt;ipython-input-18-b6d169507ca4&gt; in &lt;module&gt;
          3 # Verify that the second has a higher validation (testing) accuarcy.
          4 
    ----&gt; 5 model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))
          6 model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))
          7 print('Model with last epoch weights:')
    
    &lt;ipython-input-17-4c8cba016afe&gt; in get_model_last_epoch(model)
         12     model_last_epoch_file = tf.train.latest_checkpoint(""checkpoints_every_epoch"")
         13 
    ---&gt; 14     model.load_weights(model_last_epoch_file)
         15 
         16     return model
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in load_weights(self, filepath, by_name)
        179         raise ValueError('Load weights is not yet supported with TPUStrategy '
        180                          'with steps_per_run greater than 1.')
    --&gt; 181     return super(Model, self).load_weights(filepath, by_name)
        182 
        183   @trackable.no_automatic_dependency_tracking
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in load_weights(self, filepath, by_name)
       1137             format.
       1138     """"""
    -&gt; 1139     if _is_hdf5_filepath(filepath):
       1140       save_format = 'h5'
       1141     else:
    
    /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in _is_hdf5_filepath(filepath)
       1447 
       1448 def _is_hdf5_filepath(filepath):
    -&gt; 1449   return (filepath.endswith('.h5') or filepath.endswith('.keras') or
       1450           filepath.endswith('.hdf5'))
       1451 
    
    AttributeError: 'NoneType' object has no attribute 'endswith'

What does it mean? Sorry, I'm just a newbie, need some enlightenment. I wish you a merry christmas. Thanks a lot!",t2_52hj835v,False,,0,False,"Can someone explain to me what is error "" AttributeError: 'NoneType' object has no attribute 'endswith' "" trying to say?",[],r/tensorflow,False,6,,0,,,False,t3_kk4qt1,False,dark,0.57,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608954160.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My code is &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_checkpoint_every_epoch():
    checkpoint_every_epoch = &amp;#39;model_checkpoints_every_epoch&amp;#39;

    checkpoints = ModelCheckpoint(filepath=checkpoint_every_epoch, 

                                  frequency= &amp;#39;epoch&amp;#39;, 

                                  save_weights_only=True, 

                                  verbose=1) 

    return checkpoints


def get_checkpoint_best_only():
    checkpoint_best_path = &amp;#39;model_checkpoints_best_only/checkpoint&amp;#39;

    checkpoint_best= ModelCheckpoint(filepath=checkpoint_best_path,
                                     save_weights_only= True,
                                     monitor= &amp;#39;val_accuracy&amp;#39;,
                                     save_best_only= True,
                                     verbose=1)


    return checkpoint_best

def get_early_stopping():

    early_stopping= tf.keras.callbacks.EarlyStopping(monitor=&amp;#39;val_accuracy&amp;#39;,         
patience=3)


    return early_stopping


checkpoint_every_epoch = get_checkpoint_every_epoch()
checkpoint_best_only = get_checkpoint_best_only()
early_stopping = get_early_stopping()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Followed by this,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_model_last_epoch(model):
    model_last_epoch_file = tf.train.latest_checkpoint(&amp;quot;checkpoints_every_epoch&amp;quot;)
    model.load_weights(model_last_epoch_file)

    return model

def get_model_best_epoch(model):

     model_best_epoch_file = tf.train.latest_checkpoint(&amp;quot;checkpoints_best_only&amp;quot;)
     model.load_weights(model_best_epoch_file)

     return model

model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))
model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))
print(&amp;#39;Model with last epoch weights:&amp;#39;)
get_test_accuracy(model_last_epoch, x_test, y_test)
print(&amp;#39;&amp;#39;)
print(&amp;#39;Model with best epoch weights:&amp;#39;)
get_test_accuracy(model_best_epoch, x_test, y_test)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is where, I get this error:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AttributeError                            Traceback (most recent call last)
&amp;lt;ipython-input-18-b6d169507ca4&amp;gt; in &amp;lt;module&amp;gt;
      3 # Verify that the second has a higher validation (testing) accuarcy.
      4 
----&amp;gt; 5 model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))
      6 model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))
      7 print(&amp;#39;Model with last epoch weights:&amp;#39;)

&amp;lt;ipython-input-17-4c8cba016afe&amp;gt; in get_model_last_epoch(model)
     12     model_last_epoch_file = tf.train.latest_checkpoint(&amp;quot;checkpoints_every_epoch&amp;quot;)
     13 
---&amp;gt; 14     model.load_weights(model_last_epoch_file)
     15 
     16     return model

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in load_weights(self, filepath, by_name)
    179         raise ValueError(&amp;#39;Load weights is not yet supported with TPUStrategy &amp;#39;
    180                          &amp;#39;with steps_per_run greater than 1.&amp;#39;)
--&amp;gt; 181     return super(Model, self).load_weights(filepath, by_name)
    182 
    183   @trackable.no_automatic_dependency_tracking

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in load_weights(self, filepath, by_name)
   1137             format.
   1138     &amp;quot;&amp;quot;&amp;quot;
-&amp;gt; 1139     if _is_hdf5_filepath(filepath):
   1140       save_format = &amp;#39;h5&amp;#39;
   1141     else:

/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py in _is_hdf5_filepath(filepath)
   1447 
   1448 def _is_hdf5_filepath(filepath):
-&amp;gt; 1449   return (filepath.endswith(&amp;#39;.h5&amp;#39;) or filepath.endswith(&amp;#39;.keras&amp;#39;) or
   1450           filepath.endswith(&amp;#39;.hdf5&amp;#39;))
   1451 

AttributeError: &amp;#39;NoneType&amp;#39; object has no attribute &amp;#39;endswith&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What does it mean? Sorry, I&amp;#39;m just a newbie, need some enlightenment. I wish you a merry christmas. Thanks a lot!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kk4qt1,True,,edmondoh001,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/kk4qt1/can_someone_explain_to_me_what_is_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kk4qt1/can_someone_explain_to_me_what_is_error/,22217,1608925360.0,0,,False,,,,,,,,,
329,,tensorflow,,t2_52hj835v,False,,0,False,How do I rectify the attribute Early Stopping error?,[],r/tensorflow,False,6,,0,85.0,,False,t3_kjkw0f,False,dark,0.69,,public,5,0,{},140.0,,False,[],,True,False,,{},,False,5,,False,https://b.thumbs.redditmedia.com/xvwisVYBGw7IaToZkv64UpwR4yrxe2LYmqf6vqfUnjE.jpg,False,,[],{},,False,,1608865749.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kjkw0f,True,,edmondoh001,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kjkw0f/how_do_i_rectify_the_attribute_early_stopping/,all_ads,False,https://i.redd.it/5vhlydxoo6761.png,22217,1608836949.0,0,,False,image,https://i.redd.it/5vhlydxoo6761.png,"{'images': [{'source': {'url': 'https://preview.redd.it/5vhlydxoo6761.png?auto=webp&amp;s=2b5bf0936b868336db464e81b09c2fa8799396a6', 'width': 1240, 'height': 755}, 'resolutions': [{'url': 'https://preview.redd.it/5vhlydxoo6761.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=500315530b2b6523d7b8fadbee5902b26852ea6c', 'width': 108, 'height': 65}, {'url': 'https://preview.redd.it/5vhlydxoo6761.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a738f8e4f2d569e6b796bb5106e396963f2b64eb', 'width': 216, 'height': 131}, {'url': 'https://preview.redd.it/5vhlydxoo6761.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7b79d5aa76e7c2d661653f1d2ba8bb0e7fe42fa', 'width': 320, 'height': 194}, {'url': 'https://preview.redd.it/5vhlydxoo6761.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c70c8e561847dca5259da48f9da0e9a973da7a2', 'width': 640, 'height': 389}, {'url': 'https://preview.redd.it/5vhlydxoo6761.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a8c0bc2d1cc48c10572761c4e4b2e5c301b635e2', 'width': 960, 'height': 584}, {'url': 'https://preview.redd.it/5vhlydxoo6761.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa2de5c36558f1b506ad32a6c2efe271514a0c37', 'width': 1080, 'height': 657}], 'variants': {}, 'id': 'icVFc07fHbL4NNK6BQvwZZQ0QFA5NDQWTV0D1qvjdT8'}], 'enabled': True}",,,,,,
330,,tensorflow,"Hi everyone, I'm new to neural networks and was wondering whether someone could provide me with some high level advice.

I'm trying to create an optical music reader which can be provided with an image of multiple music notes (imagine one bar of music for example). Each of these images will only have one note in a vertical plane. 

For each image I have a list of notes (e.g. [A, B, E, A]) however the number of notes in each of my images varies.

I was wondering what format I would need to have the labels in in order to train a NN using Keras.

I have tried ragged arrays with not much luck, and have tried padding the labels with some limited luck. 

Does anyone have any ideas on how to make use of the fact that the notes (features) in each image and the labels are contiguous.

Many thanks",t2_9qarz3x,False,,0,False,Multi-feature sequential classification,[],r/tensorflow,False,6,,0,,,False,t3_kjf7wh,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1608844333.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I&amp;#39;m new to neural networks and was wondering whether someone could provide me with some high level advice.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to create an optical music reader which can be provided with an image of multiple music notes (imagine one bar of music for example). Each of these images will only have one note in a vertical plane. &lt;/p&gt;

&lt;p&gt;For each image I have a list of notes (e.g. [A, B, E, A]) however the number of notes in each of my images varies.&lt;/p&gt;

&lt;p&gt;I was wondering what format I would need to have the labels in in order to train a NN using Keras.&lt;/p&gt;

&lt;p&gt;I have tried ragged arrays with not much luck, and have tried padding the labels with some limited luck. &lt;/p&gt;

&lt;p&gt;Does anyone have any ideas on how to make use of the fact that the notes (features) in each image and the labels are contiguous.&lt;/p&gt;

&lt;p&gt;Many thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kjf7wh,True,,iliftheavyweights,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kjf7wh/multifeature_sequential_classification/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kjf7wh/multifeature_sequential_classification/,22217,1608815533.0,0,,False,,,,,,,,,
331,,tensorflow," I was doing the assignment for the ""Model validation on the Iris dataset"".

I get this error: ""Error when checking input: expected dense\_input to have shape (135,) but got array with shape (4,)"". How do I overcome this problem?

I posted this question at [https://stackoverflow.com/questions/65441320/how-to-overcome-the-wrong-dimension-issue](https://stackoverflow.com/questions/65441320/how-to-overcome-the-wrong-dimension-issue).

&amp;#x200B;

I wish someone can highlight my error. Pardon me for asking this question. I'm still a newbie. Making basic errors here and there. But anyway, I'd like to wish everyone a happy Christmas Day ahead.",t2_52hj835v,False,,0,False,"How to overcome the wrong dimension issue as in, the dimension of the shape is different from expected",[],r/tensorflow,False,6,,0,,,False,t3_kjiynv,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1608858934.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was doing the assignment for the &amp;quot;Model validation on the Iris dataset&amp;quot;.&lt;/p&gt;

&lt;p&gt;I get this error: &amp;quot;Error when checking input: expected dense_input to have shape (135,) but got array with shape (4,)&amp;quot;. How do I overcome this problem?&lt;/p&gt;

&lt;p&gt;I posted this question at &lt;a href=""https://stackoverflow.com/questions/65441320/how-to-overcome-the-wrong-dimension-issue""&gt;https://stackoverflow.com/questions/65441320/how-to-overcome-the-wrong-dimension-issue&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I wish someone can highlight my error. Pardon me for asking this question. I&amp;#39;m still a newbie. Making basic errors here and there. But anyway, I&amp;#39;d like to wish everyone a happy Christmas Day ahead.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kjiynv,True,,edmondoh001,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kjiynv/how_to_overcome_the_wrong_dimension_issue_as_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kjiynv/how_to_overcome_the_wrong_dimension_issue_as_in/,22217,1608830134.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
332,,tensorflow,,t2_1krqyfrs,False,,0,False,A tutorial where I show you how to infer and train YOLOv5 Object Detection for the purpose of detecting Chess pieces in under 15 minutes.,[],r/tensorflow,False,6,,0,105.0,,False,t3_kittmi,False,dark,0.92,,public,44,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rYlEEvrgmc8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Chess Pieces Object Detection in 15 Minutes | Queens Gambit', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rYlEEvrgmc8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Augmented Startups', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/rYlEEvrgmc8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ArduinoStartups'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rYlEEvrgmc8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kittmi', 'height': 200}",Project,False,44,,False,https://b.thumbs.redditmedia.com/lgeY62O54yi8GtFDqxrLXF_2XbshGHktCZ_Q_I7i1bA.jpg,False,,[],{},,False,,1608761683.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kittmi,True,,AugmentedStartups,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kittmi/a_tutorial_where_i_show_you_how_to_infer_and/,all_ads,False,https://youtu.be/rYlEEvrgmc8,22217,1608732883.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Chess Pieces Object Detection in 15 Minutes | Queens Gambit', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rYlEEvrgmc8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Augmented Startups', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/rYlEEvrgmc8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ArduinoStartups'}}",False,rich:video,https://youtu.be/rYlEEvrgmc8,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IcvgK9gjbTeA89aJE4do4omVPtz604MXAQEViXHa6ZE.jpg?auto=webp&amp;s=a5be0fb90a2aef4897dafbd31c4b58ec8602ff8b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/IcvgK9gjbTeA89aJE4do4omVPtz604MXAQEViXHa6ZE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8386aaabc2bacb4111ff45b2dae5529250b61851', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/IcvgK9gjbTeA89aJE4do4omVPtz604MXAQEViXHa6ZE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60403986115f716f9e113bb36b7d0f083174a277', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/IcvgK9gjbTeA89aJE4do4omVPtz604MXAQEViXHa6ZE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=95f534f8cfff414905c186262b700d417467e621', 'width': 320, 'height': 240}], 'variants': {}, 'id': '0kWcostZ_74oF9KbfN81lF44El_CzLZ_2iAguR6Nt48'}], 'enabled': False}",,,,,,
333,,tensorflow,,t2_xy0vran,False,,0,False,Pie &amp; AI meet-up: Bag of tricks paper and learning rate finder in Tensorflow,[],r/tensorflow,False,6,,0,105.0,,False,t3_kiq1wx,False,dark,0.86,,public,5,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/78j4oyFXB5c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Pie &amp; AI: Bag of Tricks for Image Classification with Convolutional Neural Networks', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/78j4oyFXB5c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Aniket Maurya', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/78j4oyFXB5c/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCRuFsj94hWecPkuEr4f5Xww'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/78j4oyFXB5c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kiq1wx', 'height': 200}",Discussion,False,5,,False,https://a.thumbs.redditmedia.com/ty2qD8AI97FIP18WypmL9nZoDZbgrrLhbZPPYEeJ3V0.jpg,False,,[],{},,False,,1608744577.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kiq1wx,True,,aniketmaurya,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kiq1wx/pie_ai_meetup_bag_of_tricks_paper_and_learning/,all_ads,False,https://youtu.be/78j4oyFXB5c,22217,1608715777.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Pie &amp; AI: Bag of Tricks for Image Classification with Convolutional Neural Networks', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/78j4oyFXB5c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Aniket Maurya', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/78j4oyFXB5c/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCRuFsj94hWecPkuEr4f5Xww'}}",False,rich:video,https://youtu.be/78j4oyFXB5c,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cjpqW5BB34cDgttnVDRUm6FYpTcdnDl_Sbzk7QFM_1o.jpg?auto=webp&amp;s=18cb78c097e1160bbd7e72e7ed23e5d124edf0cf', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/cjpqW5BB34cDgttnVDRUm6FYpTcdnDl_Sbzk7QFM_1o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97e22ed5d16e6b363e7d5af2e60768bc6ffeaaf1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/cjpqW5BB34cDgttnVDRUm6FYpTcdnDl_Sbzk7QFM_1o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a56f625b751df92ed18ef133986b318c418657ad', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/cjpqW5BB34cDgttnVDRUm6FYpTcdnDl_Sbzk7QFM_1o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d4685fb511b3d776707fe07364e5971274f8197', 'width': 320, 'height': 240}], 'variants': {}, 'id': '3DOU2L-EASLYyvOdsRsybW9o6yu4ev47iztHUE0N9xs'}], 'enabled': False}",,,,,,
334,,tensorflow,"I am running a tensorflow application that sets inter\_op, intra\_op and OMP\_NUM\_THREADS, however, it completely ignores these settings and seems to run with the defaults. Here's how I'm setting them:

&amp;#x200B;

        import tensorflow as tf
        print('Using Thread Parallelism: {} NUM_INTRA_THREADS, {} NUM_INTER_THREADS, {} OMP_NUM_THREADS'.format(os.environ['NUM_INTRA_THREADS'], os.environ['NUM_INTER_THREADS'], os.environ['OMP_NUM_THREADS']))
        
        session_conf = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=int(os.environ['NUM_INTER_THREADS']),         intra_op_parallelism_threads=int(os.environ['NUM_INTRA_THREADS']))
        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)     
    
        tf.compat.v1.keras.backend.set_session(sess)
    
    I have validated that it's reading the right values (the print prints the values as expected). I have also tried with other Tensorflow 2 versions with no success.
    
    I am at a loss as to what I'm doing wrong.
    
    Version Info: tensorflow 2.2.0 py37_2 intel tensorflow-base 2.2.0 0 intel tensorflow-estimator 2.2.0 pyh208ff02_0
    
    keras 2.4.3 0 keras-base 2.4.3 py_0 keras-preprocessing 1.1.0 py_1",t2_6i9r4mfp,False,,0,False,Tensorflow 2 not respecting thread settings,[],r/tensorflow,False,6,,0,,,False,t3_kiz1rm,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608779042.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am running a tensorflow application that sets inter_op, intra_op and OMP_NUM_THREADS, however, it completely ignores these settings and seems to run with the defaults. Here&amp;#39;s how I&amp;#39;m setting them:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    import tensorflow as tf
    print(&amp;#39;Using Thread Parallelism: {} NUM_INTRA_THREADS, {} NUM_INTER_THREADS, {} OMP_NUM_THREADS&amp;#39;.format(os.environ[&amp;#39;NUM_INTRA_THREADS&amp;#39;], os.environ[&amp;#39;NUM_INTER_THREADS&amp;#39;], os.environ[&amp;#39;OMP_NUM_THREADS&amp;#39;]))

    session_conf = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=int(os.environ[&amp;#39;NUM_INTER_THREADS&amp;#39;]),         intra_op_parallelism_threads=int(os.environ[&amp;#39;NUM_INTRA_THREADS&amp;#39;]))
    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)     

    tf.compat.v1.keras.backend.set_session(sess)

I have validated that it&amp;#39;s reading the right values (the print prints the values as expected). I have also tried with other Tensorflow 2 versions with no success.

I am at a loss as to what I&amp;#39;m doing wrong.

Version Info: tensorflow 2.2.0 py37_2 intel tensorflow-base 2.2.0 0 intel tensorflow-estimator 2.2.0 pyh208ff02_0

keras 2.4.3 0 keras-base 2.4.3 py_0 keras-preprocessing 1.1.0 py_1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kiz1rm,True,,dunn_ditty,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kiz1rm/tensorflow_2_not_respecting_thread_settings/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kiz1rm/tensorflow_2_not_respecting_thread_settings/,22217,1608750242.0,0,,False,,,,,,,,,
335,,tensorflow,"Hi there,

I am a beginner and struggling a bit to understand what are the 'protos' in TF Object Detection?

Why do we need them here?

Also, while setting up the TF API we need to download and compile protocol buffers.

There is also a 'protos' folder when one downloads the object detection module - could anyone please explain me what are those and what is the relationship between them?

This would be of immense help!

Thanks!",t2_3x6gro0i,False,,0,False,Could any one please help me to understand what are the 'protos' in TF Object Detection?,[],r/tensorflow,False,6,,0,,,False,t3_kiume2,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608764572.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;I am a beginner and struggling a bit to understand what are the &amp;#39;protos&amp;#39; in TF Object Detection?&lt;/p&gt;

&lt;p&gt;Why do we need them here?&lt;/p&gt;

&lt;p&gt;Also, while setting up the TF API we need to download and compile protocol buffers.&lt;/p&gt;

&lt;p&gt;There is also a &amp;#39;protos&amp;#39; folder when one downloads the object detection module - could anyone please explain me what are those and what is the relationship between them?&lt;/p&gt;

&lt;p&gt;This would be of immense help!&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kiume2,True,,Mandala16180,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kiume2/could_any_one_please_help_me_to_understand_what/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kiume2/could_any_one_please_help_me_to_understand_what/,22217,1608735772.0,0,,False,,,,,,,,,
336,,tensorflow,"Hey everyone,

I'm trying to use this loss function: [Weighted Hausdorff Loss](https://github.com/danielenricocahall/Keras-Weighted-Hausdorff-Distance-Loss) with this implementation of [U-Net](https://keras.io/examples/vision/oxford_pets_image_segmentation/#perpare-unet-xceptionstyle-model) .

The loss seems to be written for TF 1.15, I'm currently using TF 2.4.0. The problem is, that I'm getting **no gradients** with this loss, when using it in training, but when I give it sample data, just evaluating the loss (forward pass) works flawless, so every function used should work with TF 2.4 or am I missing something here? 

Thanks in advance.",t2_9ali49ry,False,,0,False,Problem porting loss to 2.4,[],r/tensorflow,False,6,,0,,,False,t3_kis13w,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608754520.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to use this loss function: &lt;a href=""https://github.com/danielenricocahall/Keras-Weighted-Hausdorff-Distance-Loss""&gt;Weighted Hausdorff Loss&lt;/a&gt; with this implementation of &lt;a href=""https://keras.io/examples/vision/oxford_pets_image_segmentation/#perpare-unet-xceptionstyle-model""&gt;U-Net&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;The loss seems to be written for TF 1.15, I&amp;#39;m currently using TF 2.4.0. The problem is, that I&amp;#39;m getting &lt;strong&gt;no gradients&lt;/strong&gt; with this loss, when using it in training, but when I give it sample data, just evaluating the loss (forward pass) works flawless, so every function used should work with TF 2.4 or am I missing something here? &lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kis13w,True,,MLhype,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kis13w/problem_porting_loss_to_24/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kis13w/problem_porting_loss_to_24/,22217,1608725720.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/FLutt3w8O8-5HuIub8GoiN_yJLUtoNcRhYikS2eHBfM.jpg?auto=webp&amp;s=80cf4fcfccb0556566b296fae81766940a7f089e', 'width': 264, 'height': 264}, 'resolutions': [{'url': 'https://external-preview.redd.it/FLutt3w8O8-5HuIub8GoiN_yJLUtoNcRhYikS2eHBfM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3ecdf4be83c1a992f9c286294d45f84a80f4f81', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/FLutt3w8O8-5HuIub8GoiN_yJLUtoNcRhYikS2eHBfM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8cedfc0e250fd4e7a12a8b63a5760b5ba1e148b2', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'OZWhe2BSg2_R3k6JOpYTqMOKEZKkmY2lybab5NsGBWo'}], 'enabled': False}",,,,,,
337,,tensorflow,,t2_g75w4q,False,,0,False,"Tensorflow implementation of DETR : Object Detection with Transformers, including code for inference, training, and finetuning",[],r/tensorflow,False,6,,0,78.0,,False,t3_ki4r9q,False,dark,1.0,,public,33,0,{},140.0,,False,[],,False,False,,{},,False,33,,False,https://b.thumbs.redditmedia.com/pTluxxQyz6K15DdfKZBfRC4SdzzrAvjwl6QFcaArens.jpg,False,,[],{},,False,,1608670257.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ki4r9q,True,,thibo73800,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ki4r9q/tensorflow_implementation_of_detr_object/,all_ads,False,https://github.com/Visual-Behavior/detr-tensorflow,22217,1608641457.0,0,,False,link,https://github.com/Visual-Behavior/detr-tensorflow,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?auto=webp&amp;s=e8bf1acd163eb615c53f1d6a9f330b726b2b0121', 'width': 672, 'height': 376}, 'resolutions': [{'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b5615afab664f36830b3648ba7cd230f971ebc', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=693c4dc93bd31aea8a1c38f069331a96ef045a67', 'width': 216, 'height': 120}, {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac73c8b117b5f609773d76fafab20a7ae30dd2b8', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/ga00hIqjeIxUir1eQwEMgNll3Rwj6ENlish8ThQfZTA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f88b39da685f9051e60075efaa0e89615c8e6a60', 'width': 640, 'height': 358}], 'variants': {}, 'id': 'qJzQFqiKV3LJwboWk2lyoTrrXoCLYLrNdfcNfmqAye8'}], 'enabled': False}",,,,,,
338,,tensorflow,"(posted here for more advice) 

I am making a project that utilizes MLKit. The classification model will be a TensorFlow Lite model. I noticed that the detected objects always return rectangular bounding boxes. I would like them to return polygonal bounds that are shaped like the object it is detecting, or if possible, a sort of ""3D"" bound.

I am aware of certain annotation tools, along with things like Mask RCNN, but I am not sure how to integrate them into a TensorFlow Lite model, &amp; I do not know what specific files to edit.  (or if I am supposed to implement it in the model rather than the base code) or if I can even do it at all.

I want the detected objects to return bounding polygons, or even 3D polygons/image segmentations, instead of bounding boxes, using MLKit + TensorFlow Lite. How do I achieve this?",t2_4jenmk92,False,,0,False,How to return polygon bound or 3d image segmentation for a detected object with TensorFlow Lite and MLKit?,[],r/tensorflow,False,6,,0,,,False,t3_kid3l4,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608696927.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;(posted here for more advice) &lt;/p&gt;

&lt;p&gt;I am making a project that utilizes MLKit. The classification model will be a TensorFlow Lite model. I noticed that the detected objects always return rectangular bounding boxes. I would like them to return polygonal bounds that are shaped like the object it is detecting, or if possible, a sort of &amp;quot;3D&amp;quot; bound.&lt;/p&gt;

&lt;p&gt;I am aware of certain annotation tools, along with things like Mask RCNN, but I am not sure how to integrate them into a TensorFlow Lite model, &amp;amp; I do not know what specific files to edit.  (or if I am supposed to implement it in the model rather than the base code) or if I can even do it at all.&lt;/p&gt;

&lt;p&gt;I want the detected objects to return bounding polygons, or even 3D polygons/image segmentations, instead of bounding boxes, using MLKit + TensorFlow Lite. How do I achieve this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kid3l4,True,,0zeroBudget,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kid3l4/how_to_return_polygon_bound_or_3d_image/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kid3l4/how_to_return_polygon_bound_or_3d_image/,22217,1608668127.0,0,,False,,,,,,,,,
339,,tensorflow," The code runs like this:

&amp;#x200B;

    import tensorflow as tf 
    import pandas as pd 
    import numpy as np 
    import matplotlib.pyplot as plt 
    %matplotlib inline 
    from tensorflow.keras.models import Sequential 
    from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D 
    
     
    mnist_data = tf.keras.datasets.mnist 
    (train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()
    
    
    def scale_mnist_data(train_images, test_images): 
    return (train_images / 255, test_images / 255)   
    
    
    def train_model(model, scaled_train_images, train_labels): 
    scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images) 
    
    
    

THE CODE RUNS PERFECTLY WELL AT THIS POINT,BUT HERE....

    
    scaled_train_images = scaled_train_images[..., np.newaxis]
    scaled_test_images = scaled_test_images[..., np.newaxis]
    
    

I GET THE ERROR- NameError: name 'scaled\_train\_images' is not defined

    
    
    NameError                                 Traceback (most recent call last)
    &lt;ipython-input-5-7e4c845d2449&gt; in &lt;module&gt;
      1 # Add a dummy channel dimension
      2 
    ----&gt; 3 scaled_train_images = scaled_train_images[..., np.newaxis]
      4 scaled_test_images = scaled_test_images[..., np.newaxis]
    
    
    

I wonder if inserting this code "" def train\_model(model, scaled\_train\_images, train\_labels):"" is fine. But here again, I bumped into similar issues like history, frame and some other variables being not able to be defined.",t2_52hj835v,False,,0,False,I am stuck in defining the variables.,[],r/tensorflow,False,6,,0,,,False,t3_kid0xq,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608696699.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The code runs like this:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
%matplotlib inline 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D 


mnist_data = tf.keras.datasets.mnist 
(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()


def scale_mnist_data(train_images, test_images): 
return (train_images / 255, test_images / 255)   


def train_model(model, scaled_train_images, train_labels): 
scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;THE CODE RUNS PERFECTLY WELL AT THIS POINT,BUT HERE....&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scaled_train_images = scaled_train_images[..., np.newaxis]
scaled_test_images = scaled_test_images[..., np.newaxis]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I GET THE ERROR- NameError: name &amp;#39;scaled_train_images&amp;#39; is not defined&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NameError                                 Traceback (most recent call last)
&amp;lt;ipython-input-5-7e4c845d2449&amp;gt; in &amp;lt;module&amp;gt;
  1 # Add a dummy channel dimension
  2 
----&amp;gt; 3 scaled_train_images = scaled_train_images[..., np.newaxis]
  4 scaled_test_images = scaled_test_images[..., np.newaxis]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I wonder if inserting this code &amp;quot; def train_model(model, scaled_train_images, train_labels):&amp;quot; is fine. But here again, I bumped into similar issues like history, frame and some other variables being not able to be defined.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kid0xq,True,,edmondoh001,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kid0xq/i_am_stuck_in_defining_the_variables/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kid0xq/i_am_stuck_in_defining_the_variables/,22217,1608667899.0,0,,False,,,,,,,,,
340,,tensorflow,"I've been attempting to write a program that utilizes Google's BigGAN Deep 512 model for image interpolation.  I've been attempting to test it using the example on the hub page.  Here is my code so far:

`import os`

`import tensorflow as tf`

`import tensorflow_hub as hub`

`from PIL import Image`

`import numpy as np`

&amp;#x200B;

`export_path = 'C:/Users/' + os.getlogin() + '/Documents/Python/gan_export.png'`

`model_path = 'C:/Users/' + os.getlogin() + '/Documents/Python/biggan-deep-512_1/'`

&amp;#x200B;

`module = tf.saved_model.load(model_path)`

&amp;#x200B;

`batch_size = 1`

`truncation = 0.5`  

`z = truncation * tf.random.truncated_normal([batch_size, 128])`  

`y_index = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32)`

`y = tf.one_hot(y_index, 1000)`  

&amp;#x200B;

`samples = module(dict(y=y, z=z, truncation=truncation))`

When I run this, the following error repeatedly appears in the interpreter:

`WARNING:absl:Importing a function (MetaGraph import) with ops with custom gradients. Will likely fail if a gradient is requested.`

Does anyone know what might cause this or how I could fix it?  Any help would be greatly appreciated!",t2_674ii83,False,,0,False,Problem Trying to Run Hub Module in 2.0,[],r/tensorflow,False,6,,0,,,False,t3_kibqap,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608692705.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been attempting to write a program that utilizes Google&amp;#39;s BigGAN Deep 512 model for image interpolation.  I&amp;#39;ve been attempting to test it using the example on the hub page.  Here is my code so far:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import os&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import tensorflow as tf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import tensorflow_hub as hub&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from PIL import Image&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import numpy as np&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export_path = &amp;#39;C:/Users/&amp;#39; + os.getlogin() + &amp;#39;/Documents/Python/gan_export.png&amp;#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model_path = &amp;#39;C:/Users/&amp;#39; + os.getlogin() + &amp;#39;/Documents/Python/biggan-deep-512_1/&amp;#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;module = tf.saved_model.load(model_path)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;batch_size = 1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;truncation = 0.5&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;z = truncation * tf.random.truncated_normal([batch_size, 128])&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;y_index = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;y = tf.one_hot(y_index, 1000)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;samples = module(dict(y=y, z=z, truncation=truncation))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;When I run this, the following error repeatedly appears in the interpreter:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;WARNING:absl:Importing a function (MetaGraph import) with ops with custom gradients. Will likely fail if a gradient is requested.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Does anyone know what might cause this or how I could fix it?  Any help would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kibqap,True,,RogueVision,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kibqap/problem_trying_to_run_hub_module_in_20/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kibqap/problem_trying_to_run_hub_module_in_20/,22217,1608663905.0,0,,False,,,,,,,,,
341,,tensorflow,I'm using ML Kit to label images with a custom model on Android. Which InputImage is better to pass into the model that can provide more accurate results? Image bitmap or image file URI?,t2_8d1k6s8,False,,0,False,"For classifying images, which InputImage for Android is better? Image file URI or Image Bitmap?",[],r/tensorflow,False,6,,0,,,False,t3_kiaxgh,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608690240.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using ML Kit to label images with a custom model on Android. Which InputImage is better to pass into the model that can provide more accurate results? Image bitmap or image file URI?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kiaxgh,True,,techsavvynerd91,,0,False,all_ads,False,[],False,,/r/tensorflow/comments/kiaxgh/for_classifying_images_which_inputimage_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kiaxgh/for_classifying_images_which_inputimage_for/,22217,1608661440.0,0,,False,,,,,,,,,
342,,tensorflow,"Hi, I am having trouble understanding how to set up a tensorflow model on gcp using the model using the preprocessing ""[task.py](https://task.py)""  in the gcp/AI Platform/models 

Just wondering if you have seen tutorials or courses relating to how to get gcp tensorflow up and running with  some user defined preprocessing done.",t2_6kwe4fb6,False,,0,False,"GCP Tensorflow Tutorial, need help setting up task.py or preprocessing on gcp/AI Platform/models",[],r/tensorflow,False,6,,0,,,False,t3_kiavw1,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608690113.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am having trouble understanding how to set up a tensorflow model on gcp using the model using the preprocessing &amp;quot;&lt;a href=""https://task.py""&gt;task.py&lt;/a&gt;&amp;quot;  in the gcp/AI Platform/models &lt;/p&gt;

&lt;p&gt;Just wondering if you have seen tutorials or courses relating to how to get gcp tensorflow up and running with  some user defined preprocessing done.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kiavw1,True,,Ok_Cryptographer2209,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kiavw1/gcp_tensorflow_tutorial_need_help_setting_up/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kiavw1/gcp_tensorflow_tutorial_need_help_setting_up/,22217,1608661313.0,0,,False,,,,,,,,,
343,,tensorflow,,t2_tunuoy8,False,,0,False,I opened up a new venv for learning tensorflow but the cudart64_101.dll is not getting detected in tensorflow ver: 2.4.0,[],r/tensorflow,False,6,,0,18.0,,False,t3_ki5pbp,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/2-h4pZU1c7mkez3Nmx94Jfxxn6P96DY5MdYf7XjNtps.jpg,False,,[],{},,False,,1608673902.0,text,6,,,text,reddit.com,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ki5pbp,True,,I-_-DuNn0,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ki5pbp/i_opened_up_a_new_venv_for_learning_tensorflow/,all_ads,False,https://www.reddit.com/gallery/ki5pbp,22217,1608645102.0,0,,False,,https://www.reddit.com/gallery/ki5pbp,,True,"{'fcztuif9uq661': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 14, 'x': 108, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9a2accad7ec1e5906eb71289cee5afba25640f8'}, {'y': 28, 'x': 216, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c657ba2d809d6e438630fbe2a6074173a31bf8d4'}, {'y': 41, 'x': 320, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d05905cb284ca564e622e80aa8fc2a699a08487'}, {'y': 83, 'x': 640, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=384e1be4cfd651e93fdc866c8a3442e1ea74a49a'}, {'y': 124, 'x': 960, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f3dc8d6e594ee30d1bcffa204257e5df42c79702'}, {'y': 140, 'x': 1080, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a88fcfc038295443d93ea401f22132a14a5b786d'}], 's': {'y': 519, 'x': 4000, 'u': 'https://preview.redd.it/fcztuif9uq661.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;s=4ca3e7a206dcb7401436e34264f94d582b458ece'}, 'id': 'fcztuif9uq661'}, 'w692ket9uq661': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 20, 'x': 108, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=74e34008a2390f6099dc86feabd34a8b86e75bd5'}, {'y': 40, 'x': 216, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a9948308ee78a93fa9ee179e6aff12fb4b46148'}, {'y': 60, 'x': 320, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0888915ab71dee519ddec83c4a0faed765ebb68'}, {'y': 121, 'x': 640, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dacc2fd89e17f1664a9d38cc6d36dd3c8cad7d32'}, {'y': 181, 'x': 960, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c3a85a2e93e3180cddfef5a1695528e31ec3c38c'}, {'y': 204, 'x': 1080, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dcbc0181f4bb27cc1f81ccf8d3132d51537c3b75'}], 's': {'y': 757, 'x': 4000, 'u': 'https://preview.redd.it/w692ket9uq661.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;s=3f9479933c9ad4d287cc24f429a02682bedac746'}, 'id': 'w692ket9uq661'}}","{'items': [{'media_id': 'fcztuif9uq661', 'id': 18465039}, {'media_id': 'w692ket9uq661', 'id': 18465040}]}",,,
344,,tensorflow,"Object detection is a computer vision task that has recently been influenced by all of the progress made in ML.

Now with tools like TensorFlow Object Detection API, you can create reliable models quickly and fairly easily.

If you’re unfamiliar, TensorFlow Object Detection API:
- supports TensorFlow 2, 
- lets you employ state of the art model architectures for object detection,
- gives you a simple way to configure models.

Tutorial shows everything from installation and setup, all the way to model training.

[TF object detection API tutorial](https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-how-to-train-your-own-object-detector-using-tensorflow-object-detection-api&amp;utm_content=tensorflow)",t2_5hfacnnv,False,,0,False,[Tutorial] How to Train Object Detector with TF Object Detection API,[],r/tensorflow,False,6,,0,,,False,t3_ki1vv0,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608657029.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Object detection is a computer vision task that has recently been influenced by all of the progress made in ML.&lt;/p&gt;

&lt;p&gt;Now with tools like TensorFlow Object Detection API, you can create reliable models quickly and fairly easily.&lt;/p&gt;

&lt;p&gt;If you’re unfamiliar, TensorFlow Object Detection API:
- supports TensorFlow 2, 
- lets you employ state of the art model architectures for object detection,
- gives you a simple way to configure models.&lt;/p&gt;

&lt;p&gt;Tutorial shows everything from installation and setup, all the way to model training.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-how-to-train-your-own-object-detector-using-tensorflow-object-detection-api&amp;amp;utm_content=tensorflow""&gt;TF object detection API tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ki1vv0,True,,kk_ai,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ki1vv0/tutorial_how_to_train_object_detector_with_tf/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ki1vv0/tutorial_how_to_train_object_detector_with_tf/,22217,1608628229.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?auto=webp&amp;s=58571cb365b8c1a8bc59d2d0b0c569b60f80c12d', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7a20ec5eaf433b0ea3809c3dec42ee309f5d2e9', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=72e3b29f431ea4bfa216289ac55140604892a1a9', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=edced235434d97442c58dab96ff5482854ef9d73', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ce3c086e41b72bddfb7f99f1c14fb04792f2cbb', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eb29a31ce09d575fc735fe3d8868ef202e2dc243', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/hVJocgKei4tCW0lZ7GHEqA_NaqOOn2w6dzcnEviRyAE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f693662186772d394a28ec0835cd7443bbc3cf90', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'hjSwfBBdUxIAGos5PUNCw6irLuLBKtO2o8s4t8hpbM0'}], 'enabled': False}",,,,,,
345,,tensorflow,"I am delighted to share the TensorFlow JS variants for the MIRNet model, capable of enhancing low-light images to really great extents.

The Project repo - [https://github.com/Rishit-dagli/MIRNet-TFJS](https://github.com/Rishit-dagli/MIRNet-TFJS)

Please consider giving it a star if you like it. More details in [this tweet](https://twitter.com/rishit_dagli/status/1340984448343367680).

[Project results](https://preview.redd.it/dhr9mz4laj661.jpg?width=1048&amp;format=pjpg&amp;auto=webp&amp;s=9adc6a3a4097052040513848c42995440f94154e)",t2_7t6vk108,False,,0,False,Low light image enhancement TFJS,[],r/tensorflow,False,6,,0,69.0,,False,t3_khghnv,False,dark,0.97,,public,27,0,{},140.0,,False,[],,False,False,,{},Project,False,27,,False,https://a.thumbs.redditmedia.com/0xliDPu0_ct6K1d6nfxozdLMSeQQ3PcdC_etWre11p0.jpg,1608557681.0,,[],{},,True,,1608582581.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am delighted to share the TensorFlow JS variants for the MIRNet model, capable of enhancing low-light images to really great extents.&lt;/p&gt;

&lt;p&gt;The Project repo - &lt;a href=""https://github.com/Rishit-dagli/MIRNet-TFJS""&gt;https://github.com/Rishit-dagli/MIRNet-TFJS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please consider giving it a star if you like it. More details in &lt;a href=""https://twitter.com/rishit_dagli/status/1340984448343367680""&gt;this tweet&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/dhr9mz4laj661.jpg?width=1048&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9adc6a3a4097052040513848c42995440f94154e""&gt;Project results&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,khghnv,True,,Rishit-dagli,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/khghnv/low_light_image_enhancement_tfjs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/khghnv/low_light_image_enhancement_tfjs/,22217,1608553781.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/FcCH88I9GSODUKzJJwNFlB_SSnYFSosQcNHH9lf748k.jpg?auto=webp&amp;s=8013bd4a0a1ddfb687438bec5768ba4fa9c07289', 'width': 1048, 'height': 523}, 'resolutions': [{'url': 'https://external-preview.redd.it/FcCH88I9GSODUKzJJwNFlB_SSnYFSosQcNHH9lf748k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6de420730aa9b10aa91da4310607c0f3a3f24244', 'width': 108, 'height': 53}, {'url': 'https://external-preview.redd.it/FcCH88I9GSODUKzJJwNFlB_SSnYFSosQcNHH9lf748k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8539cbf55e01f9653bd31ff926095d65aad239a2', 'width': 216, 'height': 107}, {'url': 'https://external-preview.redd.it/FcCH88I9GSODUKzJJwNFlB_SSnYFSosQcNHH9lf748k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0cb8852d19b57950826ea71e590f5445c8379c6d', 'width': 320, 'height': 159}, {'url': 'https://external-preview.redd.it/FcCH88I9GSODUKzJJwNFlB_SSnYFSosQcNHH9lf748k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1832f5161c0d214d347c82c47e250a33974e1eaf', 'width': 640, 'height': 319}, {'url': 'https://external-preview.redd.it/FcCH88I9GSODUKzJJwNFlB_SSnYFSosQcNHH9lf748k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4e51bad707616689add42dead4b9444bcb151090', 'width': 960, 'height': 479}], 'variants': {}, 'id': 'lWmCOIOqOvBVnWQuN7ztfDPPLaKnp5qWw7HvvJqUryg'}], 'enabled': False}",,"{'dhr9mz4laj661': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 53, 'x': 108, 'u': 'https://preview.redd.it/dhr9mz4laj661.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2c29f54dabc4625267ed2582a99893acfea31f6'}, {'y': 107, 'x': 216, 'u': 'https://preview.redd.it/dhr9mz4laj661.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3de775284427c521bd556e69dd05b7d5447b9e64'}, {'y': 159, 'x': 320, 'u': 'https://preview.redd.it/dhr9mz4laj661.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb5cd5bbe321973d60374bfeb1780248b28a911a'}, {'y': 319, 'x': 640, 'u': 'https://preview.redd.it/dhr9mz4laj661.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bb60e3ab245eea1ac4802ec2407eeb09a75b9158'}, {'y': 479, 'x': 960, 'u': 'https://preview.redd.it/dhr9mz4laj661.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6dcd7f665bbc37de91bbf11ee57b3243808e2eb2'}], 's': {'y': 523, 'x': 1048, 'u': 'https://preview.redd.it/dhr9mz4laj661.jpg?width=1048&amp;format=pjpg&amp;auto=webp&amp;s=9adc6a3a4097052040513848c42995440f94154e'}, 'id': 'dhr9mz4laj661'}}",,,,
346,,tensorflow,"Say you're classifying the flowers dataset. Some images aren't as good as others. Would duplicating the images that are good examples of a certain type help propagate the desired features in the network?

E.g. if I duplicate a close-up of a certain type flower head within the dataset (say a rose within /roses), would it make the network more bias towards the duplicates? 

I have a handful of ideal examples, and thousands of very variable examples. I'm unsure what's the best strategy to be more biased towards the good examples in my data..",t2_621he0r0,False,,0,False,Is duplicating images which are good representations of the type of thing being classified a good idea?,[],r/tensorflow,False,6,,0,,,False,t3_khsdom,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1608620101.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Say you&amp;#39;re classifying the flowers dataset. Some images aren&amp;#39;t as good as others. Would duplicating the images that are good examples of a certain type help propagate the desired features in the network?&lt;/p&gt;

&lt;p&gt;E.g. if I duplicate a close-up of a certain type flower head within the dataset (say a rose within /roses), would it make the network more bias towards the duplicates? &lt;/p&gt;

&lt;p&gt;I have a handful of ideal examples, and thousands of very variable examples. I&amp;#39;m unsure what&amp;#39;s the best strategy to be more biased towards the good examples in my data..&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,khsdom,True,,BananaCharmer,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/khsdom/is_duplicating_images_which_are_good/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/khsdom/is_duplicating_images_which_are_good/,22217,1608591301.0,0,,False,,,,,,,,,
347,,tensorflow,"I'm building an image classifier. I happen to have a small dataset of ideal data. Can I train a model using this idealised data, and somehow use it as a base for further training?

I've read through the docs; they all use ImageNet or tensorflow-hub datasets. I can't seem to find an example of using your own data.",t2_621he0r0,False,,0,False,Transfer learning using a small dataset,[],r/tensorflow,False,6,,0,,,False,t3_khrtu2,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608618318.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building an image classifier. I happen to have a small dataset of ideal data. Can I train a model using this idealised data, and somehow use it as a base for further training?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve read through the docs; they all use ImageNet or tensorflow-hub datasets. I can&amp;#39;t seem to find an example of using your own data.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,khrtu2,True,,BananaCharmer,,11,True,all_ads,False,[],False,,/r/tensorflow/comments/khrtu2/transfer_learning_using_a_small_dataset/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/khrtu2/transfer_learning_using_a_small_dataset/,22217,1608589518.0,0,,False,,,,,,,,,
348,,tensorflow,"I am currently studying Industrial  Engineering, but I’ve been learning DL and ML on my own. My goal is to obtain a job related with ML or AI. I don’t come from a traditional Computer Science background, do you think this certificate will add value to my CV?",t2_88v89ogp,False,,0,False,Is getting the Tensorflow Certification worth it?,[],r/tensorflow,False,6,,0,,,False,t3_kheor1,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1608574969.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently studying Industrial  Engineering, but I’ve been learning DL and ML on my own. My goal is to obtain a job related with ML or AI. I don’t come from a traditional Computer Science background, do you think this certificate will add value to my CV?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kheor1,True,,man_you_trust,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kheor1/is_getting_the_tensorflow_certification_worth_it/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kheor1/is_getting_the_tensorflow_certification_worth_it/,22217,1608546169.0,0,,False,,,,,,,,,
349,,tensorflow,"I'm looking to deploy ML models on edge. I'm not very comfortable with C++. If it is possible to deploy ML models with micropython or circuit python, it'll be great.",t2_xt6j8xa,False,,0,False,Is it possible to use TensorFlow Lite with micropython or circuit python?,[],r/tensorflow,False,6,,0,,,False,t3_khabq4,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1608554828.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking to deploy ML models on edge. I&amp;#39;m not very comfortable with C++. If it is possible to deploy ML models with micropython or circuit python, it&amp;#39;ll be great.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,khabq4,True,,clean_pegasus,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/khabq4/is_it_possible_to_use_tensorflow_lite_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/khabq4/is_it_possible_to_use_tensorflow_lite_with/,22217,1608526028.0,0,,False,,,,,,,,,
350,,tensorflow,"Hey, this is a question I had that I answered myself after some research. I can't find a flair more applicable than 'Question' so I will just answer it myself haha.

I was trying to use tf.keras.preprocessing.text.Tokenizer to train a model for a language task. I wanted my model to include certain punctuation in it's output, like exclamation points and commas and whatnot, and I wasn't sure how to do this.

I figured that since the default value for filters in the Tokenizer constructor is:

    filters='!""#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n'

then I would just have to remove the punctuation that I want to be recognized. I then spent a few hours training my model.

**DON'T DO THIS**. It will not treat the punctuation as separate tokens, but rather your vocabulary will be filled with examples such as 'man' vs 'man.' vs 'man,', etc. These will all be separate tokens.

Instead, you should preprocess all of your sentences to include spaces between any punctuation that you want. This is how I did it:

    def separate_punctuation(s, filters=',.()?'):
        new_s = ''
        for char in s:
            if char in filters:
                 new_s += ' ' + char + ' '
            else:
                new_s += char
        return new_s.strip()

This way 'Hello neighbor, how are you?' will become 'Hello neighbor , how are you ?'. Thus, all punctuation will only take up one element of your vocabulary and your model will generalize much, much better.

Hope this saves someone else's time.",t2_10sghc,False,,0,False,How to use Tokenizer with punctuation?,[],r/tensorflow,False,6,,0,,,False,t3_kh6n2u,False,dark,0.72,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1608541454.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, this is a question I had that I answered myself after some research. I can&amp;#39;t find a flair more applicable than &amp;#39;Question&amp;#39; so I will just answer it myself haha.&lt;/p&gt;

&lt;p&gt;I was trying to use tf.keras.preprocessing.text.Tokenizer to train a model for a language task. I wanted my model to include certain punctuation in it&amp;#39;s output, like exclamation points and commas and whatnot, and I wasn&amp;#39;t sure how to do this.&lt;/p&gt;

&lt;p&gt;I figured that since the default value for filters in the Tokenizer constructor is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;filters=&amp;#39;!&amp;quot;#$%&amp;amp;()*+,-./:;&amp;lt;=&amp;gt;?@[\\]^_`{|}~\t\n&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then I would just have to remove the punctuation that I want to be recognized. I then spent a few hours training my model.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DON&amp;#39;T DO THIS&lt;/strong&gt;. It will not treat the punctuation as separate tokens, but rather your vocabulary will be filled with examples such as &amp;#39;man&amp;#39; vs &amp;#39;man.&amp;#39; vs &amp;#39;man,&amp;#39;, etc. These will all be separate tokens.&lt;/p&gt;

&lt;p&gt;Instead, you should preprocess all of your sentences to include spaces between any punctuation that you want. This is how I did it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def separate_punctuation(s, filters=&amp;#39;,.()?&amp;#39;):
    new_s = &amp;#39;&amp;#39;
    for char in s:
        if char in filters:
             new_s += &amp;#39; &amp;#39; + char + &amp;#39; &amp;#39;
        else:
            new_s += char
    return new_s.strip()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This way &amp;#39;Hello neighbor, how are you?&amp;#39; will become &amp;#39;Hello neighbor , how are you ?&amp;#39;. Thus, all punctuation will only take up one element of your vocabulary and your model will generalize much, much better.&lt;/p&gt;

&lt;p&gt;Hope this saves someone else&amp;#39;s time.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kh6n2u,True,,LivingPornFree,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kh6n2u/how_to_use_tokenizer_with_punctuation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kh6n2u/how_to_use_tokenizer_with_punctuation/,22217,1608512654.0,0,,False,,,,,,,,,
351,,tensorflow,,t2_1fuhylzi,False,,0,False,How to use VGG16 in Kaggle inference ?,[],r/tensorflow,False,6,,0,,,False,t3_kgzpc3,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,default,False,,[],{},,False,,1608519115.0,text,6,,,text,self.MLQuestions,False,,,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kgzpc3,True,,maifee,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kgzpc3/how_to_use_vgg16_in_kaggle_inference/,all_ads,False,/r/MLQuestions/comments/kgzonq/how_to_use_vgg16_in_kaggle_inference/,22217,1608490315.0,0,,False,,/r/MLQuestions/comments/kgzonq/how_to_use_vgg16_in_kaggle_inference/,,,,,"[{'approved_at_utc': None, 'subreddit': 'MLQuestions', 'selftext': ""I'm trying to complete the *Interfarance* part of a competition in Kaggle :\n\n    model = VGG16(\n      weights = 'imagenet',\n      include_top = True)\n    \n    img_size = 336\n    \n    input_tensor = Input(shape=(img_size, img_size, 3))\n    \n    base_model = VGG16(\n        weights='imagenet',\n        include_top = False,\n        input_tensor = input_tensor)\n    \n    for layer in base_model.layers:\n        layer.trainable = True\n        \n    base_model.layers[0].trainable = False\n    base_model.layers[1].trainable = False\n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    \n    output = Dense(\n        5,\n        activation='softmax')(x)\n    \n    model = Model(\n        inputs=base_model.input,\n        outputs=output)\n    \n    model.compile(loss='binary_crossentropy',\n                  optimizer = Adam(lr = 1e-5),\n                  metrics = ['categorical_accuracy'])\n\n**To submit, I must turn off internet. But VGG16 requires downloading, so how can I bypass this ?**\n\nI've stored my weights in a h5 file and created a private dataset and added it there.\n\n&amp;#x200B;\n\nAnd can anyone give me a template of simple inference ?"", 'author_fullname': 't2_1fuhylzi', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to use VGG16 in Kaggle inference ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MLQuestions', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_kgzonq', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.45, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1608519054.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MLQuestions', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to complete the &lt;em&gt;Interfarance&lt;/em&gt; part of a competition in Kaggle :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;model = VGG16(\n  weights = &amp;#39;imagenet&amp;#39;,\n  include_top = True)\n\nimg_size = 336\n\ninput_tensor = Input(shape=(img_size, img_size, 3))\n\nbase_model = VGG16(\n    weights=&amp;#39;imagenet&amp;#39;,\n    include_top = False,\n    input_tensor = input_tensor)\n\nfor layer in base_model.layers:\n    layer.trainable = True\n\nbase_model.layers[0].trainable = False\nbase_model.layers[1].trainable = False\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n\noutput = Dense(\n    5,\n    activation=&amp;#39;softmax&amp;#39;)(x)\n\nmodel = Model(\n    inputs=base_model.input,\n    outputs=output)\n\nmodel.compile(loss=&amp;#39;binary_crossentropy&amp;#39;,\n              optimizer = Adam(lr = 1e-5),\n              metrics = [&amp;#39;categorical_accuracy&amp;#39;])\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;To submit, I must turn off internet. But VGG16 requires downloading, so how can I bypass this ?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve stored my weights in a h5 file and created a private dataset and added it there.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And can anyone give me a template of simple inference ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_30rel', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'kgzonq', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'maifee', 'discussion_type': None, 'num_comments': 12, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MLQuestions/comments/kgzonq/how_to_use_vgg16_in_kaggle_inference/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MLQuestions/comments/kgzonq/how_to_use_vgg16_in_kaggle_inference/', 'subreddit_subscribers': 31266, 'created_utc': 1608490254.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_kgzonq,
352,,tensorflow,,t2_6cffr6em,False,,0,False,"TF based animation generated by text and emotion labels, trained on my face",[],r/tensorflow,False,6,,0,78.0,,False,t3_kgfc2e,False,dark,0.95,,public,47,2,{},140.0,,False,[],"{'reddit_video': {'bitrate_kbps': 800, 'fallback_url': 'https://v.redd.it/jmvblpkdb7661/DASH_360.mp4?source=fallback', 'height': 360, 'width': 640, 'scrubber_media_url': 'https://v.redd.it/jmvblpkdb7661/DASH_96.mp4', 'dash_url': 'https://v.redd.it/jmvblpkdb7661/DASHPlaylist.mpd?a=1618044733%2CMDY1MzE5MTc0ZjBhN2UzZDczNTVmNzQwYjE4ZWRmZGMxNGM4MTY0ODlmZmM3Zjg2ZDY0ZmM1NGNiYWM1N2U0NA%3D%3D&amp;v=1&amp;f=sd', 'duration': 6, 'hls_url': 'https://v.redd.it/jmvblpkdb7661/HLSPlaylist.m3u8?a=1618044733%2CM2Y5YTFlNGQ2ZDllNzhkNmFlMWE4MTkwMDJlMWE1ZjBkM2M3MmVkM2ExYjEwMDVlZTdkZGNlMGFiNzNhZTAwZg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': True, 'transcoding_status': 'completed'}}",True,False,,{},Project,False,47,,False,https://b.thumbs.redditmedia.com/sJzQFMqsvtsCssJCwC-ybKfKk4rgBMKCTnDo0H60riY.jpg,False,,[],{},,False,,1608437605.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 20, 'id': 'award_5eac457f-ebac-449b-93a7-eb17b557f03c', 'penny_donate': 0, 'award_sub_type': 'PREMIUM', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=16&amp;height=16&amp;auto=webp&amp;s=bc61b528b8d075c26a3d0f2ad3d9e42259c51cbe', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=32&amp;height=32&amp;auto=webp&amp;s=d576c9a19ed29ca5624333239dbde289a146930b', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=48&amp;height=48&amp;auto=webp&amp;s=da1e45654f5acfb6be44fa07c168ad6420796f56', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=64&amp;height=64&amp;auto=webp&amp;s=677455ac05c563b5585f76e52ee96354f1430799', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=128&amp;height=128&amp;auto=webp&amp;s=25a3b6021a92685b01883fb3d947d2959a75d8b3', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you follow your heart, love is the answer', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'LOVE!', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=16&amp;height=16&amp;auto=webp&amp;s=bc61b528b8d075c26a3d0f2ad3d9e42259c51cbe', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=32&amp;height=32&amp;auto=webp&amp;s=d576c9a19ed29ca5624333239dbde289a146930b', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=48&amp;height=48&amp;auto=webp&amp;s=da1e45654f5acfb6be44fa07c168ad6420796f56', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=64&amp;height=64&amp;auto=webp&amp;s=677455ac05c563b5585f76e52ee96354f1430799', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=128&amp;height=128&amp;auto=webp&amp;s=25a3b6021a92685b01883fb3d947d2959a75d8b3', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}]",[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kgfc2e,True,,BlakeYerian,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/kgfc2e/tf_based_animation_generated_by_text_and_emotion/,all_ads,False,https://v.redd.it/jmvblpkdb7661,22217,1608408805.0,0,"{'reddit_video': {'bitrate_kbps': 800, 'fallback_url': 'https://v.redd.it/jmvblpkdb7661/DASH_360.mp4?source=fallback', 'height': 360, 'width': 640, 'scrubber_media_url': 'https://v.redd.it/jmvblpkdb7661/DASH_96.mp4', 'dash_url': 'https://v.redd.it/jmvblpkdb7661/DASHPlaylist.mpd?a=1618044733%2CMDY1MzE5MTc0ZjBhN2UzZDczNTVmNzQwYjE4ZWRmZGMxNGM4MTY0ODlmZmM3Zjg2ZDY0ZmM1NGNiYWM1N2U0NA%3D%3D&amp;v=1&amp;f=sd', 'duration': 6, 'hls_url': 'https://v.redd.it/jmvblpkdb7661/HLSPlaylist.m3u8?a=1618044733%2CM2Y5YTFlNGQ2ZDllNzhkNmFlMWE4MTkwMDJlMWE1ZjBkM2M3MmVkM2ExYjEwMDVlZTdkZGNlMGFiNzNhZTAwZg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': True, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/jmvblpkdb7661,"{'images': [{'source': {'url': 'https://external-preview.redd.it/gd0x4dsYp1KL2rHS7RCtR_BXRiv8q-5O0R6LS_7rQJ4.png?format=pjpg&amp;auto=webp&amp;s=d2a0c3c288c4322d71fca410882fb902cd09388f', 'width': 640, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/gd0x4dsYp1KL2rHS7RCtR_BXRiv8q-5O0R6LS_7rQJ4.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=bf097f4630976041b49b71fda6488bdad0bbd51d', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/gd0x4dsYp1KL2rHS7RCtR_BXRiv8q-5O0R6LS_7rQJ4.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2cf0d20ac801ca50038586273f3497b27b061323', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/gd0x4dsYp1KL2rHS7RCtR_BXRiv8q-5O0R6LS_7rQJ4.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=965ae5b993453dad84fd03fcf45de298f18c24c3', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/gd0x4dsYp1KL2rHS7RCtR_BXRiv8q-5O0R6LS_7rQJ4.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8474dbcab390daf6cf8919eece9dc9be9ddc15a7', 'width': 640, 'height': 360}], 'variants': {}, 'id': 'YOJy4MP6UtMnDBAGM2CeoJ5RrGpBDVaINkZl7ldPv1U'}], 'enabled': False}",,,,,,
353,,tensorflow,"Hi!

A week ago, I purchased a brand new workstation with RTX 3090 in it. I have set up everything (tensorflow, CUDA , cuDNN e.t.c). Everything compiles and runs without any unregular tensorflow messages. I even see that CUDA utilization on the GPU in the taskbar is where it is supposed to be at.

However, exactly same model (2 dense layers, 40 neurons each) has its inference speed reduced by a factor of 14 compared to the achieved speed on a laptop with rtx 2060. 

I have searched the web far and wide and I cant find anyone experiencing the same issue. Does anyone has any ideas?",t2_l0qwy,False,,0,False,RTX 3090 is 14 times slower on inference compared to RTX 2060 ?!,[],r/tensorflow,False,6,,0,,,False,t3_kgbr1r,False,dark,1.0,,public,17,0,{},,,False,[],,False,False,,{},,False,17,,False,self,False,,[],{},,True,,1608426942.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!&lt;/p&gt;

&lt;p&gt;A week ago, I purchased a brand new workstation with RTX 3090 in it. I have set up everything (tensorflow, CUDA , cuDNN e.t.c). Everything compiles and runs without any unregular tensorflow messages. I even see that CUDA utilization on the GPU in the taskbar is where it is supposed to be at.&lt;/p&gt;

&lt;p&gt;However, exactly same model (2 dense layers, 40 neurons each) has its inference speed reduced by a factor of 14 compared to the achieved speed on a laptop with rtx 2060. &lt;/p&gt;

&lt;p&gt;I have searched the web far and wide and I cant find anyone experiencing the same issue. Does anyone has any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kgbr1r,True,,psychodrivenmusic,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/kgbr1r/rtx_3090_is_14_times_slower_on_inference_compared/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kgbr1r/rtx_3090_is_14_times_slower_on_inference_compared/,22217,1608398142.0,0,,False,,,,,,,,,
354,,tensorflow,"I was trying to make a prediction from a loaded tensorflow model. Though I'm not sure if it's correct how I previously saved it, specifically I have doubts about code inside serving_input_fn() function (MAX_SEQ_LENGTH=128):

    def serving_input_fn():   
        feature_spec = { ""input_ids"" : tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),                
                         ""input_mask"" : tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),       
                         ""segment_ids"" : tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),       
                         ""label_ids"" :  tf.FixedLenFeature([], tf.int64)    }   
    
        serialized_tf_example = tf.placeholder(dtype=tf.string,shape=[None],name='input_example_tensor')   
        receiver_tensors = {'example': serialized_tf_example}   
        features = tf.parse_example(serialized_tf_example, feature_spec) 
    
        return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)  

    estimator.export_saved_model('gs://bucket/trained_model, serving_input_receiver_fn=serving_input_fn)

When I try to predict from loaded model:

    from tensorflow.contrib import predictor
    predict_fn = predictor.from_saved_model(LOAD_PATH)
    input_features_test = convert_examples_to_features( test_examples,label_list, MAX_SEQ_LENGTH, tokenizer)
    predictions = predict_fn({'example':input_features_test[0]})
it returns this error:
&gt; 
&gt; ValueError: Cannot feed value of shape () for Tensor 'input_example_tensor:0', which has shape '(?,)'

How should I change serving_input_fn() method?

If you want to reproduce it: [github_repo](https://github.com/cedoard/fine_tuned_bert) (you should download variables from [here](https://drive.google.com/drive/folders/1-6hvFMF7cjnnj4Ts4UhnYU7ZoXaaJEgs?usp=sharing) and put it in trained_model/1608370941/ folder)

[This](https://github.com/marcopoli/AlBERTo-it/blob/master/AlBERTo_End_to_End_\(Fine_tuning_%2B_Predicting\)_with_Cloud_TPU_Sentence_Classification_Tasks.ipynb) is the tutorial I followed to fine tune BERT model on google cloud TPU.",t2_zp2at,False,,0,False,Predict from loaded BERT model,[],r/tensorflow,False,6,,0,,,False,t3_kghknj,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1608445064.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was trying to make a prediction from a loaded tensorflow model. Though I&amp;#39;m not sure if it&amp;#39;s correct how I previously saved it, specifically I have doubts about code inside serving_input_fn() function (MAX_SEQ_LENGTH=128):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def serving_input_fn():   
    feature_spec = { &amp;quot;input_ids&amp;quot; : tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),                
                     &amp;quot;input_mask&amp;quot; : tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),       
                     &amp;quot;segment_ids&amp;quot; : tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),       
                     &amp;quot;label_ids&amp;quot; :  tf.FixedLenFeature([], tf.int64)    }   

    serialized_tf_example = tf.placeholder(dtype=tf.string,shape=[None],name=&amp;#39;input_example_tensor&amp;#39;)   
    receiver_tensors = {&amp;#39;example&amp;#39;: serialized_tf_example}   
    features = tf.parse_example(serialized_tf_example, feature_spec) 

    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)  

estimator.export_saved_model(&amp;#39;gs://bucket/trained_model, serving_input_receiver_fn=serving_input_fn)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When I try to predict from loaded model:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.contrib import predictor
predict_fn = predictor.from_saved_model(LOAD_PATH)
input_features_test = convert_examples_to_features( test_examples,label_list, MAX_SEQ_LENGTH, tokenizer)
predictions = predict_fn({&amp;#39;example&amp;#39;:input_features_test[0]})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it returns this error:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ValueError: Cannot feed value of shape () for Tensor &amp;#39;input_example_tensor:0&amp;#39;, which has shape &amp;#39;(?,)&amp;#39;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;How should I change serving_input_fn() method?&lt;/p&gt;

&lt;p&gt;If you want to reproduce it: &lt;a href=""https://github.com/cedoard/fine_tuned_bert""&gt;github_repo&lt;/a&gt; (you should download variables from &lt;a href=""https://drive.google.com/drive/folders/1-6hvFMF7cjnnj4Ts4UhnYU7ZoXaaJEgs?usp=sharing""&gt;here&lt;/a&gt; and put it in trained_model/1608370941/ folder)&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/marcopoli/AlBERTo-it/blob/master/AlBERTo_End_to_End_(Fine_tuning_%2B_Predicting)_with_Cloud_TPU_Sentence_Classification_Tasks.ipynb""&gt;This&lt;/a&gt; is the tutorial I followed to fine tune BERT model on google cloud TPU.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kghknj,True,,spaceape__,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kghknj/predict_from_loaded_bert_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kghknj/predict_from_loaded_bert_model/,22217,1608416264.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/bQGbB2Qrr6dKwz5cuC1jrwpnbeK5-6iGtI4vy7OSuaY.jpg?auto=webp&amp;s=f424b0b9dbd2085e06d0dc48cd180af6accfcdb2', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/bQGbB2Qrr6dKwz5cuC1jrwpnbeK5-6iGtI4vy7OSuaY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f24a4ee4c5eb71cb150fd17048552a048cab6f2d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/bQGbB2Qrr6dKwz5cuC1jrwpnbeK5-6iGtI4vy7OSuaY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6a21f5135c777cf51dffce8825e494aef3171ac', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/bQGbB2Qrr6dKwz5cuC1jrwpnbeK5-6iGtI4vy7OSuaY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14acab562a0eb8fe55b25b0b69eed87a1a97fed6', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'rs64T27pDpO2bDAMORKYCfScFvqhdfpf_0SPBkyDm7Y'}], 'enabled': False}",,,,,,
355,,tensorflow,"Hi there!  


Looking for a way of manipulating something like this: 

[From image \(3456px x 5184px\)](https://preview.redd.it/14uzyc8cv7661.jpg?width=3456&amp;format=pjpg&amp;auto=webp&amp;s=c4f7df7e7f635d9ac5f6319e42ccddb101d670ae)

To something like this:

[To image \(1500px x 1500px\)](https://preview.redd.it/vw2e18cdv7661.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s=040d00e1422c67ce6081b2d7c93b85fd355a86bc)

There are a decent number of variations on this, e.g. more or less zoomed in (depending on garment length), front and back sides of the garment, two different mannequins, some images without a mannequin etc. I have around 2500 garments, so around 5000 images front and back.

I've got some basic experience with TensorFlow and Keras, having completed a traffic flow prediction project for uni which used past traffic data fed into a stacked auto encoder network. Pretty inexperienced in this area though.

I have a few questions:

1. Is it even something that I'd want to be doing with TensorFlow? It feels like something I could hack together by adding extra info to the image filenames and using a library like Pillow, but there are some variations which means it may not work great in all circumstances, plus, using ML would be a more interesting project.
2. If yes, I saw that TensorFlow has an image processing library which seems like what I need, but I'm unsure on where to get started using it
3. Are there any good examples/tutorials/videos focused on image manipulation like this?

I've done a bit of research though haven't had much luck, but feel free to call me an idiot if I've missed an obvious, preexisting project or solution.

Any and all help would be greatly appreciated!",t2_tldd3b5,False,,0,False,"Tensorflow Image Resize, Crop and Centering Advice",[],r/tensorflow,False,6,,0,140.0,,False,t3_kgi3vi,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/T9c9I5wt3g3YXg2i2jkjwD4jodgUXOBj-ko5cuHJoxY.jpg,False,,[],{},,True,,1608446931.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there!  &lt;/p&gt;

&lt;p&gt;Looking for a way of manipulating something like this: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/14uzyc8cv7661.jpg?width=3456&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c4f7df7e7f635d9ac5f6319e42ccddb101d670ae""&gt;From image (3456px x 5184px)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To something like this:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/vw2e18cdv7661.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=040d00e1422c67ce6081b2d7c93b85fd355a86bc""&gt;To image (1500px x 1500px)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There are a decent number of variations on this, e.g. more or less zoomed in (depending on garment length), front and back sides of the garment, two different mannequins, some images without a mannequin etc. I have around 2500 garments, so around 5000 images front and back.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve got some basic experience with TensorFlow and Keras, having completed a traffic flow prediction project for uni which used past traffic data fed into a stacked auto encoder network. Pretty inexperienced in this area though.&lt;/p&gt;

&lt;p&gt;I have a few questions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is it even something that I&amp;#39;d want to be doing with TensorFlow? It feels like something I could hack together by adding extra info to the image filenames and using a library like Pillow, but there are some variations which means it may not work great in all circumstances, plus, using ML would be a more interesting project.&lt;/li&gt;
&lt;li&gt;If yes, I saw that TensorFlow has an image processing library which seems like what I need, but I&amp;#39;m unsure on where to get started using it&lt;/li&gt;
&lt;li&gt;Are there any good examples/tutorials/videos focused on image manipulation like this?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;#39;ve done a bit of research though haven&amp;#39;t had much luck, but feel free to call me an idiot if I&amp;#39;ve missed an obvious, preexisting project or solution.&lt;/p&gt;

&lt;p&gt;Any and all help would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kgi3vi,True,,ljackmanl,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kgi3vi/tensorflow_image_resize_crop_and_centering_advice/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kgi3vi/tensorflow_image_resize_crop_and_centering_advice/,22217,1608418131.0,0,,False,,,,,"{'vw2e18cdv7661': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=884f1d020aeefda0c3c63afa04a3bcd7db48dd11'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cf8850a9b36ae6fa2d0df74ad18480efb8f313c'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=727c0b2b4c14f6f8a16117088c924f0f2a7e2cd9'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=98249fbd8eb35c071724ae27c1e1aa29fb8e6d7d'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=32b43f0176f946df7a9bbca33d8e8b9ace8594cc'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1aef924f16958e42d39dc72d37334e914fd5c60'}], 's': {'y': 1500, 'x': 1500, 'u': 'https://preview.redd.it/vw2e18cdv7661.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s=040d00e1422c67ce6081b2d7c93b85fd355a86bc'}, 'id': 'vw2e18cdv7661'}, '14uzyc8cv7661': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 162, 'x': 108, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0be271e506b9f08a709ad354216250a0e2fdb7e'}, {'y': 324, 'x': 216, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a2fa0df3a6eedd5f7d268b2ece3a0366e28c6d4'}, {'y': 480, 'x': 320, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=23f1fe072dc7bd55bcef09ca64d4940b618dc7f5'}, {'y': 960, 'x': 640, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adc44f57db0233ce8569ae2dfb67187fcb17c96d'}, {'y': 1440, 'x': 960, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=726d2605a0cded863283c66aa471f84aa1a4bffc'}, {'y': 1620, 'x': 1080, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=187488839dd5ecb4715cd2b86b622ed2620d17cf'}], 's': {'y': 5184, 'x': 3456, 'u': 'https://preview.redd.it/14uzyc8cv7661.jpg?width=3456&amp;format=pjpg&amp;auto=webp&amp;s=c4f7df7e7f635d9ac5f6319e42ccddb101d670ae'}, 'id': '14uzyc8cv7661'}}",,,,
356,,tensorflow,"first of all it was ""tensorflow-gpu test is false"" issue for me. but i managed to run github repo below which is my goal.

[https://github.com/cysmith/neural-style-tf](https://github.com/cysmith/neural-style-tf)

then i came up with ""Could not load library cudnn\_ops\_infer64\_8.dll. Error code 126

Please make sure cudnn\_ops\_infer64\_8.dll is in your library path!"" error.

i've ""cudnn\_ops\_infer64\_8.dll.""in my downloads folder.Because i tried to match perfect cuda- tensorflow for my gpu.

\[cmd pic shows github repo works until error\]\[1\]

&amp;#x200B;

&amp;#x200B;

\[1\]: [https://i.stack.imgur.com/Gw1Yl.png](https://i.stack.imgur.com/Gw1Yl.png)

&amp;#x200B;

tensorflow:2.3.0

python:3.7.9

CUDA:v10.1

cudnn:cudnn-10.1-windows10-x64-v7.5.0.56

gpu:nvidia 840m

i'm stucked at this point.i'm new to ML and tensorflow and just want to try a simple project.thx\^\^

 yes i added “cudnn\_ops\_infer64\_8.dll” in PATH as c:\\downloads…\\bin. Nothing changed. ",t2_684z39m2,False,,0,False,tensorflow could not load librart cudnn_ops_infer64_8.dll .error code 126,[],r/tensorflow,False,6,,0,,,False,t3_kghlpb,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608445175.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;first of all it was &amp;quot;tensorflow-gpu test is false&amp;quot; issue for me. but i managed to run github repo below which is my goal.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/cysmith/neural-style-tf""&gt;https://github.com/cysmith/neural-style-tf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;then i came up with &amp;quot;Could not load library cudnn_ops_infer64_8.dll. Error code 126&lt;/p&gt;

&lt;p&gt;Please make sure cudnn_ops_infer64_8.dll is in your library path!&amp;quot; error.&lt;/p&gt;

&lt;p&gt;i&amp;#39;ve &amp;quot;cudnn_ops_infer64_8.dll.&amp;quot;in my downloads folder.Because i tried to match perfect cuda- tensorflow for my gpu.&lt;/p&gt;

&lt;p&gt;[cmd pic shows github repo works until error][1]&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;[1]: &lt;a href=""https://i.stack.imgur.com/Gw1Yl.png""&gt;https://i.stack.imgur.com/Gw1Yl.png&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;tensorflow:2.3.0&lt;/p&gt;

&lt;p&gt;python:3.7.9&lt;/p&gt;

&lt;p&gt;CUDA:v10.1&lt;/p&gt;

&lt;p&gt;cudnn:cudnn-10.1-windows10-x64-v7.5.0.56&lt;/p&gt;

&lt;p&gt;gpu:nvidia 840m&lt;/p&gt;

&lt;p&gt;i&amp;#39;m stucked at this point.i&amp;#39;m new to ML and tensorflow and just want to try a simple project.thx^^&lt;/p&gt;

&lt;p&gt;yes i added “cudnn_ops_infer64_8.dll” in PATH as c:\downloads…\bin. Nothing changed. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kghlpb,True,,elyakubu,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kghlpb/tensorflow_could_not_load_librart_cudnn_ops/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kghlpb/tensorflow_could_not_load_librart_cudnn_ops/,22217,1608416375.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?auto=webp&amp;s=f4557b9086132155e69908824afa9d9c132d570b', 'width': 1346, 'height': 716}, 'resolutions': [{'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b27ae6e5d745208253b9a26485cd4dfa6bf2dcc', 'width': 108, 'height': 57}, {'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6811c770c05d80b2d50c7320b07c7c948d97eb20', 'width': 216, 'height': 114}, {'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7f27546039e42e5572343ef8c0007f650cb85fb', 'width': 320, 'height': 170}, {'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4b3ca0733100511fbdbff3a52dab0a02a756af5', 'width': 640, 'height': 340}, {'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ba6ee5b1f6307fbc56f023f6a25bbe5028a8d2e', 'width': 960, 'height': 510}, {'url': 'https://external-preview.redd.it/qnb-l0GGIsIPgAA37zS1-MC8qVURNxTki5PY50llxMM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=95acd279ed94d1133fb7fab98421c309dc9fd3d7', 'width': 1080, 'height': 574}], 'variants': {}, 'id': 'XwFdzyvgnFDuO3_ObHqWH8Sz0JXgNo6APSQNh1SV2wI'}], 'enabled': False}",,,,,,
357,,tensorflow,"I've been working with tensorflow 2.2 and keras 2.3 in R to train a LSTM model and it has worked very well.

I wanted to try tensorflow 2.4 since it would support cuDNN 8.x but It doesn't seem to work. After installing tf 2.4 manually \[ install\_tensorflow(version=""2.4"") \] as well as CUDA 11 and cuDNN 8.x I can't seem to fit a model. Every dll is loaded successfully but end with the error ""failed to create cublas handle: CUBLAS\_STATUS\_ALLOC\_FAILED"". After some research it seems to be a memory allocation of the GPU.

Is there any work around to this problem?",t2_15v9z0,False,,0,False,Tensorflow 2.4 not working in R (GPU): CUBLAS_STATUS_ALLOC_FAILED,[],r/tensorflow,False,6,,0,,,False,t3_kgcpn8,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1608429736.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been working with tensorflow 2.2 and keras 2.3 in R to train a LSTM model and it has worked very well.&lt;/p&gt;

&lt;p&gt;I wanted to try tensorflow 2.4 since it would support cuDNN 8.x but It doesn&amp;#39;t seem to work. After installing tf 2.4 manually [ install_tensorflow(version=&amp;quot;2.4&amp;quot;) ] as well as CUDA 11 and cuDNN 8.x I can&amp;#39;t seem to fit a model. Every dll is loaded successfully but end with the error &amp;quot;failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED&amp;quot;. After some research it seems to be a memory allocation of the GPU.&lt;/p&gt;

&lt;p&gt;Is there any work around to this problem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kgcpn8,True,,DoruSonic,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kgcpn8/tensorflow_24_not_working_in_r_gpu_cublas_status/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kgcpn8/tensorflow_24_not_working_in_r_gpu_cublas_status/,22217,1608400936.0,0,,False,,,,,,,,,
358,,tensorflow,"I came across this issue in my own projects, and found the [issue linked here](https://github.com/tensorflow/tensorflow/issues/44983) on the TensorFlow github, but I feel like it isn't getting much traction for the potential severity of the problem.

Basically there was a non-release push to TF between 1.14 and 1.15 that broke some functionality for the `tf.image.per_image_standarization` routine when used on unsigned integer inputs. The majority of information content in images ends up getting lost because of the naïve type conversions done in `per_image_standardization` after 1.14. This isn't addressed in documentation, and is pretty clearly a major change in behavior befitting a major release, but was introduced before a major release, likely pointing to an untested edge case.

I'm concerned that the issue isn't getting much traction but could potentially impact labs all over the place. The simple solution is to convert your unsigned int images to float before calling `per_image_standardization`, but that isn't obvious from any of the documentation, and used to be handled naturally by the method.

Thoughts?

**Edit:** formatting.

**Update:** it looks like a TF dev got to the issue and has committed a fix. The bug should be fixed in future releases! Two days on Reddit and we got some action from the maintainers. Cheers!",t2_129fps,False,,0,False,Possibly serious issue with tf.image.per_image_standarization,[],r/tensorflow,False,6,,0,,,False,t3_kg4bm1,False,dark,1.0,,public,10,0,{},,,False,[],,False,False,,{},Discussion,False,10,,False,self,1608579946.0,,[],{},,True,,1608396132.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I came across this issue in my own projects, and found the &lt;a href=""https://github.com/tensorflow/tensorflow/issues/44983""&gt;issue linked here&lt;/a&gt; on the TensorFlow github, but I feel like it isn&amp;#39;t getting much traction for the potential severity of the problem.&lt;/p&gt;

&lt;p&gt;Basically there was a non-release push to TF between 1.14 and 1.15 that broke some functionality for the &lt;code&gt;tf.image.per_image_standarization&lt;/code&gt; routine when used on unsigned integer inputs. The majority of information content in images ends up getting lost because of the naïve type conversions done in &lt;code&gt;per_image_standardization&lt;/code&gt; after 1.14. This isn&amp;#39;t addressed in documentation, and is pretty clearly a major change in behavior befitting a major release, but was introduced before a major release, likely pointing to an untested edge case.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m concerned that the issue isn&amp;#39;t getting much traction but could potentially impact labs all over the place. The simple solution is to convert your unsigned int images to float before calling &lt;code&gt;per_image_standardization&lt;/code&gt;, but that isn&amp;#39;t obvious from any of the documentation, and used to be handled naturally by the method.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; formatting.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; it looks like a TF dev got to the issue and has committed a fix. The bug should be fixed in future releases! Two days on Reddit and we got some action from the maintainers. Cheers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kg4bm1,True,,DrSparkle713,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/kg4bm1/possibly_serious_issue_with_tfimageper_image/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kg4bm1/possibly_serious_issue_with_tfimageper_image/,22217,1608367332.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
359,,tensorflow,,t2_1fuhylzi,False,,0,False,Kernal stops after 1 epoch - Extensive CPU usage,[],r/tensorflow,False,6,,0,,,False,t3_kgdn01,False,dark,0.66,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,default,False,,[],{},,False,,1608432413.0,text,6,,,text,self.MLQuestions,False,,,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kgdn01,True,,maifee,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kgdn01/kernal_stops_after_1_epoch_extensive_cpu_usage/,all_ads,False,/r/MLQuestions/comments/kgdm41/kernal_stops_after_1_epoch_extensive_cpu_usage/,22217,1608403613.0,0,,False,link,/r/MLQuestions/comments/kgdm41/kernal_stops_after_1_epoch_extensive_cpu_usage/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?auto=webp&amp;s=8f76f8ce32dad44f8bf8a8ba142fe4a7fbda42c5', 'width': 600, 'height': 315}, 'resolutions': [{'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=03cc218f8a085f3fb37859df0167f7764f978e05', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4da315e5d9c4e3f52f5830b369ad2e03ac87849d', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=54b11964118ead687f60725eccb8ed7da7e849d9', 'width': 320, 'height': 168}], 'variants': {}, 'id': 'y_adZ6iB7dv0TS4tO2BjBzolTFjmp1cLLv6LZDdhmgs'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'MLQuestions', 'selftext': 'Hello Kaggle, I\'m trying to participate in my first capitation here. But I\'m facing some serious problems.\n\nThe major on is - My session pauses(I guess), after 1 epoch. The cell doesn\'t execute completely but the star sign disappears.\n\nAs you can see here : [imgur](https://imgur.com/pWgCum6)\n\nDuring model fitting, I\'ve used `use_multiprocessing = False` as some suggested :\n\n    history = model.fit_generator(\n                        use_multiprocessing = False,\n                        generator = train_generator,\n                        validation_steps = valid_generator.n // valid_generator.batch_size + 1,\n                        validation_data = valid_generator,\n                        steps_per_epoch = train_generator.n // train_generator.batch_size + 1,\n                        epochs = epochs)\n\nThe model is mainly based on `VGG16`. And the data-generators are quite simple, as other projects :\n\n    image_datagen = ImageDataGenerator(\n        rescale=1./255,\n        zoom_range=0.1,\n        horizontal_flip = True,\n        vertical_flip = True,\n        validation_split = 0.2)\n    \n    train_generator = image_datagen.flow_from_directory(\n            \'../img""\',\n            target_size=(img_size, img_size),\n            batch_size=8,\n            subset=""training"",\n            class_mode=""categorical"")\n    \n    valid_generator = image_datagen.flow_from_directory(\n            \'../img""\',\n            target_size=(img_size, img_size),\n            batch_size=8,\n            subset=""validation"",\n            class_mode=""categorical"")\n\nDataset contains `21k` images.\n\nComplete [video](https://www.youtube.com/watch?v=QPy-EMAEwrg&amp;feature=youtu.be) , after reducing batch\\_size and setting it to :\n\n    batch_size = 1\n\nIs there some suggestion, to resolve this ?', 'author_fullname': 't2_1fuhylzi', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Kernal stops after 1 epoch - Extensive CPU usage', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MLQuestions', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_kgdm41', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 6, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': 1608413161.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1608432334.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MLQuestions', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello Kaggle, I&amp;#39;m trying to participate in my first capitation here. But I&amp;#39;m facing some serious problems.&lt;/p&gt;\n\n&lt;p&gt;The major on is - My session pauses(I guess), after 1 epoch. The cell doesn&amp;#39;t execute completely but the star sign disappears.&lt;/p&gt;\n\n&lt;p&gt;As you can see here : &lt;a href=""https://imgur.com/pWgCum6""&gt;imgur&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;During model fitting, I&amp;#39;ve used &lt;code&gt;use_multiprocessing = False&lt;/code&gt; as some suggested :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;history = model.fit_generator(\n                    use_multiprocessing = False,\n                    generator = train_generator,\n                    validation_steps = valid_generator.n // valid_generator.batch_size + 1,\n                    validation_data = valid_generator,\n                    steps_per_epoch = train_generator.n // train_generator.batch_size + 1,\n                    epochs = epochs)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The model is mainly based on &lt;code&gt;VGG16&lt;/code&gt;. And the data-generators are quite simple, as other projects :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;image_datagen = ImageDataGenerator(\n    rescale=1./255,\n    zoom_range=0.1,\n    horizontal_flip = True,\n    vertical_flip = True,\n    validation_split = 0.2)\n\ntrain_generator = image_datagen.flow_from_directory(\n        &amp;#39;../img&amp;quot;&amp;#39;,\n        target_size=(img_size, img_size),\n        batch_size=8,\n        subset=&amp;quot;training&amp;quot;,\n        class_mode=&amp;quot;categorical&amp;quot;)\n\nvalid_generator = image_datagen.flow_from_directory(\n        &amp;#39;../img&amp;quot;&amp;#39;,\n        target_size=(img_size, img_size),\n        batch_size=8,\n        subset=&amp;quot;validation&amp;quot;,\n        class_mode=&amp;quot;categorical&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Dataset contains &lt;code&gt;21k&lt;/code&gt; images.&lt;/p&gt;\n\n&lt;p&gt;Complete &lt;a href=""https://www.youtube.com/watch?v=QPy-EMAEwrg&amp;amp;feature=youtu.be""&gt;video&lt;/a&gt; , after reducing batch_size and setting it to :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;batch_size = 1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is there some suggestion, to resolve this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?auto=webp&amp;s=8f76f8ce32dad44f8bf8a8ba142fe4a7fbda42c5', 'width': 600, 'height': 315}, 'resolutions': [{'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=03cc218f8a085f3fb37859df0167f7764f978e05', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4da315e5d9c4e3f52f5830b369ad2e03ac87849d', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/CsjOXbjWe_dLDTIelMa3xd1x5G5sbIYb0fpESjCh8FY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=54b11964118ead687f60725eccb8ed7da7e849d9', 'width': 320, 'height': 168}], 'variants': {}, 'id': 'y_adZ6iB7dv0TS4tO2BjBzolTFjmp1cLLv6LZDdhmgs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_30rel', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'kgdm41', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'maifee', 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MLQuestions/comments/kgdm41/kernal_stops_after_1_epoch_extensive_cpu_usage/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MLQuestions/comments/kgdm41/kernal_stops_after_1_epoch_extensive_cpu_usage/', 'subreddit_subscribers': 31266, 'created_utc': 1608403534.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_kgdm41,
360,,tensorflow,I've noticed this from my own experience. I feel like I get higher precision if I split the data up into multi binary classifications. What are your experiences? Any Tips or Advice?,t2_2fosmx29,False,,0,False,Is multiclass image classification harder than binary classification for Tensorflow to solve?,[],r/tensorflow,False,6,,0,,,False,t3_kgc8wn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608428487.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve noticed this from my own experience. I feel like I get higher precision if I split the data up into multi binary classifications. What are your experiences? Any Tips or Advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kgc8wn,True,,danang1986,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kgc8wn/is_multiclass_image_classification_harder_than/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kgc8wn/is_multiclass_image_classification_harder_than/,22217,1608399687.0,0,,False,,,,,,,,,
361,,tensorflow,"I published a tutorial where I explain how to build AutoEncoders with Python and Keras. In particular, in this video you’ll learn how to build the decoder component. 

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

https://www.youtube.com/watch?v=SF1uAtU5-BU&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=5",t2_12ahau,False,,0,False,I published a step-by-step tutorial on how to build autoencoders with Python/Keras (decoder),[],r/tensorflow,False,6,,0,,,False,t3_kfjd6k,False,dark,0.89,,public,20,0,{},,,False,[],,False,False,,{},Project,False,20,,False,self,False,,[],{},,True,,1608319303.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I published a tutorial where I explain how to build AutoEncoders with Python and Keras. In particular, in this video you’ll learn how to build the decoder component. &lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=SF1uAtU5-BU&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=5""&gt;https://www.youtube.com/watch?v=SF1uAtU5-BU&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kfjd6k,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kfjd6k/i_published_a_stepbystep_tutorial_on_how_to_build/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kfjd6k/i_published_a_stepbystep_tutorial_on_how_to_build/,22217,1608290503.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/7fpZHThZ1-UZkQ1q3HOek22moXbgeDksqaiACW_SXUg.jpg?auto=webp&amp;s=476df743828dd00487596e853b3a34e8a4ec766c', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/7fpZHThZ1-UZkQ1q3HOek22moXbgeDksqaiACW_SXUg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0522b40936dd8e1e8d21bf1daf43d604ffa83187', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/7fpZHThZ1-UZkQ1q3HOek22moXbgeDksqaiACW_SXUg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4479bf2ddd2b091800558290cea3db6dee8db92', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/7fpZHThZ1-UZkQ1q3HOek22moXbgeDksqaiACW_SXUg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ff62e18ae5e407ffcf9deee886c4b6895b54d59', 'width': 320, 'height': 240}], 'variants': {}, 'id': '8EARLfEaDbTWnow01IhvMnUuF-WyL4NoOXTtGMgVEBk'}], 'enabled': False}",,,,,,
362,,tensorflow,"i've geforce 840m. it is cuda 5.0.My project has dependencies as tensorflow ,opencv ,cuda 7.5+ and cudnn 5.0+.([https://github.com/dvschultz/neural-style-tf](https://github.com/dvschultz/neural-style-tf))

i keep getting this error

""W tensorflow/stream\_executor/platform/default/dso\_loader.cc:59\] Could not load dynamic library 'cudart64\_101.dll'; dlerror: cudart64\_101.dll not found""

tensorflow doesnt see my gpu.

1-is it because i've higher cuda version than my gpu?

2-is it because my tensorflow version  2.3.1 ? 

thx.",t2_684z39m2,False,,0,False,newbie here^^ ;trying to build tensorflow to old gpu,[],r/tensorflow,False,6,,0,,,False,t3_kfuddx,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1608356647.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;i&amp;#39;ve geforce 840m. it is cuda 5.0.My project has dependencies as tensorflow ,opencv ,cuda 7.5+ and cudnn 5.0+.(&lt;a href=""https://github.com/dvschultz/neural-style-tf""&gt;https://github.com/dvschultz/neural-style-tf&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;i keep getting this error&lt;/p&gt;

&lt;p&gt;&amp;quot;W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library &amp;#39;cudart64_101.dll&amp;#39;; dlerror: cudart64_101.dll not found&amp;quot;&lt;/p&gt;

&lt;p&gt;tensorflow doesnt see my gpu.&lt;/p&gt;

&lt;p&gt;1-is it because i&amp;#39;ve higher cuda version than my gpu?&lt;/p&gt;

&lt;p&gt;2-is it because my tensorflow version  2.3.1 ? &lt;/p&gt;

&lt;p&gt;thx.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kfuddx,True,,elyakubu,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kfuddx/newbie_here_trying_to_build_tensorflow_to_old_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kfuddx/newbie_here_trying_to_build_tensorflow_to_old_gpu/,22217,1608327847.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cQ7wkmqOv8lkEhV00W9SW6p9yDyByHtO-5FAZsCeomQ.jpg?auto=webp&amp;s=9f34ea3049c9d9357019da3c713ff6ebda6edad4', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/cQ7wkmqOv8lkEhV00W9SW6p9yDyByHtO-5FAZsCeomQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c539bddd57755ad8f501fd4b7a888532dc78691a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/cQ7wkmqOv8lkEhV00W9SW6p9yDyByHtO-5FAZsCeomQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f7dc6899389a17a397579619977b1d8a08b8f204', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/cQ7wkmqOv8lkEhV00W9SW6p9yDyByHtO-5FAZsCeomQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1de7e04b69cf84bb2ba5157594376007295b3bb', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'zMa9DMz_1sS2iUyxkvcVNQ3TS5mx6kfyPm_ziTSNZYM'}], 'enabled': False}",,,,,,
363,,tensorflow,"**EDIT: A (hacky) solution has been found for now until TF releases a fix. It's on the Github link below, but essentially, [if you're on Windows, you need to change this setting.](https://user-images.githubusercontent.com/8076202/102778886-c7c5d880-43ac-11eb-87a9-35284b68883f.jpg)**

[I posted this as an issue on Github](https://github.com/tensorflow/tensorflow/issues/45716), maybe someone here will have a magic solution:

* TensorFlow version: 2.4.0-rc4 (also tried with stable 2.4.0)
* TensorFlow Git version: v2.4.0-rc3-20-g97c3fef64ba
* Python version: 3.8.5
* CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0.4
* GPU model and memory: Nvidia RTX 3090, 24GB RAM


Model training regularly freezes for large models.

Sometimes the first batch or so works, but then just a few batches later and training seems stuck in a loop. From my activity monitor, I see GPU CUDA use hovering around 100%. This goes on for minutes or more, with no more batches being trained.

I don't see an OOM error, nor does it seem like I'm hitting memory limits in activity monitor or `nvidia-smi`.

I would expect the first batch to take a bit longer, then any subsequent batches to take less than &lt;1s. Never have a random batch take minutes or stall forever.

Run through all the cells in the notebook shared below to initialize the model, then run the final cell just a few times. Eventually it will hang and never finish.

https://github.com/not-Ian/tensorflow-bug-example/blob/main/tensorflow%20error%20example.ipynb

Smaller models train quickly as expected, however I think even then they eventually stall out after training many, many batches.
I had another similar, small VAE like in my example that trained for 5k-10k batches overnight before stalling. 

Someone suggested I set a hard memory limit on the GPU like this:

    gpus = tf.config.experimental.list_physical_devices('GPU')
    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 23)])


And finally, I've tried using the hacky `ptxas.exe` file from CUDA 11.1 in my CUDA 11.0 installation. This seems to remove a warning? But still no change.

Open to any other ideas, thanks.",t2_5bv2y,False,,0,False,Model training stalls forever after just a few batches.,[],r/tensorflow,False,6,,0,,,False,t3_kftp0b,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1608568405.0,,[],{},,True,,1608354436.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;EDIT: A (hacky) solution has been found for now until TF releases a fix. It&amp;#39;s on the Github link below, but essentially, &lt;a href=""https://user-images.githubusercontent.com/8076202/102778886-c7c5d880-43ac-11eb-87a9-35284b68883f.jpg""&gt;if you&amp;#39;re on Windows, you need to change this setting.&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/tensorflow/tensorflow/issues/45716""&gt;I posted this as an issue on Github&lt;/a&gt;, maybe someone here will have a magic solution:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TensorFlow version: 2.4.0-rc4 (also tried with stable 2.4.0)&lt;/li&gt;
&lt;li&gt;TensorFlow Git version: v2.4.0-rc3-20-g97c3fef64ba&lt;/li&gt;
&lt;li&gt;Python version: 3.8.5&lt;/li&gt;
&lt;li&gt;CUDA/cuDNN version: CUDA 11.0, cuDNN 8.0.4&lt;/li&gt;
&lt;li&gt;GPU model and memory: Nvidia RTX 3090, 24GB RAM&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Model training regularly freezes for large models.&lt;/p&gt;

&lt;p&gt;Sometimes the first batch or so works, but then just a few batches later and training seems stuck in a loop. From my activity monitor, I see GPU CUDA use hovering around 100%. This goes on for minutes or more, with no more batches being trained.&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t see an OOM error, nor does it seem like I&amp;#39;m hitting memory limits in activity monitor or &lt;code&gt;nvidia-smi&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I would expect the first batch to take a bit longer, then any subsequent batches to take less than &amp;lt;1s. Never have a random batch take minutes or stall forever.&lt;/p&gt;

&lt;p&gt;Run through all the cells in the notebook shared below to initialize the model, then run the final cell just a few times. Eventually it will hang and never finish.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/not-Ian/tensorflow-bug-example/blob/main/tensorflow%20error%20example.ipynb""&gt;https://github.com/not-Ian/tensorflow-bug-example/blob/main/tensorflow%20error%20example.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Smaller models train quickly as expected, however I think even then they eventually stall out after training many, many batches.
I had another similar, small VAE like in my example that trained for 5k-10k batches overnight before stalling. &lt;/p&gt;

&lt;p&gt;Someone suggested I set a hard memory limit on the GPU like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gpus = tf.config.experimental.list_physical_devices(&amp;#39;GPU&amp;#39;)
tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 23)])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And finally, I&amp;#39;ve tried using the hacky &lt;code&gt;ptxas.exe&lt;/code&gt; file from CUDA 11.1 in my CUDA 11.0 installation. This seems to remove a warning? But still no change.&lt;/p&gt;

&lt;p&gt;Open to any other ideas, thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kftp0b,True,,Deinos_Mousike,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kftp0b/model_training_stalls_forever_after_just_a_few/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kftp0b/model_training_stalls_forever_after_just_a_few/,22217,1608325636.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Q7JS8zkMh6eXuoUHr-kq5P9n5SDryCZ1qSbsFCylPcc.jpg?auto=webp&amp;s=1daf01e20e25c1e8578cb87bcdb56de10d2c856f', 'width': 376, 'height': 218}, 'resolutions': [{'url': 'https://external-preview.redd.it/Q7JS8zkMh6eXuoUHr-kq5P9n5SDryCZ1qSbsFCylPcc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ba05b493b572ec8f176b5feffbe42016a15577b', 'width': 108, 'height': 62}, {'url': 'https://external-preview.redd.it/Q7JS8zkMh6eXuoUHr-kq5P9n5SDryCZ1qSbsFCylPcc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03e9e57b2b2393e6d654097665dca6cfb12cf0c9', 'width': 216, 'height': 125}, {'url': 'https://external-preview.redd.it/Q7JS8zkMh6eXuoUHr-kq5P9n5SDryCZ1qSbsFCylPcc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9fc8411b57b0e14732229cafc0a85a8fa2d876c0', 'width': 320, 'height': 185}], 'variants': {}, 'id': 'HaZrikGnglVtIyLUuHZ2sRSECtIXIYfA0hGqsV925lE'}], 'enabled': False}",,,,,,
364,,tensorflow,"I am trying to create a Conv-6 CNN for classification using CIFAR-10 dataset. This CNN uses 3 blocks, where each block has 2 conv layers followed by a max pooling layer. This is flattened and passed to two dense layers before being passed to the output layer.

&amp;#x200B;

The code I have is:

    # input image dimensions
    img_rows, img_cols = 32, 32
    
    # Load CIFAR-10 dataset-
    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()
    
    
    if tf.keras.backend.image_data_format() == 'channels_first':
        X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)
        X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)
        input_shape = (3, img_rows, img_cols)
    else:
        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)
        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)
        input_shape = (img_rows, img_cols, 3)
    
    print(""\n'input_shape' which will be used = {0}\n"".format(input_shape))
    # 'input_shape' which will be used = (32, 32, 3)
    
    
    # Convert datasets to floating point types-
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    
    # Normalize the training and testing datasets-
    X_train /= 255.0
    X_test /= 255.0
    
    # Convert class vectors/target to binary class matrices or one-hot encoded values-
    y_train = tf.keras.utils.to_categorical(y_train, num_classes)
    y_test = tf.keras.utils.to_categorical(y_test, num_classes)
    
    print(""\nDimensions of training and testing sets are:"")
    print(""X_train.shape = {0}, y_train.shape = {1}"".format(X_train.shape, y_train.shape))
    print(""X_test.shape = {0}, y_test.shape = {1}"".format(X_test.shape, y_test.shape))
    # Dimensions of training and testing sets are:
    # X_train.shape = (50000, 32, 32, 3), y_train.shape = (50000, 10)
    # X_test.shape = (10000, 32, 32, 3), y_test.shape = (10000, 10)
    
    class Conv6(Model):
        def __init__(self, **kwargs):
            super(Conv6, self).__init__(**kwargs)
            self.conv1 = Conv2D(
                filters = 64, kernel_size = (3, 3),
                activation = 'relu', kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = 'same'
                )
            self.conv2 = Conv2D(
                filters = 64, kernel_size = (3, 3),
                activation = 'relu', kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = 'same'
                )
            self.pool1 = MaxPooling2D(
                pool_size = (2, 2),
                strides = (2, 2)
                )
            self.conv3 = Conv2D(
                filters = 128, kernel_size = (3, 3),
                activation = 'relu', kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = 'same'
                )
            self.conv4 = Conv2D(
                filters = 128, kernel_size = (3, 3),
                activation = 'relu', kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = 'same'
                )
            self.pool2 = MaxPooling2D(
                pool_size = (2, 2),
                strides = (2, 2)
                )
            self.conv5 = Conv2D(
                filters = 256, kernel_size = (3, 3),
                activation = 'relu', kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = 'same'
                )
            self.conv6 = Conv2D(
                filters = 256, kernel_size = (3, 3),
                activation = 'relu', kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = 'same'
                )
            self.flatten = Flatten()
            self.dense1 = Dense(
                units = 256, activation = 'relu',
                kernel_initializer = tf.initializers.GlorotNormal()
                )
            self.dense2 = Dense(
                units = 256, activation = 'relu',
                kernel_initializer = tf.initializers.GlorotNormal()
                )
            self.op = Dense(
                units = num_classes, activation = 'softmax'
                )
        
        def call(self, inputs):
            x = self.conv1(inputs)
            x = self.conv2(x)
            x = self.pool1(inputs)
            x = self.conv3(x)
            x = self.conv4(x)
            x = self.pool2(x)
            x = self.conv5(x)
            x = self.conv6(x)
            x = self.flatten(x)
            x = self.dense1(x)
            x = self.dense2(x)
            return self.op(x)
    
    
    # Initialize a Conv-6 CNN model-
    model = Conv6()
    
    # Compile defined model-
    model.compile(
        loss=tf.keras.losses.categorical_crossentropy,
        # optimizer='adam',
        optimizer=tf.keras.optimizers.Adam(lr = 0.0003),
        metrics=['accuracy']
        )
    
    
    # Define early stopping callback-
    early_stopping_callback = tf.keras.callbacks.EarlyStopping(
            monitor = 'val_loss', min_delta = 0.001,
            patience = 3)
    
    # Train defined and compiled model-
    history = model.fit(
        x = X_train, y = y_train,
        batch_size = batch_size, shuffle = True,
        epochs = num_epochs,
        callbacks = [early_stopping_callback],
        validation_data = (X_test, y_test)
        )

&amp;#x200B;

On calling ""[model.fit](https://model.fit)()"", it gives me the following warnings:

WARNING:tensorflow:Gradients do not exist for variables

&gt;\['conv6/conv2d/kernel:0', 'conv6/conv2d/bias:0', 'conv6/conv2d\_1/kernel:0', 'conv6/conv2d\_1/bias:0'\] when minimizing the loss. WARNING:tensorflow:Gradients do not exist for variables \['conv6/conv2d/kernel:0', 'conv6/conv2d/bias:0', 'conv6/conv2d\_1/kernel:0', 'conv6/conv2d\_1/bias:0'\] when minimizing the loss. 

&amp;#x200B;

In spite of the warnings, the defined CNN model reaches a validation accuracy of about 72% in 9 epochs.

Why am I getting these warnings?

Thanks!",t2_2mmql89p,False,,0,False,WARNING:tensorflow:Gradients do not exist for variables - Conv-6 CNN for CIFAR-10,[],r/tensorflow,False,6,,0,,,False,t3_kfpvaw,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608342471.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to create a Conv-6 CNN for classification using CIFAR-10 dataset. This CNN uses 3 blocks, where each block has 2 conv layers followed by a max pooling layer. This is flattened and passed to two dense layers before being passed to the output layer.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The code I have is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# input image dimensions
img_rows, img_cols = 32, 32

# Load CIFAR-10 dataset-
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()


if tf.keras.backend.image_data_format() == &amp;#39;channels_first&amp;#39;:
    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)
    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)
    input_shape = (3, img_rows, img_cols)
else:
    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)
    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)
    input_shape = (img_rows, img_cols, 3)

print(&amp;quot;\n&amp;#39;input_shape&amp;#39; which will be used = {0}\n&amp;quot;.format(input_shape))
# &amp;#39;input_shape&amp;#39; which will be used = (32, 32, 3)


# Convert datasets to floating point types-
X_train = X_train.astype(&amp;#39;float32&amp;#39;)
X_test = X_test.astype(&amp;#39;float32&amp;#39;)

# Normalize the training and testing datasets-
X_train /= 255.0
X_test /= 255.0

# Convert class vectors/target to binary class matrices or one-hot encoded values-
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

print(&amp;quot;\nDimensions of training and testing sets are:&amp;quot;)
print(&amp;quot;X_train.shape = {0}, y_train.shape = {1}&amp;quot;.format(X_train.shape, y_train.shape))
print(&amp;quot;X_test.shape = {0}, y_test.shape = {1}&amp;quot;.format(X_test.shape, y_test.shape))
# Dimensions of training and testing sets are:
# X_train.shape = (50000, 32, 32, 3), y_train.shape = (50000, 10)
# X_test.shape = (10000, 32, 32, 3), y_test.shape = (10000, 10)

class Conv6(Model):
    def __init__(self, **kwargs):
        super(Conv6, self).__init__(**kwargs)
        self.conv1 = Conv2D(
            filters = 64, kernel_size = (3, 3),
            activation = &amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
            strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        self.conv2 = Conv2D(
            filters = 64, kernel_size = (3, 3),
            activation = &amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
            strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        self.pool1 = MaxPooling2D(
            pool_size = (2, 2),
            strides = (2, 2)
            )
        self.conv3 = Conv2D(
            filters = 128, kernel_size = (3, 3),
            activation = &amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
            strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        self.conv4 = Conv2D(
            filters = 128, kernel_size = (3, 3),
            activation = &amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
            strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        self.pool2 = MaxPooling2D(
            pool_size = (2, 2),
            strides = (2, 2)
            )
        self.conv5 = Conv2D(
            filters = 256, kernel_size = (3, 3),
            activation = &amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
            strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        self.conv6 = Conv2D(
            filters = 256, kernel_size = (3, 3),
            activation = &amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
            strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        self.flatten = Flatten()
        self.dense1 = Dense(
            units = 256, activation = &amp;#39;relu&amp;#39;,
            kernel_initializer = tf.initializers.GlorotNormal()
            )
        self.dense2 = Dense(
            units = 256, activation = &amp;#39;relu&amp;#39;,
            kernel_initializer = tf.initializers.GlorotNormal()
            )
        self.op = Dense(
            units = num_classes, activation = &amp;#39;softmax&amp;#39;
            )

    def call(self, inputs):
        x = self.conv1(inputs)
        x = self.conv2(x)
        x = self.pool1(inputs)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.pool2(x)
        x = self.conv5(x)
        x = self.conv6(x)
        x = self.flatten(x)
        x = self.dense1(x)
        x = self.dense2(x)
        return self.op(x)


# Initialize a Conv-6 CNN model-
model = Conv6()

# Compile defined model-
model.compile(
    loss=tf.keras.losses.categorical_crossentropy,
    # optimizer=&amp;#39;adam&amp;#39;,
    optimizer=tf.keras.optimizers.Adam(lr = 0.0003),
    metrics=[&amp;#39;accuracy&amp;#39;]
    )


# Define early stopping callback-
early_stopping_callback = tf.keras.callbacks.EarlyStopping(
        monitor = &amp;#39;val_loss&amp;#39;, min_delta = 0.001,
        patience = 3)

# Train defined and compiled model-
history = model.fit(
    x = X_train, y = y_train,
    batch_size = batch_size, shuffle = True,
    epochs = num_epochs,
    callbacks = [early_stopping_callback],
    validation_data = (X_test, y_test)
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;On calling &amp;quot;&lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;()&amp;quot;, it gives me the following warnings:&lt;/p&gt;

&lt;p&gt;WARNING:tensorflow:Gradients do not exist for variables&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&amp;#39;conv6/conv2d/kernel:0&amp;#39;, &amp;#39;conv6/conv2d/bias:0&amp;#39;, &amp;#39;conv6/conv2d_1/kernel:0&amp;#39;, &amp;#39;conv6/conv2d_1/bias:0&amp;#39;] when minimizing the loss. WARNING:tensorflow:Gradients do not exist for variables [&amp;#39;conv6/conv2d/kernel:0&amp;#39;, &amp;#39;conv6/conv2d/bias:0&amp;#39;, &amp;#39;conv6/conv2d_1/kernel:0&amp;#39;, &amp;#39;conv6/conv2d_1/bias:0&amp;#39;] when minimizing the loss. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;In spite of the warnings, the defined CNN model reaches a validation accuracy of about 72% in 9 epochs.&lt;/p&gt;

&lt;p&gt;Why am I getting these warnings?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kfpvaw,True,,grid_world,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kfpvaw/warningtensorflowgradients_do_not_exist_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kfpvaw/warningtensorflowgradients_do_not_exist_for/,22217,1608313671.0,0,,False,,,,,,,,,
365,,tensorflow,"Hey guys!

I’m very new to ML, and I’m working a college project to detect allow entry to places with automatic doors (I.E. supermarkets, hospitals) only if the person is wearing a mask using a Raspberry Pi 4. I was able to train a model based on a pre-trained MobileNetV2 with TensorFlow 1.13.1, but the code is mostly written on the tensorflow/models GitHub repo &amp; it’s a very ugly and un-intuitive code to rewrite by myself &amp; it is based off another pre-trained model - all of which are things I’m trying to avoid.

I started to learn how to do something similar with TensorFlow 2 and Keras. I’ve watched the I/O 2019 ML Zero to Hero &amp; the 4 part mini-series to try and get the basic idea of convolutional networks and machine learning in general; However, I can’t find a single example of using Keras for creating a convolutional network for object detection with multi-class classification in a single model - I DID find a version where the code used a model to predict bounding boxes for faces first, extract them, and use image classification on it similar to the Rock/Paper/Scissors model in ML Zero To Hero - but that’s kind of a compromise instead of using a single model that detects masks directly, and can also slow things down considering it will be running on a Raspberry Pi, that also does some more calculations based on the results of the model (temperature check, and audio instructions to the person requesting access if they are wearing the mask incorrectly).

Here’s my current implementation (dataset is available with tfrecord, xml, and csv annotations):

[Google Colab Notebook](https://github.com/lgariv/mask-dataset/blob/main/Untitled2.ipynb)

It currently relies on the MobileNetV2 model, and for some reason While training the loss and accuracy are staying relatively the same - they’re not improving over time as they should. If there is a better way or a more efficient way of implementing what I have been trying to do, I’d be happy to learn about it.



To summarize,
What I need help with (in relation to the notebook linked above):

• Need to figure out if the way I implemented it is the ideal / code efficient way to do such task (probably not?)

• re-implement it as a completely custom network (as in the ML Zero to Hero, but object detection instead of image classification), without relying on MobileNetV2 or any other pre-trained model.

• Figure out why the model does not improve it’s accuracy when training.",t2_sv8epzg,False,,0,False,Keras Custom Multi-Class Object Detection CNN with Custom Dataset,[],r/tensorflow,False,6,,0,,,False,t3_kfj2xk,False,dark,1.0,,public,3,1,{},,,False,[],,False,False,,{},Question,False,3,,True,self,False,,[],{},,True,,1608317894.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys!&lt;/p&gt;

&lt;p&gt;I’m very new to ML, and I’m working a college project to detect allow entry to places with automatic doors (I.E. supermarkets, hospitals) only if the person is wearing a mask using a Raspberry Pi 4. I was able to train a model based on a pre-trained MobileNetV2 with TensorFlow 1.13.1, but the code is mostly written on the tensorflow/models GitHub repo &amp;amp; it’s a very ugly and un-intuitive code to rewrite by myself &amp;amp; it is based off another pre-trained model - all of which are things I’m trying to avoid.&lt;/p&gt;

&lt;p&gt;I started to learn how to do something similar with TensorFlow 2 and Keras. I’ve watched the I/O 2019 ML Zero to Hero &amp;amp; the 4 part mini-series to try and get the basic idea of convolutional networks and machine learning in general; However, I can’t find a single example of using Keras for creating a convolutional network for object detection with multi-class classification in a single model - I DID find a version where the code used a model to predict bounding boxes for faces first, extract them, and use image classification on it similar to the Rock/Paper/Scissors model in ML Zero To Hero - but that’s kind of a compromise instead of using a single model that detects masks directly, and can also slow things down considering it will be running on a Raspberry Pi, that also does some more calculations based on the results of the model (temperature check, and audio instructions to the person requesting access if they are wearing the mask incorrectly).&lt;/p&gt;

&lt;p&gt;Here’s my current implementation (dataset is available with tfrecord, xml, and csv annotations):&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/lgariv/mask-dataset/blob/main/Untitled2.ipynb""&gt;Google Colab Notebook&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It currently relies on the MobileNetV2 model, and for some reason While training the loss and accuracy are staying relatively the same - they’re not improving over time as they should. If there is a better way or a more efficient way of implementing what I have been trying to do, I’d be happy to learn about it.&lt;/p&gt;

&lt;p&gt;To summarize,
What I need help with (in relation to the notebook linked above):&lt;/p&gt;

&lt;p&gt;• Need to figure out if the way I implemented it is the ideal / code efficient way to do such task (probably not?)&lt;/p&gt;

&lt;p&gt;• re-implement it as a completely custom network (as in the ML Zero to Hero, but object detection instead of image classification), without relying on MobileNetV2 or any other pre-trained model.&lt;/p&gt;

&lt;p&gt;• Figure out why the model does not improve it’s accuracy when training.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}]",[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kfj2xk,True,,LGariv,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kfj2xk/keras_custom_multiclass_object_detection_cnn_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kfj2xk/keras_custom_multiclass_object_detection_cnn_with/,22217,1608289094.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/3WhWl-ppPh-CWiddzfESJCK9gZ8b3KdSxbvEDFGn8A8.jpg?auto=webp&amp;s=e3fdd5cd59bd1887b1262d44f2546ac9f7f73370', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/3WhWl-ppPh-CWiddzfESJCK9gZ8b3KdSxbvEDFGn8A8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f5987c673c05af2a2a6ca1fd1eeb53239ca2679', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/3WhWl-ppPh-CWiddzfESJCK9gZ8b3KdSxbvEDFGn8A8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa9ef2a05ce0cfe965d114b0ad77b58924efa192', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/3WhWl-ppPh-CWiddzfESJCK9gZ8b3KdSxbvEDFGn8A8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ad335002cf1fc4df2acf04658fea3b99118fe3d', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'UgYp3Nyv3oQ9ZFJGtqP2AxalACDMKAQUpIPMf8ghPlI'}], 'enabled': False}",,,,,,
366,,tensorflow,"Hi,    

I am using TF 1.15 and have a GTX 770 4GB. I recently came across mixed precision training and was wondering if Kepler GPUs are supported. I understand that newer NVIDIA architectures have specialised cores for accelerating FP16 ops but I am mainly interested in fitting larger networks with my card (and get faster training speeds through larger batches).   
In this guide: https://github.com/tensorflow/docs/blob/98ab6704b16b4293662d12157df10e3596db181e/site/en/guide/mixed_precision.ipynb in the Supported hardware section it is written: **Older GPUs offer no math performance benefit for using mixed precision, however memory and bandwidth savings can enable some speedups.**.   
Thanks!",t2_r0ub0,False,,0,False,Mixed Precision Training for Kepler GPUs,[],r/tensorflow,False,6,,0,,,False,t3_kfizow,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1608317430.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,    &lt;/p&gt;

&lt;p&gt;I am using TF 1.15 and have a GTX 770 4GB. I recently came across mixed precision training and was wondering if Kepler GPUs are supported. I understand that newer NVIDIA architectures have specialised cores for accelerating FP16 ops but I am mainly interested in fitting larger networks with my card (and get faster training speeds through larger batches).&lt;br/&gt;
In this guide: &lt;a href=""https://github.com/tensorflow/docs/blob/98ab6704b16b4293662d12157df10e3596db181e/site/en/guide/mixed_precision.ipynb""&gt;https://github.com/tensorflow/docs/blob/98ab6704b16b4293662d12157df10e3596db181e/site/en/guide/mixed_precision.ipynb&lt;/a&gt; in the Supported hardware section it is written: &lt;strong&gt;Older GPUs offer no math performance benefit for using mixed precision, however memory and bandwidth savings can enable some speedups.&lt;/strong&gt;.&lt;br/&gt;
Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kfizow,True,,th3owner,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kfizow/mixed_precision_training_for_kepler_gpus/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kfizow/mixed_precision_training_for_kepler_gpus/,22217,1608288630.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
367,,tensorflow,"I've run image classifications with 2,000-3,000 images with success in the past, but I'm attempting a 20,000 image set classification run this time around &amp; it's going super slow. So is it worth my time? Are more images always better?",t2_2fosmx29,False,,0,False,Are More Pictures Always better for image classification?,[],r/tensorflow,False,6,,0,,,False,t3_kflena,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608328067.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve run image classifications with 2,000-3,000 images with success in the past, but I&amp;#39;m attempting a 20,000 image set classification run this time around &amp;amp; it&amp;#39;s going super slow. So is it worth my time? Are more images always better?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kflena,True,,danang1986,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/kflena/are_more_pictures_always_better_for_image/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kflena/are_more_pictures_always_better_for_image/,22217,1608299267.0,0,,False,,,,,,,,,
368,,tensorflow,"So I have a huge dataset that devours my 32GB memory and then crashes every time before I can even begin training. Is it possible to break the dataset into chunks and train my model that way?

I'm fairly new to tensorflow so I'm not sure how to go about it. Can anyone help?

Thank you.

EDIT: the data is time series data (from a csv) that I'm loading into a pandas dataframe. From there, the data is being broken up into samples with a 10 step window. I have about 90M samples with the shape (90M, 10, 1) that should then be fed into the LSTM. The problem is that the samples crash the RAM and I have to start all over again each time.",t2_l4lbl,False,,0,False,How can I train a model on a HUGE dataset?,[],r/tensorflow,False,6,,0,,,False,t3_kex0lc,False,dark,0.88,,public,12,0,{},,,False,[],,False,False,,{},Question,False,12,,False,self,1608217607.0,,[],{},,True,,1608238840.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have a huge dataset that devours my 32GB memory and then crashes every time before I can even begin training. Is it possible to break the dataset into chunks and train my model that way?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m fairly new to tensorflow so I&amp;#39;m not sure how to go about it. Can anyone help?&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;

&lt;p&gt;EDIT: the data is time series data (from a csv) that I&amp;#39;m loading into a pandas dataframe. From there, the data is being broken up into samples with a 10 step window. I have about 90M samples with the shape (90M, 10, 1) that should then be fed into the LSTM. The problem is that the samples crash the RAM and I have to start all over again each time.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kex0lc,True,,dsm88,,21,True,all_ads,False,[],False,,/r/tensorflow/comments/kex0lc/how_can_i_train_a_model_on_a_huge_dataset/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kex0lc/how_can_i_train_a_model_on_a_huge_dataset/,22217,1608210040.0,0,,False,,,,,,,,,
369,,tensorflow,I am looking at ways to create a custom TF distribution layer to help represent the Tweedie Distribution given a p variance power. The issue that I am running into is with the Poisson - Gamma Distribution. Looking to see if any other TFP / TFD users have implemented a similar structure in a sequential model to asses modeling on insurance claim data.,t2_j4xt8,False,,0,False,Tensorflow Distribution for Tweedie / Poisson-Gamma compound,[],r/tensorflow,False,6,,0,,,False,t3_kes76r,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1608215804.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking at ways to create a custom TF distribution layer to help represent the Tweedie Distribution given a p variance power. The issue that I am running into is with the Poisson - Gamma Distribution. Looking to see if any other TFP / TFD users have implemented a similar structure in a sequential model to asses modeling on insurance claim data.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kes76r,True,,japeru01,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kes76r/tensorflow_distribution_for_tweedie_poissongamma/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kes76r/tensorflow_distribution_for_tweedie_poissongamma/,22217,1608187004.0,0,,False,,,,,,,,,
370,,tensorflow,,t2_2x2mcjpc,False,,0,False,Kubeflow: Cloud Native ML Toolbox,[],r/tensorflow,False,6,,0,105.0,,False,t3_keu5d0,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/I5ugMNd9m_0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Kubeflow: Cloud Native ML Toolbox', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/I5ugMNd9m_0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Soulman Iqbal', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/I5ugMNd9m_0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC0r3ULfK1be12VjzO27FMNA'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/I5ugMNd9m_0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/keu5d0', 'height': 200}",,False,1,,False,https://b.thumbs.redditmedia.com/p1kFx9Gz-RTkHRuXxREPY9qXj61XmX40KQSfF7Xxhpc.jpg,False,,[],{},,False,,1608225283.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,keu5d0,True,,SoulmanIqbal,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/keu5d0/kubeflow_cloud_native_ml_toolbox/,all_ads,False,https://youtu.be/I5ugMNd9m_0,22217,1608196483.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Kubeflow: Cloud Native ML Toolbox', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/I5ugMNd9m_0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Soulman Iqbal', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/I5ugMNd9m_0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC0r3ULfK1be12VjzO27FMNA'}}",False,rich:video,https://youtu.be/I5ugMNd9m_0,"{'images': [{'source': {'url': 'https://external-preview.redd.it/EJ65wMJ4zOMTBlMXH9weevFq-okud5hpos4TWvqxNUI.jpg?auto=webp&amp;s=1b55ad11d80db65991b6460621abd464c802af9f', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/EJ65wMJ4zOMTBlMXH9weevFq-okud5hpos4TWvqxNUI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9fec5bc9e0b03d7875a6c88d10d3ad0111e1447', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/EJ65wMJ4zOMTBlMXH9weevFq-okud5hpos4TWvqxNUI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2906ddefd9e05116fb42fd7adfff2f6c721cf19d', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/EJ65wMJ4zOMTBlMXH9weevFq-okud5hpos4TWvqxNUI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d7d32bfa967e9132e452abef24ba11139439adb', 'width': 320, 'height': 240}], 'variants': {}, 'id': '3oclmH2rlQKAlCZIt1bP6-3jzlzsLJXRB6K0GbYu5xY'}], 'enabled': False}",,,,,,
371,,tensorflow,"I have trained a model which outputs multiple images (say 2) at a time, and takes in multiple inputs (say 5) to do so. However my loss (MSE) is supposed to apply to only 2 pairs made of 2 of the input and output. Meaning I define my model as:

    themodel = Model( [ip1,ip2,ip3,ip4,ip5], [op1,op2] )
    themodel.compile( optimizer='Adam', loss=['mse','mse'] )

My model seems to train correctly, I just couldn't find confirmation in the docs [(compile method)](https://keras.io/api/models/model_training_apis/#compile-method) of how Tf takes care of which tensors to apply the loss to. My assumption is that it applies the first loss to the first ip-op pair, and so on till output tensors are available and nothing is applied to remaining input tensors. Is this what is happening?  Also another silly question, does this mean for multiple output models, loss has to be defined for all the outputs, and is not related to the number of inputs?",t2_2yzg0lbs,False,,0,False,Defining loss when number of inputs is greater than number of outputs,[],r/tensorflow,False,6,,0,,,False,t3_kesulq,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1608218792.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have trained a model which outputs multiple images (say 2) at a time, and takes in multiple inputs (say 5) to do so. However my loss (MSE) is supposed to apply to only 2 pairs made of 2 of the input and output. Meaning I define my model as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;themodel = Model( [ip1,ip2,ip3,ip4,ip5], [op1,op2] )
themodel.compile( optimizer=&amp;#39;Adam&amp;#39;, loss=[&amp;#39;mse&amp;#39;,&amp;#39;mse&amp;#39;] )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My model seems to train correctly, I just couldn&amp;#39;t find confirmation in the docs &lt;a href=""https://keras.io/api/models/model_training_apis/#compile-method""&gt;(compile method)&lt;/a&gt; of how Tf takes care of which tensors to apply the loss to. My assumption is that it applies the first loss to the first ip-op pair, and so on till output tensors are available and nothing is applied to remaining input tensors. Is this what is happening?  Also another silly question, does this mean for multiple output models, loss has to be defined for all the outputs, and is not related to the number of inputs?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kesulq,True,,juggy94,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kesulq/defining_loss_when_number_of_inputs_is_greater/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kesulq/defining_loss_when_number_of_inputs_is_greater/,22217,1608189992.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&amp;s=0c3f0b8af92c3a962f569a389e9673597e12f8ec', 'width': 774, 'height': 269}, 'resolutions': [{'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9985b1dc92701ea8c38c4bb72a28d50198fb54ab', 'width': 108, 'height': 37}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a7452ccf0826692f35ac78457de9275d52f5935', 'width': 216, 'height': 75}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ae2ffe955b207d1da9c058b01c62aff9e80110d7', 'width': 320, 'height': 111}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff31c7e26d2e15f6faa6e4bedc2a41dfe0eab9ab', 'width': 640, 'height': 222}], 'variants': {}, 'id': 'qsh7aKFxRPo6CaMu10A7nekvx_ez8hkySyb6h9YVvHI'}], 'enabled': False}",,,,,,
372,,tensorflow,,t2_44mbtmjy,False,,0,False,Paid ML gigs: Get compensated while further sharpening your skills on your own schedule.,[],r/tensorflow,False,6,,0,,,False,t3_kenjvv,False,dark,0.43,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,default,False,,[],{},,False,,1608198823.0,text,6,,,text,self.LatestInML,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kenjvv,True,,MLtinkerer,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kenjvv/paid_ml_gigs_get_compensated_while_further/,all_ads,False,/r/LatestInML/comments/kelv2u/paid_ml_gigs_get_compensated_while_further/,22217,1608170023.0,0,,False,link,/r/LatestInML/comments/kelv2u/paid_ml_gigs_get_compensated_while_further/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?auto=webp&amp;s=32672f4715d15292ce08ccff17f800fb7d1b3d79', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8796a67b9cfabe02b628971a0adf9da5e36d0005', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bce8aa4865efc4f013dc4dd410bc278cd406f330', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1167efd7e761c44fcb6c62915c047d3b4e09281', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f9d344ffeb2a258b78f23d5fd767e3fb6ed7a8b0', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b095516fad657b7cd2d5fc08b5b5d83b934ca8b7', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=043b04800775539618a7accc5373bdd9b38a2559', 'width': 1080, 'height': 567}], 'variants': {}, 'id': '-p_-e3JNb56wltrg0ZmyHZgAxcR8TN6LJ9nas3Ulox0'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""Sharing this here as it may be of interest to many of us:\n\n\\&gt; If you have any technical skills in machine learning, computer vision, data science, natural language processing, deep learning, etc. and are interested in paid (remote) mini-projects and gigs on the side,\n\nthen this is a good opportunity to get compensated while further sharpening your skills on your own schedule.\n\nIMHO also useful if you're a grad student, have student loans, or just want to build up your portfolio.\n\nIf you're interested, please opt in here: [https://docs.google.com/forms/d/e/1FAIpQLScK-yztp2B70GkmvUmRDIeOkUxkutRlhzsGCDRhJksgWky4mg/viewform](https://docs.google.com/forms/d/e/1FAIpQLScK-yztp2B70GkmvUmRDIeOkUxkutRlhzsGCDRhJksgWky4mg/viewform)\n\nFeel free to email [gr2511@columbia.edu](mailto:gr2511@columbia.edu) for any questions."", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Paid ML gigs: Get compensated while further sharpening your skills on your own schedule.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_kelv2u', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 7, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1608193325.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sharing this here as it may be of interest to many of us:&lt;/p&gt;\n\n&lt;p&gt;&amp;gt; If you have any technical skills in machine learning, computer vision, data science, natural language processing, deep learning, etc. and are interested in paid (remote) mini-projects and gigs on the side,&lt;/p&gt;\n\n&lt;p&gt;then this is a good opportunity to get compensated while further sharpening your skills on your own schedule.&lt;/p&gt;\n\n&lt;p&gt;IMHO also useful if you&amp;#39;re a grad student, have student loans, or just want to build up your portfolio.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, please opt in here: &lt;a href=""https://docs.google.com/forms/d/e/1FAIpQLScK-yztp2B70GkmvUmRDIeOkUxkutRlhzsGCDRhJksgWky4mg/viewform""&gt;https://docs.google.com/forms/d/e/1FAIpQLScK-yztp2B70GkmvUmRDIeOkUxkutRlhzsGCDRhJksgWky4mg/viewform&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feel free to email [&lt;a href=""mailto:gr2511@columbia.edu""&gt;gr2511@columbia.edu&lt;/a&gt;](mailto:&lt;a href=""mailto:gr2511@columbia.edu""&gt;gr2511@columbia.edu&lt;/a&gt;) for any questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?auto=webp&amp;s=32672f4715d15292ce08ccff17f800fb7d1b3d79', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8796a67b9cfabe02b628971a0adf9da5e36d0005', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bce8aa4865efc4f013dc4dd410bc278cd406f330', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1167efd7e761c44fcb6c62915c047d3b4e09281', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f9d344ffeb2a258b78f23d5fd767e3fb6ed7a8b0', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b095516fad657b7cd2d5fc08b5b5d83b934ca8b7', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/S9crEQYpwA6ekxqYobdJTHS6jzTRVu1a7_Ndizlxh3k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=043b04800775539618a7accc5373bdd9b38a2559', 'width': 1080, 'height': 567}], 'variants': {}, 'id': '-p_-e3JNb56wltrg0ZmyHZgAxcR8TN6LJ9nas3Ulox0'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'kelv2u', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/kelv2u/paid_ml_gigs_get_compensated_while_further/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/kelv2u/paid_ml_gigs_get_compensated_while_further/', 'subreddit_subscribers': 6676, 'created_utc': 1608164525.0, 'num_crossposts': 13, 'media': None, 'is_video': False}]",t3_kelv2u,
373,,tensorflow,"I'm having trouble with using tensorflow with gpu. On device list there is only my CPU. Any help how to fix that? Couldn't find any soulsion so far that would fix this... I have Cuda Toolikit, cuDNN installed

Edit: Solved. Downgraded Cuda Toolkit from 11.2 to 11.0.",t2_ijsff,False,,0,False,My 1070 GeForce GPU is not detected by tensofrlow,[],r/tensorflow,False,6,,0,,,False,t3_ke9x0k,False,dark,0.91,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,1608130888.0,,[],{},,True,,1608156835.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m having trouble with using tensorflow with gpu. On device list there is only my CPU. Any help how to fix that? Couldn&amp;#39;t find any soulsion so far that would fix this... I have Cuda Toolikit, cuDNN installed&lt;/p&gt;

&lt;p&gt;Edit: Solved. Downgraded Cuda Toolkit from 11.2 to 11.0.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ke9x0k,True,,SpookyApple,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/ke9x0k/my_1070_geforce_gpu_is_not_detected_by_tensofrlow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ke9x0k/my_1070_geforce_gpu_is_not_detected_by_tensofrlow/,22217,1608128035.0,0,,False,,,,,,,,,
374,,tensorflow,"Hi All.

I am using Keras and Tensorflow 2.0. I have code that tries to set the number of inter and intra op threads. I have added the session stuff for compatability, but it still won't work right.

&amp;#x200B;

from keras import backend as K

....

....

import tensorflow as tf

&amp;#x200B;

session\_conf = tf.compat.v1.ConfigProto(inter\_op\_parallelism\_threads=int(os.environ\['NUM\_INTER\_THREADS'\]),

intra\_op\_parallelism\_threads=int(os.environ\['NUM\_INTRA\_THREADS'\]))

sess = tf.compat.v1.Session(graph=tf.compat.v1.get\_default\_graph(), config=session\_conf)

K.set\_session(sess)

&amp;#x200B;

&amp;#x200B;

Then it blows up with:

RuntimeError: \`set\_session\` is not available when using TensorFlow 2.0.

Any advice?",t2_6i9r4mfp,False,,0,False,`set_session` is not available when using TensorFlow 2.0.,[],r/tensorflow,False,6,,0,,,False,t3_kehd9g,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1608151227.0,,[],{},,True,,1608179792.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All.&lt;/p&gt;

&lt;p&gt;I am using Keras and Tensorflow 2.0. I have code that tries to set the number of inter and intra op threads. I have added the session stuff for compatability, but it still won&amp;#39;t work right.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;from keras import backend as K&lt;/p&gt;

&lt;p&gt;....&lt;/p&gt;

&lt;p&gt;....&lt;/p&gt;

&lt;p&gt;import tensorflow as tf&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;session_conf = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=int(os.environ[&amp;#39;NUM_INTER_THREADS&amp;#39;]),&lt;/p&gt;

&lt;p&gt;intra_op_parallelism_threads=int(os.environ[&amp;#39;NUM_INTRA_THREADS&amp;#39;]))&lt;/p&gt;

&lt;p&gt;sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)&lt;/p&gt;

&lt;p&gt;K.set_session(sess)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Then it blows up with:&lt;/p&gt;

&lt;p&gt;RuntimeError: `set_session` is not available when using TensorFlow 2.0.&lt;/p&gt;

&lt;p&gt;Any advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kehd9g,True,,dunn_ditty,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/kehd9g/set_session_is_not_available_when_using/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kehd9g/set_session_is_not_available_when_using/,22217,1608150992.0,0,,False,,,,,,,,,
375,,tensorflow,"Hello All,

I am new to TensorFlow and I have a problem wherein I need to count boats on a lake using Keras. I have seen this done in two separate papers now one [counting whales](https://www.nature.com/articles/s41598-019-50795-9) and another [counting ships](https://calhoun.nps.edu/bitstream/handle/10945/61255/18Dec_Rice_Katherine.pdf?sequence=1&amp;isAllowed=y) in the ocean. however, both are using python. While I am not apposed to learning another language, I was curious if there are any tutorials out there about using Keras to count objects coding in R. does anyone know of anything like this that I could read over? atm I am stuck with either trying to muddle my way through building a CNN from scratch without any guidance or learning a new language, neither of which is something I am particularly excited about tackling.

any help would be greatly appreciated.",t2_l3c2w,False,,0,False,tutorials out there on object detection and counting using keras in R?,[],r/tensorflow,False,6,,0,,,False,t3_kecr55,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1608166106.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello All,&lt;/p&gt;

&lt;p&gt;I am new to TensorFlow and I have a problem wherein I need to count boats on a lake using Keras. I have seen this done in two separate papers now one &lt;a href=""https://www.nature.com/articles/s41598-019-50795-9""&gt;counting whales&lt;/a&gt; and another &lt;a href=""https://calhoun.nps.edu/bitstream/handle/10945/61255/18Dec_Rice_Katherine.pdf?sequence=1&amp;amp;isAllowed=y""&gt;counting ships&lt;/a&gt; in the ocean. however, both are using python. While I am not apposed to learning another language, I was curious if there are any tutorials out there about using Keras to count objects coding in R. does anyone know of anything like this that I could read over? atm I am stuck with either trying to muddle my way through building a CNN from scratch without any guidance or learning a new language, neither of which is something I am particularly excited about tackling.&lt;/p&gt;

&lt;p&gt;any help would be greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kecr55,True,,mthompson2100,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kecr55/tutorials_out_there_on_object_detection_and/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kecr55/tutorials_out_there_on_object_detection_and/,22217,1608137306.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/GTTcR6Th-4cjxdNPt_CXIi9etMxzD4BLBjTwuSag4LE.jpg?auto=webp&amp;s=90f9368958db6be8c1bf2f19914fc7c7bd27d547', 'width': 685, 'height': 429}, 'resolutions': [{'url': 'https://external-preview.redd.it/GTTcR6Th-4cjxdNPt_CXIi9etMxzD4BLBjTwuSag4LE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a949ea4905a0eadd74566921a4391ab91a42da0', 'width': 108, 'height': 67}, {'url': 'https://external-preview.redd.it/GTTcR6Th-4cjxdNPt_CXIi9etMxzD4BLBjTwuSag4LE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=37a1ac72017376a0165fb33bc6c7184834735737', 'width': 216, 'height': 135}, {'url': 'https://external-preview.redd.it/GTTcR6Th-4cjxdNPt_CXIi9etMxzD4BLBjTwuSag4LE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a24ad6327acfd8a9d8eb4d4090c058cb53835c6d', 'width': 320, 'height': 200}, {'url': 'https://external-preview.redd.it/GTTcR6Th-4cjxdNPt_CXIi9etMxzD4BLBjTwuSag4LE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e0cd35234d1fc7926a9ed551382f890758e7f849', 'width': 640, 'height': 400}], 'variants': {}, 'id': '8xjcw3BBRvVT0Q6U9TZfTTvuPoLAN1_NgpWDuvMREgk'}], 'enabled': False}",,,,,,
376,,tensorflow,Have people been using deep learning to do regression? I noticed that fitting polynomials using least squares leads to much better accuracy! Is there any rule of thumb to get arbitrary accuracy with deep regression?,t2_617u1lh9,False,,0,False,Deep regression,[],r/tensorflow,False,6,,0,,,False,t3_kecnni,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1608165821.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Have people been using deep learning to do regression? I noticed that fitting polynomials using least squares leads to much better accuracy! Is there any rule of thumb to get arbitrary accuracy with deep regression?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kecnni,True,,matibilkis,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kecnni/deep_regression/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kecnni/deep_regression/,22217,1608137021.0,0,,False,,,,,,,,,
377,,tensorflow,"When we print model.summary(), it shows the number of parameters associated with each layer. When the number is zero, it means there are no weights associated with this layer. Is that correct?

A very basic question but I just want to confirm. Having issues with loading pretrained weights 'by\_name', hence trying to debug.",t2_2yzg0lbs,False,,0,False,layers with zero parameters have no weights?,[],r/tensorflow,False,6,,0,,,False,t3_ke4eqf,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1608130896.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When we print model.summary(), it shows the number of parameters associated with each layer. When the number is zero, it means there are no weights associated with this layer. Is that correct?&lt;/p&gt;

&lt;p&gt;A very basic question but I just want to confirm. Having issues with loading pretrained weights &amp;#39;by_name&amp;#39;, hence trying to debug.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ke4eqf,True,,juggy94,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ke4eqf/layers_with_zero_parameters_have_no_weights/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ke4eqf/layers_with_zero_parameters_have_no_weights/,22217,1608102096.0,0,,False,,,,,,,,,
378,,tensorflow,"ERROR: Could not find a version that satisfies the requirement tensorflow==1.12.0 (from -r requirements.txt (line 28)) (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0)",t2_7tsfi4ds,False,,0,False,Can you solve this TensorFlow Error?,[],r/tensorflow,False,6,,0,,,False,t3_ke8llm,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1608151778.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;ERROR: Could not find a version that satisfies the requirement tensorflow==1.12.0 (from -r requirements.txt (line 28)) (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ke8llm,True,,Pablo19D,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ke8llm/can_you_solve_this_tensorflow_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ke8llm/can_you_solve_this_tensorflow_error/,22217,1608122978.0,0,,False,,,,,,,,,
379,,tensorflow,"I built some wheels for the new Tensorflow 2.4 with CUDA 11 and cuDNN 8

you can find them here: [https://github.com/davidenunes/tensorflow-wheels](https://github.com/davidenunes/tensorflow-wheels)

in case anyone finding these useful, contribute to my coffee addiction 🤣☕ and support these builds and related projects here: [https://github.com/sponsors/davidenunes](https://github.com/sponsors/davidenunes) or [https://ko-fi.com/davidenunes](https://ko-fi.com/davidenunes)  


or just say hi on [@davidelnunes](https://twitter.com/davidelnunes) on Twitter.",t2_ropk4,False,,0,False,[P] Optimized Wheels for the latest TensorFlow 2.4 with CUDA 11 and Python3.8/3.9,[],r/tensorflow,False,6,,0,,,False,t3_kdt32z,False,dark,0.99,,public,17,0,{},,,False,[],,False,False,,{},Project ,False,17,,False,self,1608079327.0,,[],{},,True,,1608090951.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I built some wheels for the new Tensorflow 2.4 with CUDA 11 and cuDNN 8&lt;/p&gt;

&lt;p&gt;you can find them here: &lt;a href=""https://github.com/davidenunes/tensorflow-wheels""&gt;https://github.com/davidenunes/tensorflow-wheels&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;in case anyone finding these useful, contribute to my coffee addiction 🤣☕ and support these builds and related projects here: &lt;a href=""https://github.com/sponsors/davidenunes""&gt;https://github.com/sponsors/davidenunes&lt;/a&gt; or &lt;a href=""https://ko-fi.com/davidenunes""&gt;https://ko-fi.com/davidenunes&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;or just say hi on &lt;a href=""https://twitter.com/davidelnunes""&gt;@davidelnunes&lt;/a&gt; on Twitter.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kdt32z,True,,davex32,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kdt32z/p_optimized_wheels_for_the_latest_tensorflow_24/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kdt32z/p_optimized_wheels_for_the_latest_tensorflow_24/,22217,1608062151.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?auto=webp&amp;s=4a3257282561a396d8b2bc2a884f26eb86eb3e9f', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c48d068f1c08ba8529402d9020d5e84d66e5f84', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=799614b370c6fc744ddafdfd32c91c32a860ca04', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/5deDNbhNLFhweBZw5ouSLqBjjm79yYABs_C2O_z-tC8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5417762d9b98409b174c1ac5d2a4edffec3bdb18', 'width': 320, 'height': 320}], 'variants': {}, 'id': '69OwC9Le6WPJSo1bqK--28JfBCNBnzn-hbX3LmD0fCE'}], 'enabled': False}",,,,,,
380,,tensorflow,"I published a tutorial where I explain how to build AutoEncoders with Python and Keras. In particular, in this video you’ll learn how to build the encoder component. 

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

[https://www.youtube.com/watch?v=TtyoFTyJuEY&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=4](https://www.youtube.com/watch?v=TtyoFTyJuEY&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=4)",t2_12ahau,False,,0,False,I published a step-by-step tutorial on how to build autoencoders,[],r/tensorflow,False,6,,0,,,False,t3_kdmd8i,False,dark,0.88,,public,18,0,{},,,False,[],,False,False,,{},Project,False,18,,False,self,False,,[],{},,True,,1608070161.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I published a tutorial where I explain how to build AutoEncoders with Python and Keras. In particular, in this video you’ll learn how to build the encoder component. &lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=TtyoFTyJuEY&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=4""&gt;https://www.youtube.com/watch?v=TtyoFTyJuEY&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=4&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,kdmd8i,True,,diabulusInMusica,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kdmd8i/i_published_a_stepbystep_tutorial_on_how_to_build/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kdmd8i/i_published_a_stepbystep_tutorial_on_how_to_build/,22217,1608041361.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/1pvwbjme1gpnJ58bEZjiZoU6JfmLl_K0V3uy-VdFWUs.jpg?auto=webp&amp;s=21695a9ab29ec665a7636159c3105b8319b6de5f', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/1pvwbjme1gpnJ58bEZjiZoU6JfmLl_K0V3uy-VdFWUs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81ddb002b23845eb232b02caa73bea66c12dcf4f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/1pvwbjme1gpnJ58bEZjiZoU6JfmLl_K0V3uy-VdFWUs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b00fb68886f29fce591d44ec47954960f3d65ccb', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/1pvwbjme1gpnJ58bEZjiZoU6JfmLl_K0V3uy-VdFWUs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0bbdf29eaa826f85620abf0529112deca667295', 'width': 320, 'height': 240}], 'variants': {}, 'id': '3jfjTuuTMFgqNL8DFOxeO6OoDbluky1UMnCk-kIdS-k'}], 'enabled': False}",,,,,,
381,,tensorflow,"Hi there! I am brand new to unbuntu and I have just build a computer running it. I am currently trying to download TensorFlow for my computer and I am trying to run the comamnd:

$. ./venv/bin/activate.fish  # fish

and it's returning this:

bash: ./venv/bin/activate.fish: line 4: syntax error near unexpected token \`-d'

bash: ./venv/bin/activate.fish: line 4: \`function deactivate -d ""Exit virtualenv and return to normal shell environment""'

Any thoughts?",t2_3eqc1qzc,False,,0,False,Ubuntu install help,[],r/tensorflow,False,6,,0,,,False,t3_ke0kmq,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1608115376.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there! I am brand new to unbuntu and I have just build a computer running it. I am currently trying to download TensorFlow for my computer and I am trying to run the comamnd:&lt;/p&gt;

&lt;p&gt;$. ./venv/bin/activate.fish  # fish&lt;/p&gt;

&lt;p&gt;and it&amp;#39;s returning this:&lt;/p&gt;

&lt;p&gt;bash: ./venv/bin/activate.fish: line 4: syntax error near unexpected token `-d&amp;#39;&lt;/p&gt;

&lt;p&gt;bash: ./venv/bin/activate.fish: line 4: `function deactivate -d &amp;quot;Exit virtualenv and return to normal shell environment&amp;quot;&amp;#39;&lt;/p&gt;

&lt;p&gt;Any thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ke0kmq,True,,Elrekl,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ke0kmq/ubuntu_install_help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ke0kmq/ubuntu_install_help/,22217,1608086576.0,0,,False,,,,,,,,,
382,,tensorflow,"I have tried to train the model with and without dropout. The only difference is that I add the last dropout layer which yields the error  'Resource exhausted:  OOM when allocating tensor with shape ' to appear? Thy is that

x = Conv2D(num\_filters, (3, 3), padding=""same"")(x)    

x = BatchNormalization()(x)    

x = Activation(""relu"")(x)    

x = Dropout(0.1)(x)",t2_128ob4,False,,0,False,Adding Dropout - Out of Memory,[],r/tensorflow,False,6,,0,,,False,t3_kdpp1g,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1608080968.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have tried to train the model with and without dropout. The only difference is that I add the last dropout layer which yields the error  &amp;#39;Resource exhausted:  OOM when allocating tensor with shape &amp;#39; to appear? Thy is that&lt;/p&gt;

&lt;p&gt;x = Conv2D(num_filters, (3, 3), padding=&amp;quot;same&amp;quot;)(x)    &lt;/p&gt;

&lt;p&gt;x = BatchNormalization()(x)    &lt;/p&gt;

&lt;p&gt;x = Activation(&amp;quot;relu&amp;quot;)(x)    &lt;/p&gt;

&lt;p&gt;x = Dropout(0.1)(x)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kdpp1g,True,,darvidas,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kdpp1g/adding_dropout_out_of_memory/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kdpp1g/adding_dropout_out_of_memory/,22217,1608052168.0,0,,False,,,,,,,,,
383,,tensorflow,"I’m mostly looking for things like how to properly define your models (for example how to define your model classes or functions in order to have a cleaner project, how to manage hyperparameters as inputs for the definition of your models,...), how to do the train (should I implement a function/class for the training part?). Thanks.

Edit: Can anyone give us a link to a “perfect” GitHub DL project? One that does everything well and clean.",t2_4xt7vl5p,False,,0,False,Does anyone have some tf/Keras best practices lists or examples?,[],r/tensorflow,False,6,,0,,,False,t3_kdc8ft,False,dark,1.0,,public,26,0,{},,,False,[],,False,False,,{},Discussion,False,26,,False,self,1608009605.0,,[],{},,True,,1608026416.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m mostly looking for things like how to properly define your models (for example how to define your model classes or functions in order to have a cleaner project, how to manage hyperparameters as inputs for the definition of your models,...), how to do the train (should I implement a function/class for the training part?). Thanks.&lt;/p&gt;

&lt;p&gt;Edit: Can anyone give us a link to a “perfect” GitHub DL project? One that does everything well and clean.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kdc8ft,True,,convnetto,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/kdc8ft/does_anyone_have_some_tfkeras_best_practices/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kdc8ft/does_anyone_have_some_tfkeras_best_practices/,22217,1607997616.0,0,,False,,,,,,,,,
384,,tensorflow,,t2_5moj37ik,False,,0,False,Battlefleet Gothic: Armada 2 - Prologue (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS,[],r/tensorflow,False,6,,0,105.0,,False,t3_kdjwej,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/5G0BJmeSIV4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Battlefleet Gothic: Armada 2 - Prologue (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/5G0BJmeSIV4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/5G0BJmeSIV4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/5G0BJmeSIV4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kdjwej', 'height': 200}",,False,1,,False,https://b.thumbs.redditmedia.com/l2dRVS3J4ePV5su6T3QjHVt2TAC6DVS1HLbFcVRL7wE.jpg,False,,[],{},,False,,1608059631.0,text,6,,,text,youtube.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kdjwej,True,,stepanmetior,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kdjwej/battlefleet_gothic_armada_2_prologue_remastered/,all_ads,False,https://www.youtube.com/watch?v=5G0BJmeSIV4,22217,1608030831.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Battlefleet Gothic: Armada 2 - Prologue (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/5G0BJmeSIV4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/5G0BJmeSIV4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=5G0BJmeSIV4,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MNKPn7iwG0f7MoAPCW2anbtqK2-n19JNeu0Q8kG7fdw.jpg?auto=webp&amp;s=73e5997c85051b98ad67d9e16c285f6c2a68dec5', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/MNKPn7iwG0f7MoAPCW2anbtqK2-n19JNeu0Q8kG7fdw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3734abb3b2107e1a0b10226b6e0de773c2dc8895', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/MNKPn7iwG0f7MoAPCW2anbtqK2-n19JNeu0Q8kG7fdw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0eff0e875de5e82bb0af0e3044841ff1fb4a10a2', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/MNKPn7iwG0f7MoAPCW2anbtqK2-n19JNeu0Q8kG7fdw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=55fb368ea93e9441eca6beff50d06ef36f0702a9', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'gOYD1ZxFgRWz1FFCNtACG0wTxs6LMqsXs29EF3nEEAU'}], 'enabled': False}",,,,,,
385,,tensorflow,"Hello everyone, I am trying to train the ssd\_mobilenet\_v2\_coco\_2018\_03\_29 network using learning transfer and the code to train (train.py) is the one in the models / research / object\_detection / legacy folder of the tensorflow api, the following is the command I use for it 

python3 train.py \\  --logtostderr \\  --train\_dir = $ TRAIN\_DIR \\  --pipeline\_config\_path = $PIPELINE\_CONFIG\_PATH

however I get the following problem

[https://pastebin.pl/view/e1cf5d7e](https://pastebin.pl/view/e1cf5d7e)

can someone give me an idea what is going on, thanks

Notes: tensorflow version 1.14.",t2_6dk8qe5z,False,,0,False,Problem trying to run object detection training,[],r/tensorflow,False,6,,0,,,False,t3_kdagqn,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1608020635.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, I am trying to train the ssd_mobilenet_v2_coco_2018_03_29 network using learning transfer and the code to train (train.py) is the one in the models / research / object_detection / legacy folder of the tensorflow api, the following is the command I use for it &lt;/p&gt;

&lt;p&gt;python3 train.py \  --logtostderr \  --train_dir = $ TRAIN_DIR \  --pipeline_config_path = $PIPELINE_CONFIG_PATH&lt;/p&gt;

&lt;p&gt;however I get the following problem&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://pastebin.pl/view/e1cf5d7e""&gt;https://pastebin.pl/view/e1cf5d7e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;can someone give me an idea what is going on, thanks&lt;/p&gt;

&lt;p&gt;Notes: tensorflow version 1.14.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kdagqn,True,,legendarypegasus,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kdagqn/problem_trying_to_run_object_detection_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kdagqn/problem_trying_to_run_object_detection_training/,22217,1607991835.0,0,,False,,,,,,,,,
386,,tensorflow,"Hi,

I am quite new to temporal forecast with images and LSTM. I really appreciate your help.

Input is a sequence of images where each image size is 28\*28, and the number of this sequence of images is set as the batch size as None the first argument of input\_shape.

suppose 4 consecutive seconds of images were fed into the NN, and the expected output of the NN would be No. 5 second label.

But I have hard time making  Conv1D and LSTM working together and ending up with one numerical  label.

    model = Sequential() 
    model.add(Conv1D(40,2, strides=2,padding='same', activation='relu', input_shape=(None,28,28))) 
    model.add(Reshape((None,576))) # or 
    model.add(Flatten()) 
    model.add(LSTM(10, activation='relu',stateful=True,return_sequences=True)) 

1. Is the Batch size set properly?
2. how to make Conv1D and LSTM linked together? I mean the data dimensionality stuff. Is it necessary to get the numerical labels from  Conv1D and then pass them to  LSTM?  or pass the original dimensional data directly from Conv1D to LSTM then from the  LSTM result, to compute one numerical label as the final result of NN?
3. also is TimeDistributed() layer needed?

Thank you so much!",t2_298vr6n0,False,,0,False,How to use a consecutive sequence of one channel images to predict next frame label with Conv1D and LSTM?,[],r/tensorflow,False,6,,0,,,False,t3_kcietl,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,1607895546.0,,[],{},,True,,1607921176.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am quite new to temporal forecast with images and LSTM. I really appreciate your help.&lt;/p&gt;

&lt;p&gt;Input is a sequence of images where each image size is 28*28, and the number of this sequence of images is set as the batch size as None the first argument of input_shape.&lt;/p&gt;

&lt;p&gt;suppose 4 consecutive seconds of images were fed into the NN, and the expected output of the NN would be No. 5 second label.&lt;/p&gt;

&lt;p&gt;But I have hard time making  Conv1D and LSTM working together and ending up with one numerical  label.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = Sequential() 
model.add(Conv1D(40,2, strides=2,padding=&amp;#39;same&amp;#39;, activation=&amp;#39;relu&amp;#39;, input_shape=(None,28,28))) 
model.add(Reshape((None,576))) # or 
model.add(Flatten()) 
model.add(LSTM(10, activation=&amp;#39;relu&amp;#39;,stateful=True,return_sequences=True)) 
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Is the Batch size set properly?&lt;/li&gt;
&lt;li&gt;how to make Conv1D and LSTM linked together? I mean the data dimensionality stuff. Is it necessary to get the numerical labels from  Conv1D and then pass them to  LSTM?  or pass the original dimensional data directly from Conv1D to LSTM then from the  LSTM result, to compute one numerical label as the final result of NN?&lt;/li&gt;
&lt;li&gt;also is TimeDistributed() layer needed?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thank you so much!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kcietl,True,,boydbuilding,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kcietl/how_to_use_a_consecutive_sequence_of_one_channel/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kcietl/how_to_use_a_consecutive_sequence_of_one_channel/,22217,1607892376.0,0,,False,,,,,,,,,
387,,tensorflow,"Hello there,

I am currently working on a [VAE](https://arxiv.org/abs/1906.02691) using tensorflow-probability. I would like to later train it on celeb\_a, but right now I am using mnist to test everything.

My model looks like this, inspired by [this example](https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE)
```
prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1), reinterpreted_batch_ndims=1)

inputs = tfk.Input(shape=input_shape)
x = tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5)(inputs)
x = tfkl.Conv2D(base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(2 * base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(2 * base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(4 * encoded_size, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu)(x)
x = tfkl.Flatten()(x)
x = tfkl.Dense(tfpl.IndependentNormal.params_size(encoded_size))(x)
x = tfpl.IndependentNormal(encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(prior))(x)

encoder = tfk.Model(inputs, x, name='encoder')
encoder.summary()

inputs = tfk.Input(shape=(encoded_size,))
x = tfkl.Reshape([1, 1, encoded_size])(inputs)
x = tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)(x)
mu = tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding='same', activation=None)(x)
mu = tfkl.Flatten()(mu)
sigma = tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding='same', activation=None)(x)
sigma = tf.exp(sigma)
sigma = tfkl.Flatten()(sigma)
x = tf.concat((mu, sigma), axis=1)
x = tfkl.LeakyReLU()(x)
x = tfpl.IndependentNormal(input_shape)(x)

decoder = tfk.Model(inputs, x)
decoder.summary()

negloglik = lambda x, rv_x: -rv_x.log_prob(x)

vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),
            loss=negloglik)

## mnist_digits are normed between 0.0 and 1.0
history = vae.fit(mnist_digits, mnist_digits, epochs=100, batch_size=300)
```

My problem here is that the loss function stops decreasing at around ~470 and the images sampled from the returned distribution look like random noise. When using a bernoulli distribution instead of the normal distribution in the decoder, the loss steadily decrease and the sampled images look like they should. I can't use a bernoulli distribution for rgb tho, which I have to when I want to train the model on celeb_a. I also can't just use a deterministic decoder, as I want to later decompose the elbo (loss term - KL divergence) as seen in [this](https://arxiv.org/abs/1802.04942).

Can someone explain to me why the normal distribution just ""doesn't work""?
How can I improve it so that it actually learns a distribution that I can sample.",t2_2y5dw7dw,False,,0,False,[Question] Sampling Images from a normal distribution for VAE,[],r/tensorflow,False,6,,0,,,False,t3_kcg3h0,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1607914034.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello there,&lt;/p&gt;

&lt;p&gt;I am currently working on a &lt;a href=""https://arxiv.org/abs/1906.02691""&gt;VAE&lt;/a&gt; using tensorflow-probability. I would like to later train it on celeb_a, but right now I am using mnist to test everything.&lt;/p&gt;

&lt;p&gt;My model looks like this, inspired by &lt;a href=""https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE""&gt;this example&lt;/a&gt;
```
prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1), reinterpreted_batch_ndims=1)&lt;/p&gt;

&lt;p&gt;inputs = tfk.Input(shape=input_shape)
x = tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5)(inputs)
x = tfkl.Conv2D(base_depth, 5, strides=1, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(base_depth, 5, strides=2, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(2 * base_depth, 5, strides=1, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(2 * base_depth, 5, strides=2, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2D(4 * encoded_size, 7, strides=1, padding=&amp;#39;valid&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Flatten()(x)
x = tfkl.Dense(tfpl.IndependentNormal.params_size(encoded_size))(x)
x = tfpl.IndependentNormal(encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(prior))(x)&lt;/p&gt;

&lt;p&gt;encoder = tfk.Model(inputs, x, name=&amp;#39;encoder&amp;#39;)
encoder.summary()&lt;/p&gt;

&lt;p&gt;inputs = tfk.Input(shape=(encoded_size,))
x = tfkl.Reshape([1, 1, encoded_size])(inputs)
x = tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1, padding=&amp;#39;valid&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(base_depth, 5, strides=1, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(base_depth, 5, strides=2, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
x = tfkl.Conv2DTranspose(base_depth, 5, strides=1, padding=&amp;#39;same&amp;#39;, activation=tf.nn.leaky_relu)(x)
mu = tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding=&amp;#39;same&amp;#39;, activation=None)(x)
mu = tfkl.Flatten()(mu)
sigma = tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding=&amp;#39;same&amp;#39;, activation=None)(x)
sigma = tf.exp(sigma)
sigma = tfkl.Flatten()(sigma)
x = tf.concat((mu, sigma), axis=1)
x = tfkl.LeakyReLU()(x)
x = tfpl.IndependentNormal(input_shape)(x)&lt;/p&gt;

&lt;p&gt;decoder = tfk.Model(inputs, x)
decoder.summary()&lt;/p&gt;

&lt;p&gt;negloglik = lambda x, rv_x: -rv_x.log_prob(x)&lt;/p&gt;

&lt;p&gt;vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),
            loss=negloglik)&lt;/p&gt;

&lt;h2&gt;mnist_digits are normed between 0.0 and 1.0&lt;/h2&gt;

&lt;p&gt;history = vae.fit(mnist_digits, mnist_digits, epochs=100, batch_size=300)
```&lt;/p&gt;

&lt;p&gt;My problem here is that the loss function stops decreasing at around ~470 and the images sampled from the returned distribution look like random noise. When using a bernoulli distribution instead of the normal distribution in the decoder, the loss steadily decrease and the sampled images look like they should. I can&amp;#39;t use a bernoulli distribution for rgb tho, which I have to when I want to train the model on celeb_a. I also can&amp;#39;t just use a deterministic decoder, as I want to later decompose the elbo (loss term - KL divergence) as seen in &lt;a href=""https://arxiv.org/abs/1802.04942""&gt;this&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Can someone explain to me why the normal distribution just &amp;quot;doesn&amp;#39;t work&amp;quot;?
How can I improve it so that it actually learns a distribution that I can sample.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kcg3h0,True,,tadachs,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kcg3h0/question_sampling_images_from_a_normal/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kcg3h0/question_sampling_images_from_a_normal/,22217,1607885234.0,0,,False,,,,,,,,,
388,,tensorflow,"I am using TF recommenders to build a model, which is using a large text feature as side input. From my understanding the way data should be loaded / modelled is as follows:

user | movie | movie summary

This means that we repeat the same movie and therefore summary many times over, and this creates a huge dataset. 

I was hoping there would be an extension of something such as the StringLookup -&gt; Embedding use case, but one which could given a key grab some arbitrary data:

```
tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.StringLookup(
    vocabulary=unique_urls, mask_token=None
  ),
  tf.keras.layers.FeatureLookup(), # Fake layer, here as example.
])
```
Is this the correct way of solving this problem, or is there a more TF to do this?

If this is the correct approach, then I assume I can subclass and implement the above.

Thanks in advance!",t2_2innaoj,False,,0,False,How to avoid repeating large text data,[],r/tensorflow,False,6,,0,,,False,t3_kcfqbj,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1607912900.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using TF recommenders to build a model, which is using a large text feature as side input. From my understanding the way data should be loaded / modelled is as follows:&lt;/p&gt;

&lt;p&gt;user | movie | movie summary&lt;/p&gt;

&lt;p&gt;This means that we repeat the same movie and therefore summary many times over, and this creates a huge dataset. &lt;/p&gt;

&lt;p&gt;I was hoping there would be an extension of something such as the StringLookup -&amp;gt; Embedding use case, but one which could given a key grab some arbitrary data:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.StringLookup(
    vocabulary=unique_urls, mask_token=None
  ),
  tf.keras.layers.FeatureLookup(), # Fake layer, here as example.
])
&lt;/code&gt;
Is this the correct way of solving this problem, or is there a more TF to do this?&lt;/p&gt;

&lt;p&gt;If this is the correct approach, then I assume I can subclass and implement the above.&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kcfqbj,True,,ydennisy,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kcfqbj/how_to_avoid_repeating_large_text_data/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kcfqbj/how_to_avoid_repeating_large_text_data/,22217,1607884100.0,0,,False,,,,,,,,,
389,,tensorflow,"Hey guys!

Google just accepted my stipend application, which means that soon enough I will be able to take the exam. Any tips and recommendations for someone's first try?

Thanks in advance!",t2_67s2s6zn,False,,0,False,Just got my stipend accepted!,[],r/tensorflow,False,6,,0,,,False,t3_kca9h5,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1607893409.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys!&lt;/p&gt;

&lt;p&gt;Google just accepted my stipend application, which means that soon enough I will be able to take the exam. Any tips and recommendations for someone&amp;#39;s first try?&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kca9h5,True,,stormleone2,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kca9h5/just_got_my_stipend_accepted/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kca9h5/just_got_my_stipend_accepted/,22217,1607864609.0,0,,False,,,,,,,,,
390,,tensorflow,"I understand the mechanics of SGs but i do not understand tensorflow's API well enough yet to implement them myself. I found various tf 1.x examples of SGs but i am having a hard time porting them to tf 2.x. Does anyone know of an example implementation of SGs in tensorflow 2.x? Or any tf 2 example of how to manipulate the flow and computation of gradients during training?

I am trying to move away from keras towards learning plain tensorflow and i want to couple that with experimentation using synthetic gradients.",t2_8ez6tpeb,False,,0,False,A TF 2.x example of Synthetic Gradients?,[],r/tensorflow,False,6,,0,,,False,t3_kcchyf,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1608335067.0,,[],{},,True,,1607902316.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I understand the mechanics of SGs but i do not understand tensorflow&amp;#39;s API well enough yet to implement them myself. I found various tf 1.x examples of SGs but i am having a hard time porting them to tf 2.x. Does anyone know of an example implementation of SGs in tensorflow 2.x? Or any tf 2 example of how to manipulate the flow and computation of gradients during training?&lt;/p&gt;

&lt;p&gt;I am trying to move away from keras towards learning plain tensorflow and i want to couple that with experimentation using synthetic gradients.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kcchyf,True,,tfhwchoice,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kcchyf/a_tf_2x_example_of_synthetic_gradients/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kcchyf/a_tf_2x_example_of_synthetic_gradients/,22217,1607873516.0,0,,False,,,,,,,,,
391,,tensorflow,,t2_5moj37ik,False,,0,False,"Warhammer 40,000 The New Edition - Trailer (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS",[],r/tensorflow,False,6,,0,105.0,,False,t3_kc6mk0,False,dark,0.66,,public,7,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/TdUYt5a89hU?start=55&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Warhammer 40,000 The New Edition - Trailer (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/TdUYt5a89hU?start=55&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/TdUYt5a89hU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/TdUYt5a89hU?start=55&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kc6mk0', 'height': 338}",,False,7,,False,https://b.thumbs.redditmedia.com/lev54vG2O7ki5dbG1avQBVVcax-tXfMtuvuWgBCq5mE.jpg,False,,[],{},,False,,1607873912.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kc6mk0,True,,stepanmetior,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kc6mk0/warhammer_40000_the_new_edition_trailer/,all_ads,False,https://www.youtube.com/watch?v=TdUYt5a89hU&amp;t=55s,22217,1607845112.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Warhammer 40,000 The New Edition - Trailer (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/TdUYt5a89hU?start=55&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/TdUYt5a89hU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=TdUYt5a89hU&amp;t=55s,"{'images': [{'source': {'url': 'https://external-preview.redd.it/DjRxCab2FB1AaOlhjfJ_owTtFjfMvQ8z81GtKp1A6uw.jpg?auto=webp&amp;s=10e4d1a6482c737d0519bade4635c4df5993a1d8', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/DjRxCab2FB1AaOlhjfJ_owTtFjfMvQ8z81GtKp1A6uw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e280d952afbcd537f4ca73875f6773ac1259d5b', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/DjRxCab2FB1AaOlhjfJ_owTtFjfMvQ8z81GtKp1A6uw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d09a28d0f02d5ad6c37cceada52204648fd541e', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/DjRxCab2FB1AaOlhjfJ_owTtFjfMvQ8z81GtKp1A6uw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=92596eaa56b31501fe87b3105ace61f93457da05', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'ShFuHCfPB0DWH_c9FIi55WQpZjgQbu-hFvxiqALeX-8'}], 'enabled': False}",,,,,,
392,,tensorflow,,t2_44mbtmjy,False,,0,False,Free browser extension for ML community that thousands of machine learning engineers/data scientists use everyday! Drop a comment for any questions/feature requests you may have!,[],r/tensorflow,False,6,,0,70.0,,False,t3_kc2yxn,False,dark,0.74,,public,9,0,{},70.0,,False,[],,False,False,,{},,False,9,,False,https://b.thumbs.redditmedia.com/tPTSJTzaygYGO_GVYZ_WjE2xV3A875hWMhGWKnpW8_c.jpg,False,,[],{},,False,,1607857547.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kc2yxn,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kc2yxn/free_browser_extension_for_ml_community_that/,all_ads,False,/r/LatestInML/comments/kc2vyx/free_browser_extension_for_ml_community_that/,22217,1607828747.0,0,,False,link,/r/LatestInML/comments/kc2vyx/free_browser_extension_for_ml_community_that/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?auto=webp&amp;s=b2ec1cfa2b9e720731d4dc172cbef8096fb37c3a', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5435b4b2d94d9df9309e4d5ceb4bc021b52783', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'TIQjNUpyCsCWmTM49ZEEAiVQDWg07G_PjT8zXCX4wSE'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'Liked by Andrew Ng as well!\n\nDrop a comment for any questions/feature requests you may have!-&gt;The extension finds code implementations for ML/AI papers anywhere on the internet!\n\nChrome [http://bit.ly/code\\_finder\\_chrome](https://bit.ly/code_finder_chrome?fbclid=IwAR23RdK9pFQwwPEXoJKIjYgXhQhmBFcGZnHVxIFFb-VZHHM3x4s4kBQnxqA)  \nFirefox [http://bit.ly/code\\_finder\\_firefox](https://bit.ly/code_finder_firefox?fbclid=IwAR2N_I1htqKSaHEZ-gYoa-J4AVnBpZKyZmLvK5Y8sjuS1hDDY_s-LEZKKbQ)\n\n&amp;#x200B;\n\nhttps://reddit.com/link/kc2vyx/video/prqwux4ldv461/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Free browser extension for ML community that thousands of machine learning engineers/data scientists use everyday! Drop a comment for any questions/feature requests you may have!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 70, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'prqwux4ldv461': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/kc2vyx/asset/prqwux4ldv461/DASHPlaylist.mpd?a=1618044739%2CNTZmMTQ1MmVjODdjNzM0ZTI5YzdlMjY3MzU5MTg0MmU3YmJmMmUxMjkxZTY0ZjNmNTVlNjNhYWRkOGU0YTdiZQ%3D%3D&amp;v=1&amp;f=sd', 'x': 1676, 'y': 1080, 'hlsUrl': 'https://v.redd.it/link/kc2vyx/asset/prqwux4ldv461/HLSPlaylist.m3u8?a=1618044739%2CYzRkZTA0Y2NkZTk2MDY0ZWQ4ZDNiOWVlNDYyYjFkZDkxOTMzNDMyMjYwMzYwYTUxY2YzMzZmMzE0YjMxZTkwZg%3D%3D&amp;v=1&amp;f=sd', 'id': 'prqwux4ldv461', 'isGif': False}}, 'name': 't3_kc2vyx', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.79, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 70, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 21, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/tPTSJTzaygYGO_GVYZ_WjE2xV3A875hWMhGWKnpW8_c.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1607857236.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Liked by Andrew Ng as well!&lt;/p&gt;\n\n&lt;p&gt;Drop a comment for any questions/feature requests you may have!-&amp;gt;The extension finds code implementations for ML/AI papers anywhere on the internet!&lt;/p&gt;\n\n&lt;p&gt;Chrome &lt;a href=""https://bit.ly/code_finder_chrome?fbclid=IwAR23RdK9pFQwwPEXoJKIjYgXhQhmBFcGZnHVxIFFb-VZHHM3x4s4kBQnxqA""&gt;http://bit.ly/code_finder_chrome&lt;/a&gt;&lt;br/&gt;\nFirefox &lt;a href=""https://bit.ly/code_finder_firefox?fbclid=IwAR2N_I1htqKSaHEZ-gYoa-J4AVnBpZKyZmLvK5Y8sjuS1hDDY_s-LEZKKbQ""&gt;http://bit.ly/code_finder_firefox&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/kc2vyx/video/prqwux4ldv461/player""&gt;https://reddit.com/link/kc2vyx/video/prqwux4ldv461/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?auto=webp&amp;s=b2ec1cfa2b9e720731d4dc172cbef8096fb37c3a', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5435b4b2d94d9df9309e4d5ceb4bc021b52783', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'TIQjNUpyCsCWmTM49ZEEAiVQDWg07G_PjT8zXCX4wSE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'kc2vyx', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/kc2vyx/free_browser_extension_for_ml_community_that/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/kc2vyx/free_browser_extension_for_ml_community_that/', 'subreddit_subscribers': 6676, 'created_utc': 1607828436.0, 'num_crossposts': 16, 'media': None, 'is_video': False}]",t3_kc2vyx,
393,,tensorflow,"Originally posted [here](https://twitter.com/rishit_dagli/status/1337668190831198208?s=20).

💡 #TensorFlowTip

Use `.prefetch` to reduce your step time of training and extracting data

* overlap the preprocessing and model execution
* while the model executes training step `n` the input pipeline is reading the data for `n+1` step
* reduces the idle time for the GPU and CPU

See the speedup with `.prefetch` in this image. Try it for yourself [here](https://gist.github.com/Rishit-dagli/27aa9fe80d467920d2d0faaabb8bbdc3).

[Speedup with .prefetch](https://preview.redd.it/nhfzum78cw461.png?width=1983&amp;format=png&amp;auto=webp&amp;s=dadbb43197a4cb465ce894e3df7c0605057fcc6b)",t2_7t6vk108,False,,0,False,A TensorFlow tip to Optimize your Training,[],r/tensorflow,False,6,,0,60.0,,False,t3_kc5m4r,False,dark,0.57,,public,1,0,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;💡&lt;a href=""https://twitter.com/hashtag/TensorFlowTip?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#TensorFlowTip&lt;/a&gt;&lt;br&gt;Use .prefetch to reduce your step time of training and extracting data&lt;br&gt;&lt;br&gt;- overlap preprocessing and model execution&lt;br&gt;- while the model executes training step n input pipeline is reading the data for n+1 step&lt;br&gt;- reduce idle time for the GPU and CPU&lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; &lt;a href=""https://t.co/TekXX13O8k""&gt;pic.twitter.com/TekXX13O8k&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1337668190831198208?ref_src=twsrc%5Etfw""&gt;December 12, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'height': 200}",140.0,,False,[],"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/rishit_dagli/status/1337668190831198208', 'author_name': 'Rishit Dagli', 'height': None, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;💡&lt;a href=""https://twitter.com/hashtag/TensorFlowTip?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#TensorFlowTip&lt;/a&gt;&lt;br&gt;Use .prefetch to reduce your step time of training and extracting data&lt;br&gt;&lt;br&gt;- overlap preprocessing and model execution&lt;br&gt;- while the model executes training step n input pipeline is reading the data for n+1 step&lt;br&gt;- reduce idle time for the GPU and CPU&lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; &lt;a href=""https://t.co/TekXX13O8k""&gt;pic.twitter.com/TekXX13O8k&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1337668190831198208?ref_src=twsrc%5Etfw""&gt;December 12, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/rishit_dagli', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,False,,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;💡&lt;a href=""https://twitter.com/hashtag/TensorFlowTip?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#TensorFlowTip&lt;/a&gt;&lt;br&gt;Use .prefetch to reduce your step time of training and extracting data&lt;br&gt;&lt;br&gt;- overlap preprocessing and model execution&lt;br&gt;- while the model executes training step n input pipeline is reading the data for n+1 step&lt;br&gt;- reduce idle time for the GPU and CPU&lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; &lt;a href=""https://t.co/TekXX13O8k""&gt;pic.twitter.com/TekXX13O8k&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1337668190831198208?ref_src=twsrc%5Etfw""&gt;December 12, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/kc5m4r', 'height': 200}",,False,1,,False,https://b.thumbs.redditmedia.com/dSoEk82091BTkyZpitt3QuCc5JHjhbQ4xDXFetxHUbY.jpg,False,,[],{},,True,,1607868750.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Originally posted &lt;a href=""https://twitter.com/rishit_dagli/status/1337668190831198208?s=20""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;💡 #TensorFlowTip&lt;/p&gt;

&lt;p&gt;Use &lt;code&gt;.prefetch&lt;/code&gt; to reduce your step time of training and extracting data&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;overlap the preprocessing and model execution&lt;/li&gt;
&lt;li&gt;while the model executes training step &lt;code&gt;n&lt;/code&gt; the input pipeline is reading the data for &lt;code&gt;n+1&lt;/code&gt; step&lt;/li&gt;
&lt;li&gt;reduces the idle time for the GPU and CPU&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the speedup with &lt;code&gt;.prefetch&lt;/code&gt; in this image. Try it for yourself &lt;a href=""https://gist.github.com/Rishit-dagli/27aa9fe80d467920d2d0faaabb8bbdc3""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/nhfzum78cw461.png?width=1983&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dadbb43197a4cb465ce894e3df7c0605057fcc6b""&gt;Speedup with .prefetch&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kc5m4r,True,,Rishit-dagli,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kc5m4r/a_tensorflow_tip_to_optimize_your_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kc5m4r/a_tensorflow_tip_to_optimize_your_training/,22217,1607839950.0,0,"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/rishit_dagli/status/1337668190831198208', 'author_name': 'Rishit Dagli', 'height': None, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;💡&lt;a href=""https://twitter.com/hashtag/TensorFlowTip?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#TensorFlowTip&lt;/a&gt;&lt;br&gt;Use .prefetch to reduce your step time of training and extracting data&lt;br&gt;&lt;br&gt;- overlap preprocessing and model execution&lt;br&gt;- while the model executes training step n input pipeline is reading the data for n+1 step&lt;br&gt;- reduce idle time for the GPU and CPU&lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; &lt;a href=""https://t.co/TekXX13O8k""&gt;pic.twitter.com/TekXX13O8k&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1337668190831198208?ref_src=twsrc%5Etfw""&gt;December 12, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/rishit_dagli', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Ee8i6hwDJmKOyAzQvOSpAuU4JVSEXxzTj5TyfhyKuRA.jpg?auto=webp&amp;s=3264a9ce35f3a0d701eabf781c3e7bb4865f7a7c', 'width': 140, 'height': 60}, 'resolutions': [{'url': 'https://external-preview.redd.it/Ee8i6hwDJmKOyAzQvOSpAuU4JVSEXxzTj5TyfhyKuRA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f3a5b2140faca9456601a82e2abb6ddebf0fe959', 'width': 108, 'height': 46}], 'variants': {}, 'id': 'KsoL4ushQMSVTquUpqu0-ABP5coX0jKP4tKYS_6fbS4'}], 'enabled': False}",,"{'nhfzum78cw461': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 47, 'x': 108, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1cd8c506222e02eb160649785b8396896564bce3'}, {'y': 94, 'x': 216, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5abee3df4f53cfbee7ba4dd661c4e960a1328ccd'}, {'y': 139, 'x': 320, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8a0431740dfb983c87dc867931b2fff193b3b232'}, {'y': 278, 'x': 640, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b03afb180f36c92e36e04aa7c85f5d4199a57a24'}, {'y': 417, 'x': 960, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee55ff8dd12f94c0225bc8ee24e332d0153d5536'}, {'y': 470, 'x': 1080, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=768ccb319d739087cb537e9a4bf4f970f92642d6'}], 's': {'y': 863, 'x': 1983, 'u': 'https://preview.redd.it/nhfzum78cw461.png?width=1983&amp;format=png&amp;auto=webp&amp;s=dadbb43197a4cb465ce894e3df7c0605057fcc6b'}, 'id': 'nhfzum78cw461'}}",,,,
394,,tensorflow,"I am using CUDA/CUDNN to train multiple tensorflow keras models on my GPU (for an evolutionary algorithm attempting to optimize hyperparameters). Initially, the program would crash with an Out of Memory error after a couple generations. Eventually, I found that using a new sub-process for every model would clear the GPU memory automatically.

However, each process seems to reinitialize CUDA (loading dynamic libraries from the .dll files), which is incredibly time-consuming. Is there any method to avoid this?

Code is pasted below. The function ""fitness_wrapper"" is called for each `indiv`idual.

    def fitness_wrapper(indiv):
        fit = multi.processing.Value('d', 0.0)
        if __name__ == '__main__':
            process = multiprocessing.Process(target=fitness, args=(indiv, fit))
            process.start()
            process.join()
        return (fit.value,)
    
    
    def fitness(indiv, fit):
        model = tf.keras.Sequential.from_config(indiv['architecture'])
        optimizer_dict = indiv['optimizer']
        opt = tf.keras.optimizers.Adam(learning_rate=optimizer_dict['lr'], beta_1=optimizer_dict['b1'],
                                   beta_2=optimizer_dict['b2'],
                                   epsilon=optimizer_dict['epsilon'])
        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
        model.fit(data_split[0], data_split[2], batch_size=32, epochs=5)
        fit = model.evaluate(data_split[1], data_split[3])[1]",t2_eje3o,False,,0,False,How to stop CUDA from re-initializing for every subprocess which trains a keras model?,[],r/tensorflow,False,6,,0,,,False,t3_kbuucl,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1607829046.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using CUDA/CUDNN to train multiple tensorflow keras models on my GPU (for an evolutionary algorithm attempting to optimize hyperparameters). Initially, the program would crash with an Out of Memory error after a couple generations. Eventually, I found that using a new sub-process for every model would clear the GPU memory automatically.&lt;/p&gt;

&lt;p&gt;However, each process seems to reinitialize CUDA (loading dynamic libraries from the .dll files), which is incredibly time-consuming. Is there any method to avoid this?&lt;/p&gt;

&lt;p&gt;Code is pasted below. The function &amp;quot;fitness_wrapper&amp;quot; is called for each &lt;code&gt;indiv&lt;/code&gt;idual.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def fitness_wrapper(indiv):
    fit = multi.processing.Value(&amp;#39;d&amp;#39;, 0.0)
    if __name__ == &amp;#39;__main__&amp;#39;:
        process = multiprocessing.Process(target=fitness, args=(indiv, fit))
        process.start()
        process.join()
    return (fit.value,)


def fitness(indiv, fit):
    model = tf.keras.Sequential.from_config(indiv[&amp;#39;architecture&amp;#39;])
    optimizer_dict = indiv[&amp;#39;optimizer&amp;#39;]
    opt = tf.keras.optimizers.Adam(learning_rate=optimizer_dict[&amp;#39;lr&amp;#39;], beta_1=optimizer_dict[&amp;#39;b1&amp;#39;],
                               beta_2=optimizer_dict[&amp;#39;b2&amp;#39;],
                               epsilon=optimizer_dict[&amp;#39;epsilon&amp;#39;])
    model.compile(loss=&amp;#39;binary_crossentropy&amp;#39;, optimizer=opt, metrics=[&amp;#39;accuracy&amp;#39;])
    model.fit(data_split[0], data_split[2], batch_size=32, epochs=5)
    fit = model.evaluate(data_split[1], data_split[3])[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kbuucl,True,,BadassGhost,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kbuucl/how_to_stop_cuda_from_reinitializing_for_every/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kbuucl/how_to_stop_cuda_from_reinitializing_for_every/,22217,1607800246.0,0,,False,,,,,,,,,
395,,tensorflow,"I'm hoping that you fabulous people in r/tensorflow can help me wrap my head around something

&amp;#x200B;

&amp;#x200B;

I'm learning TF to do object detection so that I can apply object detection on six home RTSP video feeds.  The application here is to trigger home automations based on what is detected in the feeds.  


&amp;#x200B;

Doing object detection on one camera in a Jupyter notebook with GPU looks strait forward to me...  What I can't figure out is how to I start to to do more than one of these in parallel, or in Docker for that matter.

&amp;#x200B;

I.E.   


Do I make one Jupyter workbook per video feed and Dockerize/deploy them separately?  


Do I try to have a single service that can handle each of the feeds?  


Or should I be thinking about this problem fundamentally differently like building a separate service that breaks the RTSP feed(s) into single frames (Camera1.png, Camera2.png, etc) and then feed those single frames to a TensorFlow workflow that posts the detections based on filename (or something)?

&amp;#x200B;

\----

&amp;#x200B;

The final deployment will be Docker via Kubernetes to either an Intel Nuc10 i7 w/ GPU or something like an Nvidia Xavier NX...  I have [a scaled down version deployed using a variation of TFLite](https://hub.docker.com/r/snowzach/doods) but I wanted to get more hands on and leverage some additional horsepower.",t2_a7rnj,False,,0,False,Help me understand object detection on multiple video feeds using Docker,[],r/tensorflow,False,6,,0,,,False,t3_kb86cp,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1607739779.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m hoping that you fabulous people in &lt;a href=""/r/tensorflow""&gt;r/tensorflow&lt;/a&gt; can help me wrap my head around something&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m learning TF to do object detection so that I can apply object detection on six home RTSP video feeds.  The application here is to trigger home automations based on what is detected in the feeds.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Doing object detection on one camera in a Jupyter notebook with GPU looks strait forward to me...  What I can&amp;#39;t figure out is how to I start to to do more than one of these in parallel, or in Docker for that matter.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I.E.   &lt;/p&gt;

&lt;p&gt;Do I make one Jupyter workbook per video feed and Dockerize/deploy them separately?  &lt;/p&gt;

&lt;p&gt;Do I try to have a single service that can handle each of the feeds?  &lt;/p&gt;

&lt;p&gt;Or should I be thinking about this problem fundamentally differently like building a separate service that breaks the RTSP feed(s) into single frames (Camera1.png, Camera2.png, etc) and then feed those single frames to a TensorFlow workflow that posts the detections based on filename (or something)?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;----&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The final deployment will be Docker via Kubernetes to either an Intel Nuc10 i7 w/ GPU or something like an Nvidia Xavier NX...  I have &lt;a href=""https://hub.docker.com/r/snowzach/doods""&gt;a scaled down version deployed using a variation of TFLite&lt;/a&gt; but I wanted to get more hands on and leverage some additional horsepower.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kb86cp,True,,GoingOffRoading,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kb86cp/help_me_understand_object_detection_on_multiple/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kb86cp/help_me_understand_object_detection_on_multiple/,22217,1607710979.0,0,,False,,,,,,,,,
396,,tensorflow,"I'm trying out transfer learning for the first time and I'm wondering if I can insert layers into the existing model. And is it possible to change some of the layers of the pre-trained, for example adding regularization to some of the existing layers. Thanks in advance!",t2_1fqpx8oo,False,,0,False,Inserting layers in existing pre-trained model,[],r/tensorflow,False,6,,0,,,False,t3_kb8zl4,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1607742276.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying out transfer learning for the first time and I&amp;#39;m wondering if I can insert layers into the existing model. And is it possible to change some of the layers of the pre-trained, for example adding regularization to some of the existing layers. Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kb8zl4,True,,ThomaschOmatic,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/kb8zl4/inserting_layers_in_existing_pretrained_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kb8zl4/inserting_layers_in_existing_pretrained_model/,22217,1607713476.0,0,,False,,,,,,,,,
397,,tensorflow,"Hey guys, first off I'm new to Tensorflow and Deep Learning so please have mercy.

I am currently working on a classifcation model for Parkinsons Disease (PD) which is supposed to predict whether a patient has PD or not. For this I am using about 600 MRI files (300 PD/300 healthy) in nifti format which are being fed to the CNN. The files have been properly preprocessed in Matlab before using them for DL. 

My problem is that the validation accuracy is fluctuating strongly from about 50% to sometimes 81/82% and I don't know why. I have tried anything I could think of and anything I found online.  
I tried adjusting learning rate, dropout, different network structures etc. etc. 

Can anyone help me get an idea of what I am doing wrong? My code is below and it is based on this tutorial from the Keras website: [https://keras.io/examples/vision/3D\_image\_classification/](https://keras.io/examples/vision/3D_image_classification/)

&amp;#x200B;

`import os`  
`import zipfile`  
`import numpy as np`  
`import tensorflow as tf`  
`import random`  
`import matplotlib.pyplot as plt`  
`from tensorflow import keras`  
`from tensorflow.keras import layers`  
`import datetime`  
`import nibabel as nib`  


`from scipy import ndimage`  


`def read_nifti_file(filepath):`  
 `# read file`  
 `scan = nib.load(filepath)`  
 `# get raw data`  
 `scan = scan.get_fdata()`  
 `return scan`  


`def normalize(volume):`  
 `""""""Normalize the Volume""""""`  
 `min = 1`  
 `max = 150`  
 `volume[volume &lt; min] = min`  
`volume[volume &gt; max] = max`  
`volume = (volume - min) / (max - min)`  
 `return volume`  


`def resize_volume(img):`  
 `""""""Resize across z-axis""""""`  
 `# set desired depth`  
 `desired_depth = 64`  
 `desired_width = 128`  
 `desired_height = 128`  
 `# get current depth`  
 `current_depth = img.shape[-1]`  
`current_width = img.shape[0]`  
`current_height = img.shape[1]`  
 `# compute depth factor`  
 `depth = current_depth / desired_depth`  
`width = current_width / desired_width`  
`height = current_height / desired_height`  
`depth_factor = 1 / depth`  
`width_factor = 1 / width`  
`height_factor = 1 / height`  
 `# Rotate`  
`# resize across z-axis`  
 `img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)`  
 `return img`  


`def remove_dimension(array):`  
 `for elem in array:`  
 `if elem.ndim == 4:`  
`np.squeeze(elem)`  
 `return elem`  
 `else:`  
 `return elem`  
 `return array`  


`def process_scan_3d(path):`  
 `""""""Read and resize Volume""""""`  
 `# Read scan`  
 `volume = read_nifti_file(path)`  
 `# Normalize`  
`# resize w,h and d`  
 `volume = normalize(volume)`  
`volume = resize_volume(volume)`  
 `return volume`  
`# scans vom 1. download`  
`DATADIR = ""/media/Chaitu_storage/vladiWorkingSpace/""`  
`CATEGORY1 = [""prep_healthy""]`  
`CATEGORY2 = [""prep_pds""]`  


`healthy_data = []`  
`pd_data = []`  


`def create_healthy_data():`  
 `for category in CATEGORY1:`  
`path = os.path.join(DATADIR, category)  # pfad zu MRT Scans`  
 `class_num = 0`  
 `for img in os.listdir(path):`  
`nifti_array = process_scan_3d(os.path.join(path, img))`  
`healthy_data.append([nifti_array, class_num])`  


`def create_pd_data():`  
 `for category in CATEGORY2:`  
`path = os.path.join(DATADIR, category)  # pfad zu MRT Scans`  
 `class_num = 1`  
 `for img in os.listdir(path):`  
`nifti_array = process_scan_3d(os.path.join(path, img))`  
`pd_data.append([nifti_array, class_num])`  


`create_healthy_data()`  
`create_pd_data()`  


`normal_scans = [] #pictures`  
`normal_labels = [] #labels`  
`abnormal_labels = []`  
`abnormal_scans = []`  


`for features, label in healthy_data:`  
`normal_scans.append(features)`  
`normal_labels.append(label)`  


`for features, label in pd_data:`  
`abnormal_scans.append(features)`  
`abnormal_labels.append(label)`  


`abnormal_scan_paths = [`  
`os.path.join(os.getcwd(), ""/media/Chaitu_storage/vladiWorkingSpace/prep_pds/"", x)`  
 `for x in os.listdir(""/media/Chaitu_storage/vladiWorkingSpace/prep_pds/"")`  
`]`  


`normal_scan_paths = [`  
`os.path.join(os.getcwd(), ""/media/Chaitu_storage/vladiWorkingSpace/prep_healthy/"", x)`  
 `for x in os.listdir(""/media/Chaitu_storage/vladiWorkingSpace/prep_healthy/"")`  
`]`  


`print(""Healthy MRI Scans"" + str(len(normal_scan_paths)))`  
`print(""PD MRI Scans"" + str(len(abnormal_scan_paths)))`  


`normal_scans = np.array(normal_scans)`  
`normal_labels = np.array(normal_labels)`  
`abnormal_scans = np.array(abnormal_scans)`  
`abnormal_labels = np.array(abnormal_labels)`  


`# Split data in the ratio 50-50 for training and validation.`  
`x_train = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)`  
`y_train = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)`  
`x_val = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)`  
`y_val = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)`  


`print(`  
 `""Number of samples in train and validation are %d and %d.""`  
 `% (x_train.shape[0], x_val.shape[0]),`  
`)`  


`def rotate(volume):`  


`def scipy_rotate(volume):`  
 `#define rotation angles`  
 `angles = [-20, -10, 5, 5, 10, 20]`  
 `#pick angles at random`  
 `angle = random.choice(angles)`  
 `#rotate vol.`  
 `volume = ndimage.rotate(volume, angle, reshape=False)`  
`volume[volume &lt; 0] = 0`  
 `volume[volume &gt; 1] = 1`  
 `return volume`  


   `augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)`  
 `return augmented_volume`  


`def train_preprocessing(volume, label):`  
 `""""""Process training data by rotating and adding a channel""""""`  
 `#Rotate volume`  
 `volume = tf.expand_dims(volume, axis=3)`  
 `return volume, label`  


`def validation_preprocessing(volume, label):`  
 `""""""Process validation data by only adding a channel.""""""`  
 `volume = tf.expand_dims(volume, axis=3)`  
 `return volume, label`  


`train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train)) #-&gt; input muss Tensor sein`  
`validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))`  


`batch_size = 4`  
`#augment on the fly during training`  
`train_dataset = (`  
`train_loader.shuffle(len(x_train))`  
`.map(train_preprocessing)`  
`.batch(batch_size)`  
`.prefetch(2)`  
`)`  


`validation_dataset = (`  
`validation_loader.shuffle(len(x_val))`  
`.map(validation_preprocessing)`  
`.batch(batch_size)`  
`.prefetch(2)`  
`)`  


`def get_model(width=128, height=128, depth=64):`  
 `""""""Build a 3D convolutional neural network model.""""""`  
 `inputs = keras.Input((width, height, depth, 1))`  


   `x = layers.Conv3D(filters=64, kernel_size=3, activation=""relu"")(inputs)`  
`x = layers.MaxPool3D(pool_size=2)(x)`  
`x = layers.BatchNormalization()(x)`  


   `x = layers.Conv3D(filters=64, kernel_size=3, activation=""relu"")(x)`  
`x = layers.MaxPool3D(pool_size=2)(x)`  
`x = layers.BatchNormalization()(x)`  


   `x = layers.Conv3D(filters=128, kernel_size=3, activation=""relu"")(x)`  
`x = layers.MaxPool3D(pool_size=2)(x)`  
`x = layers.BatchNormalization()(x)`  


   `x = layers.Conv3D(filters=256, kernel_size=3, activation=""relu"")(x)`  
`x = layers.MaxPool3D(pool_size=2)(x)`  
`x = layers.BatchNormalization()(x)`  


   `x = layers.GlobalAveragePooling3D()(x)`  
`x = layers.Dense(units=512, activation=""relu"")(x)`  
`x = layers.Dropout(0.5)(x)`  


   `outputs = layers.Dense(units=1, activation=""sigmoid"")(x)`  


`# Define the model.`  
 `model = keras.Model(inputs, outputs, name=""3dcnn"")`  
 `return model`  


`# Build model`  
`model = get_model(width=128, height=128, depth=64)`  
`model.summary()`  


`'''#Complie Model`  
`initial_learning_rate = 0.0005`  
`lr_schedule = keras.optimizers.schedules.ExponentialDecay(`  
`initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True`  
`)'''`  
`model.compile(`  
 `loss=""binary_crossentropy"",`  
 `optimizer=keras.optimizers.Adam(learning_rate=0.00003), #Change next run`  
 `metrics=[""acc""],`  
`)`  


`log_dir = ""logs/fit/"" + datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")`  
`tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)`  


`# Define callbacks.`  
`checkpoint_cb = keras.callbacks.ModelCheckpoint(`  
 `save_weights_only=False, filepath=""parkinson_classification.h5"", save_best_only=True, monitor=""val_acc""`  
`)`  
`early_stopping_cb = keras.callbacks.EarlyStopping(monitor=""val_acc"", patience=30)`  


`# Train the model, doing validation at the end of each epoch`  
`epochs = 100`  
`model.fit(`  
`train_dataset,`  
 `validation_data=validation_dataset,`  
 `epochs=epochs,`  
 `shuffle=True,`  
 `verbose=1,`  
 `callbacks=[checkpoint_cb,tensorboard_callback]`  
`)`",t2_zh82v,False,,0,False,3D CNN Model not learning?,[],r/tensorflow,False,6,,0,,,False,t3_kb40ua,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1607726549.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, first off I&amp;#39;m new to Tensorflow and Deep Learning so please have mercy.&lt;/p&gt;

&lt;p&gt;I am currently working on a classifcation model for Parkinsons Disease (PD) which is supposed to predict whether a patient has PD or not. For this I am using about 600 MRI files (300 PD/300 healthy) in nifti format which are being fed to the CNN. The files have been properly preprocessed in Matlab before using them for DL. &lt;/p&gt;

&lt;p&gt;My problem is that the validation accuracy is fluctuating strongly from about 50% to sometimes 81/82% and I don&amp;#39;t know why. I have tried anything I could think of and anything I found online.&lt;br/&gt;
I tried adjusting learning rate, dropout, different network structures etc. etc. &lt;/p&gt;

&lt;p&gt;Can anyone help me get an idea of what I am doing wrong? My code is below and it is based on this tutorial from the Keras website: &lt;a href=""https://keras.io/examples/vision/3D_image_classification/""&gt;https://keras.io/examples/vision/3D_image_classification/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;import os&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import zipfile&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import numpy as np&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import tensorflow as tf&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import random&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import matplotlib.pyplot as plt&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;from tensorflow import keras&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;from tensorflow.keras import layers&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import datetime&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;import nibabel as nib&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;from scipy import ndimage&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def read_nifti_file(filepath):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# read file&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;scan = nib.load(filepath)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# get raw data&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;scan = scan.get_fdata()&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return scan&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def normalize(volume):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Normalize the Volume&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;min = 1&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;max = 150&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume[volume &amp;lt; min] = min&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;volume[volume &amp;gt; max] = max&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;volume = (volume - min) / (max - min)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return volume&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def resize_volume(img):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Resize across z-axis&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# set desired depth&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;desired_depth = 64&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;desired_width = 128&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;desired_height = 128&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# get current depth&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;current_depth = img.shape[-1]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;current_width = img.shape[0]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;current_height = img.shape[1]&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# compute depth factor&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;depth = current_depth / desired_depth&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;width = current_width / desired_width&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;height = current_height / desired_height&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;depth_factor = 1 / depth&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;width_factor = 1 / width&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;height_factor = 1 / height&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Rotate&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;# resize across z-axis&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return img&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def remove_dimension(array):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for elem in array:&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;if elem.ndim == 4:&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;np.squeeze(elem)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return elem&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;else:&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return elem&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return array&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def process_scan_3d(path):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Read and resize Volume&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Read scan&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume = read_nifti_file(path)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;# Normalize&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;# resize w,h and d&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume = normalize(volume)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;volume = resize_volume(volume)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return volume&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;# scans vom 1. download&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;DATADIR = &amp;quot;/media/Chaitu_storage/vladiWorkingSpace/&amp;quot;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;CATEGORY1 = [&amp;quot;prep_healthy&amp;quot;]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;CATEGORY2 = [&amp;quot;prep_pds&amp;quot;]&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;healthy_data = []&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;pd_data = []&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def create_healthy_data():&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for category in CATEGORY1:&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;path = os.path.join(DATADIR, category)  # pfad zu MRT Scans&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;class_num = 0&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for img in os.listdir(path):&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;nifti_array = process_scan_3d(os.path.join(path, img))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;healthy_data.append([nifti_array, class_num])&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def create_pd_data():&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for category in CATEGORY2:&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;path = os.path.join(DATADIR, category)  # pfad zu MRT Scans&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;class_num = 1&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for img in os.listdir(path):&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;nifti_array = process_scan_3d(os.path.join(path, img))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;pd_data.append([nifti_array, class_num])&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;create_healthy_data()&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;create_pd_data()&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;normal_scans = [] #pictures&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;normal_labels = [] #labels&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;abnormal_labels = []&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;abnormal_scans = []&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;for features, label in healthy_data:&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;normal_scans.append(features)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;normal_labels.append(label)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;for features, label in pd_data:&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;abnormal_scans.append(features)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;abnormal_labels.append(label)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;abnormal_scan_paths = [&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;os.path.join(os.getcwd(), &amp;quot;/media/Chaitu_storage/vladiWorkingSpace/prep_pds/&amp;quot;, x)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for x in os.listdir(&amp;quot;/media/Chaitu_storage/vladiWorkingSpace/prep_pds/&amp;quot;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;]&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;normal_scan_paths = [&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;os.path.join(os.getcwd(), &amp;quot;/media/Chaitu_storage/vladiWorkingSpace/prep_healthy/&amp;quot;, x)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;for x in os.listdir(&amp;quot;/media/Chaitu_storage/vladiWorkingSpace/prep_healthy/&amp;quot;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;]&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;print(&amp;quot;Healthy MRI Scans&amp;quot; + str(len(normal_scan_paths)))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;print(&amp;quot;PD MRI Scans&amp;quot; + str(len(abnormal_scan_paths)))&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;normal_scans = np.array(normal_scans)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;normal_labels = np.array(normal_labels)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;abnormal_scans = np.array(abnormal_scans)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;abnormal_labels = np.array(abnormal_labels)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Split data in the ratio 50-50 for training and validation.&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x_train = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;y_train = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x_val = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;y_val = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;print(&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;Number of samples in train and validation are %d and %d.&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;% (x_train.shape[0], x_val.shape[0]),&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def rotate(volume):&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def scipy_rotate(volume):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#define rotation angles&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;angles = [-20, -10, 5, 5, 10, 20]&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#pick angles at random&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;angle = random.choice(angles)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#rotate vol.&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume = ndimage.rotate(volume, angle, reshape=False)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;volume[volume &amp;lt; 0] = 0&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume[volume &amp;gt; 1] = 1&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return volume&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return augmented_volume&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def train_preprocessing(volume, label):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Process training data by rotating and adding a channel&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#Rotate volume&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume = tf.expand_dims(volume, axis=3)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return volume, label&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def validation_preprocessing(volume, label):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Process validation data by only adding a channel.&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;volume = tf.expand_dims(volume, axis=3)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return volume, label&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train)) #-&amp;gt; input muss Tensor sein&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;batch_size = 4&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;#augment on the fly during training&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;train_dataset = (&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;train_loader.shuffle(len(x_train))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.map(train_preprocessing)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.batch(batch_size)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.prefetch(2)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;validation_dataset = (&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;validation_loader.shuffle(len(x_val))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.map(validation_preprocessing)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.batch(batch_size)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;.prefetch(2)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;def get_model(width=128, height=128, depth=64):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;Build a 3D convolutional neural network model.&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;inputs = keras.Input((width, height, depth, 1))&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;x = layers.Conv3D(filters=64, kernel_size=3, activation=&amp;quot;relu&amp;quot;)(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.MaxPool3D(pool_size=2)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;x = layers.Conv3D(filters=64, kernel_size=3, activation=&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.MaxPool3D(pool_size=2)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;x = layers.Conv3D(filters=128, kernel_size=3, activation=&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.MaxPool3D(pool_size=2)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;x = layers.Conv3D(filters=256, kernel_size=3, activation=&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.MaxPool3D(pool_size=2)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.BatchNormalization()(x)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;x = layers.GlobalAveragePooling3D()(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.Dense(units=512, activation=&amp;quot;relu&amp;quot;)(x)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x = layers.Dropout(0.5)(x)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;outputs = layers.Dense(units=1, activation=&amp;quot;sigmoid&amp;quot;)(x)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Define the model.&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;model = keras.Model(inputs, outputs, name=&amp;quot;3dcnn&amp;quot;)&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return model&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Build model&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model = get_model(width=128, height=128, depth=64)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.summary()&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;#39;&amp;#39;&amp;#39;#Complie Model&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;initial_learning_rate = 0.0005&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;lr_schedule = keras.optimizers.schedules.ExponentialDecay(&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&amp;#39;&amp;#39;&amp;#39;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.compile(&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;loss=&amp;quot;binary_crossentropy&amp;quot;,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;optimizer=keras.optimizers.Adam(learning_rate=0.00003), #Change next run&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;metrics=[&amp;quot;acc&amp;quot;],&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;log_dir = &amp;quot;logs/fit/&amp;quot; + datetime.datetime.now().strftime(&amp;quot;%Y%m%d-%H%M%S&amp;quot;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Define callbacks.&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;checkpoint_cb = keras.callbacks.ModelCheckpoint(&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;save_weights_only=False, filepath=&amp;quot;parkinson_classification.h5&amp;quot;, save_best_only=True, monitor=&amp;quot;val_acc&amp;quot;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;early_stopping_cb = keras.callbacks.EarlyStopping(monitor=&amp;quot;val_acc&amp;quot;, patience=30)&lt;/code&gt;  &lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Train the model, doing validation at the end of each epoch&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;epochs = 100&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.fit(&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;train_dataset,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;validation_data=validation_dataset,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;epochs=epochs,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;shuffle=True,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;verbose=1,&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;callbacks=[checkpoint_cb,tensorboard_callback]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kb40ua,True,,vladislavus,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/kb40ua/3d_cnn_model_not_learning/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kb40ua/3d_cnn_model_not_learning/,22217,1607697749.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&amp;s=0c3f0b8af92c3a962f569a389e9673597e12f8ec', 'width': 774, 'height': 269}, 'resolutions': [{'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9985b1dc92701ea8c38c4bb72a28d50198fb54ab', 'width': 108, 'height': 37}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a7452ccf0826692f35ac78457de9275d52f5935', 'width': 216, 'height': 75}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ae2ffe955b207d1da9c058b01c62aff9e80110d7', 'width': 320, 'height': 111}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff31c7e26d2e15f6faa6e4bedc2a41dfe0eab9ab', 'width': 640, 'height': 222}], 'variants': {}, 'id': 'qsh7aKFxRPo6CaMu10A7nekvx_ez8hkySyb6h9YVvHI'}], 'enabled': False}",,,,,,
398,,tensorflow,"Hi, I hope there is someone on this sub that is able to help me

I'm currently trying to recreate a TensorFlow model in MXNet and so far I'm managing okay but there is one specific variable that they use that I cannot for the life of me find a MXNet version for.

The line is  `lod_in = tf.cast(tf.get_variable('lod', initializer=np.float32(0.0), trainable=False), 'float32')`

The model I'm recreating is itself based on an older Theano model in which they have a similar variable which is initialised as:  `cur_lod = theano.shared(np.float32(0.0))`

Now I'm trying to find a MXnet version for this type of Variable but I cannot find it anywhere online.

Does anyone know a good substitution that will do the same?",t2_ze5sd,False,,0,False,Shared Variable on MXNet,[],r/tensorflow,False,6,,0,,,False,t3_kb2mmv,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1607721576.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I hope there is someone on this sub that is able to help me&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently trying to recreate a TensorFlow model in MXNet and so far I&amp;#39;m managing okay but there is one specific variable that they use that I cannot for the life of me find a MXNet version for.&lt;/p&gt;

&lt;p&gt;The line is  &lt;code&gt;lod_in = tf.cast(tf.get_variable(&amp;#39;lod&amp;#39;, initializer=np.float32(0.0), trainable=False), &amp;#39;float32&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The model I&amp;#39;m recreating is itself based on an older Theano model in which they have a similar variable which is initialised as:  &lt;code&gt;cur_lod = theano.shared(np.float32(0.0))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Now I&amp;#39;m trying to find a MXnet version for this type of Variable but I cannot find it anywhere online.&lt;/p&gt;

&lt;p&gt;Does anyone know a good substitution that will do the same?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kb2mmv,True,,Real_Skullpoopl,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kb2mmv/shared_variable_on_mxnet/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kb2mmv/shared_variable_on_mxnet/,22217,1607692776.0,0,,False,,,,,,,,,
399,,tensorflow,"Hi, a current university student and working on my own time on learning AI/ML. I've been recreating a CNN model proposed in a research paper which is as follows below. It works using the regular tensorflow environment on my CPU. 

Today I was able to find a reddit thread and create a new environment with tf-nightly-gpu and manually install CUDA 11.1 as well as cuDNN and add it to my path. Now Anaconda is able to find and detect my RTX 3080 but it throws errors which don't occur with the cpu-tensorflow. It seems to not like using ""history = model.fit("" but I couldn't find anything online for needing to use something else if I was training with my GPU. I was wondering if I was missing anything to enable using my GPU for tensorflow, as I've never used a GPU for it and don't know too much. 

I have included a screenshot of the output and error in Anaconda prompt in this picture album https://imgur.com/a/4HuOrAq. Any help could be much appreciated, thanks for your time! 

    import tensorflow as tf
    
    from tensorflow import keras
    from tensorflow.keras import datasets, layers, models
    from tensorflow.keras.preprocessing.image import ImageDataGenerator
    from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization
    from tensorflow.keras.models import Sequential
    import matplotlib.pyplot as plt
    from tensorflow.python.client import device_lib
    
    def plot_model_acc(history):
    	#model history for accuracy
    	plt.plot(history.history['accuracy'], label='accuracy')
    	plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
    	plt.title('Model Accuracy')
    	plt.xlabel('Epoch')
    	plt.ylabel('Accuracy')
    	plt.legend(['train','test'], loc='upper left')
    	plt.savefig('model_acc.png', bbox_inches='tight')
    	plt.close()
    
    def plot_model_loss(history):
    	#model history for loss
    	plt.plot(history.history['loss'], label='loss')
    	plt.plot(history.history['val_loss'], label='val_loss')
    	plt.title('Model Loss')
    	plt.ylabel('Loss')
    	plt.xlabel('Epoch')
    	plt.legend(['train', 'test'], loc='upper left')
    	plt.savefig('model_loss.png', bbox_inches='tight')
    	plt.close()
    
    #test if GPU is working
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    print(device_lib.list_local_devices())
    
    #model parameters
    train_directory = 'train'
    test_directory = 'test'
    val_directory = 'validation'
    num_train = 28709
    num_test = 7178
    num_val = 7178
    batch_size = 64
    num_epoch = 50
    
    
    #creating datagen class and rescaling pixel values from  0-255 to 0-1 for grayscale
    train_datagen = ImageDataGenerator(rescale=1./255)
    test_datagen = ImageDataGenerator(rescale=1./255)
    val_datagen = ImageDataGenerator(rescale=1./255)
    
    #angry 0, disgusted 1, fearful 2, happy 3, neutral 4, sad 5, surprised 6
    
    train_iterator = train_datagen.flow_from_directory(
    	train_directory,
    	target_size=(64, 64),
    	class_mode='categorical',
    	batch_size=batch_size,
    	color_mode='grayscale')
    
    test_iterator = test_datagen.flow_from_directory(
    	test_directory,
    	target_size=(64, 64),
    	class_mode='categorical',
    	batch_size=batch_size,
    	color_mode='grayscale')
    
    val_iterator = val_datagen.flow_from_directory(
    	val_directory,
    	target_size=(64, 64),
    	class_mode='categorical',
    	batch_size=batch_size,
    	color_mode='grayscale')
    #colormode grayscale since rescale=1./255
    #class_mode is categorical, returns 2D one-hot encoded label
    
    #model creation
    #output layer size after conv layer is 
    #[(W−K+2P)/S]+1.
    #W is the input volume - in your case 64 (for 64x64x1 image)
    #K is the Kernel size - in your case 8
    #P is the padding - in your case 0
    #S is the stride - which you have not provided.
    
    
    model = Sequential()
    
    model.add(Conv2D(32, kernel_size=(8, 8), input_shape=(64,64,1)))
    model.add(BatchNormalization())
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    
    #model.summary()
    
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    
    #model.summary()
    
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    
    #model.summary()
    
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(32, kernel_size=(8, 8), activation='relu', strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(8, 8), padding='same'))
    model.add(BatchNormalization())
    
    #model.summary()
    
    model.add(Conv2D(7, kernel_size=(7, 7), strides=(1,1), padding='same'))
    model.add(layers.Activation('softmax'))
    
    model.summary()
    
    
    #optimizer definition, learning rate, lower takes more time, but high values may cause unstable training
    adam_optimizer = keras.optimizers.Adam(learning_rate=0.0001)
    
    #CategoricalCrossentropy for one-hot encoded labels and dense layer uses softmax activation, otherwise use other loss functions
    model.compile(optimizer=adam_optimizer,
                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])
    
    history = model.fit(
    	train_iterator, 
    	steps_per_epoch=num_train // batch_size, 
    	epochs=num_epoch,
    	validation_data=test_iterator,
    	validation_steps=num_val // batch_size
    	)
    
    print(history.history.keys())
    plot_model_acc(history)
    plot_model_loss(history)
    model.save_weights('model.h5')",t2_6axlf,False,,0,False,"Tensorflow model works with CPU, but using tf-gpu environment leads to errors",[],r/tensorflow,False,6,,0,,,False,t3_kb8hvy,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1607712416.0,,[],{},,True,,1607740795.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, a current university student and working on my own time on learning AI/ML. I&amp;#39;ve been recreating a CNN model proposed in a research paper which is as follows below. It works using the regular tensorflow environment on my CPU. &lt;/p&gt;

&lt;p&gt;Today I was able to find a reddit thread and create a new environment with tf-nightly-gpu and manually install CUDA 11.1 as well as cuDNN and add it to my path. Now Anaconda is able to find and detect my RTX 3080 but it throws errors which don&amp;#39;t occur with the cpu-tensorflow. It seems to not like using &amp;quot;history = model.fit(&amp;quot; but I couldn&amp;#39;t find anything online for needing to use something else if I was training with my GPU. I was wondering if I was missing anything to enable using my GPU for tensorflow, as I&amp;#39;ve never used a GPU for it and don&amp;#39;t know too much. &lt;/p&gt;

&lt;p&gt;I have included a screenshot of the output and error in Anaconda prompt in this picture album &lt;a href=""https://imgur.com/a/4HuOrAq""&gt;https://imgur.com/a/4HuOrAq&lt;/a&gt;. Any help could be much appreciated, thanks for your time! &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
from tensorflow.python.client import device_lib

def plot_model_acc(history):
    #model history for accuracy
    plt.plot(history.history[&amp;#39;accuracy&amp;#39;], label=&amp;#39;accuracy&amp;#39;)
    plt.plot(history.history[&amp;#39;val_accuracy&amp;#39;], label = &amp;#39;val_accuracy&amp;#39;)
    plt.title(&amp;#39;Model Accuracy&amp;#39;)
    plt.xlabel(&amp;#39;Epoch&amp;#39;)
    plt.ylabel(&amp;#39;Accuracy&amp;#39;)
    plt.legend([&amp;#39;train&amp;#39;,&amp;#39;test&amp;#39;], loc=&amp;#39;upper left&amp;#39;)
    plt.savefig(&amp;#39;model_acc.png&amp;#39;, bbox_inches=&amp;#39;tight&amp;#39;)
    plt.close()

def plot_model_loss(history):
    #model history for loss
    plt.plot(history.history[&amp;#39;loss&amp;#39;], label=&amp;#39;loss&amp;#39;)
    plt.plot(history.history[&amp;#39;val_loss&amp;#39;], label=&amp;#39;val_loss&amp;#39;)
    plt.title(&amp;#39;Model Loss&amp;#39;)
    plt.ylabel(&amp;#39;Loss&amp;#39;)
    plt.xlabel(&amp;#39;Epoch&amp;#39;)
    plt.legend([&amp;#39;train&amp;#39;, &amp;#39;test&amp;#39;], loc=&amp;#39;upper left&amp;#39;)
    plt.savefig(&amp;#39;model_loss.png&amp;#39;, bbox_inches=&amp;#39;tight&amp;#39;)
    plt.close()

#test if GPU is working
print(&amp;quot;Num GPUs Available: &amp;quot;, len(tf.config.experimental.list_physical_devices(&amp;#39;GPU&amp;#39;)))
print(device_lib.list_local_devices())

#model parameters
train_directory = &amp;#39;train&amp;#39;
test_directory = &amp;#39;test&amp;#39;
val_directory = &amp;#39;validation&amp;#39;
num_train = 28709
num_test = 7178
num_val = 7178
batch_size = 64
num_epoch = 50


#creating datagen class and rescaling pixel values from  0-255 to 0-1 for grayscale
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

#angry 0, disgusted 1, fearful 2, happy 3, neutral 4, sad 5, surprised 6

train_iterator = train_datagen.flow_from_directory(
    train_directory,
    target_size=(64, 64),
    class_mode=&amp;#39;categorical&amp;#39;,
    batch_size=batch_size,
    color_mode=&amp;#39;grayscale&amp;#39;)

test_iterator = test_datagen.flow_from_directory(
    test_directory,
    target_size=(64, 64),
    class_mode=&amp;#39;categorical&amp;#39;,
    batch_size=batch_size,
    color_mode=&amp;#39;grayscale&amp;#39;)

val_iterator = val_datagen.flow_from_directory(
    val_directory,
    target_size=(64, 64),
    class_mode=&amp;#39;categorical&amp;#39;,
    batch_size=batch_size,
    color_mode=&amp;#39;grayscale&amp;#39;)
#colormode grayscale since rescale=1./255
#class_mode is categorical, returns 2D one-hot encoded label

#model creation
#output layer size after conv layer is 
#[(W−K+2P)/S]+1.
#W is the input volume - in your case 64 (for 64x64x1 image)
#K is the Kernel size - in your case 8
#P is the padding - in your case 0
#S is the stride - which you have not provided.


model = Sequential()

model.add(Conv2D(32, kernel_size=(8, 8), input_shape=(64,64,1)))
model.add(BatchNormalization())
model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())

#model.summary()

model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())
model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())

#model.summary()

model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())
model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())

#model.summary()

model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())
model.add(Conv2D(32, kernel_size=(8, 8), activation=&amp;#39;relu&amp;#39;, strides=(2,2), padding=&amp;#39;same&amp;#39;))
model.add(Conv2D(32, kernel_size=(8, 8), padding=&amp;#39;same&amp;#39;))
model.add(BatchNormalization())

#model.summary()

model.add(Conv2D(7, kernel_size=(7, 7), strides=(1,1), padding=&amp;#39;same&amp;#39;))
model.add(layers.Activation(&amp;#39;softmax&amp;#39;))

model.summary()


#optimizer definition, learning rate, lower takes more time, but high values may cause unstable training
adam_optimizer = keras.optimizers.Adam(learning_rate=0.0001)

#CategoricalCrossentropy for one-hot encoded labels and dense layer uses softmax activation, otherwise use other loss functions
model.compile(optimizer=adam_optimizer,
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=[&amp;#39;accuracy&amp;#39;])

history = model.fit(
    train_iterator, 
    steps_per_epoch=num_train // batch_size, 
    epochs=num_epoch,
    validation_data=test_iterator,
    validation_steps=num_val // batch_size
    )

print(history.history.keys())
plot_model_acc(history)
plot_model_loss(history)
model.save_weights(&amp;#39;model.h5&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kb8hvy,True,,BearBaron,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kb8hvy/tensorflow_model_works_with_cpu_but_using_tfgpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kb8hvy/tensorflow_model_works_with_cpu_but_using_tfgpu/,22217,1607711995.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?auto=webp&amp;s=b4d401009e61f3a567937997e007809180e57bf2', 'width': 2023, 'height': 1145}, 'resolutions': [{'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cbbc4dd90630a9b26de180f11f4e23ddb8575685', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4dd4755596e3e24141a1d930d6527cc676a4562', 'width': 216, 'height': 122}, {'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9e20ed7c6adb9c047b6bf2a94174ccc088a7490', 'width': 320, 'height': 181}, {'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ff8246edd7f619667cdace0265cf314837978b4', 'width': 640, 'height': 362}, {'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=524489fa03ec22735f734f00b0759699b5c1a58f', 'width': 960, 'height': 543}, {'url': 'https://external-preview.redd.it/sxuiiyIhSH2Hbnt7bERR5o0exvJdDAmmRaUPYsM9DVc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=74b33fcf26f8a224edb428efebd3487162749a89', 'width': 1080, 'height': 611}], 'variants': {}, 'id': 'eOhmzU6e1hS21LHU9Xy2ajVhWHsdQ81sRW5n8WtmGNE'}], 'enabled': False}",,,,,,
400,,tensorflow,"Hi everyone, 

I hope it is okay if I come here with my question. I am totally out of ideas and getting really frustrated. Not really an expert, so I am sorry if I use the wrong terminology.

My goal is to write a simple app  with Flutter that classifies images, as seen in countless examples (I used the Cat vs Dog classifier app as a starting point, and that works just fine). I want to use my own model for now.

I created a simple CNN using keras in Python. I trained it, tested it, saved it, and converted it to Tensorflow Lite. 

    model = Sequential()
    model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(128, 128, 3)))
    model.add(MaxPooling2D(2, 2))
    model.add(Conv2D(64, kernel_size=3, activation='relu'))
    model.add(MaxPooling2D(2, 2))
    model.add(Conv2D(128, kernel_size=3, activation='relu'))
    model.add(MaxPooling2D(2, 2))
    model.add(Conv2D(256, kernel_size=3, activation='relu'))
    model.add(MaxPooling2D(2, 2))
    model.add(Flatten())
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)

   # Convert the model
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory
    tflite_model = converter.convert()

    # Save the model.
    with open('model_displays.tflite', 'wb') as f:
        f.write(tflite_model)

Now I just changed two things in the existing, working app: I added the model to the assets folder, and changed the label.txt file to contain my two classes. And of course I changed the code to predict using my own model from the assets folder.

The model does predict stuff based on pictures I take, but the predictions are totally wrong, and it also always predicts just one class, never the other. When I play around with imageStd and imageMean in the runModelOnImage() function, I get different prediction values, but the prediction is still wrong.

When I test the saved tflite model using the tensorflow lite interpreter on my computer, it works just fine. So where I am going wrong? Why does it simply not work in Flutter/on my device?

It would be awesome if someone could help me out here.",t2_whkzc,False,,0,False,"Tensorflow Lite Model predicts wrong on device, works fine when tested with tf_lite interpreter",[],r/tensorflow,False,6,,0,,,False,t3_kazihc,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1607707080.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;

&lt;p&gt;I hope it is okay if I come here with my question. I am totally out of ideas and getting really frustrated. Not really an expert, so I am sorry if I use the wrong terminology.&lt;/p&gt;

&lt;p&gt;My goal is to write a simple app  with Flutter that classifies images, as seen in countless examples (I used the Cat vs Dog classifier app as a starting point, and that works just fine). I want to use my own model for now.&lt;/p&gt;

&lt;p&gt;I created a simple CNN using keras in Python. I trained it, tested it, saved it, and converted it to Tensorflow Lite. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model = Sequential()
model.add(Conv2D(32, kernel_size=3, activation=&amp;#39;relu&amp;#39;, input_shape=(128, 128, 3)))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(64, kernel_size=3, activation=&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(128, kernel_size=3, activation=&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(256, kernel_size=3, activation=&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(2, 2))
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation=&amp;#39;softmax&amp;#39;))

model.compile(optimizer=&amp;#39;adam&amp;#39;, loss=&amp;#39;categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;# Convert the model
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory
    tflite_model = converter.convert()&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Save the model.
with open(&amp;#39;model_displays.tflite&amp;#39;, &amp;#39;wb&amp;#39;) as f:
    f.write(tflite_model)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I just changed two things in the existing, working app: I added the model to the assets folder, and changed the label.txt file to contain my two classes. And of course I changed the code to predict using my own model from the assets folder.&lt;/p&gt;

&lt;p&gt;The model does predict stuff based on pictures I take, but the predictions are totally wrong, and it also always predicts just one class, never the other. When I play around with imageStd and imageMean in the runModelOnImage() function, I get different prediction values, but the prediction is still wrong.&lt;/p&gt;

&lt;p&gt;When I test the saved tflite model using the tensorflow lite interpreter on my computer, it works just fine. So where I am going wrong? Why does it simply not work in Flutter/on my device?&lt;/p&gt;

&lt;p&gt;It would be awesome if someone could help me out here.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kazihc,True,,Pantoffeltier,,11,True,all_ads,False,[],False,,/r/tensorflow/comments/kazihc/tensorflow_lite_model_predicts_wrong_on_device/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kazihc/tensorflow_lite_model_predicts_wrong_on_device/,22217,1607678280.0,0,,False,,,,,,,,,
401,,tensorflow,,t2_pbxa3,False,,0,False,JetBrains introduced KotlinDL: Keras-like high-level Kotlin Framework based on TensorFlow,[],r/tensorflow,False,6,,0,70.0,,False,t3_kag9fy,False,dark,0.94,,public,26,0,{},140.0,,False,[],,False,False,,{},,False,26,,False,https://b.thumbs.redditmedia.com/4tQ7KDVUueFV_bvc_uXoYltw8Mu9QhYts94s5FMHjiE.jpg,False,,[],{},,False,,1607639585.0,text,6,,,text,blog.jetbrains.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kag9fy,True,,belovrv,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/kag9fy/jetbrains_introduced_kotlindl_keraslike_highlevel/,all_ads,False,https://blog.jetbrains.com/kotlin/2020/12/deep-learning-with-kotlin-introducing-kotlindl-alpha/,22217,1607610785.0,0,,False,link,https://blog.jetbrains.com/kotlin/2020/12/deep-learning-with-kotlin-introducing-kotlindl-alpha/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?auto=webp&amp;s=589c3aa22834001b613a72e2628b515cd1497e93', 'width': 3000, 'height': 1502}, 'resolutions': [{'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83283fc12014887cce789762227f54eedf35f328', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=87809f9c683c9182c7dc648b2fa0abc3d53613c1', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=64c918dfb1a9aeedcf3cbee492ac210f5a501aaf', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2bc3d3db6f421ae213623125ed53a4a59e553239', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9f3ed88cd81dab3dfc8a517d1ed9d7790d52b815', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/ZtSnr8m-cQDxQwIS4pxMZMu4hlP8OXN70eHSzAMFJ2o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=458d7a5e8f9739fbde9d6f0f56414bb285a71d5e', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'T8UO2u2N1UQWFcUJdQyezSUjl0STemyrOKXo7JKiWaQ'}], 'enabled': False}",,,,,,
402,,tensorflow,,t2_79p1h62w,False,,0,False,AI Engineer asks what’s the difference between TensorFlow 1.0 and Tensorflow 2.0,[],r/tensorflow,False,6,,0,,,False,t3_kawpcx,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,default,False,,[],{},,False,,1607693689.0,text,6,,,text,recentlyheard.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kawpcx,True,,Shradha_Singh,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/kawpcx/ai_engineer_asks_whats_the_difference_between/,all_ads,False,https://recentlyheard.com/2020/12/10/ai-engineer-asks-whats-the-difference-between-tensorflow-1-0-and-tensorflow-2-0/,22217,1607664889.0,0,,False,,https://recentlyheard.com/2020/12/10/ai-engineer-asks-whats-the-difference-between-tensorflow-1-0-and-tensorflow-2-0/,,,,,,,
403,,tensorflow,"I get this message twice: `W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence [[{{node IteratorGetNext}}]]`

As well as this message:  `Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least (steps_per_epoch * epochs) batches (in this case, 2 batches). You may need to use the repeat() function when building your dataset.`

This is weird, because despite getting this message, the prediction works fine and I get the desired result. (It's also weird that it says ""interrupting training"", because the message only occurs during inference, not during training)

Here's the details for the model:

Images: 750

Train/test splits: 0.8

Epochs: 10

Batch size: default",t2_3006ll5,False,,0,False,"The model I trained with my own generated data works fine, but every time I make a prediction, I get some strange red text?",[],r/tensorflow,False,6,,0,,,False,t3_kaofwq,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607663837.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I get this message twice: &lt;code&gt;W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence [[{{node IteratorGetNext}}]]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As well as this message:  &lt;code&gt;Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least (steps_per_epoch * epochs) batches (in this case, 2 batches). You may need to use the repeat() function when building your dataset.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is weird, because despite getting this message, the prediction works fine and I get the desired result. (It&amp;#39;s also weird that it says &amp;quot;interrupting training&amp;quot;, because the message only occurs during inference, not during training)&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s the details for the model:&lt;/p&gt;

&lt;p&gt;Images: 750&lt;/p&gt;

&lt;p&gt;Train/test splits: 0.8&lt;/p&gt;

&lt;p&gt;Epochs: 10&lt;/p&gt;

&lt;p&gt;Batch size: default&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kaofwq,True,,MrZipZap,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kaofwq/the_model_i_trained_with_my_own_generated_data/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kaofwq/the_model_i_trained_with_my_own_generated_data/,22217,1607635037.0,0,,False,,,,,,,,,
404,,tensorflow,So I have 3D images and associated labels. The labels are 3D images of the same shape as the data images and I have 8 segmentation classes. How can I go from the raw labels (which are float pixel values with 8 fixed values between 0 and 880) to label values of integers from 0 to 7 (one int value for each class)?,t2_4xt7vl5p,False,,0,False,How do I process my 3D labels for multiclass semantic segmentation?,[],r/tensorflow,False,6,,0,,,False,t3_kajhj5,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1607649621.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have 3D images and associated labels. The labels are 3D images of the same shape as the data images and I have 8 segmentation classes. How can I go from the raw labels (which are float pixel values with 8 fixed values between 0 and 880) to label values of integers from 0 to 7 (one int value for each class)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kajhj5,True,,convnetto,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kajhj5/how_do_i_process_my_3d_labels_for_multiclass/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kajhj5/how_do_i_process_my_3d_labels_for_multiclass/,22217,1607620821.0,0,,False,,,,,,,,,
405,,tensorflow,,t2_2wsvqwhg,False,,0,False,TensorFlow Releases Its New Update: TensorFlow 2.4.0-rc4,[],r/tensorflow,False,6,,0,82.0,,False,t3_kabgnf,False,dark,0.87,,public,11,0,{},140.0,,False,[],,False,False,,{},Discussion,False,11,,False,https://b.thumbs.redditmedia.com/7BNOuO3HmSW7FlcolDjMrNyYNM37hhb5PGJ2oVXWtkM.jpg,False,,[],{},,False,,1607616232.0,text,6,,,text,marktechpost.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,kabgnf,True,,ai-lover,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/kabgnf/tensorflow_releases_its_new_update_tensorflow/,all_ads,False,https://www.marktechpost.com/2020/12/09/tensorflow-releases-its-new-update-tensorflow-2-4-0-rc4/,22217,1607587432.0,0,,False,link,https://www.marktechpost.com/2020/12/09/tensorflow-releases-its-new-update-tensorflow-2-4-0-rc4/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Dn8uLGLFMx2f654hLq5-re9v-y3TXSZswOacz9y-IWY.jpg?auto=webp&amp;s=b86698e8a5e70a0d0ea818dc5afab3582e80001b', 'width': 789, 'height': 465}, 'resolutions': [{'url': 'https://external-preview.redd.it/Dn8uLGLFMx2f654hLq5-re9v-y3TXSZswOacz9y-IWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d313b115afcd3ef604341da64cb3e7d04f1e6ed6', 'width': 108, 'height': 63}, {'url': 'https://external-preview.redd.it/Dn8uLGLFMx2f654hLq5-re9v-y3TXSZswOacz9y-IWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2cee7db2e8630271e0438c3e5b8694d913fd53f', 'width': 216, 'height': 127}, {'url': 'https://external-preview.redd.it/Dn8uLGLFMx2f654hLq5-re9v-y3TXSZswOacz9y-IWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd20d0ea964c367a73ff2b9f48bd74c015a0d509', 'width': 320, 'height': 188}, {'url': 'https://external-preview.redd.it/Dn8uLGLFMx2f654hLq5-re9v-y3TXSZswOacz9y-IWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=87e79e8f4460e6b466c63f56afa4efc4c9ab390f', 'width': 640, 'height': 377}], 'variants': {}, 'id': 'gXzIaom1dKlAbBrMRZLvaydMlCt1n4IjKAEn5PAYFek'}], 'enabled': False}",,,,,,
406,,tensorflow,"Hi everyone,

I'm trying to create a NN for reading a simple captcha that is 5 characters long. I've used a one hot encoding for each token (there are 23 of then), so my labels have shape of (5, 23). When a try to fit the model a get the following error

&amp;#x200B;

`clf.fit(x_train[0], y[0])`

`(...)`

`ValueError: Data cardinality is ambiguous:   x sizes: 1   y sizes: 5`

&amp;#x200B;

Since I'm more used to make (typical) classification models I'm unsure on how to proper encode my label vector. tks",t2_qr6xx,False,,0,False,How to fit a model for a image to text net work,[],r/tensorflow,False,6,,0,,,False,t3_kaly4h,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1607656720.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to create a NN for reading a simple captcha that is 5 characters long. I&amp;#39;ve used a one hot encoding for each token (there are 23 of then), so my labels have shape of (5, 23). When a try to fit the model a get the following error&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;clf.fit(x_train[0], y[0])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;(...)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ValueError: Data cardinality is ambiguous:   x sizes: 1   y sizes: 5&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Since I&amp;#39;m more used to make (typical) classification models I&amp;#39;m unsure on how to proper encode my label vector. tks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,kaly4h,True,,quantumloophole,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kaly4h/how_to_fit_a_model_for_a_image_to_text_net_work/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kaly4h/how_to_fit_a_model_for_a_image_to_text_net_work/,22217,1607627920.0,0,,False,,,,,,,,,
407,,tensorflow,"In Python, I've been trying to get tflite\_runtime to import on a raspberry pi zero but every time I do it I get an invalid instruction.  Some have suggested building the .whl file manually but I'm not sure how to do that.

I've been following the instructions in  [Python quickstart  |  TensorFlow Lite](https://www.tensorflow.org/lite/guide/python)  and have attempted both the Cross-Compile and Native Comile instructions out lined in  [Build TensorFlow Lite for Raspberry Pi](https://www.tensorflow.org/lite/guide/build_rpi)  but even after a sucessful compile I'm still stuck.",t2_8n2avyr,False,,0,False,What is the best way to build the .whl file for tflite_runtime manually?,[],r/tensorflow,False,6,,0,,,False,t3_kaic8d,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607646282.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In Python, I&amp;#39;ve been trying to get tflite_runtime to import on a raspberry pi zero but every time I do it I get an invalid instruction.  Some have suggested building the .whl file manually but I&amp;#39;m not sure how to do that.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been following the instructions in  &lt;a href=""https://www.tensorflow.org/lite/guide/python""&gt;Python quickstart  |  TensorFlow Lite&lt;/a&gt;  and have attempted both the Cross-Compile and Native Comile instructions out lined in  &lt;a href=""https://www.tensorflow.org/lite/guide/build_rpi""&gt;Build TensorFlow Lite for Raspberry Pi&lt;/a&gt;  but even after a sucessful compile I&amp;#39;m still stuck.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kaic8d,True,,Dalamar437,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kaic8d/what_is_the_best_way_to_build_the_whl_file_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kaic8d/what_is_the_best_way_to_build_the_whl_file_for/,22217,1607617482.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?auto=webp&amp;s=2572596fe2183c02bb87888fad10698003d1766c', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f38f154b31bbc61f967552a73eae2d908d46ae03', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=800ed1265a325e2ebbd4bac73e5a0a9f87375fc4', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef1d21237970b3962ea11427b5fb4a133b573f95', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd75fe122929cebeb28f32cabc416c0d34746e81', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e61b7e8ded8e04296fb02cef535a2339569b52b', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fce2149c6d3aad062f85426dd46ad50c64a82b2e', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'X-wKcTKmnQRaY7Q0VF7Fv5E2VV8HI6yDgaH8MhXzwMA'}], 'enabled': False}",,,,,,
408,,tensorflow,"Hi guys, i am working on a part assembly project to detect if parts are properly fitted. I have used a couple of models from the object detection zoo model trained on the coco dataset. Can anyone suggest to me a model which performs well on such a task. It a simple 'OK' ,'NOK' classifier. Please advise a model architecture which best suits my need. Is Keras with a haars cascade bounding box architecture a better way for this?

Highly appreciate your answers. 

Thanks",t2_1kh79sw8,False,,0,False,Object Detection Model-API TF-2,[],r/tensorflow,False,6,,0,,,False,t3_kacx3j,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607624113.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, i am working on a part assembly project to detect if parts are properly fitted. I have used a couple of models from the object detection zoo model trained on the coco dataset. Can anyone suggest to me a model which performs well on such a task. It a simple &amp;#39;OK&amp;#39; ,&amp;#39;NOK&amp;#39; classifier. Please advise a model architecture which best suits my need. Is Keras with a haars cascade bounding box architecture a better way for this?&lt;/p&gt;

&lt;p&gt;Highly appreciate your answers. &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kacx3j,True,,jason_rims,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/kacx3j/object_detection_modelapi_tf2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kacx3j/object_detection_modelapi_tf2/,22217,1607595313.0,0,,False,,,,,,,,,
409,,tensorflow,"Hello, I want to increase my dataset for a project where I do semantic segmentation of plants. Do you think that I can generate new images with a StyleGAN2 ada model? And that it would be high quality enough to help my semantic segmentation model with additional training data?

Have anyone done anything similar ?",t2_128ob4,False,,0,False,Generate new training data with StyleGAN2 ada ?,[],r/tensorflow,False,6,,0,,,False,t3_kacatw,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607620670.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I want to increase my dataset for a project where I do semantic segmentation of plants. Do you think that I can generate new images with a StyleGAN2 ada model? And that it would be high quality enough to help my semantic segmentation model with additional training data?&lt;/p&gt;

&lt;p&gt;Have anyone done anything similar ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,kacatw,True,,darvidas,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/kacatw/generate_new_training_data_with_stylegan2_ada/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/kacatw/generate_new_training_data_with_stylegan2_ada/,22217,1607591870.0,0,,False,,,,,,,,,
410,,tensorflow,"Hey guys.I've made a model that that tells me how I spend my time. Here's the article I published on medium. Do checkout if you are interested.

[https://aaftab-naim.medium.com/how-to-make-a-real-time-activity-recognition-model-to-monitor-your-productivity-using-tensorflow-4cc47b412db7](https://aaftab-naim.medium.com/how-to-make-a-real-time-activity-recognition-model-to-monitor-your-productivity-using-tensorflow-4cc47b412db7)",t2_5zc2v54r,False,,0,False,My First TF project: Real Time Activity Recognition,[],r/tensorflow,False,6,,0,,,False,t3_k9k5tx,False,dark,1.0,,public,13,0,{},,,False,[],,False,False,,{},,False,13,,False,self,False,,[],{},,True,,1607514012.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys.I&amp;#39;ve made a model that that tells me how I spend my time. Here&amp;#39;s the article I published on medium. Do checkout if you are interested.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://aaftab-naim.medium.com/how-to-make-a-real-time-activity-recognition-model-to-monitor-your-productivity-using-tensorflow-4cc47b412db7""&gt;https://aaftab-naim.medium.com/how-to-make-a-real-time-activity-recognition-model-to-monitor-your-productivity-using-tensorflow-4cc47b412db7&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k9k5tx,True,,Ill-Quantity-4933,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k9k5tx/my_first_tf_project_real_time_activity_recognition/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k9k5tx/my_first_tf_project_real_time_activity_recognition/,22217,1607485212.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?auto=webp&amp;s=836541b16d96cb8a853617544c38c83ec3317645', 'width': 1200, 'height': 635}, 'resolutions': [{'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23390a00985f826524cf5a53f36b242e387235ae', 'width': 108, 'height': 57}, {'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5bfbfe05f8a245f407e31b358e9284624feca24e', 'width': 216, 'height': 114}, {'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fa9c0d7599cb4d5a2bb06fbac9c3736e3134100', 'width': 320, 'height': 169}, {'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aea15939bc365b2201d4a80780ebd68d1e358356', 'width': 640, 'height': 338}, {'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57259fcbe016aaf527946eed232694107c709619', 'width': 960, 'height': 508}, {'url': 'https://external-preview.redd.it/UIO8rB8T2Hy7UU5xfnQk0kxz-PmdthCNLpsZ74kIk84.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9bb6631f65d30afd1d16f8902bc7022fb84fb5de', 'width': 1080, 'height': 571}], 'variants': {}, 'id': 'HGztL5ezMXCkAfwBZ5UPxSbN1jWiobHfNmwNd831Z9w'}], 'enabled': False}",,,,,,
411,,tensorflow,"I’m using the Keras API but I don’t get why my model gives different results after I load it back and use it to do predictions? Am I doing something wrong?

Edit: this is a TF bug (https://github.com/tensorflow/tensorflow/issues/42459) that can be resolved by explicitly specifying ‘sparse_categorical_accuracy’ instead of ‘accuracy’ when you compile your model.",t2_4xt7vl5p,False,,0,False,"How come when I load back a saved h5 model, it gives totally different (much worse) prediction results?",[],r/tensorflow,False,6,,0,,,False,t3_k9mh2i,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1608244577.0,,[],{},,True,,1607523059.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m using the Keras API but I don’t get why my model gives different results after I load it back and use it to do predictions? Am I doing something wrong?&lt;/p&gt;

&lt;p&gt;Edit: this is a TF bug (&lt;a href=""https://github.com/tensorflow/tensorflow/issues/42459""&gt;https://github.com/tensorflow/tensorflow/issues/42459&lt;/a&gt;) that can be resolved by explicitly specifying ‘sparse_categorical_accuracy’ instead of ‘accuracy’ when you compile your model.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k9mh2i,True,,convnetto,,16,True,all_ads,False,[],False,,/r/tensorflow/comments/k9mh2i/how_come_when_i_load_back_a_saved_h5_model_it/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k9mh2i/how_come_when_i_load_back_a_saved_h5_model_it/,22217,1607494259.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
412,,tensorflow,"This tutorial discusses how to train Keras models with the genetic algorithm using the open-source PyGAD library. The discussion includes building Keras models using either the Sequential Model or the Functional API, building an initial population of Keras model parameters, creating an appropriate loss and fitness function, assessing your model, and full code for regression and classification problems. You can also explore the open-source PyGAD library using free, GPU-backed Gradient Community Notebooks, with full code for regression, classification using a CNN, and many other sample projects. 

Tutorial link: [https://blog.paperspace.com/train-keras-models-using-genetic-algorithm-with-pygad/](https://blog.paperspace.com/train-keras-models-using-genetic-algorithm-with-pygad/)

Run the code for free on a Gradient Community Notebook: [https://ml-showcase.paperspace.com/projects/genetic-algorithm-with-pygad](https://ml-showcase.paperspace.com/projects/genetic-algorithm-with-pygad)",t2_15en0l,False,,0,False,[Tutorial] How To Train Keras Models Using the Genetic Algorithm,[],r/tensorflow,False,6,,0,,,False,t3_k98f95,False,dark,0.96,,public,23,0,{},,,False,[],,False,False,,{},Tutorial,False,23,,False,self,False,,[],{},,True,,1607476919.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial discusses how to train Keras models with the genetic algorithm using the open-source PyGAD library. The discussion includes building Keras models using either the Sequential Model or the Functional API, building an initial population of Keras model parameters, creating an appropriate loss and fitness function, assessing your model, and full code for regression and classification problems. You can also explore the open-source PyGAD library using free, GPU-backed Gradient Community Notebooks, with full code for regression, classification using a CNN, and many other sample projects. &lt;/p&gt;

&lt;p&gt;Tutorial link: &lt;a href=""https://blog.paperspace.com/train-keras-models-using-genetic-algorithm-with-pygad/""&gt;https://blog.paperspace.com/train-keras-models-using-genetic-algorithm-with-pygad/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the code for free on a Gradient Community Notebook: &lt;a href=""https://ml-showcase.paperspace.com/projects/genetic-algorithm-with-pygad""&gt;https://ml-showcase.paperspace.com/projects/genetic-algorithm-with-pygad&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k98f95,True,,hellopaperspace,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k98f95/tutorial_how_to_train_keras_models_using_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k98f95/tutorial_how_to_train_keras_models_using_the/,22217,1607448119.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?auto=webp&amp;s=f9fd7365b5e86b5dd33022f4bbbf94dc6ae5429d', 'width': 2000, 'height': 1424}, 'resolutions': [{'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=245390374ae3a6a699f8fe2a5415f8354ca025fd', 'width': 108, 'height': 76}, {'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=378fe066363004c88e2823080bcb9a31ecd5f8cd', 'width': 216, 'height': 153}, {'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4370626f3047f5910de0e2b48a34cab1cacfd4b', 'width': 320, 'height': 227}, {'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6034f15ebf99cba4926cd15130bd269f30037178', 'width': 640, 'height': 455}, {'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d5fd47bd471af3bdc314df29623fd363cc67436', 'width': 960, 'height': 683}, {'url': 'https://external-preview.redd.it/1cXoJYbIPKGae5DtPQgPBFCrOWx-zMg9LiJcPHoY-zc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f3ac8b7e9960bd27968b1a48a94083b5624dfa0', 'width': 1080, 'height': 768}], 'variants': {}, 'id': 'tSZq7ID9ES7NP7hPE13IELQh_xZZIEIYAupLvpP7fXk'}], 'enabled': False}",,,,,,
413,,tensorflow,"Would it be possible to use TF as a peak finder? 

Here is the full idea.

I want to control an internal combustion engine ignition timing with machine learning. 

Input would be the power output of the combustion motor.

Output from TF would be a requested Ignition timing between 0 and 40 degrees. 

The TF would need to find the right value of output to maximize the input. 

For further enhancement I would want to feed in the Manifold Pressure and RPM.

All this would be trialed with a small lawn mower engine on a bench with a 2KW electric dynameter.",t2_dgzn2,False,,0,False,Can I use TF to find a peak value in a closed loop system?,[],r/tensorflow,False,6,,0,,,False,t3_k9lfco,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1607518744.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Would it be possible to use TF as a peak finder? &lt;/p&gt;

&lt;p&gt;Here is the full idea.&lt;/p&gt;

&lt;p&gt;I want to control an internal combustion engine ignition timing with machine learning. &lt;/p&gt;

&lt;p&gt;Input would be the power output of the combustion motor.&lt;/p&gt;

&lt;p&gt;Output from TF would be a requested Ignition timing between 0 and 40 degrees. &lt;/p&gt;

&lt;p&gt;The TF would need to find the right value of output to maximize the input. &lt;/p&gt;

&lt;p&gt;For further enhancement I would want to feed in the Manifold Pressure and RPM.&lt;/p&gt;

&lt;p&gt;All this would be trialed with a small lawn mower engine on a bench with a 2KW electric dynameter.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k9lfco,True,,jacky4566,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/k9lfco/can_i_use_tf_to_find_a_peak_value_in_a_closed/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k9lfco/can_i_use_tf_to_find_a_peak_value_in_a_closed/,22217,1607489944.0,0,,False,,,,,,,,,
414,,tensorflow,"So i have a model.pb file and i want to convert it into Keras model (.h5 file). But most of the tutorials online are ""convert .h5 to .pb"". Any ideas ? Thank you for all of your answer",,False,,0,False,Convert .pb file to .h5 file ?,[],r/tensorflow,False,6,,0,,,False,t3_k9jkhi,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,,self,False,,,{},,True,,1607511906.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i have a model.pb file and i want to convert it into Keras model (.h5 file). But most of the tutorials online are &amp;quot;convert .h5 to .pb&amp;quot;. Any ideas ? Thank you for all of your answer&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k9jkhi,True,,[deleted],,0,True,all_ads,False,[],,dark,/r/tensorflow/comments/k9jkhi/convert_pb_file_to_h5_file/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k9jkhi/convert_pb_file_to_h5_file/,22217,1607483106.0,0,,False,,,,,,,,,
415,,tensorflow,"So I added tensorboard to a standard `model.fit` function through a callback and got this error.

&amp;#x200B;

https://preview.redd.it/xj9j6n3oj0461.png?width=1765&amp;format=png&amp;auto=webp&amp;s=b24603ca66e95920160b4fa2474698d246bd2b00

Here's the \[Colab\]([https://colab.research.google.com/drive/1Zd0n6oXYb4Jan1t9gpjIV88CENFHXMdI?usp=sharing](https://colab.research.google.com/drive/1Zd0n6oXYb4Jan1t9gpjIV88CENFHXMdI?usp=sharing)) link to my code.

The notebook works perfectly fine without the callback.

Please help!!!",t2_61p22te7,False,,0,False,Error When Using TensorBoard in a Tensorflow Hub Model,[],r/tensorflow,False,6,,0,28.0,,False,t3_k9awag,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://a.thumbs.redditmedia.com/A7LkRFc2Z7kyeR0cWlBjCkshZaDbo3i6ZfROhDb4EL8.jpg,False,,[],{},,True,,1607484032.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I added tensorboard to a standard &lt;code&gt;model.fit&lt;/code&gt; function through a callback and got this error.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/xj9j6n3oj0461.png?width=1765&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b24603ca66e95920160b4fa2474698d246bd2b00""&gt;https://preview.redd.it/xj9j6n3oj0461.png?width=1765&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b24603ca66e95920160b4fa2474698d246bd2b00&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s the [Colab](&lt;a href=""https://colab.research.google.com/drive/1Zd0n6oXYb4Jan1t9gpjIV88CENFHXMdI?usp=sharing""&gt;https://colab.research.google.com/drive/1Zd0n6oXYb4Jan1t9gpjIV88CENFHXMdI?usp=sharing&lt;/a&gt;) link to my code.&lt;/p&gt;

&lt;p&gt;The notebook works perfectly fine without the callback.&lt;/p&gt;

&lt;p&gt;Please help!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k9awag,True,,uriahtor,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k9awag/error_when_using_tensorboard_in_a_tensorflow_hub/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k9awag/error_when_using_tensorboard_in_a_tensorflow_hub/,22217,1607455232.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&amp;s=73eb91ea5a5347f216c0f0c4d6796396826aae49', 'width': 260, 'height': 260}, 'resolutions': [{'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b647239f77bf713f4a6209cfa4867351c055fd9', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f4234ff3f4f4ebd7f77236dedb03a2faee3e04a', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nkhh65ujo5BznFJFojoMPaKjGuLSpPj6KGhRov-ykOg'}], 'enabled': False}",,"{'xj9j6n3oj0461': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 21, 'x': 108, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c412ce90602db44cd7a0656e6632a02f14a7f707'}, {'y': 43, 'x': 216, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=62340dd04bfe06f54f6260fd43c3e056a7236406'}, {'y': 64, 'x': 320, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b243f0356639b9b20438d1168572bbb4c4091a0c'}, {'y': 129, 'x': 640, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4725285ba9231ebae7762a60eabab5756d63d9a'}, {'y': 194, 'x': 960, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1b549e532ac0f24533665cc6e563de16f18d40c0'}, {'y': 218, 'x': 1080, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1002081a97565e564b6ef4c6305001ca59eebc00'}], 's': {'y': 357, 'x': 1765, 'u': 'https://preview.redd.it/xj9j6n3oj0461.png?width=1765&amp;format=png&amp;auto=webp&amp;s=b24603ca66e95920160b4fa2474698d246bd2b00'}, 'id': 'xj9j6n3oj0461'}}",,,,
416,,tensorflow,"Here is the original [script][1] I'm trying to run on both CPU and GPU, I'm expecting a much faster training on GPU however it's taking almost the same time. I made the following modification to `main()`(the first 4 lines) because the original script does not activate / use the GPU. So, what's wrong?

    def main():
        physical_devices = tf.config.experimental.list_physical_devices('GPU')
        if len(physical_devices) &gt; 0:
            tf.config.experimental.set_memory_growth(physical_devices[0], True)
            print('GPU activated')
        env = gym.make('CartPole-v1')
        agent = Agent(env)
        agent.train(max_episodes=1000)

Full code in question which is not mine and belongs to this [repository][2]:

    import wandb
    import tensorflow as tf
    from tensorflow.keras.layers import Input, Dense
    from tensorflow.keras.optimizers import Adam
    
    import gym
    import argparse
    import numpy as np
    from collections import deque
    import random
    
    tf.keras.backend.set_floatx('float64')
    wandb.init(name='DQN', project=""deep-rl-tf2"")
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--gamma', type=float, default=0.95)
    parser.add_argument('--lr', type=float, default=0.005)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--eps', type=float, default=1.0)
    parser.add_argument('--eps_decay', type=float, default=0.995)
    parser.add_argument('--eps_min', type=float, default=0.01)
    
    args = parser.parse_args()
    
    class ReplayBuffer:
        def __init__(self, capacity=10000):
            self.buffer = deque(maxlen=capacity)
        
        def put(self, state, action, reward, next_state, done):
            self.buffer.append([state, action, reward, next_state, done])
        
        def sample(self):
            sample = random.sample(self.buffer, args.batch_size)
            states, actions, rewards, next_states, done = map(np.asarray, zip(*sample))
            states = np.array(states).reshape(args.batch_size, -1)
            next_states = np.array(next_states).reshape(args.batch_size, -1)
            return states, actions, rewards, next_states, done
        
        def size(self):
            return len(self.buffer)
    
    class ActionStateModel:
        def __init__(self, state_dim, aciton_dim):
            self.state_dim  = state_dim
            self.action_dim = aciton_dim
            self.epsilon = args.eps
            
            self.model = self.create_model()
        
        def create_model(self):
            model = tf.keras.Sequential([
                Input((self.state_dim,)),
                Dense(32, activation='relu'),
                Dense(16, activation='relu'),
                Dense(self.action_dim)
            ])
            model.compile(loss='mse', optimizer=Adam(args.lr))
            return model
        
        def predict(self, state):
            return self.model.predict(state)
        
        def get_action(self, state):
            state = np.reshape(state, [1, self.state_dim])
            self.epsilon *= args.eps_decay
            self.epsilon = max(self.epsilon, args.eps_min)
            q_value = self.predict(state)[0]
            if np.random.random() &lt; self.epsilon:
                return random.randint(0, self.action_dim-1)
            return np.argmax(q_value)
    
        def train(self, states, targets):
            self.model.fit(states, targets, epochs=1, verbose=0)
        
    
    class Agent:
        def __init__(self, env):
            self.env = env
            self.state_dim = self.env.observation_space.shape[0]
            self.action_dim = self.env.action_space.n
    
            self.model = ActionStateModel(self.state_dim, self.action_dim)
            self.target_model = ActionStateModel(self.state_dim, self.action_dim)
            self.target_update()
    
            self.buffer = ReplayBuffer()
    
        def target_update(self):
            weights = self.model.model.get_weights()
            self.target_model.model.set_weights(weights)
        
        def replay(self):
            for _ in range(10):
                states, actions, rewards, next_states, done = self.buffer.sample()
                targets = self.target_model.predict(states)
                next_q_values = self.target_model.predict(next_states).max(axis=1)
                targets[range(args.batch_size), actions] = rewards + (1-done) * next_q_values * args.gamma
                self.model.train(states, targets)
        
        def train(self, max_episodes=1000):
            for ep in range(max_episodes):
                done, total_reward = False, 0
                state = self.env.reset()
                while not done:
                    action = self.model.get_action(state)
                    next_state, reward, done, _ = self.env.step(action)
                    self.buffer.put(state, action, reward*0.01, next_state, done)
                    total_reward += reward
                    state = next_state
                if self.buffer.size() &gt;= args.batch_size:
                    self.replay()
                self.target_update()
                print('EP{} EpisodeReward={}'.format(ep, total_reward))
                wandb.log({'Reward': total_reward})
    
    
    def main():
        env = gym.make('CartPole-v1')
        agent = Agent(env)
        agent.train(max_episodes=1000)
    
    if __name__ == ""__main__"":
        main()


  [1]: https://github.com/marload/DeepRL-TensorFlow2/blob/master/DQN/DQN_Discrete.py
  [2]: https://github.com/marload/DeepRL-TensorFlow2",t2_4jbcsgd0,False,,0,False,Slow training on CPU and GPU in a small network,[],r/tensorflow,False,6,,0,,,False,t3_k93c0i,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1607459312.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Here is the original &lt;a href=""https://github.com/marload/DeepRL-TensorFlow2/blob/master/DQN/DQN_Discrete.py""&gt;script&lt;/a&gt; I&amp;#39;m trying to run on both CPU and GPU, I&amp;#39;m expecting a much faster training on GPU however it&amp;#39;s taking almost the same time. I made the following modification to &lt;code&gt;main()&lt;/code&gt;(the first 4 lines) because the original script does not activate / use the GPU. So, what&amp;#39;s wrong?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def main():
    physical_devices = tf.config.experimental.list_physical_devices(&amp;#39;GPU&amp;#39;)
    if len(physical_devices) &amp;gt; 0:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
        print(&amp;#39;GPU activated&amp;#39;)
    env = gym.make(&amp;#39;CartPole-v1&amp;#39;)
    agent = Agent(env)
    agent.train(max_episodes=1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Full code in question which is not mine and belongs to this &lt;a href=""https://github.com/marload/DeepRL-TensorFlow2""&gt;repository&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import wandb
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam

import gym
import argparse
import numpy as np
from collections import deque
import random

tf.keras.backend.set_floatx(&amp;#39;float64&amp;#39;)
wandb.init(name=&amp;#39;DQN&amp;#39;, project=&amp;quot;deep-rl-tf2&amp;quot;)

parser = argparse.ArgumentParser()
parser.add_argument(&amp;#39;--gamma&amp;#39;, type=float, default=0.95)
parser.add_argument(&amp;#39;--lr&amp;#39;, type=float, default=0.005)
parser.add_argument(&amp;#39;--batch_size&amp;#39;, type=int, default=32)
parser.add_argument(&amp;#39;--eps&amp;#39;, type=float, default=1.0)
parser.add_argument(&amp;#39;--eps_decay&amp;#39;, type=float, default=0.995)
parser.add_argument(&amp;#39;--eps_min&amp;#39;, type=float, default=0.01)

args = parser.parse_args()

class ReplayBuffer:
    def __init__(self, capacity=10000):
        self.buffer = deque(maxlen=capacity)

    def put(self, state, action, reward, next_state, done):
        self.buffer.append([state, action, reward, next_state, done])

    def sample(self):
        sample = random.sample(self.buffer, args.batch_size)
        states, actions, rewards, next_states, done = map(np.asarray, zip(*sample))
        states = np.array(states).reshape(args.batch_size, -1)
        next_states = np.array(next_states).reshape(args.batch_size, -1)
        return states, actions, rewards, next_states, done

    def size(self):
        return len(self.buffer)

class ActionStateModel:
    def __init__(self, state_dim, aciton_dim):
        self.state_dim  = state_dim
        self.action_dim = aciton_dim
        self.epsilon = args.eps

        self.model = self.create_model()

    def create_model(self):
        model = tf.keras.Sequential([
            Input((self.state_dim,)),
            Dense(32, activation=&amp;#39;relu&amp;#39;),
            Dense(16, activation=&amp;#39;relu&amp;#39;),
            Dense(self.action_dim)
        ])
        model.compile(loss=&amp;#39;mse&amp;#39;, optimizer=Adam(args.lr))
        return model

    def predict(self, state):
        return self.model.predict(state)

    def get_action(self, state):
        state = np.reshape(state, [1, self.state_dim])
        self.epsilon *= args.eps_decay
        self.epsilon = max(self.epsilon, args.eps_min)
        q_value = self.predict(state)[0]
        if np.random.random() &amp;lt; self.epsilon:
            return random.randint(0, self.action_dim-1)
        return np.argmax(q_value)

    def train(self, states, targets):
        self.model.fit(states, targets, epochs=1, verbose=0)


class Agent:
    def __init__(self, env):
        self.env = env
        self.state_dim = self.env.observation_space.shape[0]
        self.action_dim = self.env.action_space.n

        self.model = ActionStateModel(self.state_dim, self.action_dim)
        self.target_model = ActionStateModel(self.state_dim, self.action_dim)
        self.target_update()

        self.buffer = ReplayBuffer()

    def target_update(self):
        weights = self.model.model.get_weights()
        self.target_model.model.set_weights(weights)

    def replay(self):
        for _ in range(10):
            states, actions, rewards, next_states, done = self.buffer.sample()
            targets = self.target_model.predict(states)
            next_q_values = self.target_model.predict(next_states).max(axis=1)
            targets[range(args.batch_size), actions] = rewards + (1-done) * next_q_values * args.gamma
            self.model.train(states, targets)

    def train(self, max_episodes=1000):
        for ep in range(max_episodes):
            done, total_reward = False, 0
            state = self.env.reset()
            while not done:
                action = self.model.get_action(state)
                next_state, reward, done, _ = self.env.step(action)
                self.buffer.put(state, action, reward*0.01, next_state, done)
                total_reward += reward
                state = next_state
            if self.buffer.size() &amp;gt;= args.batch_size:
                self.replay()
            self.target_update()
            print(&amp;#39;EP{} EpisodeReward={}&amp;#39;.format(ep, total_reward))
            wandb.log({&amp;#39;Reward&amp;#39;: total_reward})


def main():
    env = gym.make(&amp;#39;CartPole-v1&amp;#39;)
    agent = Agent(env)
    agent.train(max_episodes=1000)

if __name__ == &amp;quot;__main__&amp;quot;:
    main()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k93c0i,True,,emadboctor,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k93c0i/slow_training_on_cpu_and_gpu_in_a_small_network/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k93c0i/slow_training_on_cpu_and_gpu_in_a_small_network/,22217,1607430512.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/AXAIzy-mtOqcGwwYEmAfpll6HLSxg2JfvB0Y8Sxhy14.jpg?auto=webp&amp;s=732eac845e645d38d02d8cb2ee0b8167d0ddb7ce', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/AXAIzy-mtOqcGwwYEmAfpll6HLSxg2JfvB0Y8Sxhy14.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc6732d2816c696cf616c20489b43c27e50ba2d5', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/AXAIzy-mtOqcGwwYEmAfpll6HLSxg2JfvB0Y8Sxhy14.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a589a4850c6d65583c58650779cb42aab29bb73a', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/AXAIzy-mtOqcGwwYEmAfpll6HLSxg2JfvB0Y8Sxhy14.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4da7aab3664f6a4848725ceebb120ab0a1185321', 'width': 320, 'height': 320}], 'variants': {}, 'id': '2MYBsz5iv5s0BwBlZ56ABDn7vnFeTicMxNHUXJWOrdg'}], 'enabled': False}",,,,,,
417,,tensorflow,"Ok so i want to run a lightweight depth prediction model on the nvidia jetson nano (4GB version). But most model i found online are pretty ""heavy to run"" on the nano. Thank you for all of your suggestion",,False,,0,False,Simple and fast tensorflow depth prediction model ?,[],r/tensorflow,False,6,,0,,,False,t3_k8vz0w,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,,self,False,,,{},,True,,1607425142.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Ok so i want to run a lightweight depth prediction model on the nvidia jetson nano (4GB version). But most model i found online are pretty &amp;quot;heavy to run&amp;quot; on the nano. Thank you for all of your suggestion&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k8vz0w,True,,[deleted],,6,True,all_ads,False,[],,dark,/r/tensorflow/comments/k8vz0w/simple_and_fast_tensorflow_depth_prediction_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k8vz0w/simple_and_fast_tensorflow_depth_prediction_model/,22217,1607396342.0,0,,False,,,,,,,,,
418,,tensorflow,,t2_60z7xdxm,False,,0,False,Generative Models Collection for share,[],r/tensorflow,False,6,,0,140.0,,False,t3_k8epq7,False,dark,1.0,,public,15,0,{},140.0,,False,[],,False,False,,{},,False,15,,False,https://b.thumbs.redditmedia.com/e5UhDA-2zl7IrPBudIgYL1hZC3bnxlR6IFsvxQAArDc.jpg,False,,[],{},,False,,1607368176.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k8epq7,True,,MrForExample,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k8epq7/generative_models_collection_for_share/,all_ads,False,https://github.com/MrForExample/Generative_Models_Collection,22217,1607339376.0,0,,False,link,https://github.com/MrForExample/Generative_Models_Collection,"{'images': [{'source': {'url': 'https://external-preview.redd.it/BdQHeapFYa_NfInNB9KWHRwnlGG8tWgg16ZJyhighzQ.jpg?auto=webp&amp;s=92885d8f2732c6e2c609ee169177bb1261931bf5', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/BdQHeapFYa_NfInNB9KWHRwnlGG8tWgg16ZJyhighzQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78f9b29cbab19dd0733e2cd86bdf89019abfd5b6', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/BdQHeapFYa_NfInNB9KWHRwnlGG8tWgg16ZJyhighzQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee0ad607d78d38699a32e3b2c62520510298ea92', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/BdQHeapFYa_NfInNB9KWHRwnlGG8tWgg16ZJyhighzQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=558270d9f876ba3e7a5df2f79849b779b45afdaa', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'Kp1AO_3Txdahu9Qa_A4CbkdMcTvCnTOF-NTMSJ8T10s'}], 'enabled': False}",,,,,,
419,,tensorflow,"It's mentioned [here](https://github.com/tensorflow/tensorflow/issues/32651#issuecomment-534685146) that we can access the ram filesystem. Does anyone know how? I can't find anything about it in the documentation...  

The reason I'd like to use this feature is that I'm trying to train a model on Colab with the use of TPU's. However there's no access to the disk of the TPU system, so I can't use tf.keras.preprocessing.image_dataset_from_directory() and the image dataset is too large to fit in RAM after normalizing (converting to float from int makes the size balloon).",t2_k4elj,False,,0,False,"Accessing the ram:// filesystem, how?",[],r/tensorflow,False,6,,0,,,False,t3_k8si4c,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1607412380.0,,[],{},,True,,1607413111.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It&amp;#39;s mentioned &lt;a href=""https://github.com/tensorflow/tensorflow/issues/32651#issuecomment-534685146""&gt;here&lt;/a&gt; that we can access the ram filesystem. Does anyone know how? I can&amp;#39;t find anything about it in the documentation...  &lt;/p&gt;

&lt;p&gt;The reason I&amp;#39;d like to use this feature is that I&amp;#39;m trying to train a model on Colab with the use of TPU&amp;#39;s. However there&amp;#39;s no access to the disk of the TPU system, so I can&amp;#39;t use tf.keras.preprocessing.image_dataset_from_directory() and the image dataset is too large to fit in RAM after normalizing (converting to float from int makes the size balloon).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k8si4c,True,,jemattie,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k8si4c/accessing_the_ram_filesystem_how/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k8si4c/accessing_the_ram_filesystem_how/,22217,1607384311.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
420,,tensorflow,"Hi there, so I am trying to run this line:

&amp;#x200B;

[hist=model.fit](https://hist=model.fit)(x=X\_train, y=Y\_train, batch\_size=32, epochs=100, np.asarray(validation\_data=(X\_val, Y\_val))

,but I am getting an unexpected EOF file while parsing. I have 253 images in my data set and I do not know how to stop the EOF error. 

&amp;#x200B;

Full Error:   File ""&lt;ipython-input-268-e6a12980b207&gt;"", line 5     hist=model.fit(x=X\_train, y=Y\_train, batch\_size=32, epochs=100, np.asarray(validation\_data=(X\_val, Y\_val))                                                                                                               \^ SyntaxError: unexpected EOF while parsing",t2_18w6l0tw,False,,0,False,[Question] EOF while parsing,[],r/tensorflow,False,6,,0,,,False,t3_k8sgfs,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1607412960.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there, so I am trying to run this line:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://hist=model.fit""&gt;hist=model.fit&lt;/a&gt;(x=X_train, y=Y_train, batch_size=32, epochs=100, np.asarray(validation_data=(X_val, Y_val))&lt;/p&gt;

&lt;p&gt;,but I am getting an unexpected EOF file while parsing. I have 253 images in my data set and I do not know how to stop the EOF error. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Full Error:   File &amp;quot;&amp;lt;ipython-input-268-e6a12980b207&amp;gt;&amp;quot;, line 5     hist=model.fit(x=X_train, y=Y_train, batch_size=32, epochs=100, np.asarray(validation_data=(X_val, Y_val))                                                                                                               ^ SyntaxError: unexpected EOF while parsing&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k8sgfs,True,,-KingKrazy-,,22,True,all_ads,False,[],False,,/r/tensorflow/comments/k8sgfs/question_eof_while_parsing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k8sgfs/question_eof_while_parsing/,22217,1607384160.0,0,,False,,,,,,,,,
421,,tensorflow,"I'm running  [Dedicated Outside Object Detection Service (DOODS)](https://hub.docker.com/r/snowzach/doods) to do people detection/workflows on three cameras in my [home automation](https://www.home-assistant.io/integrations/doods/) setup in Home Assistant.  


It works and it's stinkin cool but I think the model was built for the horsepower of a RaspberryPi so the object detection is both ""slow"" (+/- 1 FPS in Docker/Kubernetes on a Nuc 10 i7-10710U 6-Core Intel CPU) and not terribly accurate (as compared to some of the object detection tutorials I've been visiting).  


In terms of my machine vision journey, my goals are:

&amp;#x200B;

* Find ways to improve the accuracy of the models
   * Including introducing ways to add custom classifications (faces, pets, etc)
* Find the model/hardware that I can scale the object detection to higher FPS (15-30 fps) and on more cameras (6-9 would be cool). 

I think my first stop is to find an edge-device and run the GPU models... I just couldn't tell you if meeting those goals could be done on something like 1-2 Jetson Nanos, a 1080-3080 GPU, or etc.

&amp;#x200B;

What edge-devices would you recommend for something like TensorFlow or TensorFlow Lite?",t2_a7rnj,False,,0,False,Best edge-device for TensorFlow and object detection?,[],r/tensorflow,False,6,,0,,,False,t3_k86a2m,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1607331748.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m running  &lt;a href=""https://hub.docker.com/r/snowzach/doods""&gt;Dedicated Outside Object Detection Service (DOODS)&lt;/a&gt; to do people detection/workflows on three cameras in my &lt;a href=""https://www.home-assistant.io/integrations/doods/""&gt;home automation&lt;/a&gt; setup in Home Assistant.  &lt;/p&gt;

&lt;p&gt;It works and it&amp;#39;s stinkin cool but I think the model was built for the horsepower of a RaspberryPi so the object detection is both &amp;quot;slow&amp;quot; (+/- 1 FPS in Docker/Kubernetes on a Nuc 10 i7-10710U 6-Core Intel CPU) and not terribly accurate (as compared to some of the object detection tutorials I&amp;#39;ve been visiting).  &lt;/p&gt;

&lt;p&gt;In terms of my machine vision journey, my goals are:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Find ways to improve the accuracy of the models

&lt;ul&gt;
&lt;li&gt;Including introducing ways to add custom classifications (faces, pets, etc)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Find the model/hardware that I can scale the object detection to higher FPS (15-30 fps) and on more cameras (6-9 would be cool). &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I think my first stop is to find an edge-device and run the GPU models... I just couldn&amp;#39;t tell you if meeting those goals could be done on something like 1-2 Jetson Nanos, a 1080-3080 GPU, or etc.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;What edge-devices would you recommend for something like TensorFlow or TensorFlow Lite?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k86a2m,True,,GoingOffRoading,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/k86a2m/best_edgedevice_for_tensorflow_and_object/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k86a2m/best_edgedevice_for_tensorflow_and_object/,22217,1607302948.0,2,,False,,,,,,,,,
422,,tensorflow,"I'm a learner in Tensorflow. I have problems with choosing the combination of layers that should be added to neural network. In the case of image classfication, how many conv/maxpool layers should be added?
Basically, how do we choose the number(combination also) of layers in the nn?",t2_78ppxnk1,False,,0,False,Intuitions on the layers in a neural network,[],r/tensorflow,False,6,,0,,,False,t3_k87un0,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1607337501.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a learner in Tensorflow. I have problems with choosing the combination of layers that should be added to neural network. In the case of image classfication, how many conv/maxpool layers should be added?
Basically, how do we choose the number(combination also) of layers in the nn?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k87un0,True,,Strict-Visual,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k87un0/intuitions_on_the_layers_in_a_neural_network/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k87un0/intuitions_on_the_layers_in_a_neural_network/,22217,1607308701.0,0,,False,,,,,,,,,
423,,tensorflow,"Hey there,

I wrote an article that will will walk you through how to develop your own custom object detection program utilizing Tensorflow + Python and MobileNet SSD trained with a dataset of 300+ images. In the article, we construct a mask detector that can determine when people are covering themselves or not, ensuring the safety of all individuals. You can find it here :

[https://medium.com/analytics-vidhya/real-time-face-mask-detector-8b484a5a6de0](https://medium.com/analytics-vidhya/real-time-face-mask-detector-8b484a5a6de0)",t2_95xdu0rz,False,,0,False,How to Build A Real-Time Face Mask Detector 😷,[],r/tensorflow,False,6,,0,,,False,t3_k7z69a,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Project,False,3,,False,self,False,,[],{},,True,,1607308424.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;I wrote an article that will will walk you through how to develop your own custom object detection program utilizing Tensorflow + Python and MobileNet SSD trained with a dataset of 300+ images. In the article, we construct a mask detector that can determine when people are covering themselves or not, ensuring the safety of all individuals. You can find it here :&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://medium.com/analytics-vidhya/real-time-face-mask-detector-8b484a5a6de0""&gt;https://medium.com/analytics-vidhya/real-time-face-mask-detector-8b484a5a6de0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k7z69a,True,,zakirangwala,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k7z69a/how_to_build_a_realtime_face_mask_detector/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k7z69a/how_to_build_a_realtime_face_mask_detector/,22217,1607279624.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?auto=webp&amp;s=7088bed7a61c68cc88112136dcec62b7d1192987', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99816ab82f27335f70d1a99f08365f2aa3e66903', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4e301af99745e5c5fbbc1b62efbac7b22f9b794', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16c64f0ab59cb8393a345ba1d119c3963bab2e5a', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e5eb09f151ab9140552383ff244fb217e4df3fd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=de66b5335445e2ccbe1adf4f7e15e8a34db75c79', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/BgJZnV6AYoqRbjN9wzAUKB5hu26UbSFWryU63OtYBpE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2b8ed369bc9285fb26365f18c4e81e955f23782', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'XNHG3lvZ6UqAF89shQ6BHKR4RLsVfFS1QNB_OpegVwo'}], 'enabled': False}",,,,,,
424,,tensorflow,,t2_6yq7l,False,,0,False,Help me with the power consumption of the Coral dev. board for solar powering it 24/7 please,[],r/tensorflow,False,6,,0,,,False,t3_k7xakx,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,default,False,,[],{},,False,,1607302649.0,text,6,,,text,self.google,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k7xakx,True,,lazazael,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/k7xakx/help_me_with_the_power_consumption_of_the_coral/,all_ads,False,/r/google/comments/k7x9xl/help_me_with_the_power_consumption_of_the_coral/,22217,1607273849.0,0,,False,,/r/google/comments/k7x9xl/help_me_with_the_power_consumption_of_the_coral/,,,,,"[{'approved_at_utc': None, 'subreddit': 'google', 'selftext': 'I would like to build a stand-alone edge station prototype with the Coral Dev Board solar powering it 24/7. What are the specs needed for the solar subsystem needed? The coral need 5V3A on paper which makes it 360Wh/day. Is this the real-world usage of the board?\n\nAlso if you could advice exact systems or build guides which are capable of supplying the board please. Thanks in advance.', 'author_fullname': 't2_6yq7l', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Help me with the power consumption of the Coral dev. board for solar powering it 24/7 please', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/google', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_k7x9xl', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.33, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1607302593.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.google', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I would like to build a stand-alone edge station prototype with the Coral Dev Board solar powering it 24/7. What are the specs needed for the solar subsystem needed? The coral need 5V3A on paper which makes it 360Wh/day. Is this the real-world usage of the board?&lt;/p&gt;\n\n&lt;p&gt;Also if you could advice exact systems or build guides which are capable of supplying the board please. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh45', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'k7x9xl', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'lazazael', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/google/comments/k7x9xl/help_me_with_the_power_consumption_of_the_coral/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/google/comments/k7x9xl/help_me_with_the_power_consumption_of_the_coral/', 'subreddit_subscribers': 1416306, 'created_utc': 1607273793.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_k7x9xl,
425,,tensorflow,"Hi there, I am not yet ready to create my own TensorFlow projects From scratch. I'm looking for some practice problems related to deep learning or some colab netbooks with TensorFlow assignments. Can anyone suggest me some good resources with small problems based on RNN,DNN,CNN. Thanks in advance.",t2_8zc3prnb,False,,0,False,Short practice Problems based on Deep Learning Architectures,[],r/tensorflow,False,6,,0,,,False,t3_k7v7nw,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1607295722.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there, I am not yet ready to create my own TensorFlow projects From scratch. I&amp;#39;m looking for some practice problems related to deep learning or some colab netbooks with TensorFlow assignments. Can anyone suggest me some good resources with small problems based on RNN,DNN,CNN. Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k7v7nw,True,,kilvish019,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/k7v7nw/short_practice_problems_based_on_deep_learning/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k7v7nw/short_practice_problems_based_on_deep_learning/,22217,1607266922.0,0,,False,,,,,,,,,
426,,tensorflow,"I want to set up an input pipeline to load and preprocess a bunch of nifti files at a time , what would be the best way to do that as the flow from directory function wont work in this case.

Thanks",t2_38z8ddp,False,,0,False,Input pipeline for nifti files,[],r/tensorflow,False,6,,0,,,False,t3_k7vb1h,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1607296063.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to set up an input pipeline to load and preprocess a bunch of nifti files at a time , what would be the best way to do that as the flow from directory function wont work in this case.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k7vb1h,True,,iholierthanthou,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k7vb1h/input_pipeline_for_nifti_files/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k7vb1h/input_pipeline_for_nifti_files/,22217,1607267263.0,0,,False,,,,,,,,,
427,,tensorflow,,t2_2u8w9v0u,False,,0,False,How's everyone doing after last night?,[],r/tensorflow,False,6,,0,93.0,,False,t3_k7gyya,False,dark,0.6,,public,3,0,{},140.0,,False,[],,False,False,,{},,False,3,,False,https://b.thumbs.redditmedia.com/fuvKL3svLpXmzBkTD1G0wMw8gs4Ugo7fQzLwy2W63dI.jpg,False,,[],{},,False,,1607235266.0,text,6,,,text,jabde.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k7gyya,True,,TobyWasBestSpiderMan,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k7gyya/hows_everyone_doing_after_last_night/,all_ads,False,https://jabde.com/2020/12/05/clash-at-machine-learning-conference-leaves-dozens-wounded/,22217,1607206466.0,0,,False,link,https://jabde.com/2020/12/05/clash-at-machine-learning-conference-leaves-dozens-wounded/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?auto=webp&amp;s=d8cb7437db140b0c1488b9b34cf88a33e18e96b0', 'width': 1200, 'height': 799}, 'resolutions': [{'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=00bf94ca27ef3567318bfcc1ba8970c62296112d', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a15b6d3ce975c823dc81ce8c924a9d31a9f2b47', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e46e9b8cf8fb5498e35e432b95f559bf78553ee4', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b88fe51f412c4b59a5ba9aa3ff70e84b082324b9', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=90c73842b259eaee4596cec930abbac40265014f', 'width': 960, 'height': 639}, {'url': 'https://external-preview.redd.it/j9H73uOibiUfVjViqLmxz54sgG0xIpDxH5vcS_HUbwo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd64155c5cd0912de297dd51523e88c056d2bdc4', 'width': 1080, 'height': 719}], 'variants': {}, 'id': 'zm98Dho1NXN4qTSgewAuoaOtC_ncWpSSSxbfg93cjUg'}], 'enabled': False}",,,,,,
428,,tensorflow,"This is a request for help. I have spent the last 2 days researching various concepts only to find myself with less direction. 

**My vision** is to create predictions based on user habits using machine learning. For example, the model would look at the shopping history of a user and predict that they will likely need to buy milk in the next 3 days. It will need to be flexible enough to do the same thing for about 2000 products. I would like it to use the information it gathers on a rolling basis as users use my app. 

**What I think I will need to do** is create an api with Django, which serves the output of a tensorflow model, which itself will use a linear regression model. Please correct me if I'm wrong.

There are two parts that confuse me the most:

* I don't know how to save the tensorflow model in a database such that it tailors to the needs of each individual user
* I don't know how to do incremental learning in tensorflow so that it gets smarter as users interact with the app more

I'm sure these technologies exist because otherwise personalized ads would not exist on the internet. The fact that my internet searches have never turned up anything useful tells me that I'm not using the correct terminology or that what I'm doing is not a common application. I doubt it's the second one. I am hoping that somebody more educated than myself can point me in the right direction.

Thank you in advance for the help that you can provide.",t2_dy0nl,False,,0,False,User-specific predictions online,[],r/tensorflow,False,6,,0,,,False,t3_k7ec0w,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1607226519.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is a request for help. I have spent the last 2 days researching various concepts only to find myself with less direction. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My vision&lt;/strong&gt; is to create predictions based on user habits using machine learning. For example, the model would look at the shopping history of a user and predict that they will likely need to buy milk in the next 3 days. It will need to be flexible enough to do the same thing for about 2000 products. I would like it to use the information it gathers on a rolling basis as users use my app. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What I think I will need to do&lt;/strong&gt; is create an api with Django, which serves the output of a tensorflow model, which itself will use a linear regression model. Please correct me if I&amp;#39;m wrong.&lt;/p&gt;

&lt;p&gt;There are two parts that confuse me the most:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I don&amp;#39;t know how to save the tensorflow model in a database such that it tailors to the needs of each individual user&lt;/li&gt;
&lt;li&gt;I don&amp;#39;t know how to do incremental learning in tensorflow so that it gets smarter as users interact with the app more&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m sure these technologies exist because otherwise personalized ads would not exist on the internet. The fact that my internet searches have never turned up anything useful tells me that I&amp;#39;m not using the correct terminology or that what I&amp;#39;m doing is not a common application. I doubt it&amp;#39;s the second one. I am hoping that somebody more educated than myself can point me in the right direction.&lt;/p&gt;

&lt;p&gt;Thank you in advance for the help that you can provide.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k7ec0w,True,,DrewZZZ,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k7ec0w/userspecific_predictions_online/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k7ec0w/userspecific_predictions_online/,22217,1607197719.0,0,,False,,,,,,,,,
429,,tensorflow,"Hi,

I made a post a couple of days ago when I was struggling with the same project and I got great help, so I figured I'd give it another shot. I'm kind of a noob at coding/tensorflow and I need to get a webcam object detector running with a custom model for school. Before going for the webcam I figured I'd try simple classification first. Turns out, it's not that simple. Not for me at least. I managed to train a custom network and now I'm trying to run inference. I found a notebook on how to run inference on a pre-trained model (link: [https://github.com/tensorflow/models/blob/master/research/object\_detection/colab\_tutorials/object\_detection\_tutorial.ipynb](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb))

I tried to modify that code to run with my own saved model and came up with this: [https://github.com/007Nick700/object-detection/blob/main/object%20detection%20tutorial%20test.ipynb](https://github.com/007Nick700/object-detection/blob/main/object%20detection%20tutorial%20test.ipynb)

In the last code block I'm getting a bunch of errors that I can't seem to find a fix to. It states:

"" Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. ""

First thing that comes to mind is that cuDNN isn't compatible with CUDA, but it is. I'm running Cuda 10.1 and cuDNN 7.6 and I managed to train my model with it.

Would anyone happen to have an idea as to what is wrong here? The original notebook with the pre-trained model worked fine untill I changed it. 

The only things I've changed are the ""Loader"" code block, the paths to the label map/test images and the name of the model(model\_name) under ""Detection""

&amp;#x200B;

Thanks in advance!",t2_14tmdx,False,,0,False,Error trying to run inference on a saved model,[],r/tensorflow,False,6,,0,,,False,t3_k78tgc,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1607208917.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I made a post a couple of days ago when I was struggling with the same project and I got great help, so I figured I&amp;#39;d give it another shot. I&amp;#39;m kind of a noob at coding/tensorflow and I need to get a webcam object detector running with a custom model for school. Before going for the webcam I figured I&amp;#39;d try simple classification first. Turns out, it&amp;#39;s not that simple. Not for me at least. I managed to train a custom network and now I&amp;#39;m trying to run inference. I found a notebook on how to run inference on a pre-trained model (link: &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb""&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;I tried to modify that code to run with my own saved model and came up with this: &lt;a href=""https://github.com/007Nick700/object-detection/blob/main/object%20detection%20tutorial%20test.ipynb""&gt;https://github.com/007Nick700/object-detection/blob/main/object%20detection%20tutorial%20test.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the last code block I&amp;#39;m getting a bunch of errors that I can&amp;#39;t seem to find a fix to. It states:&lt;/p&gt;

&lt;p&gt;&amp;quot; Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. &amp;quot;&lt;/p&gt;

&lt;p&gt;First thing that comes to mind is that cuDNN isn&amp;#39;t compatible with CUDA, but it is. I&amp;#39;m running Cuda 10.1 and cuDNN 7.6 and I managed to train my model with it.&lt;/p&gt;

&lt;p&gt;Would anyone happen to have an idea as to what is wrong here? The original notebook with the pre-trained model worked fine untill I changed it. &lt;/p&gt;

&lt;p&gt;The only things I&amp;#39;ve changed are the &amp;quot;Loader&amp;quot; code block, the paths to the label map/test images and the name of the model(model_name) under &amp;quot;Detection&amp;quot;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k78tgc,True,,007Nick700,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k78tgc/error_trying_to_run_inference_on_a_saved_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k78tgc/error_trying_to_run_inference_on_a_saved_model/,22217,1607180117.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
430,,tensorflow,"So, I'm trying to make a text generation model, but because LSTM and GRU layers take too long, instead what I'm doing is:

1 - adding an Embedding layer with an output vector dimensions as 32

2 - adding a Convolution layer(1 dimensional obviously) to extract 16 features from the Embedding Layer (the hope is that when the program looks at the writing it can find features from the writing with this layer to pick the next word)

3 - adding a Dropout layer with 30% neuron dropout

4 - adding a BatchNormalization layer so the resulting layer can be added to a Dense Neural Network model

5 - Added a 128 neuron Dense Layer with relu activation(for obvious reason)

6 - Added the last Dense Layer with all the possible next words, along with a softmax function as to apply an np.argmax() for the prediction

I know this sounds dumb, but would there be any possibility where this would ever work?",t2_4760f5hy,False,,0,False,Is not using an LSTM or GRU layer on a text generation model a bad idea?,[],r/tensorflow,False,6,,0,,,False,t3_k7fzn1,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1607231971.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So, I&amp;#39;m trying to make a text generation model, but because LSTM and GRU layers take too long, instead what I&amp;#39;m doing is:&lt;/p&gt;

&lt;p&gt;1 - adding an Embedding layer with an output vector dimensions as 32&lt;/p&gt;

&lt;p&gt;2 - adding a Convolution layer(1 dimensional obviously) to extract 16 features from the Embedding Layer (the hope is that when the program looks at the writing it can find features from the writing with this layer to pick the next word)&lt;/p&gt;

&lt;p&gt;3 - adding a Dropout layer with 30% neuron dropout&lt;/p&gt;

&lt;p&gt;4 - adding a BatchNormalization layer so the resulting layer can be added to a Dense Neural Network model&lt;/p&gt;

&lt;p&gt;5 - Added a 128 neuron Dense Layer with relu activation(for obvious reason)&lt;/p&gt;

&lt;p&gt;6 - Added the last Dense Layer with all the possible next words, along with a softmax function as to apply an np.argmax() for the prediction&lt;/p&gt;

&lt;p&gt;I know this sounds dumb, but would there be any possibility where this would ever work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k7fzn1,True,,ARNisUsername,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/k7fzn1/is_not_using_an_lstm_or_gru_layer_on_a_text/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k7fzn1/is_not_using_an_lstm_or_gru_layer_on_a_text/,22217,1607203171.0,0,,False,,,,,,,,,
431,,tensorflow,"&amp;#x200B;

https://i.redd.it/lp2hlt6tu4361.gif

For more details see the [full video](https://youtu.be/eRwt_FXTdmg), which also shows how a medium size convolutional neural network runs on the gpu of the M1 and how it compares to a dedicated desktop graphics card (Nvidia RTX 2060).",t2_8z07cclg,False,,0,False,"New ""hardware-accelerated"" TensorFlow fork for the Apple M1 is fast!",[],r/tensorflow,False,6,,0,105.0,,False,t3_k6h9fr,False,dark,0.93,,public,33,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/eRwt_FXTdmg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Machine Learning on the new M1 Macbook Air (beats CPU server with 112 cores)', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/eRwt_FXTdmg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': 'cave notes', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/eRwt_FXTdmg/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_IdJ4-VidHg79QQBRJOnnA'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/eRwt_FXTdmg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/k6h9fr', 'height': 338}",,False,33,,False,https://b.thumbs.redditmedia.com/kPSBoifOMU0XDhnZaEIKf_jYAinALAhVB1bry9GNPrE.jpg,False,,[],{},,True,,1607100379.0,text,6,,,text,self.tensorflow,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/lp2hlt6tu4361.gif""&gt;https://i.redd.it/lp2hlt6tu4361.gif&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For more details see the &lt;a href=""https://youtu.be/eRwt_FXTdmg""&gt;full video&lt;/a&gt;, which also shows how a medium size convolutional neural network runs on the gpu of the M1 and how it compares to a dedicated desktop graphics card (Nvidia RTX 2060).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k6h9fr,True,,CaveNotes,,37,True,all_ads,False,[],False,,/r/tensorflow/comments/k6h9fr/new_hardwareaccelerated_tensorflow_fork_for_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k6h9fr/new_hardwareaccelerated_tensorflow_fork_for_the/,22217,1607071579.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Machine Learning on the new M1 Macbook Air (beats CPU server with 112 cores)', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/eRwt_FXTdmg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': 'cave notes', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/eRwt_FXTdmg/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_IdJ4-VidHg79QQBRJOnnA'}, 'type': 'youtube.com'}",False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/6sVf9P5XDjh4g65rZ_iPWQbB7Ymd1YsYoGsWcU3fqx0.jpg?auto=webp&amp;s=31ed3c777513b7b498a54c10323fd225f470256b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/6sVf9P5XDjh4g65rZ_iPWQbB7Ymd1YsYoGsWcU3fqx0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8db24caa5ce3f08d99cc9b647c857991736be857', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/6sVf9P5XDjh4g65rZ_iPWQbB7Ymd1YsYoGsWcU3fqx0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b37db3525f674acff636a3768e06bb60bcb8ad9', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/6sVf9P5XDjh4g65rZ_iPWQbB7Ymd1YsYoGsWcU3fqx0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b033b789afcc42fbb4ddb4bb769852df28c3d90f', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'LoPNVo180_Yt7F9XR-Bl0cXVBWPNkEELvNaPsYHRD6Y'}], 'enabled': False}",,"{'lp2hlt6tu4361': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/lp2hlt6tu4361.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=64b55d412b4a54ff1503bd5960cc3a1c5538bc7b'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/lp2hlt6tu4361.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=cb001babc1d81f549fdf00636c3bb9f7618bf924'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/lp2hlt6tu4361.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=47f81b1a727ae5276ba5ce1ad5117d7f2fa97225'}], 's': {'y': 338, 'gif': 'https://i.redd.it/lp2hlt6tu4361.gif', 'mp4': 'https://preview.redd.it/lp2hlt6tu4361.gif?format=mp4&amp;s=5422eb2b0dd53191a1e97eaecdda5c88aa5735f3', 'x': 600}, 'id': 'lp2hlt6tu4361'}}",,,,
432,,tensorflow," 

hi i'm wanting one image to turn into another with every training step.

First

* load 2 images (source, target)
* we calculate the error between each image
* We optimize the output image so that it looks more and more like the target image.

but when trying to run it gives me this error

ValueError: No gradients provided for any variable: \['Variable: 0'\].

What am I doing wrong?

&amp;#x200B;

    import os
    import tensorflow as tf
    # Load compressed models from tensorflow_hub
    os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'
    
    import IPython.display as display
    
    import matplotlib.pyplot as plt
    import matplotlib as mpl
    mpl.rcParams['figure.figsize'] = (12,12)
    mpl.rcParams['axes.grid'] = False
    
    import numpy as np
    import PIL.Image
    import time
    import functools
    
    
    def tensor_to_image(tensor):
      tensor = tensor*255
      tensor = np.array(tensor, dtype=np.uint8)
      if np.ndim(tensor)&gt;3:
        assert tensor.shape[0] == 1
        tensor = tensor[0]
      return PIL.Image.fromarray(tensor)
    
    
    def load_img(path_to_img):
      max_dim = 512
      img = tf.io.read_file(path_to_img)
      img = tf.image.decode_image(img, channels=3)
      img = tf.image.convert_image_dtype(img, tf.float32)
    
      shape = tf.cast(tf.shape(img)[:-1], tf.float32)
      long_dim = max(shape)
      scale = max_dim / long_dim
    
      new_shape = tf.cast(shape * scale, tf.int32)
    
      img = tf.image.resize(img, new_shape)
      img = img[tf.newaxis, :]
      return img
    
    
    def imshow(image, title=None):
      if len(image.shape) &gt; 3:
        image = tf.squeeze(image, axis=0)
    
      plt.imshow(image)
      if title:
        plt.title(title)
    
    
    content_image = load_img(""/content/source.png"")
    style_image = load_img(""/content/target.png"")
    
    
    
    plt.subplot(1, 2, 1)
    imshow(content_image, 'Content Image')
    
    plt.subplot(1, 2, 2)
    imshow(style_image, 'Style Image')
    
    
    
    image = tf.Variable(content_image)
    
    def clip_0_1(image):
      return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)
    
    opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)
    
    
    
    #calculate the error between each image
    def losss():
        
        loss  = style_image - content_image
        return loss
    
    @tf.function()
    def train_step(image):
      
      with tf.GradientTape() as tape:
        
         loss = losss()
         
      grad = tape.gradient(loss, image)
      opt.apply_gradients([(grad, image)])
      image.assign(clip_0_1(image))
    
    #train
    train_step(image)
    train_step(image)
    train_step(image)
    tensor_to_image(image)
    
    
    
    ---------------------------------------------------------------------------
    ValueError                                Traceback (most recent call last)
    &lt;ipython-input-3-172e90c94500&gt; in &lt;module&gt;()
         11 
         12 
    ---&gt; 13 train_step(image)
         14 train_step(image)
         15 train_step(image)
    
    8 frames
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
        971           except Exception as e:  # pylint:disable=broad-except
        972             if hasattr(e, ""ag_error_metadata""):
    --&gt; 973               raise e.ag_error_metadata.to_exception(e)
        974             else:
        975               raise
    
    ValueError: in user code:
    
        &lt;ipython-input-3-172e90c94500&gt;:9 train_step  *
            opt.apply_gradients([(grad, image)])
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:513 apply_gradients  **
            grads_and_vars = _filter_grads(grads_and_vars)
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1271 _filter_grads
            ([v.name for _, v in grads_and_vars],))
    
        ValueError: No gradients provided for any variable: ['Variable:0'].",t2_4jql58et,False,,0,False,ValueError: No gradients provided for any variable: ['Variable: 0'],[],r/tensorflow,False,6,,0,,,False,t3_k6ygtb,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607161151.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hi i&amp;#39;m wanting one image to turn into another with every training step.&lt;/p&gt;

&lt;p&gt;First&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;load 2 images (source, target)&lt;/li&gt;
&lt;li&gt;we calculate the error between each image&lt;/li&gt;
&lt;li&gt;We optimize the output image so that it looks more and more like the target image.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;but when trying to run it gives me this error&lt;/p&gt;

&lt;p&gt;ValueError: No gradients provided for any variable: [&amp;#39;Variable: 0&amp;#39;].&lt;/p&gt;

&lt;p&gt;What am I doing wrong?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
import tensorflow as tf
# Load compressed models from tensorflow_hub
os.environ[&amp;#39;TFHUB_MODEL_LOAD_FORMAT&amp;#39;] = &amp;#39;COMPRESSED&amp;#39;

import IPython.display as display

import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams[&amp;#39;figure.figsize&amp;#39;] = (12,12)
mpl.rcParams[&amp;#39;axes.grid&amp;#39;] = False

import numpy as np
import PIL.Image
import time
import functools


def tensor_to_image(tensor):
  tensor = tensor*255
  tensor = np.array(tensor, dtype=np.uint8)
  if np.ndim(tensor)&amp;gt;3:
    assert tensor.shape[0] == 1
    tensor = tensor[0]
  return PIL.Image.fromarray(tensor)


def load_img(path_to_img):
  max_dim = 512
  img = tf.io.read_file(path_to_img)
  img = tf.image.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)

  shape = tf.cast(tf.shape(img)[:-1], tf.float32)
  long_dim = max(shape)
  scale = max_dim / long_dim

  new_shape = tf.cast(shape * scale, tf.int32)

  img = tf.image.resize(img, new_shape)
  img = img[tf.newaxis, :]
  return img


def imshow(image, title=None):
  if len(image.shape) &amp;gt; 3:
    image = tf.squeeze(image, axis=0)

  plt.imshow(image)
  if title:
    plt.title(title)


content_image = load_img(&amp;quot;/content/source.png&amp;quot;)
style_image = load_img(&amp;quot;/content/target.png&amp;quot;)



plt.subplot(1, 2, 1)
imshow(content_image, &amp;#39;Content Image&amp;#39;)

plt.subplot(1, 2, 2)
imshow(style_image, &amp;#39;Style Image&amp;#39;)



image = tf.Variable(content_image)

def clip_0_1(image):
  return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)

opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)



#calculate the error between each image
def losss():

    loss  = style_image - content_image
    return loss

@tf.function()
def train_step(image):

  with tf.GradientTape() as tape:

     loss = losss()

  grad = tape.gradient(loss, image)
  opt.apply_gradients([(grad, image)])
  image.assign(clip_0_1(image))

#train
train_step(image)
train_step(image)
train_step(image)
tensor_to_image(image)



---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&amp;lt;ipython-input-3-172e90c94500&amp;gt; in &amp;lt;module&amp;gt;()
     11 
     12 
---&amp;gt; 13 train_step(image)
     14 train_step(image)
     15 train_step(image)

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, &amp;quot;ag_error_metadata&amp;quot;):
--&amp;gt; 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

ValueError: in user code:

    &amp;lt;ipython-input-3-172e90c94500&amp;gt;:9 train_step  *
        opt.apply_gradients([(grad, image)])
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:513 apply_gradients  **
        grads_and_vars = _filter_grads(grads_and_vars)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1271 _filter_grads
        ([v.name for _, v in grads_and_vars],))

    ValueError: No gradients provided for any variable: [&amp;#39;Variable:0&amp;#39;].
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k6ygtb,True,,molo32,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k6ygtb/valueerror_no_gradients_provided_for_any_variable/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k6ygtb/valueerror_no_gradients_provided_for_any_variable/,22217,1607132351.0,0,,False,,,,,,,,,
433,,tensorflow,"Horovod announces its v0.21 and brings many powerful new features to the Horovod community, making training deep learning models faster and easier than ever before.

[Horovod](https://eng.uber.com/horovod/) was open-sourced in 2017, and it has grown to become the standard solution for scaling deep learning training to hundreds of GPUs. Horovod can reduce training times from days or weeks to hours or minutes by adding a few lines of Python code to an existing TensorFlow, PyTorch, or Apache MXNet training script.

Summary: [https://www.marktechpost.com/2020/12/04/uber-engineering-releases-horovod-v0-21-new-features-include-local-gradient-aggregation-for-tensorflow-v1-and-v2/](https://www.marktechpost.com/2020/12/04/uber-engineering-releases-horovod-v0-21-new-features-include-local-gradient-aggregation-for-tensorflow-v1-and-v2/) 

V0.21.0: [https://github.com/horovod/horovod/releases/tag/v0.21.0](https://github.com/horovod/horovod/releases/tag/v0.21.0)",t2_2wsvqwhg,False,,0,False,Uber Engineering Releases Horovod v0.21: New Features Include Local Gradient Aggregation For TensorFlow v1 and v2,[],r/tensorflow,False,6,,0,,,False,t3_k6o2cz,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1607127898.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Horovod announces its v0.21 and brings many powerful new features to the Horovod community, making training deep learning models faster and easier than ever before.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://eng.uber.com/horovod/""&gt;Horovod&lt;/a&gt; was open-sourced in 2017, and it has grown to become the standard solution for scaling deep learning training to hundreds of GPUs. Horovod can reduce training times from days or weeks to hours or minutes by adding a few lines of Python code to an existing TensorFlow, PyTorch, or Apache MXNet training script.&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/12/04/uber-engineering-releases-horovod-v0-21-new-features-include-local-gradient-aggregation-for-tensorflow-v1-and-v2/""&gt;https://www.marktechpost.com/2020/12/04/uber-engineering-releases-horovod-v0-21-new-features-include-local-gradient-aggregation-for-tensorflow-v1-and-v2/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;V0.21.0: &lt;a href=""https://github.com/horovod/horovod/releases/tag/v0.21.0""&gt;https://github.com/horovod/horovod/releases/tag/v0.21.0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,k6o2cz,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k6o2cz/uber_engineering_releases_horovod_v021_new/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k6o2cz/uber_engineering_releases_horovod_v021_new/,22217,1607099098.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?auto=webp&amp;s=c21e7e1d29647bb650b4987615d5f9c82cd1e6ba', 'width': 1400, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd7291fc2fa92c08fa3eb7ab79b874307ee69413', 'width': 108, 'height': 46}, {'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be25fd7473d3d42c9815a73396b6c31cabddbf50', 'width': 216, 'height': 92}, {'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dba77368f8311626491e88f859ee274fed7a958b', 'width': 320, 'height': 137}, {'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab93f458d1a857f0bde303d6f2cee77c4796de03', 'width': 640, 'height': 274}, {'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bce7114c1f63a7d07d74dd512c4422699da3d863', 'width': 960, 'height': 411}, {'url': 'https://external-preview.redd.it/YdCLcVDW7yyiGDrotdM0Rmh5SDn5i5pZoaP1HIOiQmE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b7c00680949c0a149910865a322ce67e4f05ca03', 'width': 1080, 'height': 462}], 'variants': {}, 'id': 'KhOJrGA40VQHU67YQvUAWxN6z4gsiUfyr4Y3yFgAREE'}], 'enabled': False}",,,,,,
434,,tensorflow," Hi folks, I am pretty new to ML but I've been teaching myself Python and Tensorflow via Coursera/some books and I really enjoy computer vision.

I need help figuring out the architecture of this idea I have...anyone willing to spare some thoughts please? I work at a bureaucratic organization and one of my functions is to check paperwork for missing fields or errors. The applications I check are usually 3-4 pages but I want to try for the first 2 pages only.

My idea: create a model that could have a photo uploaded to recognize which info is missing (blank spaces) or incorrect (for example, a signature that's too big which needs to be in a certain bounded box, incomprehensible writing, etc)

I'd then like to add on a graphical part to the model which would box in red what info is missing or needs attention..

I don't know how I would do this though - I figure a CNN would be involved but I'm struggling to figure out how to structure this

If you were me, what would you do? I thought I'd start by putting together dozens of fake applications myself with varying levels of info (some filled out entirely, some half filled out, some missing just 2 boxes of info) and using those images to train.

Any pointers, please??

I am soooo lost tbh. I am a newbie so any guidance would be super appreciated

(I'm basically trying to figure out how to automate myself out of a job - while I can scan these applications,, I miss things here and there, and my job would be easier if I could have the vital info to review somehow highlighted first rather than reading the entire thing). I only know a bit of Python so I'd be looking to do it in this language.

Thank you!!!!!!",t2_87o12wiw,False,,0,False,Any ideas for how to put together my ML project idea? I want to do something in Tensorflow that can scan photos to recognize missing information on forms,[],r/tensorflow,False,6,,0,,,False,t3_k6pv83,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607133293.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi folks, I am pretty new to ML but I&amp;#39;ve been teaching myself Python and Tensorflow via Coursera/some books and I really enjoy computer vision.&lt;/p&gt;

&lt;p&gt;I need help figuring out the architecture of this idea I have...anyone willing to spare some thoughts please? I work at a bureaucratic organization and one of my functions is to check paperwork for missing fields or errors. The applications I check are usually 3-4 pages but I want to try for the first 2 pages only.&lt;/p&gt;

&lt;p&gt;My idea: create a model that could have a photo uploaded to recognize which info is missing (blank spaces) or incorrect (for example, a signature that&amp;#39;s too big which needs to be in a certain bounded box, incomprehensible writing, etc)&lt;/p&gt;

&lt;p&gt;I&amp;#39;d then like to add on a graphical part to the model which would box in red what info is missing or needs attention..&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know how I would do this though - I figure a CNN would be involved but I&amp;#39;m struggling to figure out how to structure this&lt;/p&gt;

&lt;p&gt;If you were me, what would you do? I thought I&amp;#39;d start by putting together dozens of fake applications myself with varying levels of info (some filled out entirely, some half filled out, some missing just 2 boxes of info) and using those images to train.&lt;/p&gt;

&lt;p&gt;Any pointers, please??&lt;/p&gt;

&lt;p&gt;I am soooo lost tbh. I am a newbie so any guidance would be super appreciated&lt;/p&gt;

&lt;p&gt;(I&amp;#39;m basically trying to figure out how to automate myself out of a job - while I can scan these applications,, I miss things here and there, and my job would be easier if I could have the vital info to review somehow highlighted first rather than reading the entire thing). I only know a bit of Python so I&amp;#39;d be looking to do it in this language.&lt;/p&gt;

&lt;p&gt;Thank you!!!!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k6pv83,True,,deepclearliquidsnow,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/k6pv83/any_ideas_for_how_to_put_together_my_ml_project/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k6pv83/any_ideas_for_how_to_put_together_my_ml_project/,22217,1607104493.0,0,,False,,,,,,,,,
435,,tensorflow,"In my new video, you can learn how AutoEncoders work in an intuitive way. You’ll learn about representation learning, latent space, and other fundamental concepts. I also explain how Autoencoders are applied to important tasks such as data generation and denoising.

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

[https://www.youtube.com/watch?v=xwrzh4e8DLs&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=3](https://www.youtube.com/watch?v=xwrzh4e8DLs&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=3)",t2_12ahau,False,,0,False,I published a video where I explain how autoencoders work easily 🎧 🤖,[],r/tensorflow,False,6,,0,,,False,t3_k5y2jv,False,dark,0.91,,public,26,0,{},,,False,[],,False,False,,{},Project,False,26,,False,self,False,,[],{},,True,,1607034145.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new video, you can learn how AutoEncoders work in an intuitive way. You’ll learn about representation learning, latent space, and other fundamental concepts. I also explain how Autoencoders are applied to important tasks such as data generation and denoising.&lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=xwrzh4e8DLs&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=3""&gt;https://www.youtube.com/watch?v=xwrzh4e8DLs&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=3&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k5y2jv,True,,diabulusInMusica,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k5y2jv/i_published_a_video_where_i_explain_how/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k5y2jv/i_published_a_video_where_i_explain_how/,22217,1607005345.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/EghSGrFEgW2u_TcDNCg8mg-qG4UNwPyp_j9a0fSmcgI.jpg?auto=webp&amp;s=643182ee103f0efeebd959a749ca3e9e0b6bcd40', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/EghSGrFEgW2u_TcDNCg8mg-qG4UNwPyp_j9a0fSmcgI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5cc88b2b739fb653c08001df895be63436871c1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/EghSGrFEgW2u_TcDNCg8mg-qG4UNwPyp_j9a0fSmcgI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=24cbba92338d2e624444851b9c165586c0644ab5', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/EghSGrFEgW2u_TcDNCg8mg-qG4UNwPyp_j9a0fSmcgI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3801a95f18dc4ddfa2a7222a499667c97712c213', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'qbl7rgnEzYlFsgGOQ1-lavgWCTwmndMfDaw6Sa0_fyE'}], 'enabled': False}",,,,,,
436,,tensorflow,How I can debug tape.gradient() . I am getting none as output. How I can debug this function step by step?,t2_2k0cf77q,False,,0,False,debugging gradients,[],r/tensorflow,False,6,,0,,,False,t3_k668z6,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607058457.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How I can debug tape.gradient() . I am getting none as output. How I can debug this function step by step?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k668z6,True,,IIAKAD,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k668z6/debugging_gradients/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k668z6/debugging_gradients/,22217,1607029657.0,0,,False,,,,,,,,,
437,,tensorflow,"I'm trying to use Tensorflow's distributed strategies to train a stock trading model. The data is intraday data, and I'm breaking it up so that each training step is an entire day's worth of data (with many individual sub-steps happening within that day). The model I'm creating is actually two models that will work and be trained together. I need to pass the features for both of those models, as well as data used to calculate what the reward should be (as I'm using RL). Before training, I loop through all the days that need to be trained on and call a function that returns these three elements. I then convert this data to a tensor using `tf.data.Dataset.from_tensor_slices(tf.ragged.constant(combined_features))`, with `combined_features` being the combined data for all days that are being trained on.

What I'm confused about is how to separate that data in the training function into the three lists of data. I also need to be able to iterate over the datasets since I need to walk through each step for that day and complete training on it. I saw there's a `Dataset.as_numpy_iterator()` function, but it says that it can only be used in eager mode. Due to performance reasons when using distributed strategies, eager mode isn't an option for me.

Any help would be much appreciated!",t2_5htoe6qg,False,,0,False,How to convert a Tensorflow Dataset into an iterable form when using a distributed strategy?,[],r/tensorflow,False,6,,0,,,False,t3_k64oug,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1607053808.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to use Tensorflow&amp;#39;s distributed strategies to train a stock trading model. The data is intraday data, and I&amp;#39;m breaking it up so that each training step is an entire day&amp;#39;s worth of data (with many individual sub-steps happening within that day). The model I&amp;#39;m creating is actually two models that will work and be trained together. I need to pass the features for both of those models, as well as data used to calculate what the reward should be (as I&amp;#39;m using RL). Before training, I loop through all the days that need to be trained on and call a function that returns these three elements. I then convert this data to a tensor using &lt;code&gt;tf.data.Dataset.from_tensor_slices(tf.ragged.constant(combined_features))&lt;/code&gt;, with &lt;code&gt;combined_features&lt;/code&gt; being the combined data for all days that are being trained on.&lt;/p&gt;

&lt;p&gt;What I&amp;#39;m confused about is how to separate that data in the training function into the three lists of data. I also need to be able to iterate over the datasets since I need to walk through each step for that day and complete training on it. I saw there&amp;#39;s a &lt;code&gt;Dataset.as_numpy_iterator()&lt;/code&gt; function, but it says that it can only be used in eager mode. Due to performance reasons when using distributed strategies, eager mode isn&amp;#39;t an option for me.&lt;/p&gt;

&lt;p&gt;Any help would be much appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k64oug,True,,EdvardDashD,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k64oug/how_to_convert_a_tensorflow_dataset_into_an/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k64oug/how_to_convert_a_tensorflow_dataset_into_an/,22217,1607025008.0,0,,False,,,,,,,,,
438,,tensorflow,"Hello anyone who is more knowledgeable than me in this... title says it all i have used pip3 install tensorflow to attempt to install tf but i seem to be recieveing the following callback errors when attempting to do ""import tensorflow as tf"":

Traceback (most recent call last):

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 64, in &lt;module&gt;

from tensorflow.python.\_pywrap\_tensorflow\_internal import \*

ImportError: DLL load failed: The specified module could not be found.

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

File ""C:/Users/manny/AppData/Local/Programs/Python/Python37/Tensorflow [Example.py](https://Example.py)"", line 1, in &lt;module&gt;

import tensorflow as tf

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 41, in &lt;module&gt;

from [tensorflow.python.tools](https://tensorflow.python.tools) import module\_util as \_module\_util

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 40, in &lt;module&gt;

from tensorflow.python.eager import context

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\[context.py](https://context.py)"", line 35, in &lt;module&gt;

from tensorflow.python import pywrap\_tfe

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap\_tfe.py"", line 28, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 83, in &lt;module&gt;

raise ImportError(msg)

ImportError: Traceback (most recent call last):

File ""C:\\Users\\manny\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 64, in &lt;module&gt;

from tensorflow.python.\_pywrap\_tensorflow\_internal import \*

ImportError: DLL load failed: The specified module could not be found.

&amp;#x200B;

&amp;#x200B;

Failed to load the native TensorFlow runtime.

&amp;#x200B;

Any help would be appreciated!",t2_2p123got,False,,0,False,Help with setting up Tensorflow in IDLE?,[],r/tensorflow,False,6,,0,,,False,t3_k5n6sn,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1606987183.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello anyone who is more knowledgeable than me in this... title says it all i have used pip3 install tensorflow to attempt to install tf but i seem to be recieveing the following callback errors when attempting to do &amp;quot;import tensorflow as tf&amp;quot;:&lt;/p&gt;

&lt;p&gt;Traceback (most recent call last):&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&amp;quot;, line 64, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;from tensorflow.python._pywrap_tensorflow_internal import *&lt;/p&gt;

&lt;p&gt;ImportError: DLL load failed: The specified module could not be found.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;During handling of the above exception, another exception occurred:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Traceback (most recent call last):&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:/Users/manny/AppData/Local/Programs/Python/Python37/Tensorflow &lt;a href=""https://Example.py""&gt;Example.py&lt;/a&gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;import tensorflow as tf&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py&amp;quot;, line 41, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;from &lt;a href=""https://tensorflow.python.tools""&gt;tensorflow.python.tools&lt;/a&gt; import module_util as _module_util&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py&amp;quot;, line 40, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;from tensorflow.python.eager import context&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\&lt;a href=""https://context.py""&gt;context.py&lt;/a&gt;&amp;quot;, line 35, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;from tensorflow.python import pywrap_tfe&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tfe.py&amp;quot;, line 28, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;from tensorflow.python import pywrap_tensorflow&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&amp;quot;, line 83, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;raise ImportError(msg)&lt;/p&gt;

&lt;p&gt;ImportError: Traceback (most recent call last):&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\manny\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&amp;quot;, line 64, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;from tensorflow.python._pywrap_tensorflow_internal import *&lt;/p&gt;

&lt;p&gt;ImportError: DLL load failed: The specified module could not be found.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Failed to load the native TensorFlow runtime.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any help would be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k5n6sn,True,,Maezzzz,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k5n6sn/help_with_setting_up_tensorflow_in_idle/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k5n6sn/help_with_setting_up_tensorflow_in_idle/,22217,1606958383.0,0,,False,,,,,,,,,
439,,tensorflow,[https://stackoverflow.com/questions/65119069/why-am-i-getting-the-nonetype-object-is-not-callable-error-when-i-apply-mo](https://stackoverflow.com/questions/65119069/why-am-i-getting-the-nonetype-object-is-not-callable-error-when-i-apply-mo),t2_4tg0bd00,False,,0,False,Can someone please answer this question for me 🥶,[],r/tensorflow,False,6,,0,,,False,t3_k5qt61,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1607000464.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://stackoverflow.com/questions/65119069/why-am-i-getting-the-nonetype-object-is-not-callable-error-when-i-apply-mo""&gt;https://stackoverflow.com/questions/65119069/why-am-i-getting-the-nonetype-object-is-not-callable-error-when-i-apply-mo&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k5qt61,True,,hallway_hobo,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k5qt61/can_someone_please_answer_this_question_for_me/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k5qt61/can_someone_please_answer_this_question_for_me/,22217,1606971664.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
440,,tensorflow,"Has anyone done this? Would love to use my R9 290 for TF so I don't have to buy an nVidia just for CUDA support.

When using bazel to build TF v1, I get a ""error\_gpu\_disabled()""",t2_34rao3vb,False,,0,False,Compile TF for ROCM (amd gpu) on windows?,[],r/tensorflow,False,6,,0,,,False,t3_k5lplj,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1606982165.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone done this? Would love to use my R9 290 for TF so I don&amp;#39;t have to buy an nVidia just for CUDA support.&lt;/p&gt;

&lt;p&gt;When using bazel to build TF v1, I get a &amp;quot;error_gpu_disabled()&amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k5lplj,True,,nuzzlet,,17,True,all_ads,False,[],False,,/r/tensorflow/comments/k5lplj/compile_tf_for_rocm_amd_gpu_on_windows/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k5lplj/compile_tf_for_rocm_amd_gpu_on_windows/,22217,1606953365.0,0,,False,,,,,,,,,
441,,tensorflow,"So, my task is to give a rating to another's algo image segmentation job using ground truth segmentation map and rating from the human expert. As i've failed to obtain any similarity metric what would correlate with the rating well enough, it's time for neural networks. Of course i could just train an autoencoder from which i will then obtain a latent representation of an image and see if those features give me better results (in fact i know they will from another person's solution to the same problem), but i also want to try a bit of a different approach. I want a network which would consist of two CNN's, for expert mask and for evaluated algo mask, which would at the fully connected part be concatenated and then use that combined vector to predict ratings. So it's sort of like a letter Y if that makes sence. The idea here to make both CNN backpropagate jointly and actually make use of rating ground truth when training CNNs, thus hopefully achieving better result. So, i know it's a valid network architecture, but how do i actually code something like this in keras? I could just write it in raw tf, but i don't want to go insane just yet. I guess the part i have the question with is how to make the model object process several inputs which would start in different branches, rest of it is fairly straightforward and i can probably figure it out on my own.",t2_wn450,False,,0,False,Stitching together complex network with several inputs with keras.,[],r/tensorflow,False,6,,0,,,False,t3_k5mmzs,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1606985269.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So, my task is to give a rating to another&amp;#39;s algo image segmentation job using ground truth segmentation map and rating from the human expert. As i&amp;#39;ve failed to obtain any similarity metric what would correlate with the rating well enough, it&amp;#39;s time for neural networks. Of course i could just train an autoencoder from which i will then obtain a latent representation of an image and see if those features give me better results (in fact i know they will from another person&amp;#39;s solution to the same problem), but i also want to try a bit of a different approach. I want a network which would consist of two CNN&amp;#39;s, for expert mask and for evaluated algo mask, which would at the fully connected part be concatenated and then use that combined vector to predict ratings. So it&amp;#39;s sort of like a letter Y if that makes sence. The idea here to make both CNN backpropagate jointly and actually make use of rating ground truth when training CNNs, thus hopefully achieving better result. So, i know it&amp;#39;s a valid network architecture, but how do i actually code something like this in keras? I could just write it in raw tf, but i don&amp;#39;t want to go insane just yet. I guess the part i have the question with is how to make the model object process several inputs which would start in different branches, rest of it is fairly straightforward and i can probably figure it out on my own.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k5mmzs,True,,Spectator696,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k5mmzs/stitching_together_complex_network_with_several/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k5mmzs/stitching_together_complex_network_with_several/,22217,1606956469.0,0,,False,,,,,,,,,
442,,tensorflow,Just installed TensorFlow-DirectML with pip. What else do I have to do to get started?,t2_34rao3vb,False,,0,False,How do I use DirectML with Tensorflow.JS,[],r/tensorflow,False,6,,0,,,False,t3_k5mjbd,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606984928.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just installed TensorFlow-DirectML with pip. What else do I have to do to get started?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k5mjbd,True,,nuzzlet,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k5mjbd/how_do_i_use_directml_with_tensorflowjs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k5mjbd/how_do_i_use_directml_with_tensorflowjs/,22217,1606956128.0,0,,False,,,,,,,,,
443,,tensorflow,Thank you. It was solved by someone!,t2_cymzy6l,False,,0,False,I will give $100 to the first person who can get Tensorflow using a GPU on my fresh install of ubuntu 18.04.,[],r/tensorflow,False,6,,0,,,False,t3_k4prp8,False,dark,0.91,,public,32,0,{},,,False,[],,False,False,,{},,False,32,,False,self,1606850349.0,,[],{},,True,,1606873276.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Thank you. It was solved by someone!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k4prp8,True,,DeepDataDiver,,19,True,all_ads,False,[],False,,/r/tensorflow/comments/k4prp8/i_will_give_100_to_the_first_person_who_can_get/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4prp8/i_will_give_100_to_the_first_person_who_can_get/,22217,1606844476.0,0,,False,,,,,,,,,
444,,tensorflow,"Getting the above error on a custom build of TF 2.3 on Ubuntu 20.04 (built in NVidia Docker against CUDA 10.1). I had to build it myself because official TF binary releases dropped support for many common compute capabilities.

So I figured I would chose the default suggestion for compute capabilities in the build script, namely 3.5 and 7.0, assuming the 3.5 kernels would be compatible to all newer GPUs.

Now, it works fine on a 2070 which has CC 7.5. However it does not work on a 1080 (CC 6.1)  and I get ""device kernel image is invalid"". But the build contains both PTX and ELF kernels for sm\_35 and sm\_70, I have verified this with cuobjdump. I would assume the sm\_35 PTX kernels should be compilable to binary code for the 1080 by the driver, right?

If I do CUDA\_FORCE\_PTX\_JIT=1 it ALSO stops working on my 2070 - even though it has PTX and ELF kernels for sm\_70 as mentioned above.

  
Also, it takes a long time (maybe 30s) after calling tf.compat.v1.Session() for the error to show up so apparently it is an issue with PTX JIT compilation. I have tried deleting the cache (.nv) and raising the cache size, same thing happens.

&amp;#x200B;

Can anyone shine some light on this issue?",t2_8xyuf,False,,0,False,Status: device kernel image is invalid even though PTX kernel is available for lower compute capability,[],r/tensorflow,False,6,,0,,,False,t3_k55kuk,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1606926902.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Getting the above error on a custom build of TF 2.3 on Ubuntu 20.04 (built in NVidia Docker against CUDA 10.1). I had to build it myself because official TF binary releases dropped support for many common compute capabilities.&lt;/p&gt;

&lt;p&gt;So I figured I would chose the default suggestion for compute capabilities in the build script, namely 3.5 and 7.0, assuming the 3.5 kernels would be compatible to all newer GPUs.&lt;/p&gt;

&lt;p&gt;Now, it works fine on a 2070 which has CC 7.5. However it does not work on a 1080 (CC 6.1)  and I get &amp;quot;device kernel image is invalid&amp;quot;. But the build contains both PTX and ELF kernels for sm_35 and sm_70, I have verified this with cuobjdump. I would assume the sm_35 PTX kernels should be compilable to binary code for the 1080 by the driver, right?&lt;/p&gt;

&lt;p&gt;If I do CUDA_FORCE_PTX_JIT=1 it ALSO stops working on my 2070 - even though it has PTX and ELF kernels for sm_70 as mentioned above.&lt;/p&gt;

&lt;p&gt;Also, it takes a long time (maybe 30s) after calling tf.compat.v1.Session() for the error to show up so apparently it is an issue with PTX JIT compilation. I have tried deleting the cache (.nv) and raising the cache size, same thing happens.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can anyone shine some light on this issue?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k55kuk,True,,fnordstar,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k55kuk/status_device_kernel_image_is_invalid_even_though/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k55kuk/status_device_kernel_image_is_invalid_even_though/,22217,1606898102.0,0,,False,,,,,,,,,
445,,tensorflow,,t2_8oczr,False,,0,False,Predicting numerical values from numerical and categorical variables with Tensorflow 2.x,[],r/tensorflow,False,6,,0,,,False,t3_k54r4s,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,default,False,,[],{},,False,,1606922796.0,text,6,,,text,self.MachineLearning,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k54r4s,True,,p_tu,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k54r4s/predicting_numerical_values_from_numerical_and/,all_ads,False,/r/MachineLearning/comments/k54f9y/housing_prices_with_tf2x_d/,22217,1606893996.0,0,,False,link,/r/MachineLearning/comments/k54f9y/housing_prices_with_tf2x_d/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?auto=webp&amp;s=96bcf5a6cdcb624f992991865dba5487b0bfa93a', 'width': 719, 'height': 262}, 'resolutions': [{'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2f9f4fa4337370c248d12e681c024bc5f4c45fc', 'width': 108, 'height': 39}, {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c74701997db7019a67ee008c47a089adb6f9bc1b', 'width': 216, 'height': 78}, {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ee580ad8023a0ec199b060deb4ac6ced0b10e2c5', 'width': 320, 'height': 116}, {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcc20a2efcb56756b216dd77ba386ac87d1e7266', 'width': 640, 'height': 233}], 'variants': {}, 'id': 'UOAqH7R1nP0KNWuMoT2ORv6nYfGYLmubjAUHi5BEWCA'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Yesterday I tried to make a model that predicts a number based on numerical and categorical variables and found this:\n\nhttps://towardsdatascience.com/simple-house-price-predictor-using-ml-through-tensorflow-in-python-cbd2b637904b\n\nHowever, in the article tf.contrib is used, which has been deprecated with TF2.0.\n\nOnly solutions that I found suggested to downgrade to 1.x, which isn’t really an optimal solution in the long-term.\n\nSo, how would you solve this with tf 2.0?\n\nThe line that’s using tf.contrib is here:\ntf.contrib.layers.real_valued_column(continuous_feature))\n\nOf course being Python, there might be other issues down the line too, so suggestions for updated instructions that use tf2.x are also welcome.', 'author_fullname': 't2_8oczr', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Housing prices with TF2.x [D]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_k54f9y', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1606921255.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Yesterday I tried to make a model that predicts a number based on numerical and categorical variables and found this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://towardsdatascience.com/simple-house-price-predictor-using-ml-through-tensorflow-in-python-cbd2b637904b""&gt;https://towardsdatascience.com/simple-house-price-predictor-using-ml-through-tensorflow-in-python-cbd2b637904b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, in the article tf.contrib is used, which has been deprecated with TF2.0.&lt;/p&gt;\n\n&lt;p&gt;Only solutions that I found suggested to downgrade to 1.x, which isn’t really an optimal solution in the long-term.&lt;/p&gt;\n\n&lt;p&gt;So, how would you solve this with tf 2.0?&lt;/p&gt;\n\n&lt;p&gt;The line that’s using tf.contrib is here:\ntf.contrib.layers.real_valued_column(continuous_feature))&lt;/p&gt;\n\n&lt;p&gt;Of course being Python, there might be other issues down the line too, so suggestions for updated instructions that use tf2.x are also welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?auto=webp&amp;s=96bcf5a6cdcb624f992991865dba5487b0bfa93a', 'width': 719, 'height': 262}, 'resolutions': [{'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2f9f4fa4337370c248d12e681c024bc5f4c45fc', 'width': 108, 'height': 39}, {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c74701997db7019a67ee008c47a089adb6f9bc1b', 'width': 216, 'height': 78}, {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ee580ad8023a0ec199b060deb4ac6ced0b10e2c5', 'width': 320, 'height': 116}, {'url': 'https://external-preview.redd.it/uazKBFsU4vk0V2FiC0t17lYP_QEUM-fN_hxqI64KTAU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcc20a2efcb56756b216dd77ba386ac87d1e7266', 'width': 640, 'height': 233}], 'variants': {}, 'id': 'UOAqH7R1nP0KNWuMoT2ORv6nYfGYLmubjAUHi5BEWCA'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'k54f9y', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'p_tu', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/k54f9y/housing_prices_with_tf2x_d/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/k54f9y/housing_prices_with_tf2x_d/', 'subreddit_subscribers': 1740788, 'created_utc': 1606892455.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_k54f9y,
446,,tensorflow,"This may be a dumb question, but what is the difference between argument and call arguments. I am looking at the LSTM documentation ([https://www.tensorflow.org/api\_docs/python/tf/keras/layers/LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)) and I am confused by this",t2_1u764t1o,False,,0,False,Tensorflow 2.0 Documentation,[],r/tensorflow,False,6,,0,,,False,t3_k4yn1m,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1606899742.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This may be a dumb question, but what is the difference between argument and call arguments. I am looking at the LSTM documentation (&lt;a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM""&gt;https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM&lt;/a&gt;) and I am confused by this&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k4yn1m,True,,BlackFreud,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k4yn1m/tensorflow_20_documentation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4yn1m/tensorflow_20_documentation/,22217,1606870942.0,0,,False,,,,,,,,,
447,,tensorflow,"Hello, I am relatively new to TensorFlow, I have been able to train models on a single machine, but want to train using multiple machines to decrease total train time. I have been receiving this error, from my worker nodes, but can not seem to get it to fix itself. I have been trying to use a ParameterServerStrategy.

    ValueError: The `experimental_distribute_dataset` method must be called inside a 
    `tf.function` passed to `create_per_worker_dataset` of 
    `tf.distribute.experimental.coordinator.ClusterCoordinator`

I have found many articles that are based on using ParameterServerStrategy, but most of them just copy each other and none of the content is original. The lines that are mentioned in the error are here:

    model.fit(ds_train,
              epochs=20,
              validation_data=ds_validation,
              callbacks=[cp_callback],
              batch_size=batch_size)
    
    model.save('saved_model/my_model')
    
    coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(strategy)
    
    @tf.function
    def per_worker_dataset_fn():
        return strategy.distribute_datasets_from_function(ds_train)
    
    
    per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)
    per_worker_iterator = iter(per_worker_dataset)

Any help whatsoever would be appreciated!",t2_2z3muqlb,False,,0,False,Help on ParameterServerStratagey() Value Error,[],r/tensorflow,False,6,,0,,,False,t3_k4yia5,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1606899314.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I am relatively new to TensorFlow, I have been able to train models on a single machine, but want to train using multiple machines to decrease total train time. I have been receiving this error, from my worker nodes, but can not seem to get it to fix itself. I have been trying to use a ParameterServerStrategy.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ValueError: The `experimental_distribute_dataset` method must be called inside a 
`tf.function` passed to `create_per_worker_dataset` of 
`tf.distribute.experimental.coordinator.ClusterCoordinator`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have found many articles that are based on using ParameterServerStrategy, but most of them just copy each other and none of the content is original. The lines that are mentioned in the error are here:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.fit(ds_train,
          epochs=20,
          validation_data=ds_validation,
          callbacks=[cp_callback],
          batch_size=batch_size)

model.save(&amp;#39;saved_model/my_model&amp;#39;)

coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(strategy)

@tf.function
def per_worker_dataset_fn():
    return strategy.distribute_datasets_from_function(ds_train)


per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)
per_worker_iterator = iter(per_worker_dataset)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Any help whatsoever would be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k4yia5,True,,DevTechs,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/k4yia5/help_on_parameterserverstratagey_value_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4yia5/help_on_parameterserverstratagey_value_error/,22217,1606870514.0,0,,False,,,,,,,,,
448,,tensorflow,"I'm not a TensorFlow engineer so this may be wrong, but I am hoping someone can tell me if I'm on the right track or what I need to do.

I was giving a model that I was told was trained in Keras. When I inspect it, I get this:

    # saved_model_cli show --dir saved_model.pb --tag_set serve --signature_def serving_default
    
    The given SavedModel SignatureDef contains the following input(s):
      inputs['conv2d_input'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1, 64, 64, 3)
          name: serving_default_conv2d_input:0
    The given SavedModel SignatureDef contains the following output(s):
      outputs['dense'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1, 3)
          name: StatefulPartitionedCall:0
    Method name is: tensorflow/serving/predict

The problem is my software runs inference and expects a model like this:

    The given SavedModel SignatureDef contains the following input(s):
      inputs['image_bytes'] tensor_info:
          dtype: DT_STRING
          shape: (-1)
          name: encoded_image_string_tensor:0
      inputs['key'] tensor_info:
          dtype: DT_STRING
          shape: (-1)
          name: key:0
    The given SavedModel SignatureDef contains the following output(s):
      outputs['detection_boxes'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1, -1, 4)
          name: detection_boxes:0
      outputs['detection_classes'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1, -1)
          name: detection_classes:0
      outputs['detection_classes_as_text'] tensor_info:
          dtype: DT_STRING
          shape: (-1, -1)
          name: detection_classes_as_text:0
      outputs['detection_multiclass_scores'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1, -1, 3)
          name: detection_multiclass_scores:0
      outputs['detection_scores'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1, -1)
          name: detection_scores:0
      outputs['image_info'] tensor_info:
          dtype: DT_INT32
          shape: (-1, 6)
          name: Tile_1:0
      outputs['key'] tensor_info:
          dtype: DT_STRING
          shape: (-1)
          name: Identity:0
      outputs['num_detections'] tensor_info:
          dtype: DT_FLOAT
          shape: (-1)
          name: num_detections:0
    Method name is: tensorflow/serving/predict

My issue is how to convert the model I was giving to have the needed inputs/outputs? I found this ([https://stackoverflow.com/questions/55373048/tensorflow-how-can-i-add-an-image-decoder-node-to-my-graph](https://stackoverflow.com/questions/55373048/tensorflow-how-can-i-add-an-image-decoder-node-to-my-graph)) and I think it can be used for the input but I'm not sure about the output. I'm assuming it's using the Object Detection API so somehow I need to convert the Keras model into an Object Detection API model?",t2_11vxbwus,False,,0,False,Keras and Object Detection API,[],r/tensorflow,False,6,,0,,,False,t3_k4ro4c,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1606878591.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m not a TensorFlow engineer so this may be wrong, but I am hoping someone can tell me if I&amp;#39;m on the right track or what I need to do.&lt;/p&gt;

&lt;p&gt;I was giving a model that I was told was trained in Keras. When I inspect it, I get this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# saved_model_cli show --dir saved_model.pb --tag_set serve --signature_def serving_default

The given SavedModel SignatureDef contains the following input(s):
  inputs[&amp;#39;conv2d_input&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 64, 64, 3)
      name: serving_default_conv2d_input:0
The given SavedModel SignatureDef contains the following output(s):
  outputs[&amp;#39;dense&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 3)
      name: StatefulPartitionedCall:0
Method name is: tensorflow/serving/predict
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem is my software runs inference and expects a model like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The given SavedModel SignatureDef contains the following input(s):
  inputs[&amp;#39;image_bytes&amp;#39;] tensor_info:
      dtype: DT_STRING
      shape: (-1)
      name: encoded_image_string_tensor:0
  inputs[&amp;#39;key&amp;#39;] tensor_info:
      dtype: DT_STRING
      shape: (-1)
      name: key:0
The given SavedModel SignatureDef contains the following output(s):
  outputs[&amp;#39;detection_boxes&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, 4)
      name: detection_boxes:0
  outputs[&amp;#39;detection_classes&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1)
      name: detection_classes:0
  outputs[&amp;#39;detection_classes_as_text&amp;#39;] tensor_info:
      dtype: DT_STRING
      shape: (-1, -1)
      name: detection_classes_as_text:0
  outputs[&amp;#39;detection_multiclass_scores&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, 3)
      name: detection_multiclass_scores:0
  outputs[&amp;#39;detection_scores&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1)
      name: detection_scores:0
  outputs[&amp;#39;image_info&amp;#39;] tensor_info:
      dtype: DT_INT32
      shape: (-1, 6)
      name: Tile_1:0
  outputs[&amp;#39;key&amp;#39;] tensor_info:
      dtype: DT_STRING
      shape: (-1)
      name: Identity:0
  outputs[&amp;#39;num_detections&amp;#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1)
      name: num_detections:0
Method name is: tensorflow/serving/predict
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My issue is how to convert the model I was giving to have the needed inputs/outputs? I found this (&lt;a href=""https://stackoverflow.com/questions/55373048/tensorflow-how-can-i-add-an-image-decoder-node-to-my-graph""&gt;https://stackoverflow.com/questions/55373048/tensorflow-how-can-i-add-an-image-decoder-node-to-my-graph&lt;/a&gt;) and I think it can be used for the input but I&amp;#39;m not sure about the output. I&amp;#39;m assuming it&amp;#39;s using the Object Detection API so somehow I need to convert the Keras model into an Object Detection API model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k4ro4c,True,,osred78,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k4ro4c/keras_and_object_detection_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4ro4c/keras_and_object_detection_api/,22217,1606849791.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
449,,tensorflow,,t2_2vlttls,False,,0,False,Making the Printed Links Clickable Using TensorFlow 2 Object Detection API,[],r/tensorflow,False,6,,0,70.0,,False,t3_k4oc00,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},Project,False,3,,False,https://b.thumbs.redditmedia.com/eWmy_4Fun5HG9XKXvBQAgKtDvP1p5F1j-5lCDCV3H3E.jpg,False,,[],{},,False,,1606869242.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k4oc00,True,,trekhleb,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k4oc00/making_the_printed_links_clickable_using/,all_ads,False,https://github.com/trekhleb/links-detector/blob/master/articles/printed_links_detection/printed_links_detection.md,22217,1606840442.0,0,,False,link,https://github.com/trekhleb/links-detector/blob/master/articles/printed_links_detection/printed_links_detection.md,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?auto=webp&amp;s=272a6fdf90209bf0caba82f793279b3170421eb9', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0546ed85df18688798aacac9022329619bda08f8', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=224b3c731434d3c989941f489a94a4dbe69ac2d9', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8be2df717acf82a50a669255e24cdeb9d8e115c', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9913fc139034312119985eb1fd998b55a5f5f3f3', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0a7a362adc3699954fd096f328dfeff5bd10f70f', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/Pu2hyHCv0EJr0fHFZaGUqmvYhdEJylkb45cWkadN_qU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=649dd587235f2c028e4f93723eea974ec8a95152', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'I3o8FYsIH74W54A5-Ey58aZIebTlz_GyZGGBB8UlHh8'}], 'enabled': False}",,,,,,
450,,tensorflow,"how do i convert a tf.Variable to numpy

&amp;#x200B;

var1 = tf.Variable(4.0)

&amp;#x200B;

I want retrun \`\[4.0\]\`",t2_4jql58et,False,,0,False,how convert tf.Variable to numpy?,[],r/tensorflow,False,6,,0,,,False,t3_k4tvby,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606884806.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;how do i convert a tf.Variable to numpy&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;var1 = tf.Variable(4.0)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I want retrun `[4.0]`&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k4tvby,True,,molo32,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k4tvby/how_convert_tfvariable_to_numpy/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4tvby/how_convert_tfvariable_to_numpy/,22217,1606856006.0,0,,False,,,,,,,,,
451,,tensorflow,"I have a model:

    inputs = layers.Input(shape=word_shape, name='input') 
    
    masking_layer = layers.Masking(mask_value=0, input_shape=word_shape)(inputs) 
    
    x = layers.Bidirectional(layers.SimpleRNN(70, return_sequences=True))(making_layer) 
    
    output_layer = layers.TimeDistributed(layers.Dense(36, activation='softmax'))(x)
    
    model = keras.Model(inputs, output_layer , name=""unnown_experimental"") 
    
    model.compile(optimizer='adam', loss='categorical_crossentropy')
    

So **masking\_layer** works right upto **output\_layer** but when *softmax activation* receives a timeframe where all the features are zeros it just calculates and I get nonsence as the return.

How to make this softmax activation leave the null timeframes alone and ignore them?",t2_10z1pk,False,,0,False,Softmax loss ignores masking and zero input.,[],r/tensorflow,False,6,,0,,,False,t3_k4syni,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1606853638.0,,[],{},,True,,1606882212.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a model:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;inputs = layers.Input(shape=word_shape, name=&amp;#39;input&amp;#39;) 

masking_layer = layers.Masking(mask_value=0, input_shape=word_shape)(inputs) 

x = layers.Bidirectional(layers.SimpleRNN(70, return_sequences=True))(making_layer) 

output_layer = layers.TimeDistributed(layers.Dense(36, activation=&amp;#39;softmax&amp;#39;))(x)

model = keras.Model(inputs, output_layer , name=&amp;quot;unnown_experimental&amp;quot;) 

model.compile(optimizer=&amp;#39;adam&amp;#39;, loss=&amp;#39;categorical_crossentropy&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &lt;strong&gt;masking_layer&lt;/strong&gt; works right upto &lt;strong&gt;output_layer&lt;/strong&gt; but when &lt;em&gt;softmax activation&lt;/em&gt; receives a timeframe where all the features are zeros it just calculates and I get nonsence as the return.&lt;/p&gt;

&lt;p&gt;How to make this softmax activation leave the null timeframes alone and ignore them?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k4syni,True,,coobit,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k4syni/softmax_loss_ignores_masking_and_zero_input/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4syni/softmax_loss_ignores_masking_and_zero_input/,22217,1606853412.0,0,,False,,,,,,,,,
452,,tensorflow,"I'm a PhD student, working on [code quality](https://arxiv.org/pdf/2007.10912.pdf) and its [improvement](https://www.cs.huji.ac.il/~feit/papers/Refactor19PROMISE.pdf).

I'm conducting a survey on motivation and its outcome in software development.

If you contributed to a GitHub repository as a developer in the last 12 months , we ask for your help by answering questions about your contribution and motivation.  


Answering [these questions](https://huji.az1.qualtrics.com/jfe/form/SV_73wu35ICXBWm07j) is estimated to take about 10 minutes of your time.  


Three of the participants will receive a 50$ gift card.",t2_3hn41pel,False,,0,False,Tensorflow developers - please participate in a survey,[],r/tensorflow,False,6,,0,,,False,t3_k4rrxo,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606878881.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a PhD student, working on &lt;a href=""https://arxiv.org/pdf/2007.10912.pdf""&gt;code quality&lt;/a&gt; and its &lt;a href=""https://www.cs.huji.ac.il/%7Efeit/papers/Refactor19PROMISE.pdf""&gt;improvement&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m conducting a survey on motivation and its outcome in software development.&lt;/p&gt;

&lt;p&gt;If you contributed to a GitHub repository as a developer in the last 12 months , we ask for your help by answering questions about your contribution and motivation.  &lt;/p&gt;

&lt;p&gt;Answering &lt;a href=""https://huji.az1.qualtrics.com/jfe/form/SV_73wu35ICXBWm07j""&gt;these questions&lt;/a&gt; is estimated to take about 10 minutes of your time.  &lt;/p&gt;

&lt;p&gt;Three of the participants will receive a 50$ gift card.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k4rrxo,True,,idan_huji,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k4rrxo/tensorflow_developers_please_participate_in_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4rrxo/tensorflow_developers_please_participate_in_a/,22217,1606850081.0,0,,False,,,,,,,,,
453,,tensorflow,"Hello everyone,

First of all I'm pretty new to python and TF so my apologies If I'm asking really dumb questions.So far I've trained a network by follow the guide found in this video:[https://www.youtube.com/watch?v=cvyDYdI2nEI](https://www.youtube.com/watch?v=cvyDYdI2nEI)

After exporting the inference graph I wanted to test the model using this colab notebook:[https://github.com/tensorflow/models/blob/master/research/object\_detection/colab\_tutorials/object\_detection\_tutorial.ipynb](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb)

I don't fully understand it however. I downloaded the TF object detection API from github and I have it saved locally on C:\\tensorflow2\\models. Whenever I run the code block below it still starts cloning, yet I already have it? Perhaps I need to set a path to it? I just don't know how.

https://preview.redd.it/i3bpif90dl261.png?width=951&amp;format=png&amp;auto=webp&amp;s=a96dc6bb49a1d14cf42a9130bde05b9a5959d232

Further down by ""Loading Label map"" I'm greeted with the same problem. I try to set the path to my label map and test images but they are not found:

https://preview.redd.it/iorei8wnel261.png?width=1296&amp;format=png&amp;auto=webp&amp;s=d236d9b88c1c6587c37eab75cf164838e5dec8be

My last question is how I would have to set the object detection model to my trained model. It is a .pb file so I believe that is correct?

&amp;#x200B;

https://preview.redd.it/tbgx1mr1fl261.png?width=627&amp;format=png&amp;auto=webp&amp;s=1c8e2ccfa99767fb36cc4506e67e42d66ae1678e

EDIT: I managed to get the directories recognized by running it locally instead of in Colab. However I'm still not quite sure how to load my own model in there, as the code is made for pretrained models. I've been trying to find an example but I haven't found anything I can use yet.

As far as I can tell I don't need this code block at all, as I'm not trying to download a pretrained model but instead use a custom one?

https://preview.redd.it/nr4byj98rs261.png?width=1367&amp;format=png&amp;auto=webp&amp;s=a0aac6f18b9e0dce24e321a56c3827d5abb644cf

I found another IPYNB here that uses custom models:   
[https://github.com/TannerGilbert/Tutorials/blob/master/Tensorflow%20Object%20Detection/object\_detection\_with\_own\_model.ipynb](https://github.com/TannerGilbert/Tutorials/blob/master/Tensorflow%20Object%20Detection/object_detection_with_own_model.ipynb)

However it's for TF1 and I'm using TF2. I've tried migrating the code to TF2 but I always run into some sort of error.

Thanks in advance, and again sorry if I am asking really dumb stuff.",t2_14tmdx,False,,0,False,Trying to run an image classifier on a custom model,[],r/tensorflow,False,6,,0,105.0,,False,t3_k4mucl,False,dark,1.0,,public,2,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/cvyDYdI2nEI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tensorflow Object Detection with Tensorflow 2: Creating a custom model', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/cvyDYdI2nEI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Gilbert Tanner', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cvyDYdI2nEI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCBOKpYBjPe2kD8FSvGRhJwA'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/cvyDYdI2nEI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/k4mucl', 'height': 338}",Question,False,2,,False,https://a.thumbs.redditmedia.com/g4yNOFyDNZ6Y_scZd2scAJrkzHU4sjcUkmhxSECgTQ0.jpg,1606925239.0,,[],{},,True,,1606864896.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;First of all I&amp;#39;m pretty new to python and TF so my apologies If I&amp;#39;m asking really dumb questions.So far I&amp;#39;ve trained a network by follow the guide found in this video:&lt;a href=""https://www.youtube.com/watch?v=cvyDYdI2nEI""&gt;https://www.youtube.com/watch?v=cvyDYdI2nEI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After exporting the inference graph I wanted to test the model using this colab notebook:&lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb""&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t fully understand it however. I downloaded the TF object detection API from github and I have it saved locally on C:\tensorflow2\models. Whenever I run the code block below it still starts cloning, yet I already have it? Perhaps I need to set a path to it? I just don&amp;#39;t know how.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/i3bpif90dl261.png?width=951&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a96dc6bb49a1d14cf42a9130bde05b9a5959d232""&gt;https://preview.redd.it/i3bpif90dl261.png?width=951&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a96dc6bb49a1d14cf42a9130bde05b9a5959d232&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Further down by &amp;quot;Loading Label map&amp;quot; I&amp;#39;m greeted with the same problem. I try to set the path to my label map and test images but they are not found:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/iorei8wnel261.png?width=1296&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d236d9b88c1c6587c37eab75cf164838e5dec8be""&gt;https://preview.redd.it/iorei8wnel261.png?width=1296&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d236d9b88c1c6587c37eab75cf164838e5dec8be&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My last question is how I would have to set the object detection model to my trained model. It is a .pb file so I believe that is correct?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/tbgx1mr1fl261.png?width=627&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c8e2ccfa99767fb36cc4506e67e42d66ae1678e""&gt;https://preview.redd.it/tbgx1mr1fl261.png?width=627&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c8e2ccfa99767fb36cc4506e67e42d66ae1678e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EDIT: I managed to get the directories recognized by running it locally instead of in Colab. However I&amp;#39;m still not quite sure how to load my own model in there, as the code is made for pretrained models. I&amp;#39;ve been trying to find an example but I haven&amp;#39;t found anything I can use yet.&lt;/p&gt;

&lt;p&gt;As far as I can tell I don&amp;#39;t need this code block at all, as I&amp;#39;m not trying to download a pretrained model but instead use a custom one?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/nr4byj98rs261.png?width=1367&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a0aac6f18b9e0dce24e321a56c3827d5abb644cf""&gt;https://preview.redd.it/nr4byj98rs261.png?width=1367&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a0aac6f18b9e0dce24e321a56c3827d5abb644cf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I found another IPYNB here that uses custom models:&lt;br/&gt;
&lt;a href=""https://github.com/TannerGilbert/Tutorials/blob/master/Tensorflow%20Object%20Detection/object_detection_with_own_model.ipynb""&gt;https://github.com/TannerGilbert/Tutorials/blob/master/Tensorflow%20Object%20Detection/object_detection_with_own_model.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However it&amp;#39;s for TF1 and I&amp;#39;m using TF2. I&amp;#39;ve tried migrating the code to TF2 but I always run into some sort of error.&lt;/p&gt;

&lt;p&gt;Thanks in advance, and again sorry if I am asking really dumb stuff.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k4mucl,True,,007Nick700,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/k4mucl/trying_to_run_an_image_classifier_on_a_custom/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4mucl/trying_to_run_an_image_classifier_on_a_custom/,22217,1606836096.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tensorflow Object Detection with Tensorflow 2: Creating a custom model', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/cvyDYdI2nEI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Gilbert Tanner', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cvyDYdI2nEI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCBOKpYBjPe2kD8FSvGRhJwA'}}",False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?auto=webp&amp;s=dc4543d85718840fe61064d95252b5e4e849a011', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c860d6659775a902cb2c1e09d86cab25d124dd4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3df8fecc8ce7bd4502912064322431c09f60be87', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/FQxo4YsjQbklKHCgwyGhSHkU1B_4RM_potwG_bVZQj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d8b6508d3c6737132c1252e272a13b266b96955', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'ADIqgKOaM8izkrToP2DHSC1LoPPLKoeG599X_jYuifA'}], 'enabled': False}",,"{'i3bpif90dl261': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 36, 'x': 108, 'u': 'https://preview.redd.it/i3bpif90dl261.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c086704293e208e591cb593c1566dffd6404f74f'}, {'y': 72, 'x': 216, 'u': 'https://preview.redd.it/i3bpif90dl261.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ecd0f6c137bd465df971a46a9cb5b63d40cf7c0c'}, {'y': 107, 'x': 320, 'u': 'https://preview.redd.it/i3bpif90dl261.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=94544dcfb707faceb6023a19d7aff72a367972e4'}, {'y': 214, 'x': 640, 'u': 'https://preview.redd.it/i3bpif90dl261.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=78ed7372a0c02af14a873f3899c511cd490baa1d'}], 's': {'y': 319, 'x': 951, 'u': 'https://preview.redd.it/i3bpif90dl261.png?width=951&amp;format=png&amp;auto=webp&amp;s=a96dc6bb49a1d14cf42a9130bde05b9a5959d232'}, 'id': 'i3bpif90dl261'}, 'iorei8wnel261': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 55, 'x': 108, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca86c5d0ea39f6e87ea9ec4fd13aa5089fcc852c'}, {'y': 110, 'x': 216, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94c3328dcb834e1de87d2815d365766cfc48bcea'}, {'y': 162, 'x': 320, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3946e38edaf25d185c306df4e01634d25b61df73'}, {'y': 325, 'x': 640, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=10f690124d08d4cc625bd6a792957a0cf2af558e'}, {'y': 488, 'x': 960, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=24594eb98da78f4a23ad5ed909708d3c60b438b9'}, {'y': 550, 'x': 1080, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a880b3996ba6cdd4f6eb6b05db7570d97bc75808'}], 's': {'y': 660, 'x': 1296, 'u': 'https://preview.redd.it/iorei8wnel261.png?width=1296&amp;format=png&amp;auto=webp&amp;s=d236d9b88c1c6587c37eab75cf164838e5dec8be'}, 'id': 'iorei8wnel261'}, 'tbgx1mr1fl261': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 44, 'x': 108, 'u': 'https://preview.redd.it/tbgx1mr1fl261.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b023dd944e431294cedb9d3ee81912e9ad4d479'}, {'y': 89, 'x': 216, 'u': 'https://preview.redd.it/tbgx1mr1fl261.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c93b20853a33eb242eae56ebd011cb3f7026bdd8'}, {'y': 132, 'x': 320, 'u': 'https://preview.redd.it/tbgx1mr1fl261.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b74bde818da8d1afdae72b6c0fa0346241ac726b'}], 's': {'y': 260, 'x': 627, 'u': 'https://preview.redd.it/tbgx1mr1fl261.png?width=627&amp;format=png&amp;auto=webp&amp;s=1c8e2ccfa99767fb36cc4506e67e42d66ae1678e'}, 'id': 'tbgx1mr1fl261'}, 'nr4byj98rs261': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 29, 'x': 108, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e2bdb601c6d4fd5031cf88cbb86d41178fe35ac'}, {'y': 59, 'x': 216, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=22f949b6708a7115c46f481a8671f0eb5a9f2d37'}, {'y': 88, 'x': 320, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7bee177f83601f5a3c067b4fb69e26279103c38f'}, {'y': 176, 'x': 640, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9275464f781d29f2dc267411dafa6075894c6010'}, {'y': 264, 'x': 960, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=92b38095c267fb8c991e2f6f458f323670a568b5'}, {'y': 297, 'x': 1080, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5261c2d3745f1b6f5c5a5d50c2049a877c36e2e7'}], 's': {'y': 376, 'x': 1367, 'u': 'https://preview.redd.it/nr4byj98rs261.png?width=1367&amp;format=png&amp;auto=webp&amp;s=a0aac6f18b9e0dce24e321a56c3827d5abb644cf'}, 'id': 'nr4byj98rs261'}}",,,,
454,,tensorflow,"`import tensorflow as tf`

`RANDOM_SEED_CONSTANT = 42  # FOR_REPRODUCIBILITY`

`tf.random.set_seed(RANDOM_SEED_CONSTANT)`

&amp;#x200B;

`# Prevent NHWC errors` [`https://www.nuomiphp.com/eplan/en/50125.html`](https://www.nuomiphp.com/eplan/en/50125.html)

`from tensorflow.keras import backend as K`

`K.set_image_data_format(""channels_last"")`

&amp;#x200B;

`from tensorflow import keras`

`from tensorflow.keras import datasets, layers, models`

&amp;#x200B;

`(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()`

`train_images, test_images = train_images / 255.0, test_images / 255.0 # Normalize pixel values to be between 0 and 1`

`# Create a simple CNN`

`model = models.Sequential()`

`model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))`

`model.add(layers.MaxPooling2D((2, 2)))`

`model.add(layers.Conv2D(64, (3, 3), activation='relu'))`

`model.add(layers.MaxPooling2D((2, 2)))`

`model.add(layers.Conv2D(64, (3, 3), activation='relu'))`

`model.add(layers.Flatten())`

`model.add(layers.Dense(64, activation='relu', kernel_initializer=tf.keras.initializers.Zeros()))`

`model.add(layers.Dense(10, kernel_initializer=tf.keras.initializers.Zeros()))`

`print(model.summary())`

&amp;#x200B;

`model.compile(optimizer='adam',`

`loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),`

`metrics=['accuracy'])`

&amp;#x200B;

`model.save_weights('myweights.h5')`

`history =` [`model.fit`](https://model.fit)`(train_images, train_labels, epochs=1,`

`shuffle=False,`

`validation_data=(test_images, test_labels))`

1563/1563 \[==============================\] - 7s 5ms/step - loss: 2.3028 - accuracy: 0.0957 - val\_loss: 2.3026 - val\_accuracy: 0.1000

`model.load_weights('myweights.h5')`

`history =` [`model.fit`](https://model.fit)`(train_images, train_labels, epochs=1,`

`shuffle=False,`

`validation_data=(test_images, test_labels))`

`model.load_weights('myweights.h5')`

1563/1563 \[==============================\] - 7s 4ms/step - loss: 2.3028 - accuracy: 0.0964 - val\_loss: 2.3026 - val\_accuracy: 0.1000

`history =` [`model.fit`](https://model.fit)`(train_images, train_labels, epochs=1,`

`shuffle=False,`

`validation_data=(test_images, test_labels))`

1563/1563 \[==============================\] - 7s 4ms/step - loss: 2.3028 - accuracy: 0.0964 - val\_loss: 2.3026 - val\_accuracy: 0.1000

Results:

The 3 [model.fit](https://model.fit)() runs give me identical results except for the train accuracy. What is the reason for this difference? I am trying to understand sources which might impede reproducing results from models. Apart from random seed, dense layers initialization, what else am I missing?",t2_etja0,False,,0,False,Tensorflow model.fit() reproducibility,[],r/tensorflow,False,6,,0,,,False,t3_k4h65d,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1606840915.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;code&gt;import tensorflow as tf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;RANDOM_SEED_CONSTANT = 42  # FOR_REPRODUCIBILITY&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.random.set_seed(RANDOM_SEED_CONSTANT)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Prevent NHWC errors&lt;/code&gt; &lt;a href=""https://www.nuomiphp.com/eplan/en/50125.html""&gt;&lt;code&gt;https://www.nuomiphp.com/eplan/en/50125.html&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from tensorflow.keras import backend as K&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;K.set_image_data_format(&amp;quot;channels_last&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from tensorflow import keras&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from tensorflow.keras import datasets, layers, models&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;train_images, test_images = train_images / 255.0, test_images / 255.0 # Normalize pixel values to be between 0 and 1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;# Create a simple CNN&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model = models.Sequential()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.Conv2D(32, (3, 3), activation=&amp;#39;relu&amp;#39;, input_shape=(32, 32, 3)))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.MaxPooling2D((2, 2)))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.Conv2D(64, (3, 3), activation=&amp;#39;relu&amp;#39;))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.MaxPooling2D((2, 2)))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.Conv2D(64, (3, 3), activation=&amp;#39;relu&amp;#39;))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.Flatten())&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.Dense(64, activation=&amp;#39;relu&amp;#39;, kernel_initializer=tf.keras.initializers.Zeros()))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.add(layers.Dense(10, kernel_initializer=tf.keras.initializers.Zeros()))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;print(model.summary())&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.compile(optimizer=&amp;#39;adam&amp;#39;,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;metrics=[&amp;#39;accuracy&amp;#39;])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.save_weights(&amp;#39;myweights.h5&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;history =&lt;/code&gt; &lt;a href=""https://model.fit""&gt;&lt;code&gt;model.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(train_images, train_labels, epochs=1,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;shuffle=False,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;validation_data=(test_images, test_labels))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;1563/1563 [==============================] - 7s 5ms/step - loss: 2.3028 - accuracy: 0.0957 - val_loss: 2.3026 - val_accuracy: 0.1000&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.load_weights(&amp;#39;myweights.h5&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;history =&lt;/code&gt; &lt;a href=""https://model.fit""&gt;&lt;code&gt;model.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(train_images, train_labels, epochs=1,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;shuffle=False,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;validation_data=(test_images, test_labels))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model.load_weights(&amp;#39;myweights.h5&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;1563/1563 [==============================] - 7s 4ms/step - loss: 2.3028 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000&lt;/p&gt;

&lt;p&gt;&lt;code&gt;history =&lt;/code&gt; &lt;a href=""https://model.fit""&gt;&lt;code&gt;model.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(train_images, train_labels, epochs=1,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;shuffle=False,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;validation_data=(test_images, test_labels))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;1563/1563 [==============================] - 7s 4ms/step - loss: 2.3028 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000&lt;/p&gt;

&lt;p&gt;Results:&lt;/p&gt;

&lt;p&gt;The 3 &lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;() runs give me identical results except for the train accuracy. What is the reason for this difference? I am trying to understand sources which might impede reproducing results from models. Apart from random seed, dense layers initialization, what else am I missing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k4h65d,True,,mbkv,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/k4h65d/tensorflow_modelfit_reproducibility/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4h65d/tensorflow_modelfit_reproducibility/,22217,1606812115.0,0,,False,,,,,,,,,
455,,tensorflow,"Hello

I used to be able to train a model a Tensorflow workload on a Geforce 1060 6GB card. Now I got a RTX 3080 10 GB. Training is unable to start because of Out of memory exceptions. It is the exact same workload but not it seems it requires more memory than 6 GB all of the sudden?

I have tried 10 different models and they all now require more VRAM to train? How is this possible?

Task manager show all the VRAM is used. It makes no sense for my models suddenly to eat 10 GB VRAM when they worked with just 6 GB?

Any one experience this?

Specs:

tensorflow-gpu           2.4.0rc3  
Nvidia driver:  457.30  
with cudnn-11.1-windows-x64-v8.0.5.39",t2_iadkj,False,,0,False,Tensorflow with RTX 3000 seems to use more VRAM for same model/dataset that runs on 1000 series?,[],r/tensorflow,False,6,,0,,,False,t3_k3vcwj,False,dark,0.91,,public,17,0,{},,,False,[],,False,False,,{},,False,17,,False,self,False,,[],{},,True,,1606770169.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello&lt;/p&gt;

&lt;p&gt;I used to be able to train a model a Tensorflow workload on a Geforce 1060 6GB card. Now I got a RTX 3080 10 GB. Training is unable to start because of Out of memory exceptions. It is the exact same workload but not it seems it requires more memory than 6 GB all of the sudden?&lt;/p&gt;

&lt;p&gt;I have tried 10 different models and they all now require more VRAM to train? How is this possible?&lt;/p&gt;

&lt;p&gt;Task manager show all the VRAM is used. It makes no sense for my models suddenly to eat 10 GB VRAM when they worked with just 6 GB?&lt;/p&gt;

&lt;p&gt;Any one experience this?&lt;/p&gt;

&lt;p&gt;Specs:&lt;/p&gt;

&lt;p&gt;tensorflow-gpu           2.4.0rc3&lt;br/&gt;
Nvidia driver:  457.30&lt;br/&gt;
with cudnn-11.1-windows-x64-v8.0.5.39&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k3vcwj,True,,mobani,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/k3vcwj/tensorflow_with_rtx_3000_seems_to_use_more_vram/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k3vcwj/tensorflow_with_rtx_3000_seems_to_use_more_vram/,22217,1606741369.0,0,,False,,,,,,,,,
456,,tensorflow,"With this tutorial, you’ll learn how to build ML components using TFX, how to create a Notebook instance on the AI Cloud Platform, how to run TFX components interactively, and finally, how to orchestrate your pipeline with Kubeflow.

If this is the first time you’re hearing about these tools, don’t worry! The tutorial is beginner-friendly and explains them well!

I think that this is really useful knowledge you can use in your next company or individual project so, here it is: [ML Models in Production With TFX and Kubeflow](https://neptune.ai/blog/deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow&amp;utm_content=tensorflow).",t2_5hfacnnv,False,,0,False,[Tutorial] ML Models in Production With Tensorflow Extended (TFX) and Kubeflow,[],r/tensorflow,False,6,,0,,,False,t3_k3z2ox,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,self,False,,[],{},,True,,1606782320.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;With this tutorial, you’ll learn how to build ML components using TFX, how to create a Notebook instance on the AI Cloud Platform, how to run TFX components interactively, and finally, how to orchestrate your pipeline with Kubeflow.&lt;/p&gt;

&lt;p&gt;If this is the first time you’re hearing about these tools, don’t worry! The tutorial is beginner-friendly and explains them well!&lt;/p&gt;

&lt;p&gt;I think that this is really useful knowledge you can use in your next company or individual project so, here it is: &lt;a href=""https://neptune.ai/blog/deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow&amp;amp;utm_content=tensorflow""&gt;ML Models in Production With TFX and Kubeflow&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,k3z2ox,True,,kk_ai,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k3z2ox/tutorial_ml_models_in_production_with_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k3z2ox/tutorial_ml_models_in_production_with_tensorflow/,22217,1606753520.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?auto=webp&amp;s=03ae04a00eedc4a9f4f5f3c501667ebc8fe4b4ba', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d858c8e4cc1eb2896738ad29aae904e3aa19362c', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=79f5b5b0d0412590a17e522fd6625c935f311dd5', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=85439fa3645994b6840973531da74fab0953d387', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1951ca6de4e41ad078704e4385f1878c8d161d7', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6234d78eca50d7e2ccd76e0a1b3acb203830512e', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/q0N9D8vkhi8M6W9RLeN9h4JmIsQ-GWrHpXeC2DFZejQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=040166e0d64f444c96ed55fc9115be80cbe4d164', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'AtjlsDiy2h7KmhaLMhXXpO_LaqpgLnZ6Z5gNX1CR-pY'}], 'enabled': False}",,,,,,
457,,tensorflow," Hello, I want to do semantic segmentation with U-Net, with the data I have I'm able to remove the background automatically. Is it beneficial for the model feature extraction if remove the background and replace it with a white/geen/yellow ect background. Maybe use multiple colors mixed in the training set or something.",t2_128ob4,False,,0,False,Semantic segmentation - background removal preprocess?,[],r/tensorflow,False,6,,0,,,False,t3_k4932b,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606810506.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I want to do semantic segmentation with U-Net, with the data I have I&amp;#39;m able to remove the background automatically. Is it beneficial for the model feature extraction if remove the background and replace it with a white/geen/yellow ect background. Maybe use multiple colors mixed in the training set or something.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k4932b,True,,darvidas,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k4932b/semantic_segmentation_background_removal/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k4932b/semantic_segmentation_background_removal/,22217,1606781706.0,0,,False,,,,,,,,,
458,,tensorflow,"I'm trying to setup up two networks that meet in a couple of fully connected layers to a single output layer. I think I know how to get the branches setup (though additional resources for that would be nice), but I'm unclear on how to manage my dataset. One of the branches is working on a dataset of text documents that I gather through the preprocessing.text_dataset_from_directory() function then do some convolution over it, while the other is a set of corresponding numbers I'd like to input into the second branch, that is stored as a .csv. I'm not entirely sure how to make sure the values and the text files are input into the network simultaneously, any help on this would be greatly appreciated.

(For additional context I currently have the network that works on the text documents working, I'm trying to add a branch of supplementary data)",t2_6l484,False,,0,False,Help setting up a branch/tangled network?,[],r/tensorflow,False,6,,0,,,False,t3_k431li,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1606780195.0,,[],{},,True,,1606792991.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to setup up two networks that meet in a couple of fully connected layers to a single output layer. I think I know how to get the branches setup (though additional resources for that would be nice), but I&amp;#39;m unclear on how to manage my dataset. One of the branches is working on a dataset of text documents that I gather through the preprocessing.text_dataset_from_directory() function then do some convolution over it, while the other is a set of corresponding numbers I&amp;#39;d like to input into the second branch, that is stored as a .csv. I&amp;#39;m not entirely sure how to make sure the values and the text files are input into the network simultaneously, any help on this would be greatly appreciated.&lt;/p&gt;

&lt;p&gt;(For additional context I currently have the network that works on the text documents working, I&amp;#39;m trying to add a branch of supplementary data)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k431li,True,,xXProdigalXx,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k431li/help_setting_up_a_branchtangled_network/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k431li/help_setting_up_a_branchtangled_network/,22217,1606764191.0,0,,False,,,,,,,,,
459,,tensorflow,"I have installed tensor flow on a nvidia jetson tx2 with: 

     sudo pip3 install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v42 tensorflow-gpu==1.13.1+nv19.3""

However when I test the installation using the following script: 

    import tensorflow as tf 
    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = ""1"" 
    if tf.test.gpu_device_name(): 
            print('Default GPU Device {}'.format(tf.test.gpu_device_name()))
    else:
            print(""Please install GPU version of TF"")

I get this error:

    2020-11-30 12:49:32.020462: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
    2020-11-30 12:49:32.020930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nvidia-desktop): /proc/driver/nvidia/version does not exist
    Please install GPU version of TF",t2_61qkwgix,False,,0,False,tensorflow-gpu Nvidia Jetson TX2,[],r/tensorflow,False,6,,0,,,False,t3_k3ufhc,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1606765980.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have installed tensor flow on a nvidia jetson tx2 with: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt; sudo pip3 install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v42 tensorflow-gpu==1.13.1+nv19.3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However when I test the installation using the following script: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf 
import os
os.environ[&amp;#39;CUDA_VISIBLE_DEVICES&amp;#39;] = &amp;quot;1&amp;quot; 
if tf.test.gpu_device_name(): 
        print(&amp;#39;Default GPU Device {}&amp;#39;.format(tf.test.gpu_device_name()))
else:
        print(&amp;quot;Please install GPU version of TF&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I get this error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2020-11-30 12:49:32.020462: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-11-30 12:49:32.020930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nvidia-desktop): /proc/driver/nvidia/version does not exist
Please install GPU version of TF
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k3ufhc,True,,sleepyleasle,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k3ufhc/tensorflowgpu_nvidia_jetson_tx2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k3ufhc/tensorflowgpu_nvidia_jetson_tx2/,22217,1606737180.0,0,,False,,,,,,,,,
460,,tensorflow,"This may sound like a silly question, but I’m actually a beginner in deeplearning and tensorflow, and have only a built a few models. I was on the tf website when I saw tensorflow probability. What’s the difference between tensorflow probability and the sequential api? Or just in general how does tensorflow probability differ from the main apis in tensorflow?",t2_5w4i5kd1,False,,0,False,What is tensorflow probability?,[],r/tensorflow,False,6,,0,,,False,t3_k3mq01,False,dark,0.92,,public,11,0,{},,,False,[],,False,False,,{},Question,False,11,,False,self,False,,[],{},,True,,1606731364.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This may sound like a silly question, but I’m actually a beginner in deeplearning and tensorflow, and have only a built a few models. I was on the tf website when I saw tensorflow probability. What’s the difference between tensorflow probability and the sequential api? Or just in general how does tensorflow probability differ from the main apis in tensorflow?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k3mq01,True,,veeeerain,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/k3mq01/what_is_tensorflow_probability/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k3mq01/what_is_tensorflow_probability/,22217,1606702564.0,0,,False,,,,,,,,,
461,,tensorflow,"I'm thinking about learning more about Tensorflow and ML.  Don't really have a project for it yet, but I was thinking about building this one. 

I was thinking about creating a ""Twitch Plays Jeopardy"" app, using questions from [jservice.io](https://jservice.io) 's API.  The problem is that the program should be flexible enough to handle minor typos and variant answers.  For example:  
A: ""The only person whose signature appears on the Declaration of Independence, the Constitution, the Treaty of Alliance with France, and the Treaty of Paris.""

Canonical Q: ""Who is Benjamin Franklin"" 

Acceptable Qs: 

* Who is Franklin?
* Who is B. Franklin?
* Who is Ben Franklin?
* Who is Bengamin Franklin
* Who is Benjamin Franklen

I'm not planning on using any AI/ML or Tensorflow at \*this\* stage.  

I'm planning on handling this pretty much the same way that it was handled in NES &amp; PC Jeopardy games from the 1980s: a bunch of checks and if any \*one\* of them is true... the answer's right. 

For example, I could use: ""does at least ONE of the words that has at least 4 consonants in it have the consonents in the right order?"" - for which any combination of BNJMN or FRNKLN would work. 

This would produce a large false-positive rate ([https://www.youtube.com/watch?v=-q5J6LJwDyY&amp;feature=youtu.be&amp;t=60](https://www.youtube.com/watch?v=-q5J6LJwDyY&amp;feature=youtu.be&amp;t=60) for a good example) but that shouldn't be too far off to actually get something a bit \*playable\*

The tougher problem would be handling the following edge cases:

* Henry VIII / Henry the Eighth / Henry the 8th / Henry Tudor
* American Independence Day / Independence Day / Fourth of July / July 4 

Here's where I'm thinking I can work with Tensorflow.  I wonder if I can offer a ""!falseneg"" or !falsepos command that allows players to dispute the answer, save that into a MongoDB database... then use the data gathered there to train an AI model into evaluating other responses correctly.  I think this would be an intersting TF project, but before I do that, I want to know if this is the \*type\* of project TF was built for.  

What do you think?",t2_ss1w,False,,0,False,"Looking for a TF project, thinking about ""Twitch plays Jeopardy"" to train language learning?",[],r/tensorflow,False,6,,0,,,False,t3_k3m5ge,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1606729267.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m thinking about learning more about Tensorflow and ML.  Don&amp;#39;t really have a project for it yet, but I was thinking about building this one. &lt;/p&gt;

&lt;p&gt;I was thinking about creating a &amp;quot;Twitch Plays Jeopardy&amp;quot; app, using questions from &lt;a href=""https://jservice.io""&gt;jservice.io&lt;/a&gt; &amp;#39;s API.  The problem is that the program should be flexible enough to handle minor typos and variant answers.  For example:&lt;br/&gt;
A: &amp;quot;The only person whose signature appears on the Declaration of Independence, the Constitution, the Treaty of Alliance with France, and the Treaty of Paris.&amp;quot;&lt;/p&gt;

&lt;p&gt;Canonical Q: &amp;quot;Who is Benjamin Franklin&amp;quot; &lt;/p&gt;

&lt;p&gt;Acceptable Qs: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Who is Franklin?&lt;/li&gt;
&lt;li&gt;Who is B. Franklin?&lt;/li&gt;
&lt;li&gt;Who is Ben Franklin?&lt;/li&gt;
&lt;li&gt;Who is Bengamin Franklin&lt;/li&gt;
&lt;li&gt;Who is Benjamin Franklen&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m not planning on using any AI/ML or Tensorflow at *this* stage.  &lt;/p&gt;

&lt;p&gt;I&amp;#39;m planning on handling this pretty much the same way that it was handled in NES &amp;amp; PC Jeopardy games from the 1980s: a bunch of checks and if any *one* of them is true... the answer&amp;#39;s right. &lt;/p&gt;

&lt;p&gt;For example, I could use: &amp;quot;does at least ONE of the words that has at least 4 consonants in it have the consonents in the right order?&amp;quot; - for which any combination of BNJMN or FRNKLN would work. &lt;/p&gt;

&lt;p&gt;This would produce a large false-positive rate (&lt;a href=""https://www.youtube.com/watch?v=-q5J6LJwDyY&amp;amp;feature=youtu.be&amp;amp;t=60""&gt;https://www.youtube.com/watch?v=-q5J6LJwDyY&amp;amp;feature=youtu.be&amp;amp;t=60&lt;/a&gt; for a good example) but that shouldn&amp;#39;t be too far off to actually get something a bit *playable*&lt;/p&gt;

&lt;p&gt;The tougher problem would be handling the following edge cases:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Henry VIII / Henry the Eighth / Henry the 8th / Henry Tudor&lt;/li&gt;
&lt;li&gt;American Independence Day / Independence Day / Fourth of July / July 4 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here&amp;#39;s where I&amp;#39;m thinking I can work with Tensorflow.  I wonder if I can offer a &amp;quot;!falseneg&amp;quot; or !falsepos command that allows players to dispute the answer, save that into a MongoDB database... then use the data gathered there to train an AI model into evaluating other responses correctly.  I think this would be an intersting TF project, but before I do that, I want to know if this is the *type* of project TF was built for.  &lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k3m5ge,True,,BrianBoyko,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k3m5ge/looking_for_a_tf_project_thinking_about_twitch/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k3m5ge/looking_for_a_tf_project_thinking_about_twitch/,22217,1606700467.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/LHWdnS7oWTEcr_O0667X33LSOk7LyaEcjjsonNBHk_U.jpg?auto=webp&amp;s=acec2108281c6a6654d59ae1c4a761949bfdeda7', 'width': 350, 'height': 377}, 'resolutions': [{'url': 'https://external-preview.redd.it/LHWdnS7oWTEcr_O0667X33LSOk7LyaEcjjsonNBHk_U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=29e7b17888c339036666306b81bf14963e071d14', 'width': 108, 'height': 116}, {'url': 'https://external-preview.redd.it/LHWdnS7oWTEcr_O0667X33LSOk7LyaEcjjsonNBHk_U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=10767ee03beb2c37073f84cc5778c113d04896da', 'width': 216, 'height': 232}, {'url': 'https://external-preview.redd.it/LHWdnS7oWTEcr_O0667X33LSOk7LyaEcjjsonNBHk_U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cae0e361034b0610f50c03f8cc160ad6f1312617', 'width': 320, 'height': 344}], 'variants': {}, 'id': 'Oo57ftAdS3Tf9JP4wSZ5S5ZjMvSJeDLzc54LVLt2F8U'}], 'enabled': False}",,,,,,
462,,tensorflow,"Hi,

&amp;#x200B;

code goes as follows

    ....
    layers.ConvLSTM2D( filters=40, kernel_size=(3, 3), padding=""same"", return_sequences=True ), 
    layers.BatchNormalization(),
    layers.Flatten()
    ...

it does not work, 

the data size from second layer to flatten layer becomes zero, any idea how to use the flatten properly in this case?

thank you!",t2_298vr6n0,False,,0,False,Flatten() after ConvLSTM2D() does not work,[],r/tensorflow,False,6,,0,,,False,t3_k3qsr6,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606748143.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;code goes as follows&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;....
layers.ConvLSTM2D( filters=40, kernel_size=(3, 3), padding=&amp;quot;same&amp;quot;, return_sequences=True ), 
layers.BatchNormalization(),
layers.Flatten()
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it does not work, &lt;/p&gt;

&lt;p&gt;the data size from second layer to flatten layer becomes zero, any idea how to use the flatten properly in this case?&lt;/p&gt;

&lt;p&gt;thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k3qsr6,True,,boydbuilding,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/k3qsr6/flatten_after_convlstm2d_does_not_work/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k3qsr6/flatten_after_convlstm2d_does_not_work/,22217,1606719343.0,0,,False,,,,,,,,,
463,,tensorflow,"Hey,

So I have download a datatset of images in the form tfrecords file from:

[https://drive.google.com/drive/folders/1M24jfI-Ylb-k2EGhELSnxssWi9wGUokg](https://drive.google.com/drive/folders/1M24jfI-Ylb-k2EGhELSnxssWi9wGUokg)

(It's from the [https://github.com/NVlabs/ffhq-dataset](https://github.com/NVlabs/ffhq-dataset) datatset)

I want to extract the data from tfrecords file to images, and saves all those images as png files in a directory. How can I do that?",t2_11zpu1,False,,0,False,[Question] read from tfrecords file,[],r/tensorflow,False,6,,0,,,False,t3_k2vkvx,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1606626044.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey,&lt;/p&gt;

&lt;p&gt;So I have download a datatset of images in the form tfrecords file from:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://drive.google.com/drive/folders/1M24jfI-Ylb-k2EGhELSnxssWi9wGUokg""&gt;https://drive.google.com/drive/folders/1M24jfI-Ylb-k2EGhELSnxssWi9wGUokg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(It&amp;#39;s from the &lt;a href=""https://github.com/NVlabs/ffhq-dataset""&gt;https://github.com/NVlabs/ffhq-dataset&lt;/a&gt; datatset)&lt;/p&gt;

&lt;p&gt;I want to extract the data from tfrecords file to images, and saves all those images as png files in a directory. How can I do that?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k2vkvx,True,,HoLeeFaak,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/k2vkvx/question_read_from_tfrecords_file/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k2vkvx/question_read_from_tfrecords_file/,22217,1606597244.0,0,,False,,,,,,,,,
464,,tensorflow,"Hello I'm originally a Back-end engineer, not a ML engineer, but i do enjoy video editing and photography. I found this tutorial of how to use tensorflow and python to videos and pictures and I think it is really cool. However, it seems that  it is really old and i was not able to set it up correctly, i kept getting \`import tensorflow as tf \` tensorflow is not installed error , even after downgrading all the dependecies listed in the [readme.md](https://readme.md) to the versions specified. I was wondering if there is another tutorial using the newest tensor (or at least not 5 years old one ) so i can try again to set it up. 

[https://github.com/cysmith/neural-style-tf](https://github.com/cysmith/neural-style-tf)&lt;- this is the tutorial   


TLDR; I want to transfer a picture style to a video using python and tensorflow, need a new tutorial using recent verisions of tensorflow and python.  


many thanks in advance.",t2_ehmmg,False,,0,False,Neural Style Transfer using tensor flow,[],r/tensorflow,False,6,,0,,,False,t3_k2hhoe,False,dark,1.0,,public,13,0,{},,,False,[],,False,False,,{},,False,13,,False,self,False,,[],{},,True,,1606567813.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello I&amp;#39;m originally a Back-end engineer, not a ML engineer, but i do enjoy video editing and photography. I found this tutorial of how to use tensorflow and python to videos and pictures and I think it is really cool. However, it seems that  it is really old and i was not able to set it up correctly, i kept getting `import tensorflow as tf ` tensorflow is not installed error , even after downgrading all the dependecies listed in the &lt;a href=""https://readme.md""&gt;readme.md&lt;/a&gt; to the versions specified. I was wondering if there is another tutorial using the newest tensor (or at least not 5 years old one ) so i can try again to set it up. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/cysmith/neural-style-tf""&gt;https://github.com/cysmith/neural-style-tf&lt;/a&gt;&amp;lt;- this is the tutorial   &lt;/p&gt;

&lt;p&gt;TLDR; I want to transfer a picture style to a video using python and tensorflow, need a new tutorial using recent verisions of tensorflow and python.  &lt;/p&gt;

&lt;p&gt;many thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k2hhoe,True,,MavericksCreed,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/k2hhoe/neural_style_transfer_using_tensor_flow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k2hhoe/neural_style_transfer_using_tensor_flow/,22217,1606539013.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/mNGwv4XuwlwJiv_njO_pf8g67tRJidAKOdfjyocIYvk.jpg?auto=webp&amp;s=9165f84659509482a7fea7d6062811b23ca547eb', 'width': 187, 'height': 187}, 'resolutions': [{'url': 'https://external-preview.redd.it/mNGwv4XuwlwJiv_njO_pf8g67tRJidAKOdfjyocIYvk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3295324bb25da3697c1b1bf09c01f6fd7a20bb36', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'q2EWwmb6Oab1viS-KBfuk2oXo9JaL6oAwAqBH6s0FeI'}], 'enabled': False}",,,,,,
465,,tensorflow,"Has anyone gotten tensorflow working with nvidia's RTX 3000 series GPUs? I'm currently working with a RTX 3070 and have tried methods such as pip installing tf-nightly-gpu, compiling from source, and using tensorflow's docker images but I can't seem get my models training using the GPU. I'm not getting any errors in the prompt and tensorflow is successfully detecting my 3070 but whenever I train my model it just uses my cpu. If you got tensorflow to work can you share how?

Update:
I am using NVIDIA 455.32 version drivers, CUDA 11.1, CUDNN 8.0.4 (for CUDA 11.1), and tf-nightly-gpu.",t2_5seypg7t,False,,0,False,Tensorflow with RTX 3000 series GPU,[],r/tensorflow,False,6,,0,,,False,t3_k25tqb,False,dark,1.0,,public,16,0,{},,,False,[],,False,False,,{},Question,False,16,,False,self,1606604077.0,,[],{},,True,,1606528008.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone gotten tensorflow working with nvidia&amp;#39;s RTX 3000 series GPUs? I&amp;#39;m currently working with a RTX 3070 and have tried methods such as pip installing tf-nightly-gpu, compiling from source, and using tensorflow&amp;#39;s docker images but I can&amp;#39;t seem get my models training using the GPU. I&amp;#39;m not getting any errors in the prompt and tensorflow is successfully detecting my 3070 but whenever I train my model it just uses my cpu. If you got tensorflow to work can you share how?&lt;/p&gt;

&lt;p&gt;Update:
I am using NVIDIA 455.32 version drivers, CUDA 11.1, CUDNN 8.0.4 (for CUDA 11.1), and tf-nightly-gpu.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k25tqb,True,,Lupuluformis,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/k25tqb/tensorflow_with_rtx_3000_series_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k25tqb/tensorflow_with_rtx_3000_series_gpu/,22217,1606499208.0,0,,False,,,,,,,,,
466,,tensorflow,"I am trying to re-use a pretrained model supplied along with its weights. There are 2 files

    model/mykerasmodel.h5
    weights/mykerasmodel.h5

I want to use this model as a feature extractor. I use only the load\_model() function as follows:

    keras_model = load_model()
    
    print(keras_model.inputs)
    print(keras_model.outputs)
    
    gives me:
    [&lt;tf.Tensor 'input_1:0' shape=(None, 160, 160, 3) dtype=float32&gt;]
    [&lt;tf.Tensor 'Bottleneck_BatchNorm/batchnorm/add_1:0' shape=(None, 128) dtype=float32&gt;]
    
    So, I simply do
    features_x = keras_model.predict(x)

I am able to get the features but how do I know they are actually right? Does \`load\_model()\`  function automatically load the weights of the Keras model as well?

If I want to use this model and re-train the last few layers on a different dataset, how should I use load\_model() and load\_weights()?",t2_etja0,False,,0,False,Keras check feature extraction and difference between load_model and load_weights,[],r/tensorflow,False,6,,0,,,False,t3_k2hvfq,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1606812195.0,,[],{},,True,,1606569331.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to re-use a pretrained model supplied along with its weights. There are 2 files&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model/mykerasmodel.h5
weights/mykerasmodel.h5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I want to use this model as a feature extractor. I use only the load_model() function as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;keras_model = load_model()

print(keras_model.inputs)
print(keras_model.outputs)

gives me:
[&amp;lt;tf.Tensor &amp;#39;input_1:0&amp;#39; shape=(None, 160, 160, 3) dtype=float32&amp;gt;]
[&amp;lt;tf.Tensor &amp;#39;Bottleneck_BatchNorm/batchnorm/add_1:0&amp;#39; shape=(None, 128) dtype=float32&amp;gt;]

So, I simply do
features_x = keras_model.predict(x)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am able to get the features but how do I know they are actually right? Does `load_model()`  function automatically load the weights of the Keras model as well?&lt;/p&gt;

&lt;p&gt;If I want to use this model and re-train the last few layers on a different dataset, how should I use load_model() and load_weights()?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k2hvfq,True,,mbkv,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k2hvfq/keras_check_feature_extraction_and_difference/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k2hvfq/keras_check_feature_extraction_and_difference/,22217,1606540531.0,1,,False,,,,,,,,,
467,,tensorflow,,t2_wdxkq,False,,0,False,Deploy and Train TensorFlow models in Go: Human Activity Recognition case study,[],r/tensorflow,False,6,,0,140.0,,False,t3_k23gia,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},Project,False,3,,False,https://b.thumbs.redditmedia.com/6Qdqn0rHBxbWmrkJpkZlcvmzhE-4BSI0GA37QzZZzkE.jpg,False,,[],{},,False,,1606520688.0,text,6,,,text,pgaleone.eu,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k23gia,True,,pgaleone,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k23gia/deploy_and_train_tensorflow_models_in_go_human/,all_ads,False,https://pgaleone.eu/tensorflow/go/2020/11/27/deploy-train-tesorflow-models-in-go-human-activity-recognition/,22217,1606491888.0,0,,False,link,https://pgaleone.eu/tensorflow/go/2020/11/27/deploy-train-tesorflow-models-in-go-human-activity-recognition/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?auto=webp&amp;s=2edba5d5ceb279f09b3527bc294bf2160a873c5c', 'width': 250, 'height': 250}, 'resolutions': [{'url': 'https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c4cbe0629697f9045e34bfbb312fe950c34df5a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=918a35885646403ffa497863194e5c62b45c606d', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'QCb-J1Fr_047ebumrG01fT3ttdPG7-jWDogxAKgzMBQ'}], 'enabled': False}",,,,,,
468,,tensorflow,"Hello,

I just pulled this [GitHub repository](https://github.com/adhishthite/sound-mnist) which builds a CNN for MNIST sound classification.

It is straight forward to use, I just cloned it, made sure I had all the libraries installed, and commented out the first two lines in the [main.py](https://main.py), since I do not use  comet\_ml.

Then, I run the [main.py](https://main.py) file. I get a lot of warnings like this

&gt;UserWarning: n\_fft=2048 is too small for input signal of length=898

which are caused by the  librosa.feature.mfcc function call in the [wav2mfcc.py](https://wav2mfcc.py) file.

Still, the file runs smoothly and starts the training with 50 epochs.

Throughout the training, however, the accuracy is always between 8 and 14 %, and the validation accuracy is in a similar range.

The testing result is similar, so it is much worse than the claimed 98 % on GitHub.

&amp;#x200B;

Can you please clone the GitHub repository, quickly run it, and tell me whether you get poor results like me, or good results?

What could be the reason for the poor results? The GitHub repository is 3 years old, I suspect some library could have changed, either with the data preprocessing, or with TensorFlow. The n\_fft warning caused by the librosa package seems to be [discussed on GitHub](https://github.com/librosa/librosa/issues/1214), but not directly related to my problem.

Do you have any idea how to fix it?

I appreciate any help, thank you very much.",t2_3egsg69n,False,,0,False,"Sound-mnist model training performs much worse on own computer, compared to Github",[],r/tensorflow,False,6,,0,,,False,t3_k27pdx,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606533692.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I just pulled this &lt;a href=""https://github.com/adhishthite/sound-mnist""&gt;GitHub repository&lt;/a&gt; which builds a CNN for MNIST sound classification.&lt;/p&gt;

&lt;p&gt;It is straight forward to use, I just cloned it, made sure I had all the libraries installed, and commented out the first two lines in the &lt;a href=""https://main.py""&gt;main.py&lt;/a&gt;, since I do not use  comet_ml.&lt;/p&gt;

&lt;p&gt;Then, I run the &lt;a href=""https://main.py""&gt;main.py&lt;/a&gt; file. I get a lot of warnings like this&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;UserWarning: n_fft=2048 is too small for input signal of length=898&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;which are caused by the  librosa.feature.mfcc function call in the &lt;a href=""https://wav2mfcc.py""&gt;wav2mfcc.py&lt;/a&gt; file.&lt;/p&gt;

&lt;p&gt;Still, the file runs smoothly and starts the training with 50 epochs.&lt;/p&gt;

&lt;p&gt;Throughout the training, however, the accuracy is always between 8 and 14 %, and the validation accuracy is in a similar range.&lt;/p&gt;

&lt;p&gt;The testing result is similar, so it is much worse than the claimed 98 % on GitHub.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can you please clone the GitHub repository, quickly run it, and tell me whether you get poor results like me, or good results?&lt;/p&gt;

&lt;p&gt;What could be the reason for the poor results? The GitHub repository is 3 years old, I suspect some library could have changed, either with the data preprocessing, or with TensorFlow. The n_fft warning caused by the librosa package seems to be &lt;a href=""https://github.com/librosa/librosa/issues/1214""&gt;discussed on GitHub&lt;/a&gt;, but not directly related to my problem.&lt;/p&gt;

&lt;p&gt;Do you have any idea how to fix it?&lt;/p&gt;

&lt;p&gt;I appreciate any help, thank you very much.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k27pdx,True,,truResearch,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k27pdx/soundmnist_model_training_performs_much_worse_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k27pdx/soundmnist_model_training_performs_much_worse_on/,22217,1606504892.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/hUlx8u8SxkI5uX1YNc_cwmBRjYE4qKmkaoawyqDko8c.jpg?auto=webp&amp;s=ac8b3ccfb67b4c6cd1021f369ed5b6018273139c', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/hUlx8u8SxkI5uX1YNc_cwmBRjYE4qKmkaoawyqDko8c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=27afd3ac243b6cd564a2092c772ad5b3f88f7f1a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/hUlx8u8SxkI5uX1YNc_cwmBRjYE4qKmkaoawyqDko8c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8faf3e8b71cf9b1bc436119626f4e146fd2a920c', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/hUlx8u8SxkI5uX1YNc_cwmBRjYE4qKmkaoawyqDko8c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=053b8a2e02de3141d186a64b5ecceaec2248ae0a', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'nRXT2QvrO71dfrs5fXxJZSUsDu3r2lNaVAjPUNgkNTw'}], 'enabled': False}",,,,,,
469,,tensorflow,"Hello tf community,

I need some help. Not new to Python or programming by any means - but new to TensorFlow and ML in practice. I'm trying to start simple and create a Sequential Model to make predictions using some data from Spotify.

My model has 12 numerical inputs and 1 numerical output (a value between 0 and 100).

Here is my model summary:


    Model: ""sequential""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense (Dense)                (None, 12)                156       
    _________________________________________________________________
    dense_1 (Dense)              (None, 1)                 13        
    =================================================================
    Total params: 169
    Trainable params: 169
    Non-trainable params: 0
    _________________________________________________________________

I was able to fit my model and evaluate it. But when I try to run `model.predict(input)` it fails.

My `input` is a numpy array of shape `(12,)`. I can verify this much. However, when I try to make a prediction, the program raises a ValueError and says:

    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 
    12 but received input with shape [None, 1]


What am I doing wrong? I am really struggling here - The VSCode debugger won't let me step into the predict function - and it *seems* that the input is of the right shape, but tf disagrees.

Thanks!",t2_zie7k,False,,0,False,Incorrect Input Shape?,[],r/tensorflow,False,6,,0,,,False,t3_k1soy2,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1606473260.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello tf community,&lt;/p&gt;

&lt;p&gt;I need some help. Not new to Python or programming by any means - but new to TensorFlow and ML in practice. I&amp;#39;m trying to start simple and create a Sequential Model to make predictions using some data from Spotify.&lt;/p&gt;

&lt;p&gt;My model has 12 numerical inputs and 1 numerical output (a value between 0 and 100).&lt;/p&gt;

&lt;p&gt;Here is my model summary:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 12)                156       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 13        
=================================================================
Total params: 169
Trainable params: 169
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I was able to fit my model and evaluate it. But when I try to run &lt;code&gt;model.predict(input)&lt;/code&gt; it fails.&lt;/p&gt;

&lt;p&gt;My &lt;code&gt;input&lt;/code&gt; is a numpy array of shape &lt;code&gt;(12,)&lt;/code&gt;. I can verify this much. However, when I try to make a prediction, the program raises a ValueError and says:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 
12 but received input with shape [None, 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What am I doing wrong? I am really struggling here - The VSCode debugger won&amp;#39;t let me step into the predict function - and it &lt;em&gt;seems&lt;/em&gt; that the input is of the right shape, but tf disagrees.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k1soy2,True,,pawsibility,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k1soy2/incorrect_input_shape/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k1soy2/incorrect_input_shape/,22217,1606444460.0,0,,False,,,,,,,,,
470,,tensorflow,"I read in [this article](https://www.tensorflow.org/lite/guide/inference) on the tensorflow lite interpreter that it uses ""static graph ordering"", but searching this only leads back to that article, and my assumed alternative to static, ""dynamic graph ordering"" returns no results at all.

I'm assuming it refers to the tf model computational graph, but I'm not clear on in what sense this can be static/dynamic. Could you give me any insight?",t2_d5qjr,False,,0,False,"What is ""static graph ordering""?",[],r/tensorflow,False,6,,0,,,False,t3_k1mda1,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1606450069.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I read in &lt;a href=""https://www.tensorflow.org/lite/guide/inference""&gt;this article&lt;/a&gt; on the tensorflow lite interpreter that it uses &amp;quot;static graph ordering&amp;quot;, but searching this only leads back to that article, and my assumed alternative to static, &amp;quot;dynamic graph ordering&amp;quot; returns no results at all.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m assuming it refers to the tf model computational graph, but I&amp;#39;m not clear on in what sense this can be static/dynamic. Could you give me any insight?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k1mda1,True,,TristanTrim,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k1mda1/what_is_static_graph_ordering/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k1mda1/what_is_static_graph_ordering/,22217,1606421269.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?auto=webp&amp;s=2572596fe2183c02bb87888fad10698003d1766c', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f38f154b31bbc61f967552a73eae2d908d46ae03', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=800ed1265a325e2ebbd4bac73e5a0a9f87375fc4', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef1d21237970b3962ea11427b5fb4a133b573f95', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd75fe122929cebeb28f32cabc416c0d34746e81', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e61b7e8ded8e04296fb02cef535a2339569b52b', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fce2149c6d3aad062f85426dd46ad50c64a82b2e', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'X-wKcTKmnQRaY7Q0VF7Fv5E2VV8HI6yDgaH8MhXzwMA'}], 'enabled': False}",,,,,,
471,,tensorflow,"So i want to use this depth prediction model ([https://github.com/nianticlabs/monodepth2](https://github.com/nianticlabs/monodepth2)) in one of my project, Tensorflow implementation of the model ([https://github.com/yamhoresh/monodepth2-TensorFlow2](https://github.com/yamhoresh/monodepth2-TensorFlow2)). I tried to load the model with this code using [Tensowflow.NET](https://Tensowflow.NET)

     var test = BaseModel.LoadModel($""{System.IO.Directory.GetCurrentDirectory()}/model/monodepth/mono.h5"");

And it failed with message Python.Runtime.PythonException: 'ValueError : Unknown layer: ReflectionPadding2D'. 

I did look through the Tensorflow implementation of the model a bit and found the custom layer ([https://github.com/yamhoresh/monodepth2-TensorFlow2/blob/master/layers.py](https://github.com/yamhoresh/monodepth2-TensorFlow2/blob/master/layers.py)). I tried to rewrite this class in C# but i have some problem. This custom layer class inherit from tf.keras.layers.layer but there is no such class in [Tensorflow.Net](https://Tensorflow.Net). Second, let's say that i have done rewrite the class but how can i load it along with the model ? Thank you for all of your answers",t2_6589szyu,False,,0,False,Load a keras model with custom layer in Tensorflow.NET ?,[],r/tensorflow,False,6,,0,,,False,t3_k1ch1p,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question (Tensorflow.NET),False,4,,False,self,False,,[],{},,True,,1606412912.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i want to use this depth prediction model (&lt;a href=""https://github.com/nianticlabs/monodepth2""&gt;https://github.com/nianticlabs/monodepth2&lt;/a&gt;) in one of my project, Tensorflow implementation of the model (&lt;a href=""https://github.com/yamhoresh/monodepth2-TensorFlow2""&gt;https://github.com/yamhoresh/monodepth2-TensorFlow2&lt;/a&gt;). I tried to load the model with this code using &lt;a href=""https://Tensowflow.NET""&gt;Tensowflow.NET&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; var test = BaseModel.LoadModel($&amp;quot;{System.IO.Directory.GetCurrentDirectory()}/model/monodepth/mono.h5&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it failed with message Python.Runtime.PythonException: &amp;#39;ValueError : Unknown layer: ReflectionPadding2D&amp;#39;. &lt;/p&gt;

&lt;p&gt;I did look through the Tensorflow implementation of the model a bit and found the custom layer (&lt;a href=""https://github.com/yamhoresh/monodepth2-TensorFlow2/blob/master/layers.py""&gt;https://github.com/yamhoresh/monodepth2-TensorFlow2/blob/master/layers.py&lt;/a&gt;). I tried to rewrite this class in C# but i have some problem. This custom layer class inherit from tf.keras.layers.layer but there is no such class in &lt;a href=""https://Tensorflow.Net""&gt;Tensorflow.Net&lt;/a&gt;. Second, let&amp;#39;s say that i have done rewrite the class but how can i load it along with the model ? Thank you for all of your answers&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k1ch1p,True,,minhduc66532,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k1ch1p/load_a_keras_model_with_custom_layer_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k1ch1p/load_a_keras_model_with_custom_layer_in/,22217,1606384112.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?auto=webp&amp;s=abc93eeedc0ed49c2771bf2f58c0fcf79ada734a', 'width': 1280, 'height': 634}, 'resolutions': [{'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4be560b323e2cce7ba9dafaae50fb7c29cd2a8b', 'width': 108, 'height': 53}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e996679901e3ab0d3673c99dc844fe13ad0d4e6', 'width': 216, 'height': 106}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9528a686214c2eae956c62b30dc52b58f38f0cd1', 'width': 320, 'height': 158}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c19a17dbc4828ba2934003595e7857e1426a1f', 'width': 640, 'height': 317}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e690f4ac23efd57d0a6fdd6375354b15640b73e', 'width': 960, 'height': 475}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0f5f427a28bed8cc07ecb86f18cd8da6f4593e30', 'width': 1080, 'height': 534}], 'variants': {}, 'id': 'wkYq3rBNvyC9-YlP6XihsokEGDrfVDvA5OnO0wKk3Zs'}], 'enabled': False}",,,,,,
472,,tensorflow,"This tutorial covers how to use TensorFlow Lite on Raspberry Pi. The deep learning models created using TensorFlow typically require high processing capabilities to perform inference. Fortunately, there is a lite version of TensorFlow called TensorFlow Lite (TFLite for short) which allows such models to run on devices with limited capabilities. Raspberry Pi is also a fun and interesting use case to get hands-on experience with machine learning.

In this tutorial, we'll see how to prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device. Specifically, we'll cover:

* Accessing Raspberry Pi from PC
* Preparing TFLite in RPi
* Downloading MobileNet
* Classifying a Single Image

Article link: [https://blog.paperspace.com/tensorflow-lite-raspberry-pi/](https://blog.paperspace.com/tensorflow-lite-raspberry-pi/)",t2_15en0l,False,,0,False,[Tutorial] How to Run TensorFlow Lite Models on Raspberry Pi,[],r/tensorflow,False,6,,0,,,False,t3_k0uyd5,False,dark,0.95,,public,18,0,{},,,False,[],,False,False,,{},Tutorial,False,18,,False,self,False,,[],{},,True,,1606349441.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial covers how to use TensorFlow Lite on Raspberry Pi. The deep learning models created using TensorFlow typically require high processing capabilities to perform inference. Fortunately, there is a lite version of TensorFlow called TensorFlow Lite (TFLite for short) which allows such models to run on devices with limited capabilities. Raspberry Pi is also a fun and interesting use case to get hands-on experience with machine learning.&lt;/p&gt;

&lt;p&gt;In this tutorial, we&amp;#39;ll see how to prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device. Specifically, we&amp;#39;ll cover:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Accessing Raspberry Pi from PC&lt;/li&gt;
&lt;li&gt;Preparing TFLite in RPi&lt;/li&gt;
&lt;li&gt;Downloading MobileNet&lt;/li&gt;
&lt;li&gt;Classifying a Single Image&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/tensorflow-lite-raspberry-pi/""&gt;https://blog.paperspace.com/tensorflow-lite-raspberry-pi/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k0uyd5,True,,hellopaperspace,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/k0uyd5/tutorial_how_to_run_tensorflow_lite_models_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k0uyd5/tutorial_how_to_run_tensorflow_lite_models_on/,22217,1606320641.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?auto=webp&amp;s=547a3003250c9f60942f08b6a651c9c13925dba0', 'width': 2000, 'height': 1125}, 'resolutions': [{'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dbf53ad840fcbba560d413efe4f02fb4e24df71', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=882c5de6d1b6fd2c5a6c58cb9085acdb3ce93a9a', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=51bbca640d64865919b041d58079b6cfdf0b3047', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=23450992a8a4c63be8a84fac5f9c02857427218c', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=388ac6d8d9a1e9dd55eff5b21a02c6c0977f3f32', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/TaUYtK7RY8MJYJvLknBEYuVFXS_SRgf9bRURy_Nz4QM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b85eccd2b7a28e876240984668672ce80ede71b', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '3CJFJCwfN-pmKUNqzCgtvWeQnCIT1uMHnj3A47w1-RI'}], 'enabled': False}",,,,,,
473,,tensorflow,"Hi everyone!

I've spent the last few weeks working on a new react library to speed up the use of tensorflowjs models in your apps. It's built with Typescript with a  TDD method (thought it would be good practice).

There are a few useful hooks ready to do the core functionality, load a  model, predict using a model. There are also a few more hooks in the pipeline (see the issues tab). If anyone's got any suggestions then feel free to add them to the issues tab for discussion!

Github: [https://github.com/joshuaellis/react-tensorflow](https://github.com/joshuaellis/react-tensorflow)  
Demo: [https://react-tensorflow-example.vercel.app/](https://react-tensorflow-example.vercel.app/)",t2_fm72yf4,False,,0,False,Introducing react-tensorflow v1.0.0! Helpful hooks for tensorflow/tfjs,[],r/tensorflow,False,6,,0,,,False,t3_k11baf,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Project,False,4,,False,self,False,,[],{},,True,,1606368502.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve spent the last few weeks working on a new react library to speed up the use of tensorflowjs models in your apps. It&amp;#39;s built with Typescript with a  TDD method (thought it would be good practice).&lt;/p&gt;

&lt;p&gt;There are a few useful hooks ready to do the core functionality, load a  model, predict using a model. There are also a few more hooks in the pipeline (see the issues tab). If anyone&amp;#39;s got any suggestions then feel free to add them to the issues tab for discussion!&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/joshuaellis/react-tensorflow""&gt;https://github.com/joshuaellis/react-tensorflow&lt;/a&gt;&lt;br/&gt;
Demo: &lt;a href=""https://react-tensorflow-example.vercel.app/""&gt;https://react-tensorflow-example.vercel.app/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k11baf,True,,TDFKA_Rick,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k11baf/introducing_reacttensorflow_v100_helpful_hooks/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k11baf/introducing_reacttensorflow_v100_helpful_hooks/,22217,1606339702.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?auto=webp&amp;s=e29b4e76a7973fcf1c6e0ac993b5f7d34ddda545', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=16b31dd78c93198f66a246c85a058ddc42cd4ce9', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ba6b6982590a6c2f28f2163e2eef76222f6a78d', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2664036813fbfbb79c73e83675c0f627efe5e6f3', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b3adcfd9fc75e8699d157581775544f9fac3294', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4512a260f088e99a74e8fb82993b3677e1e78a73', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/jUA_SJo3aT71cXsQBD94q-jZQvX6sN9MaAo8_ce_DoY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=35f4e8bd5ade40a5caf27c8007332f8c22e2cd98', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'RNjwGw8SVj-jm9B8fe4pu4Aqro9iPRPJGkHbarAaYVM'}], 'enabled': False}",,,,,,
474,,tensorflow,"Hi,

&amp;#x200B;

I am currently trying to get into Tensorflow. My main end goal is to have a model that can predict the likelihood of a wildfire with at least  85%-90% accuracy. I'm already pretty good at finding data, although finding what data I need is somewhat harder. But mainly, the problem I'm having right now is with Tensorflow. All of the tutorials are ( in my opinion ) very hard to follow along with, and don't provide enough information. Adding to this, I've been trying to get some lower-level projects working such as a weather forecaster ( going way better than the wildfire thing, mainly due to the availability of data and comprehendible tutorials. ) going. But I'd really appreciate any help I could receive. Basically, I need to figure out how to learn Tensorflow. Thank you!",t2_36vrt8pu,False,,0,False,"How do I learn Tensorflow? ( having problems learning from, in my opinion, bad tutorials. )",[],r/tensorflow,False,6,,0,,,False,t3_k11cs7,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1606368626.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am currently trying to get into Tensorflow. My main end goal is to have a model that can predict the likelihood of a wildfire with at least  85%-90% accuracy. I&amp;#39;m already pretty good at finding data, although finding what data I need is somewhat harder. But mainly, the problem I&amp;#39;m having right now is with Tensorflow. All of the tutorials are ( in my opinion ) very hard to follow along with, and don&amp;#39;t provide enough information. Adding to this, I&amp;#39;ve been trying to get some lower-level projects working such as a weather forecaster ( going way better than the wildfire thing, mainly due to the availability of data and comprehendible tutorials. ) going. But I&amp;#39;d really appreciate any help I could receive. Basically, I need to figure out how to learn Tensorflow. Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k11cs7,True,,TheMartian578,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k11cs7/how_do_i_learn_tensorflow_having_problems/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k11cs7/how_do_i_learn_tensorflow_having_problems/,22217,1606339826.0,0,,False,,,,,,,,,
475,,tensorflow,Pretty easy to setup ? All I want to use it for is to produce a v5 android app and MAYBE learn a little (I haven't programmed since BASIC and dbase),t2_12kixs3w,False,,0,False,On a i7 pixelbook,[],r/tensorflow,False,6,,0,,,False,t3_k0v6rj,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1606350205.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Pretty easy to setup ? All I want to use it for is to produce a v5 android app and MAYBE learn a little (I haven&amp;#39;t programmed since BASIC and dbase)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k0v6rj,True,,puredigital,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/k0v6rj/on_a_i7_pixelbook/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k0v6rj/on_a_i7_pixelbook/,22217,1606321405.0,0,,False,,,,,,,,,
476,,tensorflow,"i have posted this on stackoverflow already, but havent gotten a response.

The problem is the input into a tensorflow NN is apparently not in the right format, but i ahve no clue how to fix this.

&amp;#x200B;

[https://stackoverflow.com/questions/64957163/data-input-into-tensorflow-nn-apparently-not-in-the-right-format](https://stackoverflow.com/questions/64957163/data-input-into-tensorflow-nn-apparently-not-in-the-right-format)",t2_16prlc,False,,0,False,Can someone help me figure out whats wrong here?,[],r/tensorflow,False,6,,0,,,False,t3_k0r7rp,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1606335706.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;i have posted this on stackoverflow already, but havent gotten a response.&lt;/p&gt;

&lt;p&gt;The problem is the input into a tensorflow NN is apparently not in the right format, but i ahve no clue how to fix this.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://stackoverflow.com/questions/64957163/data-input-into-tensorflow-nn-apparently-not-in-the-right-format""&gt;https://stackoverflow.com/questions/64957163/data-input-into-tensorflow-nn-apparently-not-in-the-right-format&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k0r7rp,True,,schlorkyy,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/k0r7rp/can_someone_help_me_figure_out_whats_wrong_here/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k0r7rp/can_someone_help_me_figure_out_whats_wrong_here/,22217,1606306906.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
477,,tensorflow,"Hey guys, what's your review about the course:

https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/

Depending on your reviews, I might end up buying it!


Thanks",t2_2mmql89p,False,,0,False,Online RL course review,[],r/tensorflow,False,6,,0,,,False,t3_k0oaps,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1606321510.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, what&amp;#39;s your review about the course:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/""&gt;https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Depending on your reviews, I might end up buying it!&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k0oaps,True,,grid_world,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/k0oaps/online_rl_course_review/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k0oaps/online_rl_course_review/,22217,1606292710.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/F2HhWADRDWp1gCDaKYkIHvk86S8EoPw_OHv0vYqNEno.jpg?auto=webp&amp;s=b67f997ef37ee5e3929f08bd3692e300fbe3b331', 'width': 480, 'height': 270}, 'resolutions': [{'url': 'https://external-preview.redd.it/F2HhWADRDWp1gCDaKYkIHvk86S8EoPw_OHv0vYqNEno.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9f8966059ceead9bf098c3aa1159e1b49049023', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/F2HhWADRDWp1gCDaKYkIHvk86S8EoPw_OHv0vYqNEno.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c54194cfc4a161b473aca5e52639edba6e578834', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/F2HhWADRDWp1gCDaKYkIHvk86S8EoPw_OHv0vYqNEno.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a2c9ca6d63664b171a19ad8ae462ae03acf1c6ab', 'width': 320, 'height': 180}], 'variants': {}, 'id': 'V8n86ru7FD-dBqXq24ASYD6mfMAul7hwQ1R7bmNgLjI'}], 'enabled': False}",,,,,,
478,,tensorflow,,t2_13ah3w,False,,0,False,😷Real-Time Facemask Detection Tutorial using Tensorflow Object Detection API trained on Kaggle dataset😷,[],r/tensorflow,False,6,,0,78.0,,False,t3_k09umx,False,dark,0.92,,public,21,0,{},140.0,,False,[],,False,False,,{},Project,False,21,,False,https://b.thumbs.redditmedia.com/HlEPZbuIcbQh4ZOxbC9Tl_Md1WIsn1fIekVeNwY_QCo.jpg,False,,[],{},,False,,1606268903.0,text,6,,,text,medium.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k09umx,True,,horczech,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k09umx/realtime_facemask_detection_tutorial_using/,all_ads,False,https://medium.com/swlh/how-to-train-a-real-time-facemask-object-detector-with-tensorflow-object-detection-api-tfod2-a4eb9f2c2fae,22217,1606240103.0,0,,False,link,https://medium.com/swlh/how-to-train-a-real-time-facemask-object-detector-with-tensorflow-object-detection-api-tfod2-a4eb9f2c2fae,"{'images': [{'source': {'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?auto=webp&amp;s=4454428b710b2c1bc631f3af666a059277578df2', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4510c9076d6970b243d15f904bc395bbe02b5dfc', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=842f4982af3925a53240e12a61c47059b6ec2827', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=046fe88204e425ec74fe7db013b5e3a683172fb0', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c160543d10ed78acc1e0effe873578d8fde969ab', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c34b99eedb85b51fe43a4094adc723ffc8618f85', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/daCvqusfNL9zE1HOI_YalCAjxAEAaHYp4BH0P-kXnOw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb837d97a5aa0800fae07eabf6ea79f0878e972b', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '0sDsLIa-saM9Tt40KVSHjLbcFL2kDbHZpJWOJWPlSFE'}], 'enabled': False}",,,,,,
479,,tensorflow,I have a large dataset of images that needs to be pre-processed before being input into my model for training and I would like do the processing once and then store this in a Bucket on Google Cloud so that I can consume it with the TFDS API. What's the best format to do this? Numpy Arrays? Can you store a tf.Dataset object? Maybe TFRecords? Any help would be appreciated.,t2_c6wea,False,,0,False,How Do You Guys Store Pre-processed Image Data For Training Models?,[],r/tensorflow,False,6,,0,,,False,t3_k0gk0z,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1606289939.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a large dataset of images that needs to be pre-processed before being input into my model for training and I would like do the processing once and then store this in a Bucket on Google Cloud so that I can consume it with the TFDS API. What&amp;#39;s the best format to do this? Numpy Arrays? Can you store a tf.Dataset object? Maybe TFRecords? Any help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k0gk0z,True,,thelolzmaster,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/k0gk0z/how_do_you_guys_store_preprocessed_image_data_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k0gk0z/how_do_you_guys_store_preprocessed_image_data_for/,22217,1606261139.0,0,,False,,,,,,,,,
480,,tensorflow,"I am working on a project involving neural  style transfer. I am using VGG19 to extract features for style transfer  and tkinter to create GUI for the utility. Each training epoch is  divided into a number of training steps (provided by user). Versions of  libraries used are:

    OS: Windows 10 GPU: Nvidia RTX 3090 tensorflow: tf-nightly-gpu==2.5.0.dev20201028 numpy: numpy 1.19.3 (the tf-nightly-gpu installs 1.19.4, but it has a bug on windows) CUDA: 11.1 CUDnn: 8.0.4 any gpu specific tf code used: No. The code can be run on CPU only machines too 

The program starts up normally, tf detects GPU, loads all libraries  successfully and training starts without any issue. On the 1st epoch,  12th step the training halts for a while and then the program (the  tkinter gui) stops responding. On checking the GPU usage, the dedicated memory usage is found to go  upto 100% before freezing. The output on terminal and GPU usage is given as a screenshot (the code  is running on a client's machine so i do not have access to written  messages).

I know the information is really insufficient, any clue will be helpful.

&amp;#x200B;

EDIT: The code works perfectly fine in google colab and on my pc (CPU Only. TF only warns that no GPU was detected)

EDIT2: Readable images: 

[GPU Usage](https://drive.google.com/file/d/1akWLWUpXcVw7olbnbDXBcZ8KHYP_8Vaz/view?usp=sharing)

[Program output](https://drive.google.com/file/d/1FnFaINEuEmIO6Zo-uyYlWmX1ombRUO_v/view?usp=sharing)

&amp;#x200B;

[GPU usage](https://preview.redd.it/u2p9rwkia6161.png?width=360&amp;format=png&amp;auto=webp&amp;s=9fcebf57ff52bfd5e8a4a7879e7f4c01f8b79815)

[Program output](https://preview.redd.it/2gwwewkia6161.png?width=360&amp;format=png&amp;auto=webp&amp;s=4bb4b4ef73618f94c03c6836d7316d4c26bdc6d5)",t2_5t92ym0i,False,,0,False,tensorflow model freezes. RTX3090,[],r/tensorflow,False,6,,0,73.0,,False,t3_k03a6p,False,dark,0.83,,public,4,0,{},140.0,,False,[],,False,False,,{},,False,4,,False,https://b.thumbs.redditmedia.com/fYEjOK7POcP0tFZMqJhkObzlXHdwaDDmrgRJZXf-iGs.jpg,1606223662.0,,[],{},,True,,1606245910.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on a project involving neural  style transfer. I am using VGG19 to extract features for style transfer  and tkinter to create GUI for the utility. Each training epoch is  divided into a number of training steps (provided by user). Versions of  libraries used are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OS: Windows 10 GPU: Nvidia RTX 3090 tensorflow: tf-nightly-gpu==2.5.0.dev20201028 numpy: numpy 1.19.3 (the tf-nightly-gpu installs 1.19.4, but it has a bug on windows) CUDA: 11.1 CUDnn: 8.0.4 any gpu specific tf code used: No. The code can be run on CPU only machines too 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The program starts up normally, tf detects GPU, loads all libraries  successfully and training starts without any issue. On the 1st epoch,  12th step the training halts for a while and then the program (the  tkinter gui) stops responding. On checking the GPU usage, the dedicated memory usage is found to go  upto 100% before freezing. The output on terminal and GPU usage is given as a screenshot (the code  is running on a client&amp;#39;s machine so i do not have access to written  messages).&lt;/p&gt;

&lt;p&gt;I know the information is really insufficient, any clue will be helpful.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;EDIT: The code works perfectly fine in google colab and on my pc (CPU Only. TF only warns that no GPU was detected)&lt;/p&gt;

&lt;p&gt;EDIT2: Readable images: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://drive.google.com/file/d/1akWLWUpXcVw7olbnbDXBcZ8KHYP_8Vaz/view?usp=sharing""&gt;GPU Usage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://drive.google.com/file/d/1FnFaINEuEmIO6Zo-uyYlWmX1ombRUO_v/view?usp=sharing""&gt;Program output&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/u2p9rwkia6161.png?width=360&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fcebf57ff52bfd5e8a4a7879e7f4c01f8b79815""&gt;GPU usage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/2gwwewkia6161.png?width=360&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bb4b4ef73618f94c03c6836d7316d4c26bdc6d5""&gt;Program output&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,k03a6p,True,,_saan,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/k03a6p/tensorflow_model_freezes_rtx3090/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k03a6p/tensorflow_model_freezes_rtx3090/,22217,1606217110.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?auto=webp&amp;s=6e6ada434f3f6596b3ea56d5d10def6e93997653', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f0cff2abf94ff63fda3a262c033c88a2e993367', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=024b6f0c21f8c3f44672c44684a51b0fcf5d585d', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cdc66c7e6e794cd9f0b9c4057595abe234bd3077', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0899abec6e6b69a9f983032be6045a0f2f70d27', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2db976174bb712f8d410c7ee680ef9c8f714b8a6', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/i54VrUrdZYSpT61zMzthkkNKxjrcCDTMT3a4LMOVSSo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a2ba5923da1edb6e74d08d7ec1ac13475e2ad2e', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'KInxgN3ndh0NLDXpKGT4hYwa270a1MRaV-pKlXMQhuI'}], 'enabled': False}",,"{'2gwwewkia6161': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/2gwwewkia6161.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=717f348a5be8f10b7ff35a4098cdd27d6f8fa101'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/2gwwewkia6161.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0948b3fbef80f6b534e267e948b809d67cd7851f'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/2gwwewkia6161.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=13c611d71a80509b631a54ab36ac5def034a8d27'}], 's': {'y': 203, 'x': 360, 'u': 'https://preview.redd.it/2gwwewkia6161.png?width=360&amp;format=png&amp;auto=webp&amp;s=4bb4b4ef73618f94c03c6836d7316d4c26bdc6d5'}, 'id': '2gwwewkia6161'}, 'u2p9rwkia6161': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/u2p9rwkia6161.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbdab06357284b0c53494105f06cfbe2a3ca662a'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/u2p9rwkia6161.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c27111b39ad160d4aff2492165e732628c8ce1c3'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/u2p9rwkia6161.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e04e3ebfa9fd743447c63bf4a947406814c35550'}], 's': {'y': 203, 'x': 360, 'u': 'https://preview.redd.it/u2p9rwkia6161.png?width=360&amp;format=png&amp;auto=webp&amp;s=9fcebf57ff52bfd5e8a4a7879e7f4c01f8b79815'}, 'id': 'u2p9rwkia6161'}}",,,,
481,,tensorflow,"Hi everyone

If you want to learn about the best Python libraries for Data Science, then check out this article.

[https://www.learnandmakeit.com/best-python-libraries-for-data-science/](https://www.learnandmakeit.com/best-python-libraries-for-data-science/)",t2_8h4tf29m,False,,0,False,Best Python Libraries for Data Science,[],r/tensorflow,False,6,,0,,,False,t3_k04qsb,False,dark,0.33,,public,0,0,{},,,False,[],,False,False,,{},Data Science,False,0,,False,self,False,,[],{},,True,,1606252408.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone&lt;/p&gt;

&lt;p&gt;If you want to learn about the best Python libraries for Data Science, then check out this article.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.learnandmakeit.com/best-python-libraries-for-data-science/""&gt;https://www.learnandmakeit.com/best-python-libraries-for-data-science/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,k04qsb,True,,jamessidis155,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/k04qsb/best_python_libraries_for_data_science/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k04qsb/best_python_libraries_for_data_science/,22217,1606223608.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/X0pkseyR5yGBXzvn0YKd0R3epov-IwUgrTWTgRMSy3I.jpg?auto=webp&amp;s=930f9621d538aca3b994a12ba6ab51f893c8ac40', 'width': 1000, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/X0pkseyR5yGBXzvn0YKd0R3epov-IwUgrTWTgRMSy3I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0db5330255cc0e1bf996927a6ec4ccc35653bf6', 'width': 108, 'height': 64}, {'url': 'https://external-preview.redd.it/X0pkseyR5yGBXzvn0YKd0R3epov-IwUgrTWTgRMSy3I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e324b3f46ecf677df2733e66e0c2161f7a343765', 'width': 216, 'height': 129}, {'url': 'https://external-preview.redd.it/X0pkseyR5yGBXzvn0YKd0R3epov-IwUgrTWTgRMSy3I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=08e29271bcad3b2e1b6a2e8e5f80872810214bd6', 'width': 320, 'height': 192}, {'url': 'https://external-preview.redd.it/X0pkseyR5yGBXzvn0YKd0R3epov-IwUgrTWTgRMSy3I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1169703fe1e5c3635c39121fed550940f44291e2', 'width': 640, 'height': 384}, {'url': 'https://external-preview.redd.it/X0pkseyR5yGBXzvn0YKd0R3epov-IwUgrTWTgRMSy3I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d49a5d936e11d28f1050695c479804c58d5ba2a', 'width': 960, 'height': 576}], 'variants': {}, 'id': 'XuTO-lznQjy6yZzM5D3FCg6U-09zrISlvOTbyc8w8yw'}], 'enabled': False}",,,,,,
482,,tensorflow,"Im trying to implement a tf model on the Nvidia jetson nano. However I get an out of memory error when trying to inference this model on the GPU. When I bypass the GPU  using os.environ\[""CUDA\_VISIBLE\_DEVICES""\] = ""-1"" and a swap file the model runs correctly on the cpu (Very slow). At first I thought that the GPU on the jetson nano has not enough GPU memory. But when researching on the internet I read that the nano has a shared memory for the CPU and GPU. So how could it be that the model can inference on the CPU and not on the GPU?",t2_61qkwgix,False,,0,False,Nvidia jetson nano OOM error,[],r/tensorflow,False,6,,0,,,False,t3_k01vqh,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1606238823.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im trying to implement a tf model on the Nvidia jetson nano. However I get an out of memory error when trying to inference this model on the GPU. When I bypass the GPU  using os.environ[&amp;quot;CUDA_VISIBLE_DEVICES&amp;quot;] = &amp;quot;-1&amp;quot; and a swap file the model runs correctly on the cpu (Very slow). At first I thought that the GPU on the jetson nano has not enough GPU memory. But when researching on the internet I read that the nano has a shared memory for the CPU and GPU. So how could it be that the model can inference on the CPU and not on the GPU?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,k01vqh,True,,sleepyleasle,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/k01vqh/nvidia_jetson_nano_oom_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/k01vqh/nvidia_jetson_nano_oom_error/,22217,1606210023.0,0,,False,,,,,,,,,
483,,tensorflow,"Genuinely interested about the ways other teams are deploying models   


A few things I am hoping to learn  
\- Versioning  
\- Custom internal platform vs what's open source  
\- Major mistakes and things to look out for  


Context :  
My team has an ""internal platform"" situation but it's causing us some frictions",t2_13pri7,False,,0,False,How are you deploying your models in production?,[],r/tensorflow,False,6,,0,,,False,t3_jzhfiu,False,dark,0.93,,public,21,0,{},,,False,[],,False,False,,{},Question,False,21,,False,self,False,,[],{},,True,,1606166314.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Genuinely interested about the ways other teams are deploying models   &lt;/p&gt;

&lt;p&gt;A few things I am hoping to learn&lt;br/&gt;
- Versioning&lt;br/&gt;
- Custom internal platform vs what&amp;#39;s open source&lt;br/&gt;
- Major mistakes and things to look out for  &lt;/p&gt;

&lt;p&gt;Context :&lt;br/&gt;
My team has an &amp;quot;internal platform&amp;quot; situation but it&amp;#39;s causing us some frictions&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jzhfiu,True,,omar16100,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/jzhfiu/how_are_you_deploying_your_models_in_production/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jzhfiu/how_are_you_deploying_your_models_in_production/,22217,1606137514.0,2,,False,,,,,,,,,
484,,tensorflow,"Hi guys, I am new to TensorFlow. I am planning to use it for object detection purposes and currently I am training my custom model for it. Due to performance limit, I am training my model with SSD MobileNet V2 320×320 model architecture. As the input data will be resize to 320×320, may I know will the video output have that aspect ratio too? ( Input Video ratio is 16:9 and planning to keep to same/similar ratio for the output frame.) 👀😵",t2_2muedqb6,False,,0,False,New to TF and curious about input data and output video,[],r/tensorflow,False,6,,0,,,False,t3_jzhz91,False,dark,0.99,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1606168390.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I am new to TensorFlow. I am planning to use it for object detection purposes and currently I am training my custom model for it. Due to performance limit, I am training my model with SSD MobileNet V2 320×320 model architecture. As the input data will be resize to 320×320, may I know will the video output have that aspect ratio too? ( Input Video ratio is 16:9 and planning to keep to same/similar ratio for the output frame.) 👀😵&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jzhz91,True,,rchuzh,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jzhz91/new_to_tf_and_curious_about_input_data_and_output/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jzhz91/new_to_tf_and_curious_about_input_data_and_output/,22217,1606139590.0,0,,False,,,,,,,,,
485,,tensorflow,"When I need a GPU to train Tensorflow models I usually spin up an AWS EC2 GPU instance with the Deep Learning AMI and `scp` my code over. I've been looking for an alternative and I came across this tutorial for tensorflow-cloud that seems really useful ([https://blog.tensorflow.org/2020/08/train-your-tensorflow-model-on-google.html](https://blog.tensorflow.org/2020/08/train-your-tensorflow-model-on-google.html)). I love the idea of being able to provision and train on GPU instances from within my training scripts. Does anybody here have any experience with this library? Given it's apparent ease of use I'm surprised I haven't heard of it before. My main question is, if I want to train on my own dataset (as opposed to some dataset available in tf.Datasets) where would I put it in GCP so that my script and tensorflow-cloud can access it? I can't seem to find any examples of this. Any help would be appreciated. I hope this spurs some discussion around the library as well.",t2_c6wea,False,,0,False,Questions Regarding tensorflow-cloud Library,[],r/tensorflow,False,6,,0,,,False,t3_jza9bk,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1606132203.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When I need a GPU to train Tensorflow models I usually spin up an AWS EC2 GPU instance with the Deep Learning AMI and &lt;code&gt;scp&lt;/code&gt; my code over. I&amp;#39;ve been looking for an alternative and I came across this tutorial for tensorflow-cloud that seems really useful (&lt;a href=""https://blog.tensorflow.org/2020/08/train-your-tensorflow-model-on-google.html""&gt;https://blog.tensorflow.org/2020/08/train-your-tensorflow-model-on-google.html&lt;/a&gt;). I love the idea of being able to provision and train on GPU instances from within my training scripts. Does anybody here have any experience with this library? Given it&amp;#39;s apparent ease of use I&amp;#39;m surprised I haven&amp;#39;t heard of it before. My main question is, if I want to train on my own dataset (as opposed to some dataset available in tf.Datasets) where would I put it in GCP so that my script and tensorflow-cloud can access it? I can&amp;#39;t seem to find any examples of this. Any help would be appreciated. I hope this spurs some discussion around the library as well.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jza9bk,True,,thelolzmaster,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jza9bk/questions_regarding_tensorflowcloud_library/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jza9bk/questions_regarding_tensorflowcloud_library/,22217,1606103403.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?auto=webp&amp;s=4d5a1bb21ed5f31cb2b09131c7146f45f13e70f5', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0398ac5874b2f1e8a61c6d954909270f1d824c46', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=58bade227f9c9c48af41c7c81c107e25be9439e2', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82ead080dd28091a6d58aa160a011a998df385a2', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6fdd49411dff4f78cd65c16702c43aa82a115a2e', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=44564fb4ac8a9f6fb7ffb13eb9f93feca6bc5c18', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/rKwQSTUKiiyFfHQf9sru368PuN1pMMa_ktWN0QF1whg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec940a5dc4e75246c77bd08db87079d4fc1ddb10', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'Rn9pBuZfg6XJuUqs0COAaGseUQyvneGK-SIET5_ye4M'}], 'enabled': False}",,,,,,
486,,tensorflow,"I've created a custom loss function by subclassing from `tf.keras.losses.Loss` and a model using the functional API and specified its outputs to be that of two layers, I need one of them to passed to the loss function and another is the actual output that should print out to the user. Since there are two outputs I pass a list of the same loss when compiling the model and specify the loss weights as `[1.0, 0.0]` because I only care about the loss of one output. When I try the model using one of the basic losses like `categorical_crossentropy` it runs fine. But when I use the loss function I wrote it throws me `TypeError: __init__() takes 1 positional argument but 3 were given`. Furthermore, when building the model, I tried specifying the output to be only one value instead of two, and the same issue arises. [Colab link](https://colab.research.google.com/drive/1nB2kVk_e_Mj3dy8mJ0kka2gHHLUSwiHn?usp=sharing)",t2_10vrhqvg,False,,0,False,Custom loss function always throws: TypeError: __init__() takes 1 positional argument but 3 were given,[],r/tensorflow,False,6,,0,,,False,t3_jz0a91,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1606097401.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve created a custom loss function by subclassing from &lt;code&gt;tf.keras.losses.Loss&lt;/code&gt; and a model using the functional API and specified its outputs to be that of two layers, I need one of them to passed to the loss function and another is the actual output that should print out to the user. Since there are two outputs I pass a list of the same loss when compiling the model and specify the loss weights as &lt;code&gt;[1.0, 0.0]&lt;/code&gt; because I only care about the loss of one output. When I try the model using one of the basic losses like &lt;code&gt;categorical_crossentropy&lt;/code&gt; it runs fine. But when I use the loss function I wrote it throws me &lt;code&gt;TypeError: __init__() takes 1 positional argument but 3 were given&lt;/code&gt;. Furthermore, when building the model, I tried specifying the output to be only one value instead of two, and the same issue arises. &lt;a href=""https://colab.research.google.com/drive/1nB2kVk_e_Mj3dy8mJ0kka2gHHLUSwiHn?usp=sharing""&gt;Colab link&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jz0a91,True,,nopickles_,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jz0a91/custom_loss_function_always_throws_typeerror_init/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jz0a91/custom_loss_function_always_throws_typeerror_init/,22217,1606068601.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?auto=webp&amp;s=ffc13b63083ce9180bdf2cf28705ee407b659975', 'width': 256, 'height': 256}, 'resolutions': [{'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f53340195fae0f84ec3871625087bf02fd428ab', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6722a649351a89204dede7d65ad009eea43566c', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'mAwt5FN14h93icEvsjkWqFiukRT9FqTVVq54ZHDgaos'}], 'enabled': False}",,,,,,True
487,,tensorflow," [GitHub - nianticlabs/monodepth2: \[ICCV 2019\] Monocular depth estimation from a single image](https://github.com/nianticlabs/monodepth2) 

So i came across this cool depth prediction model and want to use it in my project. The problem i have no idea how to load .npy weights file. I also did some research but found nothing. Most of the articles/tutorials i found are for loading training data in numpy format. I also came across this model ( [GitHub - iro-cp/FCRN-DepthPrediction: Deeper Depth Prediction with Fully Convolutional Residual Networks (FCRN)](https://github.com/iro-cp/FCRN-DepthPrediction)). This project has the model available in 2 format .npy and .ckpt. I tried the .ckpt one but it has multiple file  .data-00000-of-00001 .meta .index

Thank you for all of your answer ? Sorry if this question is a bit dumb",t2_6589szyu,False,,0,False,Load a .npy weights file ?,[],r/tensorflow,False,6,,0,,,False,t3_jyu1t3,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1606072442.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/nianticlabs/monodepth2""&gt;GitHub - nianticlabs/monodepth2: [ICCV 2019] Monocular depth estimation from a single image&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;So i came across this cool depth prediction model and want to use it in my project. The problem i have no idea how to load .npy weights file. I also did some research but found nothing. Most of the articles/tutorials i found are for loading training data in numpy format. I also came across this model ( &lt;a href=""https://github.com/iro-cp/FCRN-DepthPrediction""&gt;GitHub - iro-cp/FCRN-DepthPrediction: Deeper Depth Prediction with Fully Convolutional Residual Networks (FCRN)&lt;/a&gt;). This project has the model available in 2 format .npy and .ckpt. I tried the .ckpt one but it has multiple file  .data-00000-of-00001 .meta .index&lt;/p&gt;

&lt;p&gt;Thank you for all of your answer ? Sorry if this question is a bit dumb&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jyu1t3,True,,minhduc66532,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jyu1t3/load_a_npy_weights_file/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jyu1t3/load_a_npy_weights_file/,22217,1606043642.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?auto=webp&amp;s=abc93eeedc0ed49c2771bf2f58c0fcf79ada734a', 'width': 1280, 'height': 634}, 'resolutions': [{'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4be560b323e2cce7ba9dafaae50fb7c29cd2a8b', 'width': 108, 'height': 53}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e996679901e3ab0d3673c99dc844fe13ad0d4e6', 'width': 216, 'height': 106}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9528a686214c2eae956c62b30dc52b58f38f0cd1', 'width': 320, 'height': 158}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c19a17dbc4828ba2934003595e7857e1426a1f', 'width': 640, 'height': 317}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e690f4ac23efd57d0a6fdd6375354b15640b73e', 'width': 960, 'height': 475}, {'url': 'https://external-preview.redd.it/yUfVDCsKSYH2_LKrKwLkV0e2ImwITbAZLPQtOneWcaQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0f5f427a28bed8cc07ecb86f18cd8da6f4593e30', 'width': 1080, 'height': 534}], 'variants': {}, 'id': 'wkYq3rBNvyC9-YlP6XihsokEGDrfVDvA5OnO0wKk3Zs'}], 'enabled': False}",,,,,,
488,,tensorflow,"TensorFlow 2 offers best-in-class training performance on various platforms, devices, and hardware. This empowers researchers and professionals to work on their favored platform. TensorFlow users on Intel Macs or Macs powered by Apple’s new M1 chip can now benefit from accelerated training using Apple’s [Mac-optimized version of TensorFlow 2.4](https://github.com/apple/tensorflow_macos) and the new machine learning (ML) Compute framework. Tensor’s ability to support high-performance machine learning execution on Apple hardware has been enhanced with these improvements and Apple developers’ ability to execute TensorFlow on iOS through [TensorFlow Lite](https://www.tensorflow.org/lite).

### Training performance on the Mac with ML Compute framework

The Mac has been prominent among developers and researchers. Formerly, TensorFlow has only used the CPU for training on Mac. The new updated version of Mac contains the new [M1 chip](https://www.apple.com/mac/m1/). Apple’s Mac-optimized version of TensorFlow 2.4 leverages Mac’s full power with a significant performance improvement. 

Summary: [https://www.marktechpost.com/2020/11/21/leveraging-ml-compute-framework-for-accelerated-tensorflow-performance-on-mac/](https://www.marktechpost.com/2020/11/21/leveraging-ml-compute-framework-for-accelerated-tensorflow-performance-on-mac/)

Github: [https://github.com/apple/tensorflow\_macos](https://github.com/apple/tensorflow_macos) 

&amp;#x200B;

https://preview.redd.it/w8awit6b4o061.jpg?width=980&amp;format=pjpg&amp;auto=webp&amp;s=ae3a3063061b8a9a73a45d8ec92b49028b546c43",t2_2wsvqwhg,False,,0,False,Leveraging ML Compute Framework For Accelerated TensorFlow Performance On Mac,[],r/tensorflow,False,6,,0,90.0,,False,t3_jyjsud,False,dark,0.81,,public,13,0,{},140.0,,False,[],,False,False,,{},Discussion,False,13,,False,https://b.thumbs.redditmedia.com/mEHoA1ru5ZMYckNV9YWkDBNYN4BvUX3luYittjFbAqc.jpg,False,,[],{},,True,,1606025902.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TensorFlow 2 offers best-in-class training performance on various platforms, devices, and hardware. This empowers researchers and professionals to work on their favored platform. TensorFlow users on Intel Macs or Macs powered by Apple’s new M1 chip can now benefit from accelerated training using Apple’s &lt;a href=""https://github.com/apple/tensorflow_macos""&gt;Mac-optimized version of TensorFlow 2.4&lt;/a&gt; and the new machine learning (ML) Compute framework. Tensor’s ability to support high-performance machine learning execution on Apple hardware has been enhanced with these improvements and Apple developers’ ability to execute TensorFlow on iOS through &lt;a href=""https://www.tensorflow.org/lite""&gt;TensorFlow Lite&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Training performance on the Mac with ML Compute framework&lt;/h3&gt;

&lt;p&gt;The Mac has been prominent among developers and researchers. Formerly, TensorFlow has only used the CPU for training on Mac. The new updated version of Mac contains the new &lt;a href=""https://www.apple.com/mac/m1/""&gt;M1 chip&lt;/a&gt;. Apple’s Mac-optimized version of TensorFlow 2.4 leverages Mac’s full power with a significant performance improvement. &lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/11/21/leveraging-ml-compute-framework-for-accelerated-tensorflow-performance-on-mac/""&gt;https://www.marktechpost.com/2020/11/21/leveraging-ml-compute-framework-for-accelerated-tensorflow-performance-on-mac/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/apple/tensorflow_macos""&gt;https://github.com/apple/tensorflow_macos&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/w8awit6b4o061.jpg?width=980&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ae3a3063061b8a9a73a45d8ec92b49028b546c43""&gt;https://preview.redd.it/w8awit6b4o061.jpg?width=980&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ae3a3063061b8a9a73a45d8ec92b49028b546c43&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jyjsud,True,,ai-lover,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jyjsud/leveraging_ml_compute_framework_for_accelerated/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jyjsud/leveraging_ml_compute_framework_for_accelerated/,22217,1605997102.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/gRhLuVcYhgROsT8QJghgNkRNjX_4muhXkECZBd_DvRE.jpg?auto=webp&amp;s=1e697b7c19cbf102c3b9e95c423ac9472baeb4fa', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/gRhLuVcYhgROsT8QJghgNkRNjX_4muhXkECZBd_DvRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bea3d48225506bc547af59817e0e3803f9e5e01d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/gRhLuVcYhgROsT8QJghgNkRNjX_4muhXkECZBd_DvRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=740538c867bfcd4df7c87f601d5a6b21c567365d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/gRhLuVcYhgROsT8QJghgNkRNjX_4muhXkECZBd_DvRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba766c2bf70d9668c7478caacd93491f3abf41fb', 'width': 320, 'height': 320}], 'variants': {}, 'id': 's7IcdpD5AY9pVJYUb4mhT4BMzKhtjXok2c1miMKtVdI'}], 'enabled': False}",,"{'w8awit6b4o061': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 69, 'x': 108, 'u': 'https://preview.redd.it/w8awit6b4o061.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbd4c45229f0b942ec9085b2e1a5a6289818dfc4'}, {'y': 138, 'x': 216, 'u': 'https://preview.redd.it/w8awit6b4o061.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7b8c8bc53d63eef92521410956bde5a08e1a49ea'}, {'y': 205, 'x': 320, 'u': 'https://preview.redd.it/w8awit6b4o061.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1137e5b9d10a4d5b765cc52062787e6a45c1ee6'}, {'y': 411, 'x': 640, 'u': 'https://preview.redd.it/w8awit6b4o061.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b166e373365207b80ac937f4f81badcb28f88c7b'}, {'y': 617, 'x': 960, 'u': 'https://preview.redd.it/w8awit6b4o061.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=48c01c2a228a6f33d2e5c1c7c56ea74b9801807c'}], 's': {'y': 630, 'x': 980, 'u': 'https://preview.redd.it/w8awit6b4o061.jpg?width=980&amp;format=pjpg&amp;auto=webp&amp;s=ae3a3063061b8a9a73a45d8ec92b49028b546c43'}, 'id': 'w8awit6b4o061'}}",,,,
489,,tensorflow,"&amp;#x200B;

[Error](https://preview.redd.it/vjvnh8noxq061.png?width=1920&amp;format=png&amp;auto=webp&amp;s=7e9e3c82db8575587272529b310aa1275c946cd6)

Hi, I've been trying to convert a keras model to a tflite model on google colabs.

However the runtime crashes after a little while saying that the RAM is not enough.I also tried using GPU and also tf-nightly with no success.Tried everything suggested in other threads as well.Has anyone faced this before?Any workaround?

Also if  its a memory issue that can't be fixed without expanding the ram, is there any way I could make my keras model smaller?

Any help with this is highly appreciated.Thanks in advance.",t2_5zc2v54r,False,,0,False,Colabs crashing when trying to convert keras model to tflite,[],r/tensorflow,False,6,,0,62.0,,False,t3_jyrxn6,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/YeambH77JeAZmeKmzkvD3wU7GZFaR1kbVURyoMzMrIY.jpg,False,,[],{},,True,,1606059998.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/vjvnh8noxq061.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7e9e3c82db8575587272529b310aa1275c946cd6""&gt;Error&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hi, I&amp;#39;ve been trying to convert a keras model to a tflite model on google colabs.&lt;/p&gt;

&lt;p&gt;However the runtime crashes after a little while saying that the RAM is not enough.I also tried using GPU and also tf-nightly with no success.Tried everything suggested in other threads as well.Has anyone faced this before?Any workaround?&lt;/p&gt;

&lt;p&gt;Also if  its a memory issue that can&amp;#39;t be fixed without expanding the ram, is there any way I could make my keras model smaller?&lt;/p&gt;

&lt;p&gt;Any help with this is highly appreciated.Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jyrxn6,True,,Ill-Quantity-4933,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jyrxn6/colabs_crashing_when_trying_to_convert_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jyrxn6/colabs_crashing_when_trying_to_convert_keras/,22217,1606031198.0,0,,False,,,,,"{'vjvnh8noxq061': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 48, 'x': 108, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=803d6172bf121114bb0ddd45d7b67c2a8551a9b1'}, {'y': 96, 'x': 216, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9da6313c107bd29aa8a60836dfb3c1a9a14673d5'}, {'y': 142, 'x': 320, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=050deef3ad092d34f9cc739d9e377ce53a970675'}, {'y': 285, 'x': 640, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2a03d4552a56aecebf2500926619dcb6cba44846'}, {'y': 428, 'x': 960, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=13467b59a0d3988d4c1a3ee7b36d2895db4aea22'}, {'y': 481, 'x': 1080, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14e2cc7289ff810de4344cfe59fc9fb8fc901317'}], 's': {'y': 856, 'x': 1920, 'u': 'https://preview.redd.it/vjvnh8noxq061.png?width=1920&amp;format=png&amp;auto=webp&amp;s=7e9e3c82db8575587272529b310aa1275c946cd6'}, 'id': 'vjvnh8noxq061'}}",,,,
490,,tensorflow,"I'm trying to run a simple neural net on 3 (up to 8) cluster nodes with 1 GPU each. For some reason, my code stops (or just waits, idk I let it run for over an hour) and does nothing before printing the first epoch. I'm using Tensorflow 2.0 and Keras.

I've posted my code and question to SO, if anyone could help out, that would be greatly appreciated.

Code and full question: [https://stackoverflow.com/q/64949605/9570045?sem=2](https://stackoverflow.com/q/64949605/9570045?sem=2)",t2_27nx9ak0,False,,0,False,Trouble with MultiWorkerMirroredStrategy,[],r/tensorflow,False,6,,0,,,False,t3_jymf71,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1606035407.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to run a simple neural net on 3 (up to 8) cluster nodes with 1 GPU each. For some reason, my code stops (or just waits, idk I let it run for over an hour) and does nothing before printing the first epoch. I&amp;#39;m using Tensorflow 2.0 and Keras.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve posted my code and question to SO, if anyone could help out, that would be greatly appreciated.&lt;/p&gt;

&lt;p&gt;Code and full question: &lt;a href=""https://stackoverflow.com/q/64949605/9570045?sem=2""&gt;https://stackoverflow.com/q/64949605/9570045?sem=2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jymf71,True,,quelam_,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jymf71/trouble_with_multiworkermirroredstrategy/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jymf71/trouble_with_multiworkermirroredstrategy/,22217,1606006607.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
491,,tensorflow,I've spent a tremendous amount of time trying to understand and build this architecture in Keras. I have colleagues and we're trying to run an experiment with different sizes of the Resnet architecture but Keras/TF doesn't have the ones we need built in. Would anyone know a useful open-source repository or guide that can help expedite this search?,t2_2wlufzwf,False,,0,False,"Trouble building Resnet-44, can anyone recommend a source?",[],r/tensorflow,False,6,,0,,,False,t3_jye69n,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1606006877.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve spent a tremendous amount of time trying to understand and build this architecture in Keras. I have colleagues and we&amp;#39;re trying to run an experiment with different sizes of the Resnet architecture but Keras/TF doesn&amp;#39;t have the ones we need built in. Would anyone know a useful open-source repository or guide that can help expedite this search?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jye69n,True,,PictoChris,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jye69n/trouble_building_resnet44_can_anyone_recommend_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jye69n/trouble_building_resnet44_can_anyone_recommend_a/,22217,1605978077.0,0,,False,,,,,,,,,
492,,tensorflow,"Stackoverflow: https://stackoverflow.com/questions/64941304/unable-to-give-keras-neural-network-multiple-inputs

So I set up a complete data pipeline to feed into the neural net, but it keeps throwing this error

 TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset\_ops.\_NestedVariant'&gt; to Tensor. Contents: &lt;tensorflow.python.data.ops.dataset\_ops.\_NestedVariant object at 0x7f9b0eefff60&gt;. Consider casting elements to a supported type. 

Have tried doing everything I can. If anyone can help, I am willing to share the Colab with them to debug",,False,,0,False,Can someone please help me debug this piece of code for a NLP project,[],r/tensorflow,False,6,,0,,,False,t3_jy6t81,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,,self,1605954092.0,,,{},,True,,1605972481.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Stackoverflow: &lt;a href=""https://stackoverflow.com/questions/64941304/unable-to-give-keras-neural-network-multiple-inputs""&gt;https://stackoverflow.com/questions/64941304/unable-to-give-keras-neural-network-multiple-inputs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So I set up a complete data pipeline to feed into the neural net, but it keeps throwing this error&lt;/p&gt;

&lt;p&gt;TypeError: Failed to convert object of type &amp;lt;class &amp;#39;tensorflow.python.data.ops.dataset\_ops.\_NestedVariant&amp;#39;&amp;gt; to Tensor. Contents: &amp;lt;tensorflow.python.data.ops.dataset\_ops.\_NestedVariant object at 0x7f9b0eefff60&amp;gt;. Consider casting elements to a supported type. &lt;/p&gt;

&lt;p&gt;Have tried doing everything I can. If anyone can help, I am willing to share the Colab with them to debug&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jy6t81,True,,[deleted],,4,True,all_ads,False,[],,dark,/r/tensorflow/comments/jy6t81/can_someone_please_help_me_debug_this_piece_of/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jy6t81/can_someone_please_help_me_debug_this_piece_of/,22217,1605943681.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
493,,tensorflow,"I ussually do it either using tf.data.Dataset.from\_tensor\_slices or just splitting using numpy.split, or even slicing the a la python! But maybe there's something cooler I'm not aware! Importantly, I frequently use a custrom training\_step, hence avoid using [model.fit](https://model.fit)

&amp;#x200B;

Muchas gracias amigos !",t2_617u1lh9,False,,0,False,Training on TensorFlow: how do you split your numpy-array(ed) dataset to feed into your TensorFlow Model?,[],r/tensorflow,False,6,,0,,,False,t3_jyccqm,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1606000574.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I ussually do it either using tf.data.Dataset.from_tensor_slices or just splitting using numpy.split, or even slicing the a la python! But maybe there&amp;#39;s something cooler I&amp;#39;m not aware! Importantly, I frequently use a custrom training_step, hence avoid using &lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Muchas gracias amigos !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jyccqm,True,,matibilkis,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jyccqm/training_on_tensorflow_how_do_you_split_your/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jyccqm/training_on_tensorflow_how_do_you_split_your/,22217,1605971774.0,0,,False,,,,,,,,,
494,,tensorflow,"Hello here, 

I am looking for some help to implement multi worker or mirrored strategy on this notebook 

[https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan\_overriding\_train\_step.ipynb#scrollTo=8\_b88\_bRo7Ca](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb#scrollTo=8_b88_bRo7Ca)

while keeping the custom train\_set and [model.fit](https://model.fit) functionalities",t2_11cnwe,False,,0,False,Distribute training,[],r/tensorflow,False,6,,0,,,False,t3_jyawas,False,dark,1.0,,public,1,1,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{'gid_1': 1},,True,,1605994841.0,text,6,,,text,self.tensorflow,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello here, &lt;/p&gt;

&lt;p&gt;I am looking for some help to implement multi worker or mirrored strategy on this notebook &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb#scrollTo=8_b88_bRo7Ca""&gt;https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb#scrollTo=8_b88_bRo7Ca&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;while keeping the custom train_set and &lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt; functionalities&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jyawas,True,,DNA1987,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jyawas/distribute_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jyawas/distribute_training/,22217,1605966041.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?auto=webp&amp;s=ffc13b63083ce9180bdf2cf28705ee407b659975', 'width': 256, 'height': 256}, 'resolutions': [{'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f53340195fae0f84ec3871625087bf02fd428ab', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6722a649351a89204dede7d65ad009eea43566c', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'mAwt5FN14h93icEvsjkWqFiukRT9FqTVVq54ZHDgaos'}], 'enabled': False}",,,,,,
495,,tensorflow,"Do something. Throws an error. You don't know why it's happening, and watching 23 exceptions unfurl at once isn't pleasant. Change something. Nothing happens.

Am I the only one?",,False,,0,False,Is it just me or is debugging Tensorflow seriously hard?,[],r/tensorflow,False,6,,0,,,False,t3_jxvlcj,False,dark,0.95,,public,20,0,{},,,False,[],,False,False,,{},Discussion,False,20,,,self,False,,,{},,True,,1605928977.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do something. Throws an error. You don&amp;#39;t know why it&amp;#39;s happening, and watching 23 exceptions unfurl at once isn&amp;#39;t pleasant. Change something. Nothing happens.&lt;/p&gt;

&lt;p&gt;Am I the only one?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jxvlcj,True,,[deleted],,14,True,all_ads,False,[],,dark,/r/tensorflow/comments/jxvlcj/is_it_just_me_or_is_debugging_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jxvlcj/is_it_just_me_or_is_debugging_tensorflow/,22217,1605900177.0,0,,False,,,,,,,,,
496,,tensorflow,"&amp;#x200B;

https://preview.redd.it/mx4qpvbqbi061.png?width=1920&amp;format=png&amp;auto=webp&amp;s=dceb7f9ed3861b755ee36c9ab3486f56342280e0",t2_128ob4,False,,0,False,U-Net model showing 99% accuracy but not segmenting anything in the test data,[],r/tensorflow,False,6,,0,78.0,,False,t3_jy36rn,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://a.thumbs.redditmedia.com/brpTd2oYsdwW12IJhnYvDP1WwkulcIT00x76ywEh4R0.jpg,False,,[],{},,True,,1605955780.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/mx4qpvbqbi061.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dceb7f9ed3861b755ee36c9ab3486f56342280e0""&gt;https://preview.redd.it/mx4qpvbqbi061.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dceb7f9ed3861b755ee36c9ab3486f56342280e0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jy36rn,True,,darvidas,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jy36rn/unet_model_showing_99_accuracy_but_not_segmenting/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jy36rn/unet_model_showing_99_accuracy_but_not_segmenting/,22217,1605926980.0,0,,False,,,,,"{'mx4qpvbqbi061': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5031075013f08a3096a9e1e7587c4251d6de0e5'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0199b59ce9f1382d189994c443c62126ea6a0504'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e2cb803bc8d025d78bb06fe1c88cd8471ef8ef0d'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5ba15de1cefa2e9efc914c8fe34145ca8c86585'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f99a7e8785c53588ee1368ce8d1075aecc83e354'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=207d5c63691c20eedff911c8f4cf3dd20bd135d8'}], 's': {'y': 1080, 'x': 1920, 'u': 'https://preview.redd.it/mx4qpvbqbi061.png?width=1920&amp;format=png&amp;auto=webp&amp;s=dceb7f9ed3861b755ee36c9ab3486f56342280e0'}, 'id': 'mx4qpvbqbi061'}}",,,,
497,,tensorflow,"In my new video, I discuss the approaches and Deep Learning models used to generate sound. I also outline the challenges encountered with different methods, and discuss the features used to train generative sound systems. 

By the end of this video you’ll have an understanding of the sound generation task, and will be able to classify different types of sound generation systems.

This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖

Here’s the video:

[https://www.youtube.com/watch?v=pwV8K9wXY2E&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=2](https://www.youtube.com/watch?v=pwV8K9wXY2E&amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;index=2)",t2_12ahau,False,,0,False,I published a video where I introduce the sound generation task with deep learning 🎧 🤖,[],r/tensorflow,False,6,,0,,,False,t3_jxn54s,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},Project,False,8,,False,self,False,,[],{},,True,,1605899162.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new video, I discuss the approaches and Deep Learning models used to generate sound. I also outline the challenges encountered with different methods, and discuss the features used to train generative sound systems. &lt;/p&gt;

&lt;p&gt;By the end of this video you’ll have an understanding of the sound generation task, and will be able to classify different types of sound generation systems.&lt;/p&gt;

&lt;p&gt;This video is part of  a series called “Generating Sound with Neural Networks”. In this series, you’ll learn how to generate sound from audio files 🎧 🎧 using Variational Autoencoders 🤖 🤖&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=pwV8K9wXY2E&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=2""&gt;https://www.youtube.com/watch?v=pwV8K9wXY2E&amp;amp;list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&amp;amp;index=2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jxn54s,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jxn54s/i_published_a_video_where_i_introduce_the_sound/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jxn54s/i_published_a_video_where_i_introduce_the_sound/,22217,1605870362.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/EvNggZG_Ro3-65utiNF04aXXLVwdwH7cypzPZrB2GWY.jpg?auto=webp&amp;s=64eccbd84739526c7e099736059864c5ed141832', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/EvNggZG_Ro3-65utiNF04aXXLVwdwH7cypzPZrB2GWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c50d8b7bed67ab0b089171f511995e2b9f2305be', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/EvNggZG_Ro3-65utiNF04aXXLVwdwH7cypzPZrB2GWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0ecb981fe665fc16535bbe26f90b0a0274dd7da', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/EvNggZG_Ro3-65utiNF04aXXLVwdwH7cypzPZrB2GWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=884993ce27d15a9956439c7609d9ee70593ddf40', 'width': 320, 'height': 240}], 'variants': {}, 'id': '-pgsnUJNUy4NDkXA7xkQ4LztP792-qfqNJtHLxLWVz8'}], 'enabled': False}",,,,,,
498,,tensorflow,"Hi, 

I'm trying to import the Tensorflow source to VS Code, but i can't get the IntelliSense features to work. Is there a Tutorial available ? I'm basically just looking for a way to conviniently analyze the code, (no need for building it)

Thanks in advance",t2_2aj7hvxe,False,,0,False,Tensorflow Source IntelliSense,[],r/tensorflow,False,6,,0,,,False,t3_jxrimj,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605916436.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, &lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to import the Tensorflow source to VS Code, but i can&amp;#39;t get the IntelliSense features to work. Is there a Tutorial available ? I&amp;#39;m basically just looking for a way to conviniently analyze the code, (no need for building it)&lt;/p&gt;

&lt;p&gt;Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jxrimj,True,,harry_toft,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jxrimj/tensorflow_source_intellisense/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jxrimj/tensorflow_source_intellisense/,22217,1605887636.0,0,,False,,,,,,,,,
499,,tensorflow,"Hello everyone  


Just installed bitGym nice app that using phone camera and try to determin your speen while you run on treadmill  by your movements.  


And got interested if I can implement this in Javascript using some existing TS model  


I look throught models on TS site but didn't think they are good.  


Any thoughts how bitGym did that?  


Thank you in advance",t2_3pgdpyoe,False,,0,False,Using a smartPhone camera to analyze person movements model,[],r/tensorflow,False,6,,0,,,False,t3_jxlbgc,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1605889031.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone  &lt;/p&gt;

&lt;p&gt;Just installed bitGym nice app that using phone camera and try to determin your speen while you run on treadmill  by your movements.  &lt;/p&gt;

&lt;p&gt;And got interested if I can implement this in Javascript using some existing TS model  &lt;/p&gt;

&lt;p&gt;I look throught models on TS site but didn&amp;#39;t think they are good.  &lt;/p&gt;

&lt;p&gt;Any thoughts how bitGym did that?  &lt;/p&gt;

&lt;p&gt;Thank you in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jxlbgc,True,,OleksandrPoshtaruk,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jxlbgc/using_a_smartphone_camera_to_analyze_person/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jxlbgc/using_a_smartphone_camera_to_analyze_person/,22217,1605860231.0,0,,False,,,,,,,,,
500,,tensorflow,"Hello.

Please can someone help me to understand where is my error?

I am just studying the tensorflowlite on android for text classification. 

My code goes in this exception when try to create a new TextClassificationV2 instance:

&gt;**model = TextClassificationV2.newInstance(application.applicationContext)**  
&gt;  
&gt;**java.lang.IllegalArgumentException: Destination type INT32 is not supported.**

***This this my configuration:***

* *Android Studio 4.1.1*
* *Gradle plugin 4.1.1*
* *Gradle 6.5*
* *Dependencies ( added automatically)*
   * *implementation 'org.tensorflow:tensorflow-lite-support:0.1.0-rc1'*
   * *implementation 'org.tensorflow:tensorflow-lite-metadata:0.1.0-rc1'*",t2_5i17ircv,False,,0,False,TensorflowLite on Android : Destination type INT32 is not supported Exception,[],r/tensorflow,False,6,,0,,,False,t3_jxmdmf,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1605895022.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello.&lt;/p&gt;

&lt;p&gt;Please can someone help me to understand where is my error?&lt;/p&gt;

&lt;p&gt;I am just studying the tensorflowlite on android for text classification. &lt;/p&gt;

&lt;p&gt;My code goes in this exception when try to create a new TextClassificationV2 instance:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;model = TextClassificationV2.newInstance(application.applicationContext)&lt;/strong&gt;  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;java.lang.IllegalArgumentException: Destination type INT32 is not supported.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;This this my configuration:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Android Studio 4.1.1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Gradle plugin 4.1.1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Gradle 6.5&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Dependencies ( added automatically)&lt;/em&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;implementation &amp;#39;org.tensorflow:tensorflow-lite-support:0.1.0-rc1&amp;#39;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;implementation &amp;#39;org.tensorflow:tensorflow-lite-metadata:0.1.0-rc1&amp;#39;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jxmdmf,True,,i_cook_bits,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jxmdmf/tensorflowlite_on_android_destination_type_int32/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jxmdmf/tensorflowlite_on_android_destination_type_int32/,22217,1605866222.0,0,,False,,,,,,,,,
501,,tensorflow,"A year ago, TensorFlow open-sourced a platform that enables sliced evaluation of machine learning (ML) model performance, called [Fairness Indicators](https://www.tensorflow.org/responsible_ai/fairness_indicators/guide). Response evaluation is a first step toward avoiding bias and allowing the company to determine how the models work for various users. Identifying that their model underperforms on specific slices of data, there was a need for the TensorFlow team to come up with some strategy to mitigate this to avoid creating or reinforcing unfair bias, in line with [Google’s AI Principles](https://ai.google/principles/).

A few days back, TensorFlow announced a technique for addressing unfair bias in machine learning (ML) models, known as [MinDiff](https://www.tensorflow.org/responsible_ai/model_remediation/). MinDiff works with given slices of data by penalizing the model for differences in scores between the sets. While training the model, it will try to minimize the penalty by bringing the distributions closer together. MinDiff is the first step towards a more extensive Model Remediation Library of techniques suitable for different use cases. 

**Summary:** [https://www.marktechpost.com/2020/11/19/tensorflow-releases-mindiff-a-technique-for-addressing-unfair-bias-in-machine-learning-models/](https://www.marktechpost.com/2020/11/19/tensorflow-releases-mindiff-a-technique-for-addressing-unfair-bias-in-machine-learning-models/)

**Source:** [https://blog.tensorflow.org/2020/11/applying-mindiff-to-improve-model.html](https://blog.tensorflow.org/2020/11/applying-mindiff-to-improve-model.html) 

**Reference:** https://ai.googleblog.com/2020/11/mitigating-unfair-bias-in-ml-models.html

**Model Remediation Case Study:** [https://github.com/tensorflow/model-remediation/blob/master/docs/min\_diff/tutorials/min\_diff\_keras.ipynb](https://github.com/tensorflow/model-remediation/blob/master/docs/min_diff/tutorials/min_diff_keras.ipynb)",t2_2wsvqwhg,False,,0,False,TensorFlow Releases MinDiff: A Technique For Addressing Unfair Bias In Machine Learning Models,[],r/tensorflow,False,6,,0,,,False,t3_jx5mm4,False,dark,0.94,,public,15,0,{},,,False,[],,False,False,,{},Discussion,False,15,,False,self,False,,[],{},,True,,1605831478.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A year ago, TensorFlow open-sourced a platform that enables sliced evaluation of machine learning (ML) model performance, called &lt;a href=""https://www.tensorflow.org/responsible_ai/fairness_indicators/guide""&gt;Fairness Indicators&lt;/a&gt;. Response evaluation is a first step toward avoiding bias and allowing the company to determine how the models work for various users. Identifying that their model underperforms on specific slices of data, there was a need for the TensorFlow team to come up with some strategy to mitigate this to avoid creating or reinforcing unfair bias, in line with &lt;a href=""https://ai.google/principles/""&gt;Google’s AI Principles&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A few days back, TensorFlow announced a technique for addressing unfair bias in machine learning (ML) models, known as &lt;a href=""https://www.tensorflow.org/responsible_ai/model_remediation/""&gt;MinDiff&lt;/a&gt;. MinDiff works with given slices of data by penalizing the model for differences in scores between the sets. While training the model, it will try to minimize the penalty by bringing the distributions closer together. MinDiff is the first step towards a more extensive Model Remediation Library of techniques suitable for different use cases. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Summary:&lt;/strong&gt; &lt;a href=""https://www.marktechpost.com/2020/11/19/tensorflow-releases-mindiff-a-technique-for-addressing-unfair-bias-in-machine-learning-models/""&gt;https://www.marktechpost.com/2020/11/19/tensorflow-releases-mindiff-a-technique-for-addressing-unfair-bias-in-machine-learning-models/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href=""https://blog.tensorflow.org/2020/11/applying-mindiff-to-improve-model.html""&gt;https://blog.tensorflow.org/2020/11/applying-mindiff-to-improve-model.html&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt; &lt;a href=""https://ai.googleblog.com/2020/11/mitigating-unfair-bias-in-ml-models.html""&gt;https://ai.googleblog.com/2020/11/mitigating-unfair-bias-in-ml-models.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model Remediation Case Study:&lt;/strong&gt; &lt;a href=""https://github.com/tensorflow/model-remediation/blob/master/docs/min_diff/tutorials/min_diff_keras.ipynb""&gt;https://github.com/tensorflow/model-remediation/blob/master/docs/min_diff/tutorials/min_diff_keras.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jx5mm4,True,,ai-lover,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jx5mm4/tensorflow_releases_mindiff_a_technique_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jx5mm4/tensorflow_releases_mindiff_a_technique_for/,22217,1605802678.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?auto=webp&amp;s=f4748f932a1706799375896fa13c11e9ac0f2c23', 'width': 1244, 'height': 700}, 'resolutions': [{'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6157c9e31cb4445102f06e85c708fd533c94c655', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=58534e8319683bf956857b85790ad984e2e7a291', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=70739405cda17f1d4e58bdbbc337384ce063db19', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a25cf232ab265559e41da4569aa49f432233754d', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f80e8b2293b3e4f5ee8e1a53d6139aeb8a526bf0', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/U49Lgsogn-1inaYFJS6rygMzq0Xq5Wptiqhmnmz8J9Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cdc6fa0218be3275f4d73c23ad0ac04ca86e47f', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'VzvfbH38RV1ZjuO0bQYax7gDFUICD8hOry_zCRZdLcg'}], 'enabled': False}",,,,,,
502,,tensorflow,"Hey there,

I've been working on a concept that allows you to upload your ML models (Tensorflow, Pytorch, etc) and turn them into sharable web apps super quickly, without writing code (for the deployment/ UI part at least).

Here's the landing page I threw together for a more in-depth description of what I'm imagining it could look like: [https://www.getaiko.com/](https://www.getaiko.com/)

Looking for feedback on the concept - wondering if you would find this useful if it existed?",t2_gmwuj,False,,0,False,ML tool idea - looking for feedback/ want to hear about your experiences,[],r/tensorflow,False,6,,0,,,False,t3_jx8056,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Project,False,5,,False,self,False,,[],{},,True,,1605838679.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been working on a concept that allows you to upload your ML models (Tensorflow, Pytorch, etc) and turn them into sharable web apps super quickly, without writing code (for the deployment/ UI part at least).&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s the landing page I threw together for a more in-depth description of what I&amp;#39;m imagining it could look like: &lt;a href=""https://www.getaiko.com/""&gt;https://www.getaiko.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Looking for feedback on the concept - wondering if you would find this useful if it existed?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jx8056,True,,BillCrum,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jx8056/ml_tool_idea_looking_for_feedback_want_to_hear/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jx8056/ml_tool_idea_looking_for_feedback_want_to_hear/,22217,1605809879.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?auto=webp&amp;s=1e7635e7154f5f207d6ebcfb7e6270d013600ade', 'width': 2732, 'height': 1566}, 'resolutions': [{'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bf839fa2aae81a3b393baaf389710976dd0879d', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c5e49c655af057f7c1f28e38f1067f080c66acb', 'width': 216, 'height': 123}, {'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=871f558d804628c156dc78629a3d461934ce2528', 'width': 320, 'height': 183}, {'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31517e27af6fbefd593a5982ed58415fc5d1dcfe', 'width': 640, 'height': 366}, {'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a255426981646fe1bd71ee58ba311f4fda25a154', 'width': 960, 'height': 550}, {'url': 'https://external-preview.redd.it/4fUh-EzSbL1yhOdtEEWX2S40e4dFR6IiSMfdKMPP7og.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14b42403636e1a21e4bd4036d66cf556fc7f0d58', 'width': 1080, 'height': 619}], 'variants': {}, 'id': 'I6mP4-ETJQSAvUhl9uzx0lvHNypGoFtEGt-NtcXsxu4'}], 'enabled': False}",,,,,,
503,,tensorflow,TF on Apple M1: [https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html](https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html),t2_kavrn0,False,,0,False,TF on Apple M1,[],r/tensorflow,False,6,,0,,,False,t3_jwpg7j,False,dark,0.9,,public,23,0,{},,,False,[],,False,False,,{},,False,23,,False,self,False,,[],{},,True,,1605765543.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TF on Apple M1: &lt;a href=""https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html""&gt;https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jwpg7j,True,,ebarsoum,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/jwpg7j/tf_on_apple_m1/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jwpg7j/tf_on_apple_m1/,22217,1605736743.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?auto=webp&amp;s=f7bb2daf94a2abea8cb060d9412b3b4350474699', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2babdda596e56a9d44cea06ad0069d9b18736a3b', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe8d9f8ce27bed37952f8cb7fa13b50676bf4d56', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07d4a77549b54ec05f9d63c267893790c6d64d04', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cbe98b9889dde3c76634bd3b508397fbdcf0edfe', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0346437cdf710b55af497bc1c10dce975a0d2dcd', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/liqXcwxVckiULNzO1RLprAHYXy9rRnWXZhCRBS94Xik.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1d75312e8474f74eb818507855eca4ff3a7c54f4', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'V-pqSudxO5ebWP6cywAHz3ZuyYwvIbje5vFxseUZ1LU'}], 'enabled': False}",,,,,,
504,,tensorflow,"I am trying to make an estimation how fast my model will be in production when moving from my desktop PC to a server.

The way I see this determining FLOPS for the model in use would be a good starting point. But I can't find a way to profile this. There are packages that calculate FLOPS for [Keras models](https://pypi.org/project/keras-flops/). Is there a way to convert a model I downloaded from the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) to a Keras model?

Or is there a better way to estimate model performance all together? The model zoo lists performance in milliseconds, yet I don't see what system these values come from.",t2_5qz5k,False,,0,False,Profiling an Model from the Object Detection Api,[],r/tensorflow,False,6,,0,,,False,t3_jx1lt2,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605816719.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to make an estimation how fast my model will be in production when moving from my desktop PC to a server.&lt;/p&gt;

&lt;p&gt;The way I see this determining FLOPS for the model in use would be a good starting point. But I can&amp;#39;t find a way to profile this. There are packages that calculate FLOPS for &lt;a href=""https://pypi.org/project/keras-flops/""&gt;Keras models&lt;/a&gt;. Is there a way to convert a model I downloaded from the &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md""&gt;model zoo&lt;/a&gt; to a Keras model?&lt;/p&gt;

&lt;p&gt;Or is there a better way to estimate model performance all together? The model zoo lists performance in milliseconds, yet I don&amp;#39;t see what system these values come from.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jx1lt2,True,,maechtigerAal,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jx1lt2/profiling_an_model_from_the_object_detection_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jx1lt2/profiling_an_model_from_the_object_detection_api/,22217,1605787919.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/p3HQXQzdkmyXyJ89enL6PkgmSdstFY5z1QkzOzRNUaU.jpg?auto=webp&amp;s=01b29ed2d2e90d072e1fc7295da2c1cb3797f686', 'width': 300, 'height': 300}, 'resolutions': [{'url': 'https://external-preview.redd.it/p3HQXQzdkmyXyJ89enL6PkgmSdstFY5z1QkzOzRNUaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54fdfef1cb192ed04e4ba25828970287fc1ecde9', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/p3HQXQzdkmyXyJ89enL6PkgmSdstFY5z1QkzOzRNUaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=22ff535b36cf2b9412be48a21108ba34479e2ba5', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'POVR4AtJHvry29k6WQQwgYhMSdLrOeYwBodMqA6lPGk'}], 'enabled': False}",,,,,,
505,,tensorflow,,t2_6fgqhah1,False,,0,False,Accuracy killed when using ImageDataGenerator TensorFlow Keras,[],r/tensorflow,False,6,,0,140.0,,False,t3_jx0xqw,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/a3d2-ersdUM6sc8yybvDL9_hAe-J4wzM5JBCnvpMcRs.jpg,False,,[],{},,False,,1605813410.0,text,6,,,text,stackoverflow.com,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jx0xqw,True,,jebeszivot,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jx0xqw/accuracy_killed_when_using_imagedatagenerator/,all_ads,False,https://stackoverflow.com/questions/64910527/accuracy-killed-when-using-imagedatagenerator-tensorflow-keras,22217,1605784610.0,0,,False,link,https://stackoverflow.com/questions/64910527/accuracy-killed-when-using-imagedatagenerator-tensorflow-keras,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
506,,tensorflow,"Currently doing the deeplearning.ai specialization on coursera with Andrew ng. Where he essentially starts with the basics of neural networks from scratch in numpy, and moves to more advanced topics. I was going to apply these skills when doing the tensorflow developer specialization course but realized that today a new advanced tensorflow specialization released. It seems to me the tensorflow developer specialization really focuses on the sequential api, and the new one has its first two courses (other two don’t come until dec and Jan) functional api and gradient tape. You think going through the first tensorflow course with the sequential api is useful considering that I would have learned how to implement nets from scratch in deeplearning.AI course? I found using the sequential api kind of hard to debug, and was thinking about moving ahead to the more advanced one. Thoughts?",t2_5w4i5kd1,False,,0,False,"New tensorflow advanced specialization course on coursera, thoughts?",[],r/tensorflow,False,6,,0,,,False,t3_jwo9rb,False,dark,0.82,,public,7,0,{},,,False,[],,False,False,,{},Discussion,False,7,,False,self,False,,[],{},,True,,1605761844.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently doing the deeplearning.ai specialization on coursera with Andrew ng. Where he essentially starts with the basics of neural networks from scratch in numpy, and moves to more advanced topics. I was going to apply these skills when doing the tensorflow developer specialization course but realized that today a new advanced tensorflow specialization released. It seems to me the tensorflow developer specialization really focuses on the sequential api, and the new one has its first two courses (other two don’t come until dec and Jan) functional api and gradient tape. You think going through the first tensorflow course with the sequential api is useful considering that I would have learned how to implement nets from scratch in deeplearning.AI course? I found using the sequential api kind of hard to debug, and was thinking about moving ahead to the more advanced one. Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jwo9rb,True,,veeeerain,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jwo9rb/new_tensorflow_advanced_specialization_course_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jwo9rb/new_tensorflow_advanced_specialization_course_on/,22217,1605733044.0,0,,False,,,,,,,,,
507,,tensorflow,I know it's a noob question (sorry for that) but I'm trying to learn more about computer vision and object detection in deep learning. So I'm wondering what's the difference between just implementing the model with Karas and using the API. I'm sure there are advantages but for me the benefits and the distinctions are not very clear.,t2_ebr6t,False,,0,False,Why use the Tensorflow Object Detection API?,[],r/tensorflow,False,6,,0,,,False,t3_jwrfvn,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1605772034.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know it&amp;#39;s a noob question (sorry for that) but I&amp;#39;m trying to learn more about computer vision and object detection in deep learning. So I&amp;#39;m wondering what&amp;#39;s the difference between just implementing the model with Karas and using the API. I&amp;#39;m sure there are advantages but for me the benefits and the distinctions are not very clear.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jwrfvn,True,,m9321,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jwrfvn/why_use_the_tensorflow_object_detection_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jwrfvn/why_use_the_tensorflow_object_detection_api/,22217,1605743234.0,0,,False,,,,,,,,,
508,,tensorflow,"I got the following error but i cant figure out whats wrong:

 InvalidArgumentError:  Incompatible shapes at component 0: expected \[?,256,256,1\] but got \[1,256,256\].",t2_128ob4,False,,0,False,CNN input shape error,[],r/tensorflow,False,6,,0,,,False,t3_jwsban,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605774994.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I got the following error but i cant figure out whats wrong:&lt;/p&gt;

&lt;p&gt;InvalidArgumentError:  Incompatible shapes at component 0: expected [?,256,256,1] but got [1,256,256].&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jwsban,True,,darvidas,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jwsban/cnn_input_shape_error/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jwsban/cnn_input_shape_error/,22217,1605746194.0,0,,False,,,,,,,,,
509,,tensorflow,"I'm trying to implement this loss function [link](https://imgur.com/a/A4G8Bsy) and have written the following code:
```
class EndToEndLoss(tf.keras.losses.Loss):
    def __init__(self, **kwargs):
        self.threshold = 0.7
        self.neg_b = int(str(self.threshold).split(""."")[1])
        self.w = 10
        super().__init__(**kwargs)

    def call(self, y_true, y_pred):
        score, _ = y_pred
        loss = (
            tf.keras.backend.log(
                (1 + tf.keras.backend.exp(-self.w * score * self.neg_b)) ** -1
            )
        ) * -1
        if y_true == 1:
            return loss
        else:
            return 1 - loss
```
However whenever I try to evaluate it before actually running the model no matter what the inputs are it always returns a tensor of either `1.0` or `0.0`. Did you make a mistake in translating the equation to code?",t2_10vrhqvg,False,,0,False,Implementing custom loss function always returns 1 or 0,[],r/tensorflow,False,6,,0,,,False,t3_jwhwa1,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605742532.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to implement this loss function &lt;a href=""https://imgur.com/a/A4G8Bsy""&gt;link&lt;/a&gt; and have written the following code:
```
class EndToEndLoss(tf.keras.losses.Loss):
    def &lt;strong&gt;init&lt;/strong&gt;(self, &lt;strong&gt;kwargs):
        self.threshold = 0.7
        self.neg&lt;em&gt;b = int(str(self.threshold).split(&amp;quot;.&amp;quot;)[1])
        self.w = 10
        super().&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_(&lt;/strong&gt;kwargs)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def call(self, y_true, y_pred):
    score, _ = y_pred
    loss = (
        tf.keras.backend.log(
            (1 + tf.keras.backend.exp(-self.w * score * self.neg_b)) ** -1
        )
    ) * -1
    if y_true == 1:
        return loss
    else:
        return 1 - loss
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;``&lt;code&gt;
However whenever I try to evaluate it before actually running the model no matter what the inputs are it always returns a tensor of either&lt;/code&gt;1.0&lt;code&gt;or&lt;/code&gt;0.0`. Did you make a mistake in translating the equation to code?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jwhwa1,True,,nopickles_,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/jwhwa1/implementing_custom_loss_function_always_returns/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jwhwa1/implementing_custom_loss_function_always_returns/,22217,1605713732.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?auto=webp&amp;s=2f5e419b2db20ac8a80c0205e06257c8ae3bde13', 'width': 543, 'height': 144}, 'resolutions': [{'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abf97fd880a7c9c58556766be42529490af2c106', 'width': 108, 'height': 28}, {'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8582fa1f0f95b7e91bedd31f43d1192011e70f1a', 'width': 216, 'height': 57}, {'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=48ef2f25721334c240453df419dbf76c0b01205c', 'width': 320, 'height': 84}], 'variants': {}, 'id': 'bh8HL5RFoaTZL81L_V7CqJ0Q5E03qBZzofaYr1i8EyE'}], 'enabled': False}",,,,,,True
510,,tensorflow,"Hi,

Just upgraded to a 3090 for the VRAM. After installing it, I was surprised to see that I get 40GB: 24GB from the GPU and 16GB shared memory (half of my total 32GB). I tried searching for it but couldn't find too much info.

Is this something to do with NVLink? Do other cards in the lineup have it?

More importantly, does anybody here have experience with its performance if I overstep the onboard 24GB? Is it something best to be avoided, like swap space?

Thanks!",t2_bjb1l,False,,0,False,Shared memory performance for NVidia cards,[],r/tensorflow,False,6,,0,,,False,t3_jvudxs,False,dark,0.92,,public,11,0,{},,,False,[],,False,False,,{},,False,11,,False,self,False,,[],{},,True,,1605653924.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;Just upgraded to a 3090 for the VRAM. After installing it, I was surprised to see that I get 40GB: 24GB from the GPU and 16GB shared memory (half of my total 32GB). I tried searching for it but couldn&amp;#39;t find too much info.&lt;/p&gt;

&lt;p&gt;Is this something to do with NVLink? Do other cards in the lineup have it?&lt;/p&gt;

&lt;p&gt;More importantly, does anybody here have experience with its performance if I overstep the onboard 24GB? Is it something best to be avoided, like swap space?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jvudxs,True,,felixgravila,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jvudxs/shared_memory_performance_for_nvidia_cards/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvudxs/shared_memory_performance_for_nvidia_cards/,22217,1605625124.0,0,,False,,,,,,,,,
511,,tensorflow,"We use Pexip as a video engine for our video conferencing solution. Pexip doesn't have features like Bokeh effect and Virtual background. So, to implement Bokeh effect, I had to process the input stream with TF Body segmentation to create a blurred background effect and then pass the input stream to the Pexip server. I was successful in doing that. However, I am unable to create a Virtual Background feature in the similar manner. I have tried out everything that I can. Can someone help?",t2_1djx81sp,False,,0,False,Virtual Background in live stream,[],r/tensorflow,False,6,,0,,,False,t3_jvzgkz,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1605669871.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We use Pexip as a video engine for our video conferencing solution. Pexip doesn&amp;#39;t have features like Bokeh effect and Virtual background. So, to implement Bokeh effect, I had to process the input stream with TF Body segmentation to create a blurred background effect and then pass the input stream to the Pexip server. I was successful in doing that. However, I am unable to create a Virtual Background feature in the similar manner. I have tried out everything that I can. Can someone help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jvzgkz,True,,mandarashtekar,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jvzgkz/virtual_background_in_live_stream/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvzgkz/virtual_background_in_live_stream/,22217,1605641071.0,0,,False,,,,,,,,,
512,,tensorflow,"Hi guys, I tried to change the evaluation interval in my pipeline file. I tried to add inside the eval\_config   ""eval\_interval\_secs: 1800"" (so every 30 minutes), but it didn't apply those changes. It is now running every 5 Minutes (I guess) and in this timespan I do only around 400 steps...

Thanks",t2_50xaogdx,False,,0,False,"TF 1.5 Object Detection: Does anyone know, where I can configure the evaluation interval?",[],r/tensorflow,False,6,,0,,,False,t3_jvzonn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1605670558.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I tried to change the evaluation interval in my pipeline file. I tried to add inside the eval_config   &amp;quot;eval_interval_secs: 1800&amp;quot; (so every 30 minutes), but it didn&amp;#39;t apply those changes. It is now running every 5 Minutes (I guess) and in this timespan I do only around 400 steps...&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jvzonn,True,,rene7vick,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jvzonn/tf_15_object_detection_does_anyone_know_where_i/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvzonn/tf_15_object_detection_does_anyone_know_where_i/,22217,1605641758.0,0,,False,,,,,,,,,
513,,tensorflow,"I am looking to upgrade my old laptop with an external gpu which i plan to use for my ML stuff as well and i'm looking at the decent deal for used rx 590. So, what's the status of AMD gpus with tf2 as of this moment? Is it workable? If yes, is it much of a hassle to set up? Should i just look for 1060 or something instead?",t2_wn450,False,,0,False,Tensorflow 2 with radeon rx 590?,[],r/tensorflow,False,6,,0,,,False,t3_jvl0s2,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1605609930.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking to upgrade my old laptop with an external gpu which i plan to use for my ML stuff as well and i&amp;#39;m looking at the decent deal for used rx 590. So, what&amp;#39;s the status of AMD gpus with tf2 as of this moment? Is it workable? If yes, is it much of a hassle to set up? Should i just look for 1060 or something instead?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jvl0s2,True,,Spectator696,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/jvl0s2/tensorflow_2_with_radeon_rx_590/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvl0s2/tensorflow_2_with_radeon_rx_590/,22217,1605581130.0,0,,False,,,,,,,,,
514,,tensorflow,"Hey there have any of you been able to get TF lite running on a pi zero? They distribute armv7 wheel files but none for armv6. I tried cross-compiling, but unfortunately the rpi tools arm g++ seems to not fully (correctly?) implement C++ 11.

All I really need is tflite\_runtime for python. If I couldn't get that but could get the appropriate tf lite .a file I could rewrite my program in C++, though I really wouldn't want to do that. I was able to get bazel to build a tflite\_runtime setup, but the \_pywrap\_tensorflow\_interpreter\_wrapper.so of course matches the architecture it was built on so it's useless by the time it got to the pi.",t2_ae7qu,False,,0,False,TF Lite on Pi Zero?,[],r/tensorflow,False,6,,0,,,False,t3_jvizwr,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1605602299.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there have any of you been able to get TF lite running on a pi zero? They distribute armv7 wheel files but none for armv6. I tried cross-compiling, but unfortunately the rpi tools arm g++ seems to not fully (correctly?) implement C++ 11.&lt;/p&gt;

&lt;p&gt;All I really need is tflite_runtime for python. If I couldn&amp;#39;t get that but could get the appropriate tf lite .a file I could rewrite my program in C++, though I really wouldn&amp;#39;t want to do that. I was able to get bazel to build a tflite_runtime setup, but the _pywrap_tensorflow_interpreter_wrapper.so of course matches the architecture it was built on so it&amp;#39;s useless by the time it got to the pi.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jvizwr,True,,god_is_my_father,,11,True,all_ads,False,[],False,,/r/tensorflow/comments/jvizwr/tf_lite_on_pi_zero/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvizwr/tf_lite_on_pi_zero/,22217,1605573499.0,0,,False,,,,,,,,,
515,,tensorflow,"I'm extracting an attribute from an object in Tensorflow and am trying to input it into another function. However, this attribute is extracted as a string but it works if I type it out into the function. Is there a way to ""unstring"" this attribute to input into the function?

Here is what I am doing that gets me a type error:

    layer = model.layers[2]._keras_api_names[0]  
    print(layer) #output: tf.keras.layers.Conv2D  
    type(layer) #output: str  
    function(model.layers[2]._keras_api_names[0]) #TypeError 

This is the working code:

    function(tf.keras.layers.Conv2D) #this works",t2_8x5nycqg,False,,0,False,Extracting attribute from an object for function input,[],r/tensorflow,False,6,,0,,,False,t3_jvma4x,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605614930.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m extracting an attribute from an object in Tensorflow and am trying to input it into another function. However, this attribute is extracted as a string but it works if I type it out into the function. Is there a way to &amp;quot;unstring&amp;quot; this attribute to input into the function?&lt;/p&gt;

&lt;p&gt;Here is what I am doing that gets me a type error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;layer = model.layers[2]._keras_api_names[0]  
print(layer) #output: tf.keras.layers.Conv2D  
type(layer) #output: str  
function(model.layers[2]._keras_api_names[0]) #TypeError 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the working code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function(tf.keras.layers.Conv2D) #this works
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jvma4x,True,,Substantial_Ticket64,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jvma4x/extracting_attribute_from_an_object_for_function/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvma4x/extracting_attribute_from_an_object_for_function/,22217,1605586130.0,0,,False,,,,,,,,,
516,,tensorflow,"Dear all, 

  I encounter an issue when I train my Convolutional neural network. My training sample includes over 3000 images. But when I start training the model, the model only train about 100 images.

  Does anyone know what happened to my model?",t2_4or022lw,False,,0,False,Training sample size becomes small when training model,[],r/tensorflow,False,6,,0,,,False,t3_jvkuvl,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1605609315.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear all, &lt;/p&gt;

&lt;p&gt;I encounter an issue when I train my Convolutional neural network. My training sample includes over 3000 images. But when I start training the model, the model only train about 100 images.&lt;/p&gt;

&lt;p&gt;Does anyone know what happened to my model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jvkuvl,True,,GeraltofUW,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jvkuvl/training_sample_size_becomes_small_when_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvkuvl/training_sample_size_becomes_small_when_training/,22217,1605580515.0,0,,False,,,,,,,,,
517,,tensorflow,"I was reading that the Recall and Precision metrics are only for binary data and won't work for multi-class models. I mean they work for me, but I don't know if the numbers its producing are true because of this.

I really want to find another metric other than 'Accuracy' to gauge my models performance.

I did find this post: https://github.com/tensorflow/addons/issues/1753 that suggests it *may* already be in Tensorflow but I have no way to verify if that's true.

What is the best way to Check my segmentation models performance?",t2_5wuzf,False,,0,False,How to judge multi-class precision and recall on image segmentation model?,[],r/tensorflow,False,6,,0,,,False,t3_jvdnw0,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1605584955.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was reading that the Recall and Precision metrics are only for binary data and won&amp;#39;t work for multi-class models. I mean they work for me, but I don&amp;#39;t know if the numbers its producing are true because of this.&lt;/p&gt;

&lt;p&gt;I really want to find another metric other than &amp;#39;Accuracy&amp;#39; to gauge my models performance.&lt;/p&gt;

&lt;p&gt;I did find this post: &lt;a href=""https://github.com/tensorflow/addons/issues/1753""&gt;https://github.com/tensorflow/addons/issues/1753&lt;/a&gt; that suggests it &lt;em&gt;may&lt;/em&gt; already be in Tensorflow but I have no way to verify if that&amp;#39;s true.&lt;/p&gt;

&lt;p&gt;What is the best way to Check my segmentation models performance?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jvdnw0,True,,thejeran,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jvdnw0/how_to_judge_multiclass_precision_and_recall_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvdnw0/how_to_judge_multiclass_precision_and_recall_on/,22217,1605556155.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
518,,tensorflow,"Just asking to see if someone has already done this to save me some time.

has anyone made an AI that guesses the base resolution from a basic upscale image like bicubic and nearest neighbor? give Tensor a 4K image and it can tell you it was originally 1080p",t2_9ga94it,False,,0,False,Resolution guessing?,[],r/tensorflow,False,6,,0,,,False,t3_jvbz1y,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605579845.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just asking to see if someone has already done this to save me some time.&lt;/p&gt;

&lt;p&gt;has anyone made an AI that guesses the base resolution from a basic upscale image like bicubic and nearest neighbor? give Tensor a 4K image and it can tell you it was originally 1080p&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jvbz1y,True,,Redstoner7,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jvbz1y/resolution_guessing/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jvbz1y/resolution_guessing/,22217,1605551045.0,0,,False,,,,,,,,,
519,,tensorflow,"I have manually downloaded the stl-10 dataset from [https://cs.stanford.edu/\~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)

I have these files on the path ""C:\\Users\\Kyle\\Desktop\\stl10\\stl10\_binary"":

https://preview.redd.it/j3c57r222hz51.png?width=617&amp;format=png&amp;auto=webp&amp;s=44e7252a6392fd9d527c76bbf32d8186e195cc82

But I have never manually downloaded a dataset manually before so im struggling a bit with how to access these and work with them. If someone could provide some simple code so that I can access these files with the TensorFlow Datasets API it would be appreciated.

I have tried something along the lines of

    train_data = tfds.load(name='stl10', data_dir=r'C:\Users\Kyle\Desktop\stl10\stl10_binary\train_X.bin', download=False)

but this does not work as I get the error message;""

 **AssertionError**: Dataset stl10: could not find data in C:\\Users\\Kyle\\Desktop\\stl10\\stl10\_binary\\train\_X.bin. Please make sure to call dataset\_builder.download\_and\_prepare(), or pass download=True to tfds.load() before trying to access the tf.data.Dataset object. """,t2_ppqwo,False,,0,False,Accessing already downloaded dataset,[],r/tensorflow,False,6,,0,140.0,,False,t3_juu0kp,False,dark,0.76,,public,6,0,{},140.0,,False,[],,False,False,,{},,False,6,,False,https://b.thumbs.redditmedia.com/ku-0eZgI8bIfexKjkuer-xJ0Ig7oKsGPHLfqnJ9OeJE.jpg,False,,[],{},,True,,1605504801.0,text,6,,,text,self.tensorflow,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have manually downloaded the stl-10 dataset from &lt;a href=""https://cs.stanford.edu/%7Eacoates/stl10/""&gt;https://cs.stanford.edu/~acoates/stl10/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have these files on the path &amp;quot;C:\Users\Kyle\Desktop\stl10\stl10_binary&amp;quot;:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/j3c57r222hz51.png?width=617&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44e7252a6392fd9d527c76bbf32d8186e195cc82""&gt;https://preview.redd.it/j3c57r222hz51.png?width=617&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44e7252a6392fd9d527c76bbf32d8186e195cc82&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But I have never manually downloaded a dataset manually before so im struggling a bit with how to access these and work with them. If someone could provide some simple code so that I can access these files with the TensorFlow Datasets API it would be appreciated.&lt;/p&gt;

&lt;p&gt;I have tried something along the lines of&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train_data = tfds.load(name=&amp;#39;stl10&amp;#39;, data_dir=r&amp;#39;C:\Users\Kyle\Desktop\stl10\stl10_binary\train_X.bin&amp;#39;, download=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but this does not work as I get the error message;&amp;quot;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AssertionError&lt;/strong&gt;: Dataset stl10: could not find data in C:\Users\Kyle\Desktop\stl10\stl10_binary\train_X.bin. Please make sure to call dataset_builder.download_and_prepare(), or pass download=True to tfds.load() before trying to access the tf.data.Dataset object. &amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,juu0kp,True,,Chilltyy,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/juu0kp/accessing_already_downloaded_dataset/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/juu0kp/accessing_already_downloaded_dataset/,22217,1605476001.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IHrxDqw6coPuWsVpVnnO1VDft3TQN6FxQQrZnf-kgm8.jpg?auto=webp&amp;s=c77f984b2ad318b101563d92847553b93e5905f7', 'width': 681, 'height': 682}, 'resolutions': [{'url': 'https://external-preview.redd.it/IHrxDqw6coPuWsVpVnnO1VDft3TQN6FxQQrZnf-kgm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db159863f99c364e32760aa969501f6c78e35205', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/IHrxDqw6coPuWsVpVnnO1VDft3TQN6FxQQrZnf-kgm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=905118431d5a2edc525de0d1d5936e802b19aabe', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/IHrxDqw6coPuWsVpVnnO1VDft3TQN6FxQQrZnf-kgm8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d5060acae81bbd56a7f975731de39dc27f5cd054', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/IHrxDqw6coPuWsVpVnnO1VDft3TQN6FxQQrZnf-kgm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c9c675ab2bc7500c9c3578f28c24c7437df463c', 'width': 640, 'height': 640}], 'variants': {}, 'id': '_-VzOj33ptYpNILkvGQUhe-S0jaj_kuYl2XGru9IVec'}], 'enabled': False}",,"{'j3c57r222hz51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 33, 'x': 108, 'u': 'https://preview.redd.it/j3c57r222hz51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=078421a7c60ac0627dc2c65c2c245a8155392a23'}, {'y': 67, 'x': 216, 'u': 'https://preview.redd.it/j3c57r222hz51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=201023b6f69e4fac96999e38b3a314028dc5daa7'}, {'y': 100, 'x': 320, 'u': 'https://preview.redd.it/j3c57r222hz51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a07d978d4364b9cbb899969acf56dcbf471613bb'}], 's': {'y': 193, 'x': 617, 'u': 'https://preview.redd.it/j3c57r222hz51.png?width=617&amp;format=png&amp;auto=webp&amp;s=44e7252a6392fd9d527c76bbf32d8186e195cc82'}, 'id': 'j3c57r222hz51'}}",,,,
520,,tensorflow,"I have a transformer model I'd like to train distributed across several workers on the Google Cloud AI Platform using Actor-Critic RL for training. I have my data broken up into individual files by date and uploaded to Cloud Storage. Since I'm using Actor-Critic RL, I have a custom loss function that calculates and applies the gradient. All the examples I've come across for distributed training make use of `model.fit`, which I'm not going to be able to do. I haven't been able to find any information on using a custom loss instead. Any resources you can point to?

Along with distributing it across several machines, I'd like to know how to properly distribute training across several CPU cores as well. From my understanding `model.fit` takes care of this stuff normally.

Here's the custom loss function; right now it's the equivalent of a batch size of 1 I believe:

`def learn(self, state_value_starting: tf.Tensor, probabilities: tf.Tensor, state_new: tf.Tensor, reward: tf.Tensor, is_done: tf.Tensor):`

`with tf.GradientTape() as tape:`

`state_value_starting = tf.squeeze(state_value_starting)`

`state_value_new, _ =` [`self.call`](https://self.call)`(state_new)`

`state_value_new = tf.squeeze(state_value_new)`

&amp;#x200B;

`action_probabilities = tfp.distributions.Categorical(probs=probabilities)`

`log_probability = action_probabilities.log_prob(self._last_action)`

&amp;#x200B;

`delta = reward + (self._discount_factor * state_value_new * (1 - int(is_done))) - state_value_starting`

`actor_loss = -log_probability * delta`

`critic_loss = delta ** 2`

`total_loss = actor_loss + critic_loss`

&amp;#x200B;

`gradient = tape.gradient(total_loss, self.trainable_variables)`

`self.optimizer.apply_gradients(zip(gradient, self.trainable_variables))`",t2_5htoe6qg,False,,0,False,How to use distributed training with a custom loss?,[],r/tensorflow,False,6,,0,,,False,t3_jummdp,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,1605451382.0,,[],{},,True,,1605479087.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a transformer model I&amp;#39;d like to train distributed across several workers on the Google Cloud AI Platform using Actor-Critic RL for training. I have my data broken up into individual files by date and uploaded to Cloud Storage. Since I&amp;#39;m using Actor-Critic RL, I have a custom loss function that calculates and applies the gradient. All the examples I&amp;#39;ve come across for distributed training make use of &lt;code&gt;model.fit&lt;/code&gt;, which I&amp;#39;m not going to be able to do. I haven&amp;#39;t been able to find any information on using a custom loss instead. Any resources you can point to?&lt;/p&gt;

&lt;p&gt;Along with distributing it across several machines, I&amp;#39;d like to know how to properly distribute training across several CPU cores as well. From my understanding &lt;code&gt;model.fit&lt;/code&gt; takes care of this stuff normally.&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s the custom loss function; right now it&amp;#39;s the equivalent of a batch size of 1 I believe:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;def learn(self, state_value_starting: tf.Tensor, probabilities: tf.Tensor, state_new: tf.Tensor, reward: tf.Tensor, is_done: tf.Tensor):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;with tf.GradientTape() as tape:&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;state_value_starting = tf.squeeze(state_value_starting)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;state_value_new, _ =&lt;/code&gt; &lt;a href=""https://self.call""&gt;&lt;code&gt;self.call&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(state_new)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;state_value_new = tf.squeeze(state_value_new)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;action_probabilities = tfp.distributions.Categorical(probs=probabilities)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;log_probability = action_probabilities.log_prob(self._last_action)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;delta = reward + (self._discount_factor * state_value_new * (1 - int(is_done))) - state_value_starting&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;actor_loss = -log_probability * delta&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;critic_loss = delta ** 2&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;total_loss = actor_loss + critic_loss&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;gradient = tape.gradient(total_loss, self.trainable_variables)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;self.optimizer.apply_gradients(zip(gradient, self.trainable_variables))&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jummdp,True,,EdvardDashD,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jummdp/how_to_use_distributed_training_with_a_custom_loss/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jummdp/how_to_use_distributed_training_with_a_custom_loss/,22217,1605450287.0,0,,False,,,,,,,,,
521,,tensorflow,"Hello all, as said in the title, I am starting out with Tensorflow, but the main reason is that I had a model written in scikit-learn and wanted to convert it to a tensorflow compatible mode, but unfortunately couldn't. So I am starting to learn Tensorflow in order to write the equivalent of the model using tensorflow, but I am having trouble finding tutorials or books that do not focus on deep learning but rather classification algorithms using tensorflow; As i use random forest in model. So any help with how I should go about to have resources talking about classification and regression algorithms instead deep learning. Thank you!",t2_4ikn0zxf,False,,0,False,How to go about starting TensorFlow with a particular end-goal in mind,[],r/tensorflow,False,6,,0,,,False,t3_juk3kd,False,dark,1.0,,public,2,1,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1605466099.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all, as said in the title, I am starting out with Tensorflow, but the main reason is that I had a model written in scikit-learn and wanted to convert it to a tensorflow compatible mode, but unfortunately couldn&amp;#39;t. So I am starting to learn Tensorflow in order to write the equivalent of the model using tensorflow, but I am having trouble finding tutorials or books that do not focus on deep learning but rather classification algorithms using tensorflow; As i use random forest in model. So any help with how I should go about to have resources talking about classification and regression algorithms instead deep learning. Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 20, 'id': 'award_5eac457f-ebac-449b-93a7-eb17b557f03c', 'penny_donate': 0, 'award_sub_type': 'PREMIUM', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=16&amp;height=16&amp;auto=webp&amp;s=bc61b528b8d075c26a3d0f2ad3d9e42259c51cbe', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=32&amp;height=32&amp;auto=webp&amp;s=d576c9a19ed29ca5624333239dbde289a146930b', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=48&amp;height=48&amp;auto=webp&amp;s=da1e45654f5acfb6be44fa07c168ad6420796f56', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=64&amp;height=64&amp;auto=webp&amp;s=677455ac05c563b5585f76e52ee96354f1430799', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=128&amp;height=128&amp;auto=webp&amp;s=25a3b6021a92685b01883fb3d947d2959a75d8b3', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you follow your heart, love is the answer', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'LOVE!', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=16&amp;height=16&amp;auto=webp&amp;s=bc61b528b8d075c26a3d0f2ad3d9e42259c51cbe', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=32&amp;height=32&amp;auto=webp&amp;s=d576c9a19ed29ca5624333239dbde289a146930b', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=48&amp;height=48&amp;auto=webp&amp;s=da1e45654f5acfb6be44fa07c168ad6420796f56', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=64&amp;height=64&amp;auto=webp&amp;s=677455ac05c563b5585f76e52ee96354f1430799', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=128&amp;height=128&amp;auto=webp&amp;s=25a3b6021a92685b01883fb3d947d2959a75d8b3', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png'}]",[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,juk3kd,True,,randomBlackbox_,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/juk3kd/how_to_go_about_starting_tensorflow_with_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/juk3kd/how_to_go_about_starting_tensorflow_with_a/,22217,1605437299.0,0,,False,,,,,,,,,
522,,tensorflow,,t2_lbgod45,False,,0,False,How to detect Tesorflow/Keras model objects automatically,[],r/tensorflow,False,6,,0,140.0,,False,t3_jumdjm,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/T_CFqdmRbGdxSNt8pk8I7n3ALM26sByuLnvVO2Lby5M.jpg,False,,[],{},,False,,1605478030.0,text,6,,,text,stackoverflow.com,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jumdjm,True,,mohammedi-haroune,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jumdjm/how_to_detect_tesorflowkeras_model_objects/,all_ads,False,https://stackoverflow.com/questions/64845295/how-to-detect-tf-keras-model-objects-automatically,22217,1605449230.0,0,,False,link,https://stackoverflow.com/questions/64845295/how-to-detect-tf-keras-model-objects-automatically,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
523,,tensorflow,"I have got some input data with a maximum length of 32 and output has also got max length of 32. Ive padded the input data with 0s and set mask_zero = True in the Embedding layer. Now what should I do with outputs - should I also pad them? If we pad output should I allow the network to predict &lt;PAD&gt; token in the softmax output of Dense Layer? 
Any help is appreciated, thanks.",t2_677jd8j,False,,0,False,Help with padding in Seq2Seq model,[],r/tensorflow,False,6,,0,,,False,t3_jui3a3,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1605453815.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have got some input data with a maximum length of 32 and output has also got max length of 32. Ive padded the input data with 0s and set mask_zero = True in the Embedding layer. Now what should I do with outputs - should I also pad them? If we pad output should I allow the network to predict &amp;lt;PAD&amp;gt; token in the softmax output of Dense Layer? 
Any help is appreciated, thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jui3a3,True,,pooplicker88869,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jui3a3/help_with_padding_in_seq2seq_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jui3a3/help_with_padding_in_seq2seq_model/,22217,1605425015.0,0,,False,,,,,,,,,
524,,tensorflow,,t2_50xaogdx,False,,0,False,"Does anyone knows why my distance-learned SSD Mobilenet V2 Quant. model detects closer/bigger object with less percentage than smaller ones or what causes this? If its close it to ~50%, but on images with smaller people it gets around 99% (TF 1.X, 20.000 steps, 16 batch size, 800 images in dataset)",[],r/tensorflow,False,6,,0,111.0,,False,t3_ju79qd,False,dark,0.81,,public,9,0,{},140.0,,False,[],,False,False,,{},Question,False,9,,False,https://a.thumbs.redditmedia.com/ISu0XUVb2XiJ0T2qWWuDTjAV59kRN_bng378pN2SrQ4.jpg,False,,[],{},,False,,1605409559.0,text,6,,,text,reddit.com,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ju79qd,True,,rene7vick,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/ju79qd/does_anyone_knows_why_my_distancelearned_ssd/,all_ads,False,https://www.reddit.com/gallery/ju79qd,22217,1605380759.0,0,,False,,https://www.reddit.com/gallery/ju79qd,,True,"{'skhc9z0o79z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 62, 'x': 108, 'u': 'https://preview.redd.it/skhc9z0o79z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a4532964300e414862f7a335b6e5aa8d185d2a4a'}, {'y': 125, 'x': 216, 'u': 'https://preview.redd.it/skhc9z0o79z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=63d3524515738408f5b47e4cc1709fe698c73a83'}, {'y': 185, 'x': 320, 'u': 'https://preview.redd.it/skhc9z0o79z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e42ec9e8d6684038d934b679f297c51e630a4b5'}, {'y': 371, 'x': 640, 'u': 'https://preview.redd.it/skhc9z0o79z51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0794419406b4f23abf1b4ba71d973ed43e1e812'}], 's': {'y': 411, 'x': 709, 'u': 'https://preview.redd.it/skhc9z0o79z51.png?width=709&amp;format=png&amp;auto=webp&amp;s=b2bae043922c169967ea8d01ea7fd8a3b6f2059e'}, 'id': 'skhc9z0o79z51'}, 'o9ztpx0o79z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/o9ztpx0o79z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=23596478c646f3ccca9ac38f22342116c9943eaa'}, {'y': 120, 'x': 216, 'u': 'https://preview.redd.it/o9ztpx0o79z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a9bb6dd28bfe03a997282f1fdef5e9cc8019cf0b'}, {'y': 179, 'x': 320, 'u': 'https://preview.redd.it/o9ztpx0o79z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b21a24dd7d18e3a49aa2e4e39e2f588336d757a'}, {'y': 358, 'x': 640, 'u': 'https://preview.redd.it/o9ztpx0o79z51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa57dfab9b1e334db4c50af5737fbc551bbd4e09'}], 's': {'y': 397, 'x': 709, 'u': 'https://preview.redd.it/o9ztpx0o79z51.png?width=709&amp;format=png&amp;auto=webp&amp;s=c3aaf91269665d5df105e55a2f19ca6c01ff7068'}, 'id': 'o9ztpx0o79z51'}, 'gpikww0o79z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 85, 'x': 108, 'u': 'https://preview.redd.it/gpikww0o79z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=09a25201a20ffd1e5e76a3f7d59d2806bbccf5f5'}, {'y': 171, 'x': 216, 'u': 'https://preview.redd.it/gpikww0o79z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=736523b0fb043e6792ed0982e18a9186d0e941be'}, {'y': 254, 'x': 320, 'u': 'https://preview.redd.it/gpikww0o79z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=57c2f18231459576047476c699b477d975f0635f'}, {'y': 509, 'x': 640, 'u': 'https://preview.redd.it/gpikww0o79z51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=91ed3e026b3ce33e2d020635054074015a711f03'}, {'y': 764, 'x': 960, 'u': 'https://preview.redd.it/gpikww0o79z51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1672620ad1fbdaa9dae179c3bde6307759400c0e'}], 's': {'y': 796, 'x': 1000, 'u': 'https://preview.redd.it/gpikww0o79z51.png?width=1000&amp;format=png&amp;auto=webp&amp;s=78b095b66ffc82665b3eeb172875c132c2307652'}, 'id': 'gpikww0o79z51'}}","{'items': [{'media_id': 'gpikww0o79z51', 'id': 12844621}, {'media_id': 'o9ztpx0o79z51', 'id': 12844622}, {'media_id': 'skhc9z0o79z51', 'id': 12844623}]}",,,
525,,tensorflow,"    train_data = tfds.load('stl10', 
                             split='train',
                             as_supervised=True, 
                             shuffle_files=True, 
                             data_dir='R:\AI')

When I try to load the stl10 dataset I get this error:   
"" **OutOfRangeError**: R:\\AI\\downloads\\extracted\\TAR\_GZ.ai.stanfo.edu\_acoate\_stl10\_stl10\_binarynuAgVd1\_Lj1RAaeO4CiJCU\_LSELvnJKSMGQERT-ZKHs.tar.gz\\stl10\_binary/unlabeled\_X.bin; value too large""

What does this mean and how do I fix this? I have more than enough disk space available (about 300 GB), so this have nothing to do with it I think",t2_ppqwo,False,,0,False,"OutOfRangeError ""value too large""",[],r/tensorflow,False,6,,0,,,False,t3_ju53uf,False,dark,0.76,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1605401942.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;train_data = tfds.load(&amp;#39;stl10&amp;#39;, 
                         split=&amp;#39;train&amp;#39;,
                         as_supervised=True, 
                         shuffle_files=True, 
                         data_dir=&amp;#39;R:\AI&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When I try to load the stl10 dataset I get this error:&lt;br/&gt;
&amp;quot; &lt;strong&gt;OutOfRangeError&lt;/strong&gt;: R:\AI\downloads\extracted\TAR_GZ.ai.stanfo.edu_acoate_stl10_stl10_binarynuAgVd1_Lj1RAaeO4CiJCU_LSELvnJKSMGQERT-ZKHs.tar.gz\stl10_binary/unlabeled_X.bin; value too large&amp;quot;&lt;/p&gt;

&lt;p&gt;What does this mean and how do I fix this? I have more than enough disk space available (about 300 GB), so this have nothing to do with it I think&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ju53uf,True,,Chilltyy,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/ju53uf/outofrangeerror_value_too_large/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ju53uf/outofrangeerror_value_too_large/,22217,1605373142.0,0,,False,,,,,,,,,
526,,tensorflow,"Hello community, I want to implement an algorithm from a scientific paper, but it seems that the Keras / TF2.0 don't have Autoregressive Neural Network as a layer:

I want to code that:

&amp;#x200B;

https://preview.redd.it/36n7fov8o9z51.png?width=732&amp;format=png&amp;auto=webp&amp;s=500b1c5fd2766e3f10de9d069c24d59c1a2e3686

Do you have any ideas about how to implement this layer?",t2_7l9ti89m,False,,0,False,Did any already use AutoregressiveNN in TF ?,[],r/tensorflow,False,6,,0,45.0,,False,t3_ju8v5y,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/wTu9Flub_EgKQV-NmrNV0xKw9o8fead8HrQ6fRVqFsc.jpg,False,,[],{},,True,,1605415142.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community, I want to implement an algorithm from a scientific paper, but it seems that the Keras / TF2.0 don&amp;#39;t have Autoregressive Neural Network as a layer:&lt;/p&gt;

&lt;p&gt;I want to code that:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/36n7fov8o9z51.png?width=732&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=500b1c5fd2766e3f10de9d069c24d59c1a2e3686""&gt;https://preview.redd.it/36n7fov8o9z51.png?width=732&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=500b1c5fd2766e3f10de9d069c24d59c1a2e3686&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do you have any ideas about how to implement this layer?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ju8v5y,True,,rayanaay,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ju8v5y/did_any_already_use_autoregressivenn_in_tf/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ju8v5y/did_any_already_use_autoregressivenn_in_tf/,22217,1605386342.0,0,,False,,,,,"{'36n7fov8o9z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 35, 'x': 108, 'u': 'https://preview.redd.it/36n7fov8o9z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8754d84b0d27ba266d274c1020286829766eef9'}, {'y': 70, 'x': 216, 'u': 'https://preview.redd.it/36n7fov8o9z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d35df012126cdaeadeaf4bea6529920770b66dcc'}, {'y': 104, 'x': 320, 'u': 'https://preview.redd.it/36n7fov8o9z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2799facab6f273fabb21f8ad2e279b2b307ed5f'}, {'y': 208, 'x': 640, 'u': 'https://preview.redd.it/36n7fov8o9z51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ecff3a8995c936af36a00f3870ccce988c4f9f5'}], 's': {'y': 238, 'x': 732, 'u': 'https://preview.redd.it/36n7fov8o9z51.png?width=732&amp;format=png&amp;auto=webp&amp;s=500b1c5fd2766e3f10de9d069c24d59c1a2e3686'}, 'id': '36n7fov8o9z51'}}",,,,
527,,tensorflow,"I have a computer with a nvidia gpu. I want to make it so it runs on a gpu. I added the import tensorflow-gpu, but I have a feeling that's not all. Any clue how I would do it for my  code below?

note: I cannot use anaconda with this code, because it interferes with my env",t2_8a76myk5,False,,0,False,How to enable tensorflow code to run on a gpu?,[],r/tensorflow,False,6,,0,,,False,t3_jtwcth,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,1605368151.0,,[],{},,True,,1605359481.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a computer with a nvidia gpu. I want to make it so it runs on a gpu. I added the import tensorflow-gpu, but I have a feeling that&amp;#39;s not all. Any clue how I would do it for my  code below?&lt;/p&gt;

&lt;p&gt;note: I cannot use anaconda with this code, because it interferes with my env&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jtwcth,True,,AwkwardRound,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/jtwcth/how_to_enable_tensorflow_code_to_run_on_a_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jtwcth/how_to_enable_tensorflow_code_to_run_on_a_gpu/,22217,1605330681.0,0,,False,,,,,,,,,
528,,tensorflow,"So, I'm trying to create a text generator, and how I'm doing it so far is encoding text in a sentence one word at a time

For example:

""Hello there"" from a dataset with words ""Hi Hello Up there"" would be:

\[0 1 0 0\] --&gt; \[3\]  \[0 1 0 1\] --&gt; \['done'\]

however, this takes forever to get the train data, and there must be a better way to get the data?",t2_4760f5hy,False,,0,False,What would be the better train data for a text generator neural network,[],r/tensorflow,False,6,,0,,,False,t3_jtw7qi,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1605358842.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So, I&amp;#39;m trying to create a text generator, and how I&amp;#39;m doing it so far is encoding text in a sentence one word at a time&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;p&gt;&amp;quot;Hello there&amp;quot; from a dataset with words &amp;quot;Hi Hello Up there&amp;quot; would be:&lt;/p&gt;

&lt;p&gt;[0 1 0 0] --&amp;gt; [3]  [0 1 0 1] --&amp;gt; [&amp;#39;done&amp;#39;]&lt;/p&gt;

&lt;p&gt;however, this takes forever to get the train data, and there must be a better way to get the data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jtw7qi,True,,ARNisUsername,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jtw7qi/what_would_be_the_better_train_data_for_a_text/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jtw7qi/what_would_be_the_better_train_data_for_a_text/,22217,1605330042.0,0,,False,,,,,,,,,
529,,tensorflow,,t2_2d2tgpew,False,,0,False,"Just want to share some benchmarks I've done with the Zotac GeForce RTX 3070 Twin Edge OC, Tensorflow 1.x and Resnet-50. It looks that FP16 is not working as expected. Also is is very interesting having about ~90% of FP2 performance using a power limit of 125W (this card has an upper limit of 242W)",[],r/tensorflow,False,6,,0,86.0,,False,t3_jti5gs,False,dark,0.93,,public,19,0,{},140.0,,False,[],,False,False,,{},"Discussion, Benchmarks, ResNet",False,19,,False,https://a.thumbs.redditmedia.com/EPJfm7NhoIW3r2vccMX3JNj7ydob3UQM87A4EAvlxu4.jpg,False,,[],{},,False,,1605311685.0,text,6,,,text,reddit.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jti5gs,True,,henry2man,,17,True,all_ads,False,[],False,,/r/tensorflow/comments/jti5gs/just_want_to_share_some_benchmarks_ive_done_with/,all_ads,False,https://www.reddit.com/gallery/jti5gs,22217,1605282885.0,0,,False,,https://www.reddit.com/gallery/jti5gs,,True,"{'g5v3kaem31z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/g5v3kaem31z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e589c12bd0d212928f3cbf79939c5f98bbda94d8'}, {'y': 133, 'x': 216, 'u': 'https://preview.redd.it/g5v3kaem31z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e32e3ed203aae47f63cdbb660623ab354551785'}, {'y': 197, 'x': 320, 'u': 'https://preview.redd.it/g5v3kaem31z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=08cf093d21f3f0cacbcf4ec425ddcb7938b678a4'}], 's': {'y': 371, 'x': 600, 'u': 'https://preview.redd.it/g5v3kaem31z51.png?width=600&amp;format=png&amp;auto=webp&amp;s=75303b81d22279c05fc59dfec43d96b157d13e9b'}, 'id': 'g5v3kaem31z51'}, 'b5tafi0n31z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/b5tafi0n31z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dddb314f49f8332cedcb183493791c8516ac0825'}, {'y': 133, 'x': 216, 'u': 'https://preview.redd.it/b5tafi0n31z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cc0e0d0f8745fa222d5289cd081da9a4698d532'}, {'y': 197, 'x': 320, 'u': 'https://preview.redd.it/b5tafi0n31z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac1bf6ce05f08181943526d0bf99d46f0be81d73'}], 's': {'y': 371, 'x': 600, 'u': 'https://preview.redd.it/b5tafi0n31z51.png?width=600&amp;format=png&amp;auto=webp&amp;s=d92de33a4f512dbfae0164677bebfbe722ad8e98'}, 'id': 'b5tafi0n31z51'}, 'tfbz1tnm31z51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/tfbz1tnm31z51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=db5d6144b42cfceecf4f924adbcfa6412ca67bec'}, {'y': 133, 'x': 216, 'u': 'https://preview.redd.it/tfbz1tnm31z51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d7d928f3312065468623eb7bf9326c92f6df2b27'}, {'y': 197, 'x': 320, 'u': 'https://preview.redd.it/tfbz1tnm31z51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e12d6f9ae5b53e68a7849da3b0f5369c2c914581'}], 's': {'y': 371, 'x': 600, 'u': 'https://preview.redd.it/tfbz1tnm31z51.png?width=600&amp;format=png&amp;auto=webp&amp;s=6287241ff3f64ad80d3e185e24037248f90763a3'}, 'id': 'tfbz1tnm31z51'}}","{'items': [{'caption': 'RTX 3070 - ResNet-50 v1.5 - Images/sec by Power Limit', 'outbound_url': 'https://tecnoconcriterio.wordpress.com/2020/11/13/benchmark-zotac-geforce-rtx-3070-twin-edge-oc-con-resnet-50/', 'media_id': 'b5tafi0n31z51', 'id': 12670590}, {'caption': 'RTX 3070 - Images/sec per watt by Power Limit', 'outbound_url': 'https://tecnoconcriterio.wordpress.com/2020/11/13/benchmark-zotac-geforce-rtx-3070-twin-edge-oc-con-resnet-50/', 'media_id': 'tfbz1tnm31z51', 'id': 12670591}, {'caption': 'RTX 3070 - ResNet-50 v1.5 - Relative performance (100% = 220W) by Power Limit', 'outbound_url': 'https://tecnoconcriterio.wordpress.com/2020/11/13/benchmark-zotac-geforce-rtx-3070-twin-edge-oc-con-resnet-50/', 'media_id': 'g5v3kaem31z51', 'id': 12670592}]}",,,
530,,tensorflow,,t2_6pfjsdhv,False,,0,False,[OC] Most Popular Machine Learning Libraries (on GitHub) - 2014/2019,[],r/tensorflow,False,6,,0,105.0,,False,t3_jtg5pl,False,dark,0.71,,public,7,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ZtOlJF_RQEY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Most Popular Machine Learning Libraries (on GitHub) - 2014/2019', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ZtOlJF_RQEY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Statistics and data', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ZtOlJF_RQEY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCDFQRnMhoUK9miY3XmhBJbw'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ZtOlJF_RQEY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/jtg5pl', 'height': 338}",Discussion,False,7,,False,https://b.thumbs.redditmedia.com/x6L6ph336SdRvX5vA03WqvUM0XIBnixfnvBtT0lllQQ.jpg,False,,[],{},,False,,1605299510.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jtg5pl,True,,accappatoiviola,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jtg5pl/oc_most_popular_machine_learning_libraries_on/,all_ads,False,https://youtu.be/ZtOlJF_RQEY,22217,1605270710.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Most Popular Machine Learning Libraries (on GitHub) - 2014/2019', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ZtOlJF_RQEY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Statistics and data', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ZtOlJF_RQEY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCDFQRnMhoUK9miY3XmhBJbw'}}",False,rich:video,https://youtu.be/ZtOlJF_RQEY,"{'images': [{'source': {'url': 'https://external-preview.redd.it/B3rBCCUa15jYcMjpp3V2A7HJwot8rDI94broYYAiFEA.jpg?auto=webp&amp;s=86655a78a4e43cbc50d68629cb73f126d18421ce', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/B3rBCCUa15jYcMjpp3V2A7HJwot8rDI94broYYAiFEA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b62967538e5e4ee574847c0bae811c192ba12b5a', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/B3rBCCUa15jYcMjpp3V2A7HJwot8rDI94broYYAiFEA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=939b48f8273bf75e06b6f24b6edef8218a3d9a23', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/B3rBCCUa15jYcMjpp3V2A7HJwot8rDI94broYYAiFEA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f9d86b78a8ac406311f52e0b089aa58ca42df105', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'yC7TtyhePWs8NKYJkYt5ROHoJDSfS4rAHLm3h8I0ses'}], 'enabled': False}",,,,,,
531,,tensorflow,,t2_6k78j5vp,False,,0,False,"Virtual Background for Video Conferencing using image segmentation ( TensorFlow DeepLab v3) and OpenCV, Python",[],r/tensorflow,False,6,,0,93.0,,False,t3_jtiawk,False,dark,0.57,,public,1,0,{},140.0,,False,[],,False,False,,{},Project,False,1,,False,https://b.thumbs.redditmedia.com/QENxdwexgkeA2VA83kmgPOsKiqNZ2BOKPHUFPs7zVXI.jpg,False,,[],{},,False,,1605312129.0,text,6,,,text,towardsdatascience.com,False,,,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jtiawk,True,,Shaashwat05,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jtiawk/virtual_background_for_video_conferencing_using/,all_ads,False,https://towardsdatascience.com/virtual-background-for-video-conferencing-using-machine-learning-dfba17d90aa9,22217,1605283329.0,0,,False,link,https://towardsdatascience.com/virtual-background-for-video-conferencing-using-machine-learning-dfba17d90aa9,"{'images': [{'source': {'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?auto=webp&amp;s=377c12c66ea2ae371d0d3038e1ca29da9e3b6d0d', 'width': 1200, 'height': 798}, 'resolutions': [{'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e1e5922a3d3c3f21aa6072cf6b6ca44e8efa24aa', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15cf91cf94f6f7d2f3e28a0d0dc1953ae5f39829', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=81280c02d4ebfb6fdbfaece883fd3dc76cb2b5d0', 'width': 320, 'height': 212}, {'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5d397e8a48cb7966496f5eb26ea4d40f3e471c41', 'width': 640, 'height': 425}, {'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=368fe3e6bd9ddba18a3dc73f632bdd8b0df7c139', 'width': 960, 'height': 638}, {'url': 'https://external-preview.redd.it/nQB8w7qldMIrU6oZAzTqcTG2voUNdX96HNdUL1SL4pE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5ebe3fbd7d4c32bedcb528c05dae33d310ba55d9', 'width': 1080, 'height': 718}], 'variants': {}, 'id': 'Ayom_Y8RLxbWTVNOq4tF43n_g4UEB21Iv1-nSGx0ZhU'}], 'enabled': False}",,,,,,
532,,tensorflow,"**EDIT: This issue has been solved**

Some stack exchange thread said CUDA 11 should be backwards compatible, but it was not!

TF nightly supports CUDA 11 as of August 22, but current stable release does not (and still requires *exactly* CUDA 10.1 and cuDNN 7.6).

Also: the density of suggestions for Linux make me think I should move to Linux for future projects. Woops.

---

I'm getting an error just from importing TF.

``` Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found ```

Which tells me I fucked up the CUDA set up? But I honestly don't know how thats possible, its literally just a wizard + extract cuDNN to wherever the hell you want + set some path variables.

Really new to all this. Grad student in an ML class, professor had us implement everything ourselves in either MATLAB or Python until this assignment. I just need to set up a simple 2 layer MLP to classify some point clouds, but the size of the data makes computation sort of infeasible without GPU.",t2_6z0vp,False,,0,False,Absolute noob question: official install guide still says to use CUDA 10.1 and cuDNN 7.6 --- is this still true?,[],r/tensorflow,False,6,,0,,,False,t3_jtbaog,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,1605288516.0,,[],{},,True,,1605273559.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;EDIT: This issue has been solved&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Some stack exchange thread said CUDA 11 should be backwards compatible, but it was not!&lt;/p&gt;

&lt;p&gt;TF nightly supports CUDA 11 as of August 22, but current stable release does not (and still requires &lt;em&gt;exactly&lt;/em&gt; CUDA 10.1 and cuDNN 7.6).&lt;/p&gt;

&lt;p&gt;Also: the density of suggestions for Linux make me think I should move to Linux for future projects. Woops.&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;I&amp;#39;m getting an error just from importing TF.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Could not load dynamic library &amp;#39;cudart64_101.dll&amp;#39;; dlerror: cudart64_101.dll not found&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Which tells me I fucked up the CUDA set up? But I honestly don&amp;#39;t know how thats possible, its literally just a wizard + extract cuDNN to wherever the hell you want + set some path variables.&lt;/p&gt;

&lt;p&gt;Really new to all this. Grad student in an ML class, professor had us implement everything ourselves in either MATLAB or Python until this assignment. I just need to set up a simple 2 layer MLP to classify some point clouds, but the size of the data makes computation sort of infeasible without GPU.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jtbaog,True,,SeptimusAstrum,,22,True,all_ads,False,[],False,,/r/tensorflow/comments/jtbaog/absolute_noob_question_official_install_guide/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jtbaog/absolute_noob_question_official_install_guide/,22217,1605244759.0,0,,False,,,,,,,,,
533,,tensorflow,,t2_7cd0jpaa,False,,0,False,The power of Tensorflow for generating art,[],r/tensorflow,False,6,,0,140.0,,False,t3_jssyn8,False,dark,0.97,,public,86,0,{},140.0,,False,[],,False,False,,{},,False,86,,False,https://b.thumbs.redditmedia.com/6XuaMyWt2mAH8RpSHv8lZ3ioYKomHCqW3oSteTW0Weo.jpg,False,,[],{},,False,,1605208856.0,text,6,,,text,reddit.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jssyn8,True,,EmergentArt,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/jssyn8/the_power_of_tensorflow_for_generating_art/,all_ads,False,https://www.reddit.com/gallery/jssyn8,22217,1605180056.0,0,,False,,https://www.reddit.com/gallery/jssyn8,,True,"{'2igm10eaksy51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0db14bde2b21ad55d729a7de7591ae9ac3eb1fd8'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d6528193ed0b830df08d94dc4b05fb217e18e88'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=440ae899f82d2a83566f234fd24b5b1230a73ab8'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b752c81bbb746acc4a92f9adf9785a75085c8080'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=90e9fe83efc06ce8020791a97c782c98965238bc'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0317afd7d3dc9203eb1f2828f7382dac47312448'}], 's': {'y': 4096, 'x': 4096, 'u': 'https://preview.redd.it/2igm10eaksy51.jpg?width=4096&amp;format=pjpg&amp;auto=webp&amp;s=9842eedf9bcd4bbac4ed4e098712d590044625bb'}, 'id': '2igm10eaksy51'}, '5m34j5eaksy51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=09f1b6c35c0952b72a7aefede5cf26fe9f3e6bb5'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd86075614a5bfa93bc6264c6955ad6a704b358a'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6e7371f673c89d93a2442c3e39f7269726ee9fd0'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=45afe0067cbb90541376112ffa568f41e04e07e5'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87f02fe0a7f1907a3825cf6bfe47ec76e0816d0b'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7ad9661db2743b5b6f4673d835d0f3fb32cae9ef'}], 's': {'y': 2307, 'x': 2307, 'u': 'https://preview.redd.it/5m34j5eaksy51.jpg?width=2307&amp;format=pjpg&amp;auto=webp&amp;s=1d865388d3bb6d0ea0070117eb58a1a547d1638c'}, 'id': '5m34j5eaksy51'}, 'uv336z9nksy51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db25f23cb8a47790698dd895735a557cde17da9d'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=71f0a54e4df36b367d1e3d2826681188bb03ed24'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2614cbdd03c81e9ca504c059599b1665ed1b3402'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0991f2d6a34230050f39cc971022e8fd72c69ae7'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e020f51c7ac96c21bbec900e25738c52a8b7a685'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=33894342979b5b6a366321be0632c8841ec6a3a7'}], 's': {'y': 3740, 'x': 3740, 'u': 'https://preview.redd.it/uv336z9nksy51.jpg?width=3740&amp;format=pjpg&amp;auto=webp&amp;s=24937732a68a8ef30dff22a87b71a9323bf00d9c'}, 'id': 'uv336z9nksy51'}, 'e4lmweseksy51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=451e18fe7fc600aa5e754cc7984cae7e17a77562'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8acd5a876f38a3725d87c83e633534ec5d13aed5'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b481af294d283350f6b60bb20aec8e643a40127c'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93eaa6f3b04cfdde90e14025480a72a19c30a8c0'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=88bc62e3c5bf5a32adf0f196433da65311505d0e'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0e46d5ac6205104bcca8c6758e85c0c67989b584'}], 's': {'y': 1234, 'x': 1234, 'u': 'https://preview.redd.it/e4lmweseksy51.jpg?width=1234&amp;format=pjpg&amp;auto=webp&amp;s=e2659f9f26597d9b5a3a4cd045e343ae2b33ab5d'}, 'id': 'e4lmweseksy51'}}","{'items': [{'caption': 'Styled black panther', 'media_id': '2igm10eaksy51', 'id': 12516213}, {'caption': 'detail close up', 'media_id': '5m34j5eaksy51', 'id': 12516214}, {'caption': 'Style image', 'media_id': 'uv336z9nksy51', 'id': 12516215}, {'caption': 'Content image', 'media_id': 'e4lmweseksy51', 'id': 12516216}]}",,,
534,,tensorflow,"Hi!

I'm currently looking for a way to replace my Python keras.resnet50 application with Go/Java/C++ for faster inference. Does anyone know of libs that implement the keras.applications package?

Cheers!",t2_da9ad,False,,0,False,Low latency inference,[],r/tensorflow,False,6,,0,,,False,t3_jtf22n,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605293699.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently looking for a way to replace my Python keras.resnet50 application with Go/Java/C++ for faster inference. Does anyone know of libs that implement the keras.applications package?&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jtf22n,True,,blanonymous,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jtf22n/low_latency_inference/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jtf22n/low_latency_inference/,22217,1605264899.0,0,,False,,,,,,,,,
535,,tensorflow,"I'm trying to upgrade source code from tf 1.13.1 to tf 2.3.1.  The most of the code I managed to upgrade automatically with the ""tf\_upgrade\_v2"" script . How ever I'm struggling to upgrade te contrib modules that are used in the source code.   somebody suggestions to update/upgrade/fix these errors??

The script outputs the following report

TensorFlow 2.0 Upgrade Script

\-----------------------------

Converted 1 files

Detected 2 issues that require attention

\--------------------------------------------------------------------------------

\--------------------------------------------------------------------------------

File: convolution\_utils.py

\--------------------------------------------------------------------------------

convolution\_utils.py:80:17: ERROR: Using member tf.contrib.framework.model\_variable in deprecated module tf.contrib. tf.contrib.framework.model\_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.

convolution\_utils.py:82:17: ERROR: Using member tf.contrib.framework.model\_variable in deprecated module tf.contrib. tf.contrib.framework.model\_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.

================================================================================

Detailed log follows:

&amp;#x200B;

================================================================================

\--------------------------------------------------------------------------------

Processing file 'convolution\_utils.py'

 outputting to 'convolution\_utils.py'

\--------------------------------------------------------------------------------

&amp;#x200B;

5:16: INFO: Renamed 'tf.image.resize\_bilinear' to 'tf.compat.v1.image.resize\_bilinear'

12:21: INFO: Added keywords to args of function 'tf.shape'

18:9: INFO: Renamed 'tf.variable\_scope' to 'tf.compat.v1.variable\_scope'

46:8: INFO: Renamed 'tf.layers.conv2d' to 'tf.compat.v1.layers.conv2d'

50:8: INFO: Renamed 'tf.layers.batch\_normalization' to 'tf.compat.v1.layers.batch\_normalization'

70:9: INFO: Renamed 'tf.variable\_scope' to 'tf.compat.v1.variable\_scope'

71:27: INFO: Renamed 'tf.image.resize\_nearest\_neighbor' to 'tf.compat.v1.image.resize\_nearest\_neighbor'

78:16: INFO: Changing tf.contrib.layers xavier initializer to a tf.compat.v1.keras.initializers.VarianceScaling and converting arguments.

&amp;#x200B;

78:70: INFO: tf.constant\_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition\_info argument in the \_\_call\_\_ method.

The calls have been converted to compat.v1 for safety (even though they may already have been correct).

78:70: INFO: Renamed 'tf.constant\_initializer' to 'tf.compat.v1.constant\_initializer'

79:9: INFO: Renamed 'tf.variable\_scope' to 'tf.compat.v1.variable\_scope'

80:17: ERROR: Using member tf.contrib.framework.model\_variable in deprecated module tf.contrib. tf.contrib.framework.model\_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.

81:15: INFO: Added keywords to args of function 'tf.nn.conv2d'

81:15: INFO: Renamed keyword argument for tf.nn.conv2d from filter to filters

82:17: ERROR: Using member tf.contrib.framework.model\_variable in deprecated module tf.contrib. tf.contrib.framework.model\_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.

88:13: INFO: Renamed 'tf.image.resize\_images' to 'tf.image.resize'

\--------------------------------------------------------------------------------",t2_61qkwgix,False,,0,False,upgrade tensorflow code tf_upgrade_v2,[],r/tensorflow,False,6,,0,,,False,t3_jtens4,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1605291347.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to upgrade source code from tf 1.13.1 to tf 2.3.1.  The most of the code I managed to upgrade automatically with the &amp;quot;tf_upgrade_v2&amp;quot; script . How ever I&amp;#39;m struggling to upgrade te contrib modules that are used in the source code.   somebody suggestions to update/upgrade/fix these errors??&lt;/p&gt;

&lt;p&gt;The script outputs the following report&lt;/p&gt;

&lt;p&gt;TensorFlow 2.0 Upgrade Script&lt;/p&gt;

&lt;p&gt;-----------------------------&lt;/p&gt;

&lt;p&gt;Converted 1 files&lt;/p&gt;

&lt;p&gt;Detected 2 issues that require attention&lt;/p&gt;

&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;File: convolution_utils.py&lt;/p&gt;

&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;convolution_utils.py:80:17: ERROR: Using member tf.contrib.framework.model_variable in deprecated module tf.contrib. tf.contrib.framework.model_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.&lt;/p&gt;

&lt;p&gt;convolution_utils.py:82:17: ERROR: Using member tf.contrib.framework.model_variable in deprecated module tf.contrib. tf.contrib.framework.model_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.&lt;/p&gt;

&lt;h1&gt;&lt;/h1&gt;

&lt;p&gt;Detailed log follows:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;h1&gt;&lt;/h1&gt;

&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Processing file &amp;#39;convolution_utils.py&amp;#39;&lt;/p&gt;

&lt;p&gt;outputting to &amp;#39;convolution_utils.py&amp;#39;&lt;/p&gt;

&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;5:16: INFO: Renamed &amp;#39;tf.image.resize_bilinear&amp;#39; to &amp;#39;tf.compat.v1.image.resize_bilinear&amp;#39;&lt;/p&gt;

&lt;p&gt;12:21: INFO: Added keywords to args of function &amp;#39;tf.shape&amp;#39;&lt;/p&gt;

&lt;p&gt;18:9: INFO: Renamed &amp;#39;tf.variable_scope&amp;#39; to &amp;#39;tf.compat.v1.variable_scope&amp;#39;&lt;/p&gt;

&lt;p&gt;46:8: INFO: Renamed &amp;#39;tf.layers.conv2d&amp;#39; to &amp;#39;tf.compat.v1.layers.conv2d&amp;#39;&lt;/p&gt;

&lt;p&gt;50:8: INFO: Renamed &amp;#39;tf.layers.batch_normalization&amp;#39; to &amp;#39;tf.compat.v1.layers.batch_normalization&amp;#39;&lt;/p&gt;

&lt;p&gt;70:9: INFO: Renamed &amp;#39;tf.variable_scope&amp;#39; to &amp;#39;tf.compat.v1.variable_scope&amp;#39;&lt;/p&gt;

&lt;p&gt;71:27: INFO: Renamed &amp;#39;tf.image.resize_nearest_neighbor&amp;#39; to &amp;#39;tf.compat.v1.image.resize_nearest_neighbor&amp;#39;&lt;/p&gt;

&lt;p&gt;78:16: INFO: Changing tf.contrib.layers xavier initializer to a tf.compat.v1.keras.initializers.VarianceScaling and converting arguments.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;78:70: INFO: tf.constant_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.&lt;/p&gt;

&lt;p&gt;The calls have been converted to compat.v1 for safety (even though they may already have been correct).&lt;/p&gt;

&lt;p&gt;78:70: INFO: Renamed &amp;#39;tf.constant_initializer&amp;#39; to &amp;#39;tf.compat.v1.constant_initializer&amp;#39;&lt;/p&gt;

&lt;p&gt;79:9: INFO: Renamed &amp;#39;tf.variable_scope&amp;#39; to &amp;#39;tf.compat.v1.variable_scope&amp;#39;&lt;/p&gt;

&lt;p&gt;80:17: ERROR: Using member tf.contrib.framework.model_variable in deprecated module tf.contrib. tf.contrib.framework.model_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.&lt;/p&gt;

&lt;p&gt;81:15: INFO: Added keywords to args of function &amp;#39;tf.nn.conv2d&amp;#39;&lt;/p&gt;

&lt;p&gt;81:15: INFO: Renamed keyword argument for tf.nn.conv2d from filter to filters&lt;/p&gt;

&lt;p&gt;82:17: ERROR: Using member tf.contrib.framework.model_variable in deprecated module tf.contrib. tf.contrib.framework.model_variable cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.&lt;/p&gt;

&lt;p&gt;88:13: INFO: Renamed &amp;#39;tf.image.resize_images&amp;#39; to &amp;#39;tf.image.resize&amp;#39;&lt;/p&gt;

&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jtens4,True,,sleepyleasle,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jtens4/upgrade_tensorflow_code_tf_upgrade_v2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jtens4/upgrade_tensorflow_code_tf_upgrade_v2/,22217,1605262547.0,0,,False,,,,,,,,,
536,,tensorflow,"    import tensorflow_datasets as tfds
    from tensorflow.keras.layers import Dense, Flatten, Conv2D
    from tensorflow.keras import Model
    import tensorflow as tf
    
    import numpy as np
    import matplotlib.pyplot as plt
    
    train_data = tfds.load('stl10', 
                            split='train',
                            #split=['train', 'test'], 
                            as_supervised=True, 
                            shuffle_files=True,
                            data_dir=""."")
            
    model = tf.keras.models.Sequential([
      tf.keras.layers.Flatten(input_shape=(28, 28)),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.Dense(10, activation='softmax')
    ])
    
    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  #loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    
    model.fit(train_data, epochs=10)

Im trying here to import the stl-10 dataset and train it.

But from model.fit I get an error message which says:  
ValueError: Input 0 of layer dense\_12 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape \[96, 288\]

could anyone help with this? I didnt get this error with the mnist dataset etc.

Also, may I ask if it is enough to just add train\_data and epochs in the model.fit()? What about the labels? how will it know how accurate it is if it doesnt have any labels in the parameters along with the train\_data?

Please ask if you need me to clarify something etc.  
Thank you for any kind help!:)",t2_ppqwo,False,,0,False,Tensorflow: model.fit() problem,[],r/tensorflow,False,6,,0,,,False,t3_jt4hwh,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1605247941.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;import tensorflow_datasets as tfds
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
import tensorflow as tf

import numpy as np
import matplotlib.pyplot as plt

train_data = tfds.load(&amp;#39;stl10&amp;#39;, 
                        split=&amp;#39;train&amp;#39;,
                        #split=[&amp;#39;train&amp;#39;, &amp;#39;test&amp;#39;], 
                        as_supervised=True, 
                        shuffle_files=True,
                        data_dir=&amp;quot;.&amp;quot;)

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation=&amp;#39;relu&amp;#39;),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation=&amp;#39;softmax&amp;#39;)
])

model.compile(optimizer=&amp;#39;adam&amp;#39;,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              #loss=&amp;#39;sparse_categorical_crossentropy&amp;#39;,
              metrics=[&amp;#39;accuracy&amp;#39;])

model.fit(train_data, epochs=10)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Im trying here to import the stl-10 dataset and train it.&lt;/p&gt;

&lt;p&gt;But from model.fit I get an error message which says:&lt;br/&gt;
ValueError: Input 0 of layer dense_12 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [96, 288]&lt;/p&gt;

&lt;p&gt;could anyone help with this? I didnt get this error with the mnist dataset etc.&lt;/p&gt;

&lt;p&gt;Also, may I ask if it is enough to just add train_data and epochs in the model.fit()? What about the labels? how will it know how accurate it is if it doesnt have any labels in the parameters along with the train_data?&lt;/p&gt;

&lt;p&gt;Please ask if you need me to clarify something etc.&lt;br/&gt;
Thank you for any kind help!:)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jt4hwh,True,,Chilltyy,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jt4hwh/tensorflow_modelfit_problem/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jt4hwh/tensorflow_modelfit_problem/,22217,1605219141.0,0,,False,,,,,,,,,
537,,tensorflow,"I've seen several tutorials on Transfer Learning and Image Classification where the last layer is retrained, or several layers are fine-tuned.

However when looking for similar method and Object Detection, every tutorial seems to use the Object Detection API. Is this the only way to perform transfer learning for object detection in Tensorflow?  Using the Object Detection API, its not clear to me if just the last layer is retrained, or whether multiple layers of the base network are fine-tuned.  There doesn't seem to be a way to control which layers to freeze and which layers to replace/retrain using the Object Detection API.  

Am I missing something?",t2_9owuw,False,,0,False,Object Detection Transfer Learning w/o using Tensorflow Object Detection API?,[],r/tensorflow,False,6,,0,,,False,t3_jt2i4a,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1605241709.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve seen several tutorials on Transfer Learning and Image Classification where the last layer is retrained, or several layers are fine-tuned.&lt;/p&gt;

&lt;p&gt;However when looking for similar method and Object Detection, every tutorial seems to use the Object Detection API. Is this the only way to perform transfer learning for object detection in Tensorflow?  Using the Object Detection API, its not clear to me if just the last layer is retrained, or whether multiple layers of the base network are fine-tuned.  There doesn&amp;#39;t seem to be a way to control which layers to freeze and which layers to replace/retrain using the Object Detection API.  &lt;/p&gt;

&lt;p&gt;Am I missing something?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jt2i4a,True,,yahma,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jt2i4a/object_detection_transfer_learning_wo_using/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jt2i4a/object_detection_transfer_learning_wo_using/,22217,1605212909.0,0,,False,,,,,,,,,
538,,tensorflow,"I'm trying to use graph execution (as opposed to eager execution) for the first time. I'm wrapping the model instantiation code in `tf.function`, and am getting an error stating that `'Function' object has no attribute 'compile'`. I've tried searching around for a solution, but I'm not finding anything other than people saying that you can't use `compile` when using graph execution. What I'm not finding is information about how to compile a model without using `compile`.

If anyone has resources they can point to that'd be awesome!",t2_5htoe6qg,False,,0,False,How do you compile a model without calling model.compile?,[],r/tensorflow,False,6,,0,,,False,t3_jsuv87,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1605217718.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to use graph execution (as opposed to eager execution) for the first time. I&amp;#39;m wrapping the model instantiation code in &lt;code&gt;tf.function&lt;/code&gt;, and am getting an error stating that &lt;code&gt;&amp;#39;Function&amp;#39; object has no attribute &amp;#39;compile&amp;#39;&lt;/code&gt;. I&amp;#39;ve tried searching around for a solution, but I&amp;#39;m not finding anything other than people saying that you can&amp;#39;t use &lt;code&gt;compile&lt;/code&gt; when using graph execution. What I&amp;#39;m not finding is information about how to compile a model without using &lt;code&gt;compile&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If anyone has resources they can point to that&amp;#39;d be awesome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jsuv87,True,,EdvardDashD,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jsuv87/how_do_you_compile_a_model_without_calling/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jsuv87/how_do_you_compile_a_model_without_calling/,22217,1605188918.0,0,,False,,,,,,,,,
539,,tensorflow,"I was wondering which one of these is the best. Has anyone used them all? If so what are the pros and cons of them all?

My use case is 3D character animation. My main priority is accuracy and also making it realtime if possible.",t2_2l48bxrf,False,,0,False,BlazePose vs PoseNet vs BodyPix?,[],r/tensorflow,False,6,,0,,,False,t3_jsps4z,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Discussion,False,6,,False,self,False,,[],{},,True,,1605191355.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was wondering which one of these is the best. Has anyone used them all? If so what are the pros and cons of them all?&lt;/p&gt;

&lt;p&gt;My use case is 3D character animation. My main priority is accuracy and also making it realtime if possible.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jsps4z,True,,GamerWael,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jsps4z/blazepose_vs_posenet_vs_bodypix/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jsps4z/blazepose_vs_posenet_vs_bodypix/,22217,1605162555.0,1,,False,,,,,,,,,
540,,tensorflow,"Hi all,

what is the exact meaning of the step log in tensorflow lite. I am training an object detection and my idea was that it means how many images where processed. So that if i have 5000 images an step count is at 10000 every images was seen twice by the model. Now I am training two exact equal models and the only difference is the number of training images. The model with more training images needs more time per step. Because of this i am not sure if i understand the step log correctly. Can anyone explain?",t2_54sgggqt,False,,0,False,Meaning of step in tensorflow lite,[],r/tensorflow,False,6,,0,,,False,t3_jstx6u,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605213654.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;what is the exact meaning of the step log in tensorflow lite. I am training an object detection and my idea was that it means how many images where processed. So that if i have 5000 images an step count is at 10000 every images was seen twice by the model. Now I am training two exact equal models and the only difference is the number of training images. The model with more training images needs more time per step. Because of this i am not sure if i understand the step log correctly. Can anyone explain?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jstx6u,True,,alex12385298,,0,False,all_ads,False,[],False,,/r/tensorflow/comments/jstx6u/meaning_of_step_in_tensorflow_lite/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jstx6u/meaning_of_step_in_tensorflow_lite/,22217,1605184854.0,0,,False,,,,,,,,,
541,,tensorflow,"I recently bought an RTX 3090 (upgrading from a GTX 1060) and needed my keras/tensorflow notebooks to work. There are some guides on this on the internet, but these were often skipping some steps or explanations, so I wanted to share a very simple, ""for dummies"" kind of step by step instruction with explanations on how I got it to work on my system. It is similar to [this guide](https://stevejeffersonr.medium.com/setting-up-your-nvidia-gpu-for-deep-learning-2020-22c153d4200b), but a bit different as I encountered some problems that was not mentioned in that guide. I am using a Ryzen 2700X and Windows 10 Home.

So, what you need to know beforehand: The NVIDIA 3000 Series GPUs (Ampere) require CUDA v11 and cuDNN v8 to work. The tensorflow versions on anaconda and pip on Windows (currently at max tensorflow 2.3) do not include a tensorflow built with CUDA v11. But you can use pip to install a nightly build of tensorflow (currently tensorflow 2.5) which built with CUDA v11. Apart from a tensorflow build with CUDA v11, you will also need the actual DLLs for CUDA v11 and cuDNN v8. Normally, you would just install these with anaconda with the packages cudatoolkit and cudnn, but while cudatoolkit is available with v11, for cudnn, at least for Windows, v8 is not available in anaconda. The workaround is to manually get these DLLs and set them in the system environment path (so that python/tensorflow can find and load them). So let's start:

&amp;#x200B;

1. First, install anaconda if you haven't already. Open the anaconda prompt with admin rights.
2. Type `conda create -n tf2 python=3.8` and hit enter to create a new anaconda environment with python 3.8 (the tensorflow nightly build needs python 3.8 or higher, that's why we are using python 3.8)
3. Type `activate tf2` or `conda activate tf2` and hit enter to enter that new environment.
4. Install the nightly tensorflow build with `pip3 install tf-nightly-gpu`
5. Install other packages that you might need. For me, it's `conda install jupyter scikit-learn matplotlib pandas`
6. Now, download CUDA v11 from NVIDIA ([https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads) or [https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive)). Yeah, the file is pretty big with 3GB.
7. Additionally, apparently we also need a Microsoft Visual Studio version for C++ for the installer to run properly. Download the free Visual Studio Community Edition ([https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)) and install the C++ components. For this, select ""Desktop development with C++"", select the first 6 options and install. This step is taken from [the guide I mentioned earlier](https://stevejeffersonr.medium.com/setting-up-your-nvidia-gpu-for-deep-learning-2020-22c153d4200b), so refer to it if you have trouble with this. For me, I already had Visual Studio with C++ in mind set up on my computer, so I could skip this step.
8. Now, let's first execute the CUDA v11 installer. Execute it. You can do the express installation, but if you already have GeForce Experience installed, you can also choose the Custom option and deselect everything that you already have installed with a higher version. For me, I only needed the very first checkbox with the CUDA options, so that might be enough.
9. What the CUDA v11 installer basically did was installing all the CUDA v11 DLLs, Headers, and stuff in the directory ""C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1"" (the version may be different for you). What we will do next: Add the cuDNN DLLs, Headers, etc. in this directory as well and then add this directory to the system path. Ok, let's go.
10. Download cuDNN from NVIDIA ([https://developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download)). This file is around 700MB. You need to register as a developer and answer some questions, but don't worry, it's free. When asked for an email, you can type in any email, since in the next page, you will get an option to login using google or facebook as an alternative (which you may or may not prefer). Once you downloaded the file, extract it. Going into the directory, you will see three folders ""bin"", ""include"", ""lib"". Comparing it with the CUDA v11 directory (C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1), you'll notice that these directories are present there as well! So just copy the folders from cuDNN to the CUDA v11 directory. Windows will add the files into the existing folders.
11. Now, let's add those directories to the system path. In windows, open start and search for ""This PC"". Rightclick and select ""Properties"" to open a Window called ""System"". On the left side at the bottom, select ""Advanced system settings"". Click ""Environment Variables..."" at the bottom. Here, in the lower half, in ""System variables"", find and open ""Path"". Here, click ""New"" to add a new directory to the system path. Do this every time for each of the following directories (as mentioned earlier, the version number may be different for you). Some of the directories may be already listed there, so feel free to skip them (there is no negative effect from double entries though, so don't worry too much):  
`C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\bin`  
`C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\libnvvp`  
`C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\extras\CUPTI\lib64`  
`C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\include`
12. Now, very important: Restart your system!
13. Now, run your code to see if everything works. For me, it was through a jupyter notebook. A simple thing to do first is to import tensorflow and check the physical devices:import tensorflow as tftf.config.list\_physical\_devices()
14. Your GPU may not show up. Take a close look at the output of the console (for me, it was the anaconda prompt with which I started up my jupyter notebook). There, you should see logs like  `tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll` or a similar log stating that a certain DLL could not be loaded! In my case, everything loaded except the DLL ""cusolver64\_10.dll"". So, I went to the CUDA v11 directory  (C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1), opened the ""bin"" folder (the DLLs are in there) to check if that DLL was there. Nope, it was not. Instead, there was ""cusolver64\_11.dll"". So what I did was just copy that DLL and renamed the copy to ""cusolver64\_10.dll"". Yeah, sounds dumb, but after that, everything worked.

I hope this guide helps at least someone. Hopefully, we will get official versions of tensorflow 2.5 and the CUDA/cudnn packages soon so that these kind of workarounds will not be required anymore.

&amp;#x200B;

EDIT: Somewhat obvious thing I noticed today: Had a video call running and was using the background removal of NVIDIA Broadcast. Tried to do some inference during the call and it was failing with error messages like `Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED` and `tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`. Well, yeah, that was because NVIDIA Broadcast was running, which itself uses the machine learning capabilities of the GPU. After closing it, things worked normally again. Kind of obvious, but somewhat easy to overlook/forget.",t2_lap1r,False,,0,False,RTX 3090 and Tensorflow for Windows 10 - step by step,[],r/tensorflow,False,6,,0,,,False,t3_jsalkw,False,dark,0.98,,public,44,1,{},,,False,[],,False,False,,{},,False,44,,False,self,1605808984.0,,[],{},,True,,1605138912.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently bought an RTX 3090 (upgrading from a GTX 1060) and needed my keras/tensorflow notebooks to work. There are some guides on this on the internet, but these were often skipping some steps or explanations, so I wanted to share a very simple, &amp;quot;for dummies&amp;quot; kind of step by step instruction with explanations on how I got it to work on my system. It is similar to &lt;a href=""https://stevejeffersonr.medium.com/setting-up-your-nvidia-gpu-for-deep-learning-2020-22c153d4200b""&gt;this guide&lt;/a&gt;, but a bit different as I encountered some problems that was not mentioned in that guide. I am using a Ryzen 2700X and Windows 10 Home.&lt;/p&gt;

&lt;p&gt;So, what you need to know beforehand: The NVIDIA 3000 Series GPUs (Ampere) require CUDA v11 and cuDNN v8 to work. The tensorflow versions on anaconda and pip on Windows (currently at max tensorflow 2.3) do not include a tensorflow built with CUDA v11. But you can use pip to install a nightly build of tensorflow (currently tensorflow 2.5) which built with CUDA v11. Apart from a tensorflow build with CUDA v11, you will also need the actual DLLs for CUDA v11 and cuDNN v8. Normally, you would just install these with anaconda with the packages cudatoolkit and cudnn, but while cudatoolkit is available with v11, for cudnn, at least for Windows, v8 is not available in anaconda. The workaround is to manually get these DLLs and set them in the system environment path (so that python/tensorflow can find and load them). So let&amp;#39;s start:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;First, install anaconda if you haven&amp;#39;t already. Open the anaconda prompt with admin rights.&lt;/li&gt;
&lt;li&gt;Type &lt;code&gt;conda create -n tf2 python=3.8&lt;/code&gt; and hit enter to create a new anaconda environment with python 3.8 (the tensorflow nightly build needs python 3.8 or higher, that&amp;#39;s why we are using python 3.8)&lt;/li&gt;
&lt;li&gt;Type &lt;code&gt;activate tf2&lt;/code&gt; or &lt;code&gt;conda activate tf2&lt;/code&gt; and hit enter to enter that new environment.&lt;/li&gt;
&lt;li&gt;Install the nightly tensorflow build with &lt;code&gt;pip3 install tf-nightly-gpu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install other packages that you might need. For me, it&amp;#39;s &lt;code&gt;conda install jupyter scikit-learn matplotlib pandas&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Now, download CUDA v11 from NVIDIA (&lt;a href=""https://developer.nvidia.com/cuda-downloads""&gt;https://developer.nvidia.com/cuda-downloads&lt;/a&gt; or &lt;a href=""https://developer.nvidia.com/cuda-toolkit-archive""&gt;https://developer.nvidia.com/cuda-toolkit-archive&lt;/a&gt;). Yeah, the file is pretty big with 3GB.&lt;/li&gt;
&lt;li&gt;Additionally, apparently we also need a Microsoft Visual Studio version for C++ for the installer to run properly. Download the free Visual Studio Community Edition (&lt;a href=""https://visualstudio.microsoft.com/downloads/""&gt;https://visualstudio.microsoft.com/downloads/&lt;/a&gt;) and install the C++ components. For this, select &amp;quot;Desktop development with C++&amp;quot;, select the first 6 options and install. This step is taken from &lt;a href=""https://stevejeffersonr.medium.com/setting-up-your-nvidia-gpu-for-deep-learning-2020-22c153d4200b""&gt;the guide I mentioned earlier&lt;/a&gt;, so refer to it if you have trouble with this. For me, I already had Visual Studio with C++ in mind set up on my computer, so I could skip this step.&lt;/li&gt;
&lt;li&gt;Now, let&amp;#39;s first execute the CUDA v11 installer. Execute it. You can do the express installation, but if you already have GeForce Experience installed, you can also choose the Custom option and deselect everything that you already have installed with a higher version. For me, I only needed the very first checkbox with the CUDA options, so that might be enough.&lt;/li&gt;
&lt;li&gt;What the CUDA v11 installer basically did was installing all the CUDA v11 DLLs, Headers, and stuff in the directory &amp;quot;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1&amp;quot; (the version may be different for you). What we will do next: Add the cuDNN DLLs, Headers, etc. in this directory as well and then add this directory to the system path. Ok, let&amp;#39;s go.&lt;/li&gt;
&lt;li&gt;Download cuDNN from NVIDIA (&lt;a href=""https://developer.nvidia.com/rdp/cudnn-download""&gt;https://developer.nvidia.com/rdp/cudnn-download&lt;/a&gt;). This file is around 700MB. You need to register as a developer and answer some questions, but don&amp;#39;t worry, it&amp;#39;s free. When asked for an email, you can type in any email, since in the next page, you will get an option to login using google or facebook as an alternative (which you may or may not prefer). Once you downloaded the file, extract it. Going into the directory, you will see three folders &amp;quot;bin&amp;quot;, &amp;quot;include&amp;quot;, &amp;quot;lib&amp;quot;. Comparing it with the CUDA v11 directory (C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1), you&amp;#39;ll notice that these directories are present there as well! So just copy the folders from cuDNN to the CUDA v11 directory. Windows will add the files into the existing folders.&lt;/li&gt;
&lt;li&gt;Now, let&amp;#39;s add those directories to the system path. In windows, open start and search for &amp;quot;This PC&amp;quot;. Rightclick and select &amp;quot;Properties&amp;quot; to open a Window called &amp;quot;System&amp;quot;. On the left side at the bottom, select &amp;quot;Advanced system settings&amp;quot;. Click &amp;quot;Environment Variables...&amp;quot; at the bottom. Here, in the lower half, in &amp;quot;System variables&amp;quot;, find and open &amp;quot;Path&amp;quot;. Here, click &amp;quot;New&amp;quot; to add a new directory to the system path. Do this every time for each of the following directories (as mentioned earlier, the version number may be different for you). Some of the directories may be already listed there, so feel free to skip them (there is no negative effect from double entries though, so don&amp;#39;t worry too much):&lt;br/&gt;
&lt;code&gt;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\bin&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\libnvvp&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\extras\CUPTI\lib64&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\include&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Now, very important: Restart your system!&lt;/li&gt;
&lt;li&gt;Now, run your code to see if everything works. For me, it was through a jupyter notebook. A simple thing to do first is to import tensorflow and check the physical devices:import tensorflow as tftf.config.list_physical_devices()&lt;/li&gt;
&lt;li&gt;Your GPU may not show up. Take a close look at the output of the console (for me, it was the anaconda prompt with which I started up my jupyter notebook). There, you should see logs like  &lt;code&gt;tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll&lt;/code&gt; or a similar log stating that a certain DLL could not be loaded! In my case, everything loaded except the DLL &amp;quot;cusolver64_10.dll&amp;quot;. So, I went to the CUDA v11 directory  (C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1), opened the &amp;quot;bin&amp;quot; folder (the DLLs are in there) to check if that DLL was there. Nope, it was not. Instead, there was &amp;quot;cusolver64_11.dll&amp;quot;. So what I did was just copy that DLL and renamed the copy to &amp;quot;cusolver64_10.dll&amp;quot;. Yeah, sounds dumb, but after that, everything worked.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I hope this guide helps at least someone. Hopefully, we will get official versions of tensorflow 2.5 and the CUDA/cudnn packages soon so that these kind of workarounds will not be required anymore.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;EDIT: Somewhat obvious thing I noticed today: Had a video call running and was using the background removal of NVIDIA Broadcast. Tried to do some inference during the call and it was failing with error messages like &lt;code&gt;Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED&lt;/code&gt; and &lt;code&gt;tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.&lt;/code&gt;. Well, yeah, that was because NVIDIA Broadcast was running, which itself uses the machine learning capabilities of the GPU. After closing it, things worked normally again. Kind of obvious, but somewhat easy to overlook/forget.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jsalkw,True,,mumei-chan,,70,True,all_ads,False,[],False,,/r/tensorflow/comments/jsalkw/rtx_3090_and_tensorflow_for_windows_10_step_by/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jsalkw/rtx_3090_and_tensorflow_for_windows_10_step_by/,22217,1605110112.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?auto=webp&amp;s=dcd6fb569df041349d29c2b2c15ee94b26e68b67', 'width': 1200, 'height': 717}, 'resolutions': [{'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b735c875d85335e1e32fdf22577b24c541fc2511', 'width': 108, 'height': 64}, {'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d446dd7e2fdb38a3df1dbe65c02895efcfe306f', 'width': 216, 'height': 129}, {'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0b5de2bd85c84268cc350794ef01772d6cfdcba', 'width': 320, 'height': 191}, {'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=944c47de1396820140dea669e4299c1c3f969b3b', 'width': 640, 'height': 382}, {'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d7f290a76bafff33df0fd4e546084e2dab06f83b', 'width': 960, 'height': 573}, {'url': 'https://external-preview.redd.it/CuY9sED--e54lYweRdg6xSaxC3T8b59wJv4jBX_hDeY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a30f7247aaa561a6bc4e0c9b0e045fa59927fe4d', 'width': 1080, 'height': 645}], 'variants': {}, 'id': 'o10PlHJY05U9tVmUNATs2_DSZYxR2KPDIrmr2zLFUPk'}], 'enabled': False}",,,,,,
542,,tensorflow,,t2_ffekw,False,,0,False,Over 20% of downloads on PyPI are still TF 1.X,[],r/tensorflow,False,6,,0,,,False,t3_jsa5rj,False,dark,0.97,,public,26,0,{},,,False,[],,False,False,,{},,False,26,,False,default,False,,[],{},,False,,1605137476.0,text,6,,,text,package.wiki,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jsa5rj,True,,rastarobbie1,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/jsa5rj/over_20_of_downloads_on_pypi_are_still_tf_1x/,all_ads,False,https://package.wiki/tensorflow,22217,1605108676.0,0,,False,,https://package.wiki/tensorflow,,,,,,,
543,,tensorflow,"Hello, I am aware that tensorflow has its own tools and packages for preprocessing say text for recurrent neural networks. However, I have always been used to using sklearn for feature engineering when I was doing sentiment analysis with sklearn models. My question is, can I use these same pre processing techniques before fitting models into tensorflow neural nets? My issue is that using sklearns preprocessing tools may not return the data in a shape that’s best for neural networks in tensorflow. Has anyone incorporated sklearn in their workflow this way? And if so can they link their GitHub?",t2_5w4i5kd1,False,,0,False,Sklearn preprocessing methods for tf neural nets?,[],r/tensorflow,False,6,,0,,,False,t3_jsmbvx,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1605177059.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I am aware that tensorflow has its own tools and packages for preprocessing say text for recurrent neural networks. However, I have always been used to using sklearn for feature engineering when I was doing sentiment analysis with sklearn models. My question is, can I use these same pre processing techniques before fitting models into tensorflow neural nets? My issue is that using sklearns preprocessing tools may not return the data in a shape that’s best for neural networks in tensorflow. Has anyone incorporated sklearn in their workflow this way? And if so can they link their GitHub?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jsmbvx,True,,veeeerain,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jsmbvx/sklearn_preprocessing_methods_for_tf_neural_nets/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jsmbvx/sklearn_preprocessing_methods_for_tf_neural_nets/,22217,1605148259.0,0,,False,,,,,,,,,
544,,tensorflow,"Hi, so I'm trying to make a chatbot with tensorflow's keras, and I'm inputting numbers from 1-11000 that represent different words, and trying to output 98 words with the output array, yet the outputs are all numbers from 0-100?

Is there any way to fix it, or am I just doing everything completely wrong?",t2_4760f5hy,False,,0,False,How to convert Dense output on tensorflow neural network back to words?,[],r/tensorflow,False,6,,0,,,False,t3_jsfb8r,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1605153137.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, so I&amp;#39;m trying to make a chatbot with tensorflow&amp;#39;s keras, and I&amp;#39;m inputting numbers from 1-11000 that represent different words, and trying to output 98 words with the output array, yet the outputs are all numbers from 0-100?&lt;/p&gt;

&lt;p&gt;Is there any way to fix it, or am I just doing everything completely wrong?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jsfb8r,True,,ARNisUsername,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jsfb8r/how_to_convert_dense_output_on_tensorflow_neural/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jsfb8r/how_to_convert_dense_output_on_tensorflow_neural/,22217,1605124337.0,0,,False,,,,,,,,,
545,,tensorflow,"I made a small repo to help users interface quickly with TF2 Object Detection API. No long tutorials, extraneous code, or dealing with protocol buffers. Python version between 3.5 and 3.8 should be all you need.

[https://github.com/thomasmatt88/tfhub-od-easy](https://github.com/thomasmatt88/tfhub-od-easy)",t2_83w9rbaf,False,,0,False,Tensorflow 2.0 Object Detection Made Easy,[],r/tensorflow,False,6,,0,,,False,t3_jryz08,False,dark,0.97,,public,24,0,{},,,False,[],,False,False,,{},Project,False,24,,False,self,False,,[],{},,True,,1605088837.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I made a small repo to help users interface quickly with TF2 Object Detection API. No long tutorials, extraneous code, or dealing with protocol buffers. Python version between 3.5 and 3.8 should be all you need.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/thomasmatt88/tfhub-od-easy""&gt;https://github.com/thomasmatt88/tfhub-od-easy&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jryz08,True,,International_Fix_94,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jryz08/tensorflow_20_object_detection_made_easy/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jryz08/tensorflow_20_object_detection_made_easy/,22217,1605060037.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/8t88Zr258aLo48PlxyJ-WM0ABrRtzZDrXdsLBy1hWXg.jpg?auto=webp&amp;s=271c275fc325736d160f702699595adf53f0ef65', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/8t88Zr258aLo48PlxyJ-WM0ABrRtzZDrXdsLBy1hWXg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91f1142a770d0274b23c5727ddb871f7ab18bf3d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/8t88Zr258aLo48PlxyJ-WM0ABrRtzZDrXdsLBy1hWXg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=afb235137bff147e6c679545d0a44b3639a97a62', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/8t88Zr258aLo48PlxyJ-WM0ABrRtzZDrXdsLBy1hWXg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bec7c074f672f7d6417313f5da4e98521b51b15f', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'ugn1hMmWtGCeVuoeB3yonRx7WVnwGgJskXIteI-QSBI'}], 'enabled': False}",,,,,,
546,,tensorflow,,t2_wdxkq,False,,0,False,galeone/tfgo: simplified TensorFlow's Go bindings with 2.3 support,[],r/tensorflow,False,6,,0,140.0,,False,t3_js51zh,False,dark,1.0,,public,5,0,{},140.0,,False,[],,False,False,,{},,False,5,,False,https://b.thumbs.redditmedia.com/nJqbt-m9LKxTggqgiNf4Y7GZE0T6Lv1tAb_1gPfMGQc.jpg,False,,[],{},,False,,1605115311.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,js51zh,True,,pgaleone,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/js51zh/galeonetfgo_simplified_tensorflows_go_bindings/,all_ads,False,https://github.com/galeone/tfgo,22217,1605086511.0,0,,False,link,https://github.com/galeone/tfgo,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?auto=webp&amp;s=2edba5d5ceb279f09b3527bc294bf2160a873c5c', 'width': 250, 'height': 250}, 'resolutions': [{'url': 'https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c4cbe0629697f9045e34bfbb312fe950c34df5a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=918a35885646403ffa497863194e5c62b45c606d', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'QCb-J1Fr_047ebumrG01fT3ttdPG7-jWDogxAKgzMBQ'}], 'enabled': False}",,,,,,
547,,tensorflow,"Hi there! I try to replicate the results of [this paper](https://link.springer.com/article/10.1007/s11263-015-0872-3). They state, that they used VGG16- and VGG19-models pretrained on imagenet and used the output of the last convolutional layer (without relu and max-pooling) as feature vectors.

My configuration to configure the model accordingly is the following:

    from tensorflow.keras.models import Model
    from tensorflow.keras.applications import VGG16
    
    base_model = VGG16(include_top=False)  # Cut off the fully-connected-layers
    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_conv3').output)  # Discard the last max-pooling-layer
    model.layers[-1].activation = None  # Change activation-function of last layer from Relu to Linear

and i get a feature-tensor of shape (1, 14, 14, 512) for the default input-shape of (224, 224, 3). So far, this looks the way i would want it to be. However, the authors state:

&gt;The VGG-M \[equivalent to VGG16 in the context of the paper\] convolutional features are extracted as the output of the last  convolutional layer, directly from the linear filters excluding ReLU  and max pooling, which **yields a field of 512-dimensional descriptor  vectors**

Now, i have stated above, that the number 512 is part of my output-shape. However i thought, that it means that i get back 512 individual image-patches of size 14x14! The only way i could think of, that would get me 512-dimensional descriptor vectors would be something like this:

    features = model.predict(img)
    
    feature_vectors = []
    for i in range(features.shape[1]):
        for j in range(features.shape[2]):
            feature_vectors.append(features[0, i, j, :])
    feature_vectors = np.array(feature_vectors)

But then i would slice through all of the existing image-patches!

**Question 1:**

Did the authors mean to do just that? Is this a common practice anyone her has used before? All the tutorials or blogposts i found online just `flatten()` the output-tensor and add it to the database of existing feature-vectors.

**Question 2:**

The authors also state, that:

&gt;...local descriptors are extracted at multiple scales, obtained by rescaling the image by factors 2^s, s=−3,−2.5,...,1.5 (but, for efficiency, discarding scales that would make the image larger than 1024^2 pixels).

I can totally extract images at different scales, by specifying the `input_shape`, when instantiating the VGG16-model. My method of getting 512-dimensional feature-vectors stated above would also work in that case, even though the output-tensor could be much larger (i.e. a shape of (1, 64, 64, 512)) in case of a bigger image.

Is this the way to do feature-extraction at multiple scales?",t2_nh2e2a3,False,,0,False,Keras: Extract Features at Multiple Image-Scales,[],r/tensorflow,False,6,,0,,,False,t3_js7csn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1605126962.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there! I try to replicate the results of &lt;a href=""https://link.springer.com/article/10.1007/s11263-015-0872-3""&gt;this paper&lt;/a&gt;. They state, that they used VGG16- and VGG19-models pretrained on imagenet and used the output of the last convolutional layer (without relu and max-pooling) as feature vectors.&lt;/p&gt;

&lt;p&gt;My configuration to configure the model accordingly is the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG16

base_model = VGG16(include_top=False)  # Cut off the fully-connected-layers
model = Model(inputs=base_model.input, outputs=base_model.get_layer(&amp;#39;block5_conv3&amp;#39;).output)  # Discard the last max-pooling-layer
model.layers[-1].activation = None  # Change activation-function of last layer from Relu to Linear
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and i get a feature-tensor of shape (1, 14, 14, 512) for the default input-shape of (224, 224, 3). So far, this looks the way i would want it to be. However, the authors state:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The VGG-M [equivalent to VGG16 in the context of the paper] convolutional features are extracted as the output of the last  convolutional layer, directly from the linear filters excluding ReLU  and max pooling, which &lt;strong&gt;yields a field of 512-dimensional descriptor  vectors&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now, i have stated above, that the number 512 is part of my output-shape. However i thought, that it means that i get back 512 individual image-patches of size 14x14! The only way i could think of, that would get me 512-dimensional descriptor vectors would be something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;features = model.predict(img)

feature_vectors = []
for i in range(features.shape[1]):
    for j in range(features.shape[2]):
        feature_vectors.append(features[0, i, j, :])
feature_vectors = np.array(feature_vectors)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But then i would slice through all of the existing image-patches!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 1:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Did the authors mean to do just that? Is this a common practice anyone her has used before? All the tutorials or blogposts i found online just &lt;code&gt;flatten()&lt;/code&gt; the output-tensor and add it to the database of existing feature-vectors.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 2:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The authors also state, that:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...local descriptors are extracted at multiple scales, obtained by rescaling the image by factors 2&lt;sup&gt;s,&lt;/sup&gt; s=−3,−2.5,...,1.5 (but, for efficiency, discarding scales that would make the image larger than 1024&lt;sup&gt;2&lt;/sup&gt; pixels).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I can totally extract images at different scales, by specifying the &lt;code&gt;input_shape&lt;/code&gt;, when instantiating the VGG16-model. My method of getting 512-dimensional feature-vectors stated above would also work in that case, even though the output-tensor could be much larger (i.e. a shape of (1, 64, 64, 512)) in case of a bigger image.&lt;/p&gt;

&lt;p&gt;Is this the way to do feature-extraction at multiple scales?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,js7csn,True,,tim-hilt,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/js7csn/keras_extract_features_at_multiple_imagescales/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/js7csn/keras_extract_features_at_multiple_imagescales/,22217,1605098162.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/XAoSHV_xXP2Ro75NtVv5EpwFXZoKd6RP8jHynT797HI.jpg?auto=webp&amp;s=a5d13d53c38fa05d447147693f278810a2f50a8f', 'width': 110, 'height': 147}, 'resolutions': [{'url': 'https://external-preview.redd.it/XAoSHV_xXP2Ro75NtVv5EpwFXZoKd6RP8jHynT797HI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75fffa689fe6ec5d2200e1ab9873d208f86ea882', 'width': 108, 'height': 144}], 'variants': {}, 'id': '6Nts2xEdHaSArROFAiIPvBAuDodTrgFXkxVred8mkIs'}], 'enabled': False}",,,,,,
548,,tensorflow,"For context, I'm building a neural network bot which learns how to play competitive Pokemon over at the simulator https://play.pokemonshowdown.com/ using Deep Q reinforcement learning and the `keras.rl` package.

I'm feeding 1469 points of float data, normalized between [0-1]. This data is stuff like Pokemon types, health percentages, field conditions, move powers, item IDs, ability IDs, etc. Most of the stuff is integer data which gets normalized in order to fit into that 0-1 range.

The neural net produces an output vector of size 22, which uses an epsilon greedy policy to choose the best Q value (and therefore the best action).

I originally used a series of dense layers -- an input layer, 3 hidden layers, and an output layer. However, [after watching a few videos](https://www.youtube.com/watch?v=Tnu4O_xEmVk) I noticed that a lot of Q learning stuff used LSTM cells, so I built this network:

    Model: ""sequential""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #
    =================================================================
    Input_LSTM (LSTM)            (None, 5, 1024)           10215424
    _________________________________________________________________
    Hidden_Layer_1 (Dense)       (None, 5, 512)            524800
    _________________________________________________________________
    leaky_re_lu (LeakyReLU)      (None, 5, 512)            0
    _________________________________________________________________
    Hidden_Drop_1 (Dropout)      (None, 5, 512)            0
    _________________________________________________________________
    Hidden_LSTM_1 (LSTM)         (None, 5, 256)            787456
    _________________________________________________________________
    Hidden_Layer_2 (Dense)       (None, 5, 128)            32896
    _________________________________________________________________
    leaky_re_lu_1 (LeakyReLU)    (None, 5, 128)            0
    _________________________________________________________________
    Hidden_Drop_2 (Dropout)      (None, 5, 128)            0
    _________________________________________________________________
    Hidden_LSTM_2 (LSTM)         (None, 64)                49408     
    _________________________________________________________________
    Inner_Output (Dense)         (None, 22)                1430
    _________________________________________________________________
    Model_Output (Dense)         (None, 22)                506
    =================================================================
    Total params: 11,611,920
    Trainable params: 11,611,920
    Non-trainable params: 0
    _________________________________________________________________

(The reason behind the 2 final layers being the same size is because the `DQNAgent` provided by `keras.rl` has a ""dueling network"" setting which pits the results of the last 2 layers against each other.)

I then [train it against a variety of opponent agents](https://imgur.com/a/LnEgOMi) -- first someone that always does random actions, then once that model bottoms out it swaps to someone always doing the action at index 0, then an agent always doing the max possible damage per turn, followed by a minimax agent. You can see when the agents swap by looking at the discontinuities on the graph.

I added a callback to enable logging to Tensorboard:

    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=config.get_tensorboard_log_dir(self.format), histogram_freq=20, write_images=True)

The thing is... I don't really know what I'm looking at.

* The only one that sort of makes sense [is the Histogram view](https://imgur.com/a/JlJU4r0), which looks like my dense layers are learning but the LSTM cells aren't? Am I reading that right?

* [My scalars view has a weird twisty line for some reason](https://i.imgur.com/jhgtAwQ.png). Some things are also marked as being validation data when this is all training in reinforcement learning.

* [My images just look like random noise](https://i.imgur.com/RaFys8N.png)

* [The distributions view doesn't seem terribly helpful](https://i.imgur.com/EErk3H0.png) -- it tells me a general range for some values, but I'm not really sure what the values mean or if this is good or bad.

* [The projections view is very pretty but doesn't have any useful labels for the points.](https://i.imgur.com/pqTJXyQ.png) All of the input and output points could be pretty easily assigned labels, but I'm not really sure how to do that -- everywhere I've seen uses it for text-based data, where it seems like they make an embedding layer and somehow the data comes straight from there?

I would imagine I'm doing something wrong, and the data I'm seeing on Tensorboard is telling me that... but I have no idea how to read any of it. Any help?",t2_6d405,False,,0,False,"I don't really ""get"" Tensorboard -- what exactly am I looking at here?",[],r/tensorflow,False,6,,0,,,False,t3_jrz6hq,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,True,self,1605062119.0,,[],{},,True,,1605089566.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For context, I&amp;#39;m building a neural network bot which learns how to play competitive Pokemon over at the simulator &lt;a href=""https://play.pokemonshowdown.com/""&gt;https://play.pokemonshowdown.com/&lt;/a&gt; using Deep Q reinforcement learning and the &lt;code&gt;keras.rl&lt;/code&gt; package.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m feeding 1469 points of float data, normalized between [0-1]. This data is stuff like Pokemon types, health percentages, field conditions, move powers, item IDs, ability IDs, etc. Most of the stuff is integer data which gets normalized in order to fit into that 0-1 range.&lt;/p&gt;

&lt;p&gt;The neural net produces an output vector of size 22, which uses an epsilon greedy policy to choose the best Q value (and therefore the best action).&lt;/p&gt;

&lt;p&gt;I originally used a series of dense layers -- an input layer, 3 hidden layers, and an output layer. However, &lt;a href=""https://www.youtube.com/watch?v=Tnu4O_xEmVk""&gt;after watching a few videos&lt;/a&gt; I noticed that a lot of Q learning stuff used LSTM cells, so I built this network:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
Input_LSTM (LSTM)            (None, 5, 1024)           10215424
_________________________________________________________________
Hidden_Layer_1 (Dense)       (None, 5, 512)            524800
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 5, 512)            0
_________________________________________________________________
Hidden_Drop_1 (Dropout)      (None, 5, 512)            0
_________________________________________________________________
Hidden_LSTM_1 (LSTM)         (None, 5, 256)            787456
_________________________________________________________________
Hidden_Layer_2 (Dense)       (None, 5, 128)            32896
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 5, 128)            0
_________________________________________________________________
Hidden_Drop_2 (Dropout)      (None, 5, 128)            0
_________________________________________________________________
Hidden_LSTM_2 (LSTM)         (None, 64)                49408     
_________________________________________________________________
Inner_Output (Dense)         (None, 22)                1430
_________________________________________________________________
Model_Output (Dense)         (None, 22)                506
=================================================================
Total params: 11,611,920
Trainable params: 11,611,920
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(The reason behind the 2 final layers being the same size is because the &lt;code&gt;DQNAgent&lt;/code&gt; provided by &lt;code&gt;keras.rl&lt;/code&gt; has a &amp;quot;dueling network&amp;quot; setting which pits the results of the last 2 layers against each other.)&lt;/p&gt;

&lt;p&gt;I then &lt;a href=""https://imgur.com/a/LnEgOMi""&gt;train it against a variety of opponent agents&lt;/a&gt; -- first someone that always does random actions, then once that model bottoms out it swaps to someone always doing the action at index 0, then an agent always doing the max possible damage per turn, followed by a minimax agent. You can see when the agents swap by looking at the discontinuities on the graph.&lt;/p&gt;

&lt;p&gt;I added a callback to enable logging to Tensorboard:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tb_callback = tf.keras.callbacks.TensorBoard(log_dir=config.get_tensorboard_log_dir(self.format), histogram_freq=20, write_images=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The thing is... I don&amp;#39;t really know what I&amp;#39;m looking at.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The only one that sort of makes sense &lt;a href=""https://imgur.com/a/JlJU4r0""&gt;is the Histogram view&lt;/a&gt;, which looks like my dense layers are learning but the LSTM cells aren&amp;#39;t? Am I reading that right?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=""https://i.imgur.com/jhgtAwQ.png""&gt;My scalars view has a weird twisty line for some reason&lt;/a&gt;. Some things are also marked as being validation data when this is all training in reinforcement learning.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=""https://i.imgur.com/RaFys8N.png""&gt;My images just look like random noise&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=""https://i.imgur.com/EErk3H0.png""&gt;The distributions view doesn&amp;#39;t seem terribly helpful&lt;/a&gt; -- it tells me a general range for some values, but I&amp;#39;m not really sure what the values mean or if this is good or bad.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=""https://i.imgur.com/pqTJXyQ.png""&gt;The projections view is very pretty but doesn&amp;#39;t have any useful labels for the points.&lt;/a&gt; All of the input and output points could be pretty easily assigned labels, but I&amp;#39;m not really sure how to do that -- everywhere I&amp;#39;ve seen uses it for text-based data, where it seems like they make an embedding layer and somehow the data comes straight from there?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I would imagine I&amp;#39;m doing something wrong, and the data I&amp;#39;m seeing on Tensorboard is telling me that... but I have no idea how to read any of it. Any help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jrz6hq,True,,EnglishMobster,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jrz6hq/i_dont_really_get_tensorboard_what_exactly_am_i/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jrz6hq/i_dont_really_get_tensorboard_what_exactly_am_i/,22217,1605060766.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/9P_XwyZByraRSolutHYvV8ewx9CYjduxCdC-VgnZjrM.jpg?auto=webp&amp;s=27f44c0d299b846047de05b72e4f3aa611c3fd32', 'width': 640, 'height': 480}, 'resolutions': [{'url': 'https://external-preview.redd.it/9P_XwyZByraRSolutHYvV8ewx9CYjduxCdC-VgnZjrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7dc6b80b8a2a99c271b0ed1261d6489c8a147631', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/9P_XwyZByraRSolutHYvV8ewx9CYjduxCdC-VgnZjrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=591fe8d7dcc04ec9b1bc8f5516feaf6e18413b8e', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/9P_XwyZByraRSolutHYvV8ewx9CYjduxCdC-VgnZjrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=39d94fc62035b2d53ba75afc49ad6a26af3c49e1', 'width': 320, 'height': 240}, {'url': 'https://external-preview.redd.it/9P_XwyZByraRSolutHYvV8ewx9CYjduxCdC-VgnZjrM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eceb57ef4145d266902e970ac03f842bc9c2552', 'width': 640, 'height': 480}], 'variants': {}, 'id': 'BvaFsAxz-sg3ERLd_YRa4zL8bPyl5mmNlLsItVIF7vo'}], 'enabled': False}",,,,,,
549,,tensorflow,,t2_xt6j8xa,False,,0,False,I wrote a blog on TinyML. This is about how you can deploy machine learning models on embedded systems like Arduino. I think you'll find it useful,[],r/tensorflow,False,6,,0,93.0,,False,t3_jrk9ir,False,dark,1.0,,public,29,0,{},140.0,,False,[],,False,False,,{},,False,29,,False,https://a.thumbs.redditmedia.com/H_BdoAsDKPKFn3n98CEF7uKWFi4HuHj9aLv5Z9iybO0.jpg,False,,[],{},,False,,1605040860.0,text,6,,,text,cleanpegasus.medium.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jrk9ir,True,,clean_pegasus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jrk9ir/i_wrote_a_blog_on_tinyml_this_is_about_how_you/,all_ads,False,https://cleanpegasus.medium.com/an-introduction-to-tinyml-4617f314aa79,22217,1605012060.0,0,,False,link,https://cleanpegasus.medium.com/an-introduction-to-tinyml-4617f314aa79,"{'images': [{'source': {'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?auto=webp&amp;s=0a9183315a32ae740aa19ca8fe2c01a292bfcfb3', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ee41a93a215d1d146bfbbacf51ae3b9da935a14', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5484dc5d917adc62f78d44384a9208ffebcd5395', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4742a8731b3a8c3998f30e3e6e454fcf0014bf4c', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5f9445d9435122c79e238e06c41d760e6e39d45', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8952ff84e9b4fa3f82959ac1f85a938f1a4187c2', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/V3WA92NXCXyV7LFg57Ni8wJWbqd4g0RF_7q8Ui4zHx4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7f96947fb4745f7db6054222c21c95d43c6d0e3', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'UjsGHhUMRXIhkBL1KT8qBkbaO-QfoyAbsjvh99I_ck0'}], 'enabled': False}",,,,,,
550,,tensorflow," I am trying to create a custom loss function in tensorflow.keras; particularly, shannon's entropy. Here is the basic neural net structure 

    import tensorflow as tf
    import numpy as np
    
    import matplotlib.pyplot as plt
    
    from scipy.stats import entropy
    import numpy as np
    
    
    
    
    mnist = tf.keras.datasets.mnist
    
    (x_train, y_train),(x_test, y_test) = mnist.load_data()
    x_train =x_train / 255.0
    
    
    
    
    
    model = tf.keras.models.Sequential([
    
      tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
    
      tf.keras.layers.Dense(128, activation=tf.nn.sigmoid),
      tf.keras.layers.Dense(10, activation=tf.nn.sigmoid)
    ])
    model.compile(optimizer='sgd',
                  loss=entropy_loss,
                  metrics=['accuracy'])
    
    model.fit(x_train, y_train, epochs=1,batch_size=512)

 

And I am trying 2 ways to calculate entropy, neither of which is working. The 1st way is to convert the y\_true and y\_pred to numpy, get the error, then calculate entropy using scipy's entropy measure. I am facing errors for converting to numpy. The 2nd way I am using tensorflow calculations. I prefer a solution to the 1st method over the 2nd one, because I want to do some further modifications that would require converting  the tensorflow values to numpy arrays.

&amp;#x200B;

method1

    def entropy_loss(y_true,y_pred):
    
        # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer
       
        return tf.cast(entropy(y_pred.numpy() - y_true.numpy() , base=2))
       
        # Return a function
        #return loss

 the 1st way has this error: 

&amp;#x200B;

      &lt;ipython-input-4-14c95bd6b1a3&gt;:5 entropy_loss  *
            return tf.cast(entropy(y_pred.numpy() - y_true.numpy() , base=2))
    
        AttributeError: 'Tensor' object has no attribute 'numpy'

 method2 

    def entropy_loss(y_true,y_pred):
    
        y_true=tf.cast(y_true, tf.float32)
        y_pred=tf.cast(y_pred, tf.float32)
        e=y_true-y_pred
        print(e)
        loss= entropy_1(e) 
        #return e
        # Return a function
        return loss
    def entropy_1( x):
        def row_entropy(row):
            _, _, count = tf.unique_with_counts(row)
            prob = count / tf.reduce_sum(count)
            return -tf.reduce_sum(prob * tf.math.log(prob))
    
        value_ranges = [-10.0, 100.0]
        nbins = 50
        new_f_w_t = tf.histogram_fixed_width_bins(x, value_ranges, nbins)
        result = tf.map_fn(row_entropy, new_f_w_t,dtype=tf.float32)

 This method has the following error: 

     ValueError: Trying to read from list with wrong element dtype. List has type double but expected type float for '{{node entropy_loss/map/TensorArrayV2Stack/TensorListStack}} = TensorListStack[element_dtype=DT_FLOAT, num_elements=-1](entropy_loss/map/while:3, entropy_loss/map/TensorArrayV2Stack/Const)' with input shapes: [], [0].",t2_8u7xja2z,False,,0,False,"trying to calculate entropy of errors for my custom loss function, how to do?",[],r/tensorflow,False,6,,0,,,False,t3_jrz2au,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1605089145.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to create a custom loss function in tensorflow.keras; particularly, shannon&amp;#39;s entropy. Here is the basic neural net structure &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
import numpy as np

import matplotlib.pyplot as plt

from scipy.stats import entropy
import numpy as np




mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train =x_train / 255.0





model = tf.keras.models.Sequential([

  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),

  tf.keras.layers.Dense(128, activation=tf.nn.sigmoid),
  tf.keras.layers.Dense(10, activation=tf.nn.sigmoid)
])
model.compile(optimizer=&amp;#39;sgd&amp;#39;,
              loss=entropy_loss,
              metrics=[&amp;#39;accuracy&amp;#39;])

model.fit(x_train, y_train, epochs=1,batch_size=512)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And I am trying 2 ways to calculate entropy, neither of which is working. The 1st way is to convert the y_true and y_pred to numpy, get the error, then calculate entropy using scipy&amp;#39;s entropy measure. I am facing errors for converting to numpy. The 2nd way I am using tensorflow calculations. I prefer a solution to the 1st method over the 2nd one, because I want to do some further modifications that would require converting  the tensorflow values to numpy arrays.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;method1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def entropy_loss(y_true,y_pred):

    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer

    return tf.cast(entropy(y_pred.numpy() - y_true.numpy() , base=2))

    # Return a function
    #return loss
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the 1st way has this error: &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;ipython-input-4-14c95bd6b1a3&amp;gt;:5 entropy_loss  *
        return tf.cast(entropy(y_pred.numpy() - y_true.numpy() , base=2))

    AttributeError: &amp;#39;Tensor&amp;#39; object has no attribute &amp;#39;numpy&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;method2 &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def entropy_loss(y_true,y_pred):

    y_true=tf.cast(y_true, tf.float32)
    y_pred=tf.cast(y_pred, tf.float32)
    e=y_true-y_pred
    print(e)
    loss= entropy_1(e) 
    #return e
    # Return a function
    return loss
def entropy_1( x):
    def row_entropy(row):
        _, _, count = tf.unique_with_counts(row)
        prob = count / tf.reduce_sum(count)
        return -tf.reduce_sum(prob * tf.math.log(prob))

    value_ranges = [-10.0, 100.0]
    nbins = 50
    new_f_w_t = tf.histogram_fixed_width_bins(x, value_ranges, nbins)
    result = tf.map_fn(row_entropy, new_f_w_t,dtype=tf.float32)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This method has the following error: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt; ValueError: Trying to read from list with wrong element dtype. List has type double but expected type float for &amp;#39;{{node entropy_loss/map/TensorArrayV2Stack/TensorListStack}} = TensorListStack[element_dtype=DT_FLOAT, num_elements=-1](entropy_loss/map/while:3, entropy_loss/map/TensorArrayV2Stack/Const)&amp;#39; with input shapes: [], [0].
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jrz2au,True,,customkquestion,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jrz2au/trying_to_calculate_entropy_of_errors_for_my/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jrz2au/trying_to_calculate_entropy_of_errors_for_my/,22217,1605060345.0,1,,False,,,,,,,,,
551,,tensorflow,,t2_1fzf7xak,False,,0,False,"Tensorflow docker, keras module not found? I ran this command "" nvidia-docker run -u $(id -u):$(id -g) --name myjupyternotebook --gpus all -it -p 8888:8888 -v ~/my_jupyter_notebooks/:/tf tensorflow/tensorflow:latest-gpu-py3-jupyter""",[],r/tensorflow,False,6,,0,140.0,,False,t3_jrr0e8,False,dark,1.0,,public,1,0,{},140.0,,False,[],,True,False,,{},,False,1,,False,https://a.thumbs.redditmedia.com/ljmDIKkN5bCFe3jI_m211QZsFyTthop7Z65hrSgFgN8.jpg,False,,[],{},,False,,1605063407.0,text,6,,,text,i.redd.it,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jrr0e8,True,,Otaken96,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/jrr0e8/tensorflow_docker_keras_module_not_found_i_ran/,all_ads,False,https://i.redd.it/ll9lwsk9mgy51.png,22217,1605034607.0,0,,False,image,https://i.redd.it/ll9lwsk9mgy51.png,"{'images': [{'source': {'url': 'https://preview.redd.it/ll9lwsk9mgy51.png?auto=webp&amp;s=c76fe0dfa3933a1d4899e1105a0d8a99d5b29cdf', 'width': 691, 'height': 734}, 'resolutions': [{'url': 'https://preview.redd.it/ll9lwsk9mgy51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7e88e3dd06ab1a5612bd34cf2b703a4f8daaa38', 'width': 108, 'height': 114}, {'url': 'https://preview.redd.it/ll9lwsk9mgy51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6c8020909837bb747fcdd847579b8528d469ec0', 'width': 216, 'height': 229}, {'url': 'https://preview.redd.it/ll9lwsk9mgy51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7eeffdec3beff17978f761f73238abbc8627639e', 'width': 320, 'height': 339}, {'url': 'https://preview.redd.it/ll9lwsk9mgy51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ef7f2b5a7014ab3069e6a4de21076a750e9e2d6', 'width': 640, 'height': 679}], 'variants': {}, 'id': 'XrYUYShry7H928y9YZZAPyRFG01-fGCsaagQK9hlvko'}], 'enabled': True}",,,,,,
552,,tensorflow,"I know I obviously need to collect more data, but any ideas for what I should be doing right now with my NN? Currently I'm having an 11x11 neural network with a 60.5% accuracy",t2_4760f5hy,False,,0,False,"I have a text classification dataset with 2,365 text(each text has 250 length, there are 2 total features in the y ) and I'm wondering what would be the best neurons and layers for my neural network",[],r/tensorflow,False,6,,0,,,False,t3_jqilne,False,dark,0.74,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1604895192.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know I obviously need to collect more data, but any ideas for what I should be doing right now with my NN? Currently I&amp;#39;m having an 11x11 neural network with a 60.5% accuracy&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jqilne,True,,ARNisUsername,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jqilne/i_have_a_text_classification_dataset_with_2365/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jqilne/i_have_a_text_classification_dataset_with_2365/,22217,1604866392.0,0,,False,,,,,,,,,
553,,tensorflow,"I'm using a CNN to categorize sounds using keras in Google Colab and it gave me an OOM error when training the model. It worked fine when I was using 30 samples, but I increased it to 100 and it errors out. I tried decreasing the batch size but it was of no help.

Please let me know what I can do to fix this. Thanks!",t2_5xwgd1f8,False,,0,False,OOM when using keras in Google Colab with GPU acceleration,[],r/tensorflow,False,6,,0,,,False,t3_jq69kd,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1604841793.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using a CNN to categorize sounds using keras in Google Colab and it gave me an OOM error when training the model. It worked fine when I was using 30 samples, but I increased it to 100 and it errors out. I tried decreasing the batch size but it was of no help.&lt;/p&gt;

&lt;p&gt;Please let me know what I can do to fix this. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jq69kd,True,,llub888,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jq69kd/oom_when_using_keras_in_google_colab_with_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jq69kd/oom_when_using_keras_in_google_colab_with_gpu/,22217,1604812993.0,0,,False,,,,,,,,,
554,,tensorflow,"[Perceptilabs](https://www.perceptilabs.com/) has been working on building an easy to use GUI for machine learning frameworks, especially Tensorflow to make modeling faster, simpler and intuitive for ml enthusiasts from different fields. This approach can lower the barrier of entry for beginners while providing advanced users with code-level access to their models.

[Building image classification model on Perceptilabs](https://reddit.com/link/jq0gwd/video/4ormqe4pfwx51/player)

What do you think about it? I myself have been practicing machine learning for past 6 years and started working at Perceptilabs about a year ago. I would appreciate your feedback on what you like about this platform, what you don't like and what kind of features do you think are missing :)",t2_8s91dqux,False,,0,False,A new easy to use GUI for Tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_jq0gwd,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,self,False,,[],{},,True,,1604819195.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.perceptilabs.com/""&gt;Perceptilabs&lt;/a&gt; has been working on building an easy to use GUI for machine learning frameworks, especially Tensorflow to make modeling faster, simpler and intuitive for ml enthusiasts from different fields. This approach can lower the barrier of entry for beginners while providing advanced users with code-level access to their models.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/jq0gwd/video/4ormqe4pfwx51/player""&gt;Building image classification model on Perceptilabs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What do you think about it? I myself have been practicing machine learning for past 6 years and started working at Perceptilabs about a year ago. I would appreciate your feedback on what you like about this platform, what you don&amp;#39;t like and what kind of features do you think are missing :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jq0gwd,True,,ml-agent,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jq0gwd/a_new_easy_to_use_gui_for_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jq0gwd/a_new_easy_to_use_gui_for_tensorflow/,22217,1604790395.0,0,,False,,,,,"{'4ormqe4pfwx51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/jq0gwd/asset/4ormqe4pfwx51/DASHPlaylist.mpd?a=1618044785%2CMTBmNjNkYjRjMzUxOWI0Njk4YmRmYjI3ZTQwNjkxMWMyODAzOTg1MTY4NDNhMDMzOWRjNmFkNTBjZTcwMGYxMQ%3D%3D&amp;v=1&amp;f=sd', 'x': 1920, 'y': 1075, 'hlsUrl': 'https://v.redd.it/link/jq0gwd/asset/4ormqe4pfwx51/HLSPlaylist.m3u8?a=1618044785%2CZTlkNzM2MjQ1MGUzOWZmNzdkOTliNGMxZWQ3MTNjNmQ0ZGJhM2E4Y2VkMjdiMmQ3ZWU5M2UyOTczNjNkMWE5MQ%3D%3D&amp;v=1&amp;f=sd', 'id': '4ormqe4pfwx51', 'isGif': False}}",,,,
555,,tensorflow,"As a beginner in deep learning for the past few months, I noticed that the Sequential API was very easy for me to pick up, because it was aimed at helping people build models fairly easily as a beginner. It was aimed towards beginners. However, I was wondering when did you guys end up switching to using the functional or subclassing API after using the sequential api? Does the subclassing api have any more benefits as opposed to the sequential? Same for the functional api, does this serve  a better purpose? If any of you did switch what made you decide to leave the sequential api and take on the other two?",t2_5w4i5kd1,False,,0,False,Transitioning from Sequential API to Functional/Subclassing API,[],r/tensorflow,False,6,,0,,,False,t3_jpx16z,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1604807667.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As a beginner in deep learning for the past few months, I noticed that the Sequential API was very easy for me to pick up, because it was aimed at helping people build models fairly easily as a beginner. It was aimed towards beginners. However, I was wondering when did you guys end up switching to using the functional or subclassing API after using the sequential api? Does the subclassing api have any more benefits as opposed to the sequential? Same for the functional api, does this serve  a better purpose? If any of you did switch what made you decide to leave the sequential api and take on the other two?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jpx16z,True,,veeeerain,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jpx16z/transitioning_from_sequential_api_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jpx16z/transitioning_from_sequential_api_to/,22217,1604778867.0,0,,False,,,,,,,,,
556,,tensorflow,"For example I have nine classes. Lets say a class makes up 5% of the data, should I set that weight to 0.95 or some other number based off the other classes? 



Class| % of data | weight
---|---|----
1| 20| ?
2| 10| ?
3| 40| ?
4| 30| ?

How would I select the weights for this? would it be

Class| % of data | weight
---|---|----
1| 20| 0.8
2| 10| 0.9
3| 40| 0.6
4| 30| 0.7

or something else?",t2_5wuzf,False,,0,False,"When weighting imbalanced classes, should the weights add up to 1 or should each weight be proportional to it's representation in the data?",[],r/tensorflow,False,6,,0,,,False,t3_jpz0qd,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1604814260.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For example I have nine classes. Lets say a class makes up 5% of the data, should I set that weight to 0.95 or some other number based off the other classes? &lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Class&lt;/th&gt;
&lt;th&gt;% of data&lt;/th&gt;
&lt;th&gt;weight&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;How would I select the weights for this? would it be&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Class&lt;/th&gt;
&lt;th&gt;% of data&lt;/th&gt;
&lt;th&gt;weight&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;0.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;0.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;or something else?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jpz0qd,True,,thejeran,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jpz0qd/when_weighting_imbalanced_classes_should_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jpz0qd/when_weighting_imbalanced_classes_should_the/,22217,1604785460.0,0,,False,,,,,,,,,
557,,tensorflow,"Iris tracking enables many applications, such as hands-free interfaces for assistive technologies and understanding user behavior beyond clicks and gestures. It is also a challenging computer vision problem. The major challenge in iris tracking is that sometimes eyes may appear different under variable light conditions, or occluded by the hair, or the shape may depend on the head’s angle of rotation and the person’s expression. Current solutions rely heavily on specialized hardware that requires an expensive headset or a remote eye tracker system. Since mobile devices have limited computing resources, these approaches do not serve mobile devices’ purposes.

In March 2020, TensorFlow announced a new package for detecting facial landmarks in the browser. Recently, in addition to this package, it came up with the addition of a new feature, i.e., iris tracking through [TensorFlow.js face landmarks detection model](https://www.npmjs.com/package/@tensorflow-models/face-landmarks-detection).

Summary: [https://www.marktechpost.com/2020/11/06/tensorflow-introduces-improved-iris-tracking-in-the-browser-with-tensorflow-js-face-landmarks-detection-model/](https://www.marktechpost.com/2020/11/06/tensorflow-introduces-improved-iris-tracking-in-the-browser-with-tensorflow-js-face-landmarks-detection-model/)

Demo: [https://storage.googleapis.com/tfjs-models/demos/face-landmarks-detection/index.html](https://storage.googleapis.com/tfjs-models/demos/face-landmarks-detection/index.html)

Source: https://blog.tensorflow.org/2020/11/iris-landmark-tracking-in-browser-with-MediaPipe-and-TensorFlowJS.html  

&amp;#x200B;

https://i.redd.it/404dz6a0hnx51.gif",t2_2wsvqwhg,False,,0,False,TensorFlow Introduces Improved Iris Tracking In The Browser With TensorFlow.js Face Landmarks Detection Model,[],r/tensorflow,False,6,,0,73.0,,False,t3_jp8ocq,False,dark,0.95,,public,20,0,{},140.0,,False,[],,False,False,,{},Discussion,False,20,,False,https://b.thumbs.redditmedia.com/DxbkaadwJ7pYRAvQcmGjxpo0VBg3ji9oT6WuubwSjpg.jpg,False,,[],{},,True,,1604710493.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Iris tracking enables many applications, such as hands-free interfaces for assistive technologies and understanding user behavior beyond clicks and gestures. It is also a challenging computer vision problem. The major challenge in iris tracking is that sometimes eyes may appear different under variable light conditions, or occluded by the hair, or the shape may depend on the head’s angle of rotation and the person’s expression. Current solutions rely heavily on specialized hardware that requires an expensive headset or a remote eye tracker system. Since mobile devices have limited computing resources, these approaches do not serve mobile devices’ purposes.&lt;/p&gt;

&lt;p&gt;In March 2020, TensorFlow announced a new package for detecting facial landmarks in the browser. Recently, in addition to this package, it came up with the addition of a new feature, i.e., iris tracking through &lt;a href=""https://www.npmjs.com/package/@tensorflow-models/face-landmarks-detection""&gt;TensorFlow.js face landmarks detection model&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/11/06/tensorflow-introduces-improved-iris-tracking-in-the-browser-with-tensorflow-js-face-landmarks-detection-model/""&gt;https://www.marktechpost.com/2020/11/06/tensorflow-introduces-improved-iris-tracking-in-the-browser-with-tensorflow-js-face-landmarks-detection-model/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Demo: &lt;a href=""https://storage.googleapis.com/tfjs-models/demos/face-landmarks-detection/index.html""&gt;https://storage.googleapis.com/tfjs-models/demos/face-landmarks-detection/index.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Source: &lt;a href=""https://blog.tensorflow.org/2020/11/iris-landmark-tracking-in-browser-with-MediaPipe-and-TensorFlowJS.html""&gt;https://blog.tensorflow.org/2020/11/iris-landmark-tracking-in-browser-with-MediaPipe-and-TensorFlowJS.html&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/404dz6a0hnx51.gif""&gt;https://i.redd.it/404dz6a0hnx51.gif&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jp8ocq,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jp8ocq/tensorflow_introduces_improved_iris_tracking_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jp8ocq/tensorflow_introduces_improved_iris_tracking_in/,22217,1604681693.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?auto=webp&amp;s=dc9f3722e4f26a0d394e974bdc658bd002ee6f3d', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=29849972d1063666bb20bfca982ed849dbab0739', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2e78155bcf431bc82859db1b9cc141779445961', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b8fc1121ee3f0761b7c5ec9e306f65c99c715db', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18cce76337e2ca3f939805374b20a68b0a1671af', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=940123d8c0b4043a88a028062a5a195676254f4d', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/WaI7ci8y_BucxfTyRMw9rEGVoXvk-w3erN7z645l-H8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=70f261d64e65120035e417a634c19726e4e3576d', 'width': 1080, 'height': 567}], 'variants': {}, 'id': '3CAm7f2euOP7diXidheIHavSdc1loh3U46B-FOssKu4'}], 'enabled': False}",,"{'404dz6a0hnx51': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 35, 'x': 108, 'u': 'https://preview.redd.it/404dz6a0hnx51.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=8e78fbb9fa20d3f0ed1cdd4b4348743553528730'}, {'y': 70, 'x': 216, 'u': 'https://preview.redd.it/404dz6a0hnx51.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=296cfb9251aa1e9cee469bca892eedcc26f874ee'}, {'y': 104, 'x': 320, 'u': 'https://preview.redd.it/404dz6a0hnx51.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=dfc8c9ac4a89346c860bfdd1b9db02d4a9cab0f3'}, {'y': 209, 'x': 640, 'u': 'https://preview.redd.it/404dz6a0hnx51.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=b92631652a70444c03c8701375a2ca5b1ef63938'}], 's': {'y': 262, 'gif': 'https://i.redd.it/404dz6a0hnx51.gif', 'mp4': 'https://preview.redd.it/404dz6a0hnx51.gif?format=mp4&amp;s=a5bd93c1dd865ed99e40a88c26a1f3be52d6f37d', 'x': 800}, 'id': '404dz6a0hnx51'}}",,,,
558,,tensorflow,"I am using Python3 and TensorFlow 2.0 and I have a pruned LeNet-300-100 Dense neural network with 94.44% sparsity. The layer-wise number of surviving parameters are:

layer: (784, 300) has 12932 parameters

layer: (300,) has 0 parameters

layer: (300, 100) has 1650 parameters

layer: (100,) has 0 parameters

layer: (100, 10) has 254 parameters

layer: (10,) has 0 parameters

&amp;#x200B;

Pruned LeNet-300-100 has 14836 surviving parameters, whereas the original and unpruned model has 266610 parameters/weights.

&amp;#x200B;

The code to define the LeNet-300-100 architecture is:

&amp;#x200B;

        def lenet_nn():
            """"""
            Function to define the architecture of a dense neural network
            model following 300 100 architecture for MNIST dataset.        
            Output: Returns designed and compiled neural network model
            """"""        
            model = Sequential()    
            model.add(InputLayer(input_shape=(784, )))
            # model.add(Flatten())        
            model.add(Dense(units = 300, activation='relu', kernel_initializer=tf.initializers.GlorotUniform()))
            # model.add(l.Dropout(0.2))
            model.add(Dense(units = 100, activation='relu', kernel_initializer=tf.initializers.GlorotUniform()))            
            # model.add(l.Dropout(0.1))    
            model.add(Dense(units = num_classes, activation='softmax'))
            # Compile NN-
            model.compile(
                loss=tf.keras.losses.categorical_crossentropy,
                # optimizer='adam',
                optimizer=tf.keras.optimizers.Adam(lr = 0.0012),
                metrics=['accuracy'])
    
            return model

&amp;#x200B;

Once I have the pruned model with 94.44% sparsity, how can I remove the dead neurons which don't get activated anymore due to the pruning? This should give a new architecture due to pruning of the neurons.

&amp;#x200B;

Thanks",t2_2mmql89p,False,,0,False,Pruning neurons - TensorFlow2,[],r/tensorflow,False,6,,0,,,False,t3_jpbgjv,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1604719196.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using Python3 and TensorFlow 2.0 and I have a pruned LeNet-300-100 Dense neural network with 94.44% sparsity. The layer-wise number of surviving parameters are:&lt;/p&gt;

&lt;p&gt;layer: (784, 300) has 12932 parameters&lt;/p&gt;

&lt;p&gt;layer: (300,) has 0 parameters&lt;/p&gt;

&lt;p&gt;layer: (300, 100) has 1650 parameters&lt;/p&gt;

&lt;p&gt;layer: (100,) has 0 parameters&lt;/p&gt;

&lt;p&gt;layer: (100, 10) has 254 parameters&lt;/p&gt;

&lt;p&gt;layer: (10,) has 0 parameters&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Pruned LeNet-300-100 has 14836 surviving parameters, whereas the original and unpruned model has 266610 parameters/weights.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The code to define the LeNet-300-100 architecture is:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    def lenet_nn():
        &amp;quot;&amp;quot;&amp;quot;
        Function to define the architecture of a dense neural network
        model following 300 100 architecture for MNIST dataset.        
        Output: Returns designed and compiled neural network model
        &amp;quot;&amp;quot;&amp;quot;        
        model = Sequential()    
        model.add(InputLayer(input_shape=(784, )))
        # model.add(Flatten())        
        model.add(Dense(units = 300, activation=&amp;#39;relu&amp;#39;, kernel_initializer=tf.initializers.GlorotUniform()))
        # model.add(l.Dropout(0.2))
        model.add(Dense(units = 100, activation=&amp;#39;relu&amp;#39;, kernel_initializer=tf.initializers.GlorotUniform()))            
        # model.add(l.Dropout(0.1))    
        model.add(Dense(units = num_classes, activation=&amp;#39;softmax&amp;#39;))
        # Compile NN-
        model.compile(
            loss=tf.keras.losses.categorical_crossentropy,
            # optimizer=&amp;#39;adam&amp;#39;,
            optimizer=tf.keras.optimizers.Adam(lr = 0.0012),
            metrics=[&amp;#39;accuracy&amp;#39;])

        return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Once I have the pruned model with 94.44% sparsity, how can I remove the dead neurons which don&amp;#39;t get activated anymore due to the pruning? This should give a new architecture due to pruning of the neurons.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jpbgjv,True,,grid_world,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jpbgjv/pruning_neurons_tensorflow2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jpbgjv/pruning_neurons_tensorflow2/,22217,1604690396.0,0,,False,,,,,,,,,
559,,tensorflow,"Part of my preprocessing is to convert images into arrays. But this is a timely process as it has to go through each pixel. I'd like to export all my images as arrays instead.

However, exporting such numpy arrays makes it 26MB per array. which would add up to 200GB for all my images. What other ways are there?

SOLVED: I had my arrays as float64 and not int8",t2_5wuzf,False,,0,False,Whats the most disk space friendly way to save arrays?,[],r/tensorflow,False,6,,0,,,False,t3_josaml,False,dark,1.0,,public,15,0,{},,,False,[],,False,False,,{},Question,False,15,,False,self,1604655205.0,,[],{},,True,,1604643039.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Part of my preprocessing is to convert images into arrays. But this is a timely process as it has to go through each pixel. I&amp;#39;d like to export all my images as arrays instead.&lt;/p&gt;

&lt;p&gt;However, exporting such numpy arrays makes it 26MB per array. which would add up to 200GB for all my images. What other ways are there?&lt;/p&gt;

&lt;p&gt;SOLVED: I had my arrays as float64 and not int8&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,josaml,True,,thejeran,,24,True,all_ads,False,[],False,,/r/tensorflow/comments/josaml/whats_the_most_disk_space_friendly_way_to_save/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/josaml/whats_the_most_disk_space_friendly_way_to_save/,22217,1604614239.0,0,,False,,,,,,,,,
560,,tensorflow,"    from tensorflow.keras.datasets import reuters
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, LSTM, Embedding, Flatten, Input
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.models import load_model
    
    (X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)
    
    max_len = 100
    X_train = pad_sequences(X_train, maxlen=max_len)
    X_test = pad_sequences(X_test, maxlen=max_len)
    
    y_train = to_categorical(y_train)
    y_test = to_categorical(y_test)
    
    model = Sequential()
    model.add(Embedding(1000, 120))
    model.add(Dense(120))
    model.add(Dense(46, activation='softmax'))
    
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])
    history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))

I use model.add(LSTM(120)) replace to Dense(120)

but get a error message. I don't now what I'm wrong. It is very simple code

Any one help me? How should I fix this code?

    InvalidArgumentError: 2 root error(s) found.
      (0) Invalid argument:  Incompatible shapes: [32] vs. [32,100]
    	 [[node metrics/acc/Equal (defined at &lt;ipython-input-10-aa5270d1cea3&gt;:25) ]]
    	 [[Reshape_20/_58]]
      (1) Invalid argument:  Incompatible shapes: [32] vs. [32,100]
    	 [[node metrics/acc/Equal (defined at &lt;ipython-input-10-aa5270d1cea3&gt;:25) ]]
    0 successful operations.
    0 derived errors ignored. [Op:__inference_distributed_function_3063]
    
    Function call stack:
    distributed_function -&gt; distributed_function",t2_8rxp96qv,False,,0,False,using dense layer instead of lstm,[],r/tensorflow,False,6,,0,,,False,t3_jozyd1,False,dark,0.75,,public,2,1,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1604644005.0,,[],{'gid_1': 1},,True,,1604672339.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;from tensorflow.keras.datasets import reuters
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Embedding, Flatten, Input
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import load_model

(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)

max_len = 100
X_train = pad_sequences(X_train, maxlen=max_len)
X_test = pad_sequences(X_test, maxlen=max_len)

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

model = Sequential()
model.add(Embedding(1000, 120))
model.add(Dense(120))
model.add(Dense(46, activation=&amp;#39;softmax&amp;#39;))

model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;, optimizer=&amp;#39;adam&amp;#39;, metrics=[&amp;#39;acc&amp;#39;])
history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I use model.add(LSTM(120)) replace to Dense(120)&lt;/p&gt;

&lt;p&gt;but get a error message. I don&amp;#39;t now what I&amp;#39;m wrong. It is very simple code&lt;/p&gt;

&lt;p&gt;Any one help me? How should I fix this code?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Incompatible shapes: [32] vs. [32,100]
     [[node metrics/acc/Equal (defined at &amp;lt;ipython-input-10-aa5270d1cea3&amp;gt;:25) ]]
     [[Reshape_20/_58]]
  (1) Invalid argument:  Incompatible shapes: [32] vs. [32,100]
     [[node metrics/acc/Equal (defined at &amp;lt;ipython-input-10-aa5270d1cea3&amp;gt;:25) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_3063]

Function call stack:
distributed_function -&amp;gt; distributed_function
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jozyd1,True,,akari_tsumugi,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jozyd1/using_dense_layer_instead_of_lstm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jozyd1/using_dense_layer_instead_of_lstm/,22217,1604643539.0,0,,False,,,,,,,,,
561,,tensorflow,"Currently, we have a PC with 2080Ti for training and we would like to know besides the training time difference between running tensor with GPU and CPU-only, are there any significant difference for object detection part? 

We are looking for a mini PC to fit in our robot for object detection and we're not sure whether to get the one with Nvidia GPU or a normal one with built-in Intel Graphics.",t2_8qitli23,False,,0,False,Tensorflow with GPU vs CPU-only,[],r/tensorflow,False,6,,0,,,False,t3_jowgjj,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1604658016.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Currently, we have a PC with 2080Ti for training and we would like to know besides the training time difference between running tensor with GPU and CPU-only, are there any significant difference for object detection part? &lt;/p&gt;

&lt;p&gt;We are looking for a mini PC to fit in our robot for object detection and we&amp;#39;re not sure whether to get the one with Nvidia GPU or a normal one with built-in Intel Graphics.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jowgjj,True,,ariccspstk,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/jowgjj/tensorflow_with_gpu_vs_cpuonly/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jowgjj/tensorflow_with_gpu_vs_cpuonly/,22217,1604629216.0,0,,False,,,,,,,,,
562,,tensorflow,"Greetings, I am a little bit of a  beginner in TensorFlow, today I came across this piece of code for train validation split.

'

\#  Start Training CNN with Parameters.validation\_generator = train\_datagen.flow\_from\_directory(                       train\_dir, # same directory as training data                       target\_size=(img\_height, img\_width),                       batch\_size=batch\_size)opt=keras.optimizers.Adam(lr=0.001)model.compile(optimizer=opt,loss='categorical\_crossentropy',metrics=\['accuracy'\])train=model.fit\_generator(train\_generator,                          nb\_epoch=10,                          steps\_per\_epoch=train\_generator.samples//batch\_size,                          validation\_data=validation\_generator,                          nb\_val\_samples=validation\_generator.samples//batch\_size,                          verbose=1)

'",t2_6gkg6e3l,False,,0,False,"I came across this code for train validation split online, is this actually correct?",[],r/tensorflow,False,6,,0,,,False,t3_joty7r,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1604656178.0,,[],{},,True,,1604648648.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Greetings, I am a little bit of a  beginner in TensorFlow, today I came across this piece of code for train validation split.&lt;/p&gt;

&lt;p&gt;&amp;#39;&lt;/p&gt;

&lt;p&gt;#  Start Training CNN with Parameters.validation_generator = train_datagen.flow_from_directory(                       train_dir, # same directory as training data                       target_size=(img_height, img_width),                       batch_size=batch_size)opt=keras.optimizers.Adam(lr=0.001)model.compile(optimizer=opt,loss=&amp;#39;categorical_crossentropy&amp;#39;,metrics=[&amp;#39;accuracy&amp;#39;])train=model.fit_generator(train_generator,                          nb_epoch=10,                          steps_per_epoch=train_generator.samples//batch_size,                          validation_data=validation_generator,                          nb_val_samples=validation_generator.samples//batch_size,                          verbose=1)&lt;/p&gt;

&lt;p&gt;&amp;#39;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,joty7r,True,,Learner1729,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/joty7r/i_came_across_this_code_for_train_validation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/joty7r/i_came_across_this_code_for_train_validation/,22217,1604619848.0,0,,False,,,,,,,,,
563,,tensorflow,"I have mainly done a lot of computer vision in tensorflow, but I’ve yet to explore NLP, but I have an end goal of a project I definitely want to do once I learn the preprocessing/architectures associated with NLP. Have any of you tried doing a project with auto music generation? Some context: my plan is to scrape songs from an artists discography, and create a model to build a new song from the lyrics it has learned. Is this something which is plausible? Has anyone done this and could maybe drop a repo to see how you went about it? 

Again I’m quite new to deep learning + NLP and have only worked with CNNs so please enlighten me if this is something which is even possible or not",t2_5w4i5kd1,False,,0,False,NLP and Auto Music Generation?,[],r/tensorflow,False,6,,0,,,False,t3_joim3m,False,dark,1.0,,public,11,0,{},,,False,[],,False,False,,{},Question,False,11,,False,self,False,,[],{},,True,,1604611150.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have mainly done a lot of computer vision in tensorflow, but I’ve yet to explore NLP, but I have an end goal of a project I definitely want to do once I learn the preprocessing/architectures associated with NLP. Have any of you tried doing a project with auto music generation? Some context: my plan is to scrape songs from an artists discography, and create a model to build a new song from the lyrics it has learned. Is this something which is plausible? Has anyone done this and could maybe drop a repo to see how you went about it? &lt;/p&gt;

&lt;p&gt;Again I’m quite new to deep learning + NLP and have only worked with CNNs so please enlighten me if this is something which is even possible or not&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,joim3m,True,,veeeerain,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/joim3m/nlp_and_auto_music_generation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/joim3m/nlp_and_auto_music_generation/,22217,1604582350.0,0,,False,,,,,,,,,
564,,tensorflow,"Is it possible to retrain a .tflite model? 

Do we have to convert it to .pb tensorflow format? Or is it possible to train the model in the tflite format?",t2_2oelp4gv,False,,0,False,TFlite training,[],r/tensorflow,False,6,,0,,,False,t3_jotyk0,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1604648680.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to retrain a .tflite model? &lt;/p&gt;

&lt;p&gt;Do we have to convert it to .pb tensorflow format? Or is it possible to train the model in the tflite format?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jotyk0,True,,BrunoMelicio,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jotyk0/tflite_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jotyk0/tflite_training/,22217,1604619880.0,0,,False,,,,,,,,,
565,,tensorflow,"Hi,

I am training a GAN model and training performance are pretty bad (cpu &lt; 5%, gpu &lt; 20% )

Because it is a GAN model I train only on small batches and it seems to be the reason that I can;t leverage the full gpu.

Recently, I got access to a hpc with many GPUs so I converted my dataset to tf\_records and added the distribute strategy. The training seems to be dispatched properly but it is still very slow.

Would there be a way to tell TF to distribute the training on every core, like it does for the gpu ?",t2_11cnwe,False,,0,False,Distributed training for gan model,[],r/tensorflow,False,6,,0,,,False,t3_jnzoz7,False,dark,0.79,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1604536007.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am training a GAN model and training performance are pretty bad (cpu &amp;lt; 5%, gpu &amp;lt; 20% )&lt;/p&gt;

&lt;p&gt;Because it is a GAN model I train only on small batches and it seems to be the reason that I can;t leverage the full gpu.&lt;/p&gt;

&lt;p&gt;Recently, I got access to a hpc with many GPUs so I converted my dataset to tf_records and added the distribute strategy. The training seems to be dispatched properly but it is still very slow.&lt;/p&gt;

&lt;p&gt;Would there be a way to tell TF to distribute the training on every core, like it does for the gpu ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jnzoz7,True,,DNA1987,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jnzoz7/distributed_training_for_gan_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jnzoz7/distributed_training_for_gan_model/,22217,1604507207.0,0,,False,,,,,,,,,
566,,tensorflow,Does anyone know of an MS COCO or other dataset that will detect windows/window panes?,t2_3r7d1ob2,False,,0,False,Windows/Window Pane Detection,[],r/tensorflow,False,6,,0,,,False,t3_jo01gb,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1604537119.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone know of an MS COCO or other dataset that will detect windows/window panes?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jo01gb,True,,von_roga,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jo01gb/windowswindow_pane_detection/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jo01gb/windowswindow_pane_detection/,22217,1604508319.0,0,,False,,,,,,,,,
567,,tensorflow,,t2_5p0v62j0,False,,0,False,Why is this model with pre-trained weights poor? (there's an obvious person in the test picture),[],r/tensorflow,False,6,,0,80.0,,False,t3_jnjn1i,False,dark,1.0,,public,18,0,{},140.0,,False,[],,True,False,,{},,False,18,,False,https://b.thumbs.redditmedia.com/Qz-V9AyV-myUKuVF2u6dmVfeirw80-7_CUMTGmnPDdE.jpg,False,,[],{},,False,,1604468845.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jnjn1i,True,,Even-Fisherman,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/jnjn1i/why_is_this_model_with_pretrained_weights_poor/,all_ads,False,https://i.redd.it/mh21mf3ei3x51.png,22217,1604440045.0,0,,False,image,https://i.redd.it/mh21mf3ei3x51.png,"{'images': [{'source': {'url': 'https://preview.redd.it/mh21mf3ei3x51.png?auto=webp&amp;s=fa7bf0b36514d59e49ac1947088a01623e2f8f4f', 'width': 1295, 'height': 741}, 'resolutions': [{'url': 'https://preview.redd.it/mh21mf3ei3x51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8d2fdab5f8d78f38184b769d58c0b13cc000dab', 'width': 108, 'height': 61}, {'url': 'https://preview.redd.it/mh21mf3ei3x51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f375d61c35b6203c5111e7926788a8d1555f044', 'width': 216, 'height': 123}, {'url': 'https://preview.redd.it/mh21mf3ei3x51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=553bec65f8943bb4faf15eec349651fefb38f8f8', 'width': 320, 'height': 183}, {'url': 'https://preview.redd.it/mh21mf3ei3x51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e6572d89de90fa5ce41fda2e1fb429af795dd60', 'width': 640, 'height': 366}, {'url': 'https://preview.redd.it/mh21mf3ei3x51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e0a409e208354be48063887f94c67a1fe9e70809', 'width': 960, 'height': 549}, {'url': 'https://preview.redd.it/mh21mf3ei3x51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f255b850761dbc4a855ae2006e7f4a002295c078', 'width': 1080, 'height': 617}], 'variants': {}, 'id': '3oHB_73hx-Ic_avYwVzvp4CbQYOYeT-D_D9qQOGbJIg'}], 'enabled': True}",,,,,,
568,,tensorflow,,t2_79p1h62w,False,,0,False,Build a Collaborative Chatbot with Google Sheets and TensorFlow,[],r/tensorflow,False,6,,0,79.0,,False,t3_jn548v,False,dark,0.92,,public,9,0,{},140.0,,False,[],,False,False,,{},,False,9,,False,https://b.thumbs.redditmedia.com/Cz7Z7I1StsafCUYXagJZ4AH_qU8-a_SIcQ0ivQJmi3k.jpg,False,,[],{},,False,,1604412182.0,text,6,,,text,jonathanbgn.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jn548v,True,,Shradha_Singh,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jn548v/build_a_collaborative_chatbot_with_google_sheets/,all_ads,False,https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html,22217,1604383382.0,0,,False,link,https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html,"{'images': [{'source': {'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?auto=webp&amp;s=bea45c962a7e5cc700fa5412a2f34b239e0ca589', 'width': 2356, 'height': 1332}, 'resolutions': [{'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb368e808363deacc2768fd67af8798046949f45', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d04fc327c4428e23d324aeba4fd5651dbae3811', 'width': 216, 'height': 122}, {'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5960d7d7b13f7e85abf164a916f4eb5f7276400f', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e10d6e91de7e1bc26e06d4511adee27f370fcccb', 'width': 640, 'height': 361}, {'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5e3553c2e654af2d3841517eb0733b2b1a4a98f', 'width': 960, 'height': 542}, {'url': 'https://external-preview.redd.it/xyFU5BZjV9Bv2pBS_IkJZdmJYTMCFJgEP26ZOwrr6UU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9243e9309e59b4362500d64248a5308194f2968', 'width': 1080, 'height': 610}], 'variants': {}, 'id': 'ccgRYQV4O98YxQKTC8J0blgOFkrCN5eOF2HZxdLNFdY'}], 'enabled': False}",,,,,,
569,,tensorflow,,t2_aa5s6ix,False,,0,False,Pre-Release: TensorFlow 2.4.0-rc0,[],r/tensorflow,False,6,,0,140.0,,False,t3_jmz3gw,False,dark,0.98,,public,28,0,{},140.0,,False,[],,False,False,,{},Discussion,False,28,,False,https://a.thumbs.redditmedia.com/2xlRWAzBrtnnquvtYoqgLtRgbC31d_hdAI6tpP2yl18.jpg,False,,[],{},,False,,1604389016.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jmz3gw,True,,cryptoel,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/jmz3gw/prerelease_tensorflow_240rc0/,all_ads,False,https://github.com/tensorflow/tensorflow/releases/tag/v2.4.0-rc0,22217,1604360216.0,0,,False,link,https://github.com/tensorflow/tensorflow/releases/tag/v2.4.0-rc0,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
570,,tensorflow,"I've installed TensorFlow cuda from the Arch Linux repos (tensorflow-cuda python-tensorflow-cuda packages) and this behaviour is happening when summing float tensors:

    a = tf.constant(1.0)
    b = tf.constant(2.0)
    tf.print(tf.add(a, b))

This operation gives a scalar tensor with value 0.

This is the whole output with tf logs: [https://pastebin.com/HGxJZJBg](https://pastebin.com/HGxJZJBg)

Im wondering whether this happened to someone else and im doing something wrong or its a bug in the arch package.",t2_1obznewx,False,,0,False,TensorFlow installation gives weird results when working with float tensors,[],r/tensorflow,False,6,,0,,,False,t3_jn7z9m,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1604427945.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve installed TensorFlow cuda from the Arch Linux repos (tensorflow-cuda python-tensorflow-cuda packages) and this behaviour is happening when summing float tensors:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a = tf.constant(1.0)
b = tf.constant(2.0)
tf.print(tf.add(a, b))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This operation gives a scalar tensor with value 0.&lt;/p&gt;

&lt;p&gt;This is the whole output with tf logs: &lt;a href=""https://pastebin.com/HGxJZJBg""&gt;https://pastebin.com/HGxJZJBg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Im wondering whether this happened to someone else and im doing something wrong or its a bug in the arch package.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jn7z9m,True,,ekardnam_,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jn7z9m/tensorflow_installation_gives_weird_results_when/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jn7z9m/tensorflow_installation_gives_weird_results_when/,22217,1604399145.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;s=07c121a0180003f7373863af66192b6ff6a937da', 'width': 150, 'height': 150}, 'resolutions': [{'url': 'https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9c6a296446d05d873c629a30253398c4d29c1b', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs'}], 'enabled': False}",,,,,,
571,,tensorflow,"So I've been following the tutorial to create a linear model from here:

[https://www.tensorflow.org/tutorials/estimator/linear](https://www.tensorflow.org/tutorials/estimator/linear)

I have now changed the data set to fit my project. I am trying to use this linear model to predict the next day's increase in covid cases. I don't know if my error has to do with the way I set up my data or something else. I'm not super experienced with TensorFlow so I don't even know if I'm using the wrong model for my project.

This is the error I get:

    tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Labels must be &lt;= n_classes - 1] [Condition x &lt;= y did not hold element-wise:] [x (head/losses/Cast:0) = ] [[28037][31986][88452]...] [y (head/losses/check_label_range/Const:0) = ] [1]
     `[[{{node Assert}}]]`

And this is my code:

    import os
    import sys
    
    import numpy as np
    import pandas as pd
    
    from IPython.display import clear_output
    
    import tensorflow as tf
    from tensorflow import data
    
    Data = data.Dataset
    
    # initialize dataframe for prediction model
    df = pd.read_csv('https://api.covidtracking.com/v1/us/daily.csv')
    positive_increase_change = []
    for i in range(len(df.index) - 1):
        positive_increase_change.append(df['positiveIncrease'].tolist()[i] - df['positiveIncrease'].tolist()[i + 1])
    positive_increase_change.append(0)
    
    df.insert(3, 'positiveIncreaseDifference', positive_increase_change, True)
    df = df[df['date'] &gt;= 20200329]
    
    
    def add_num_days_col():
        """"""Adds a column to dataframe with days for later calculations""""""
        days = []
        for i in range(len(df.index)):
            days.append(i + 1)
        days.reverse()
        df.insert(0, ""days"", days, True)
    
    
    add_num_days_col()
    
    # creating training and eval set
    dftrain = df.loc[1:, :].copy()
    dfeval = df.loc[0, :].copy()
    dftrain, dfeval = dftrain[['positiveIncrease','pending', 'recovered', 'positiveIncreaseDifference']], dfeval[['positiveIncrease','pending', 'recovered', 'positiveIncreaseDifference']]
    y_train = dftrain.pop('positiveIncrease')
    y_eval = dfeval.pop('positiveIncrease')
    
    dftrain.describe()
    
    # picking columns for use in model
    NUMERIC_COLUMNS = ['pending', 'positiveIncreaseDifference']
    feature_columns = []
    for feature_name in NUMERIC_COLUMNS:
        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))
    
    
    
    def make_input_fn(data_df, label_df, num_epochs=5, shuffle=True, batch_size=32):
        """"""Make TensorFlow input for actual model testing""""""
        def input_function():
            ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))
            if shuffle:
                ds = ds.shuffle(1000)
            ds = ds.batch(batch_size).repeat(num_epochs)
            return ds
    
        return input_function
    
    
    train_input_fn = make_input_fn(dftrain, y_train)
    eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)
    
    
    linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)
    
    linear_est.train(train_input_fn)
    result = linear_est.evaluate(eval_input_fn)
    
    clear_output()
    print(result['accuracy'])
    
    pred_dicts = list(linear_est.predict(eval_input_fn))
    print(pred_dicts)

I have kinda pinpointed it to the fact that my batch numbers are really large. Other models I've seen have batch values of 0 or 1. If anyone knows what's wrong with my model and can help that would be greatly appreciated!",t2_8kgm2cz,False,,0,False,Training model gives me an AssertionError and I don't really know how to solve this. Would love the help!,[],r/tensorflow,False,6,,0,,,False,t3_jn5bq9,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1604413186.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;ve been following the tutorial to create a linear model from here:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.tensorflow.org/tutorials/estimator/linear""&gt;https://www.tensorflow.org/tutorials/estimator/linear&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have now changed the data set to fit my project. I am trying to use this linear model to predict the next day&amp;#39;s increase in covid cases. I don&amp;#39;t know if my error has to do with the way I set up my data or something else. I&amp;#39;m not super experienced with TensorFlow so I don&amp;#39;t even know if I&amp;#39;m using the wrong model for my project.&lt;/p&gt;

&lt;p&gt;This is the error I get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Labels must be &amp;lt;= n_classes - 1] [Condition x &amp;lt;= y did not hold element-wise:] [x (head/losses/Cast:0) = ] [[28037][31986][88452]...] [y (head/losses/check_label_range/Const:0) = ] [1]
 `[[{{node Assert}}]]`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is my code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
import sys

import numpy as np
import pandas as pd

from IPython.display import clear_output

import tensorflow as tf
from tensorflow import data

Data = data.Dataset

# initialize dataframe for prediction model
df = pd.read_csv(&amp;#39;https://api.covidtracking.com/v1/us/daily.csv&amp;#39;)
positive_increase_change = []
for i in range(len(df.index) - 1):
    positive_increase_change.append(df[&amp;#39;positiveIncrease&amp;#39;].tolist()[i] - df[&amp;#39;positiveIncrease&amp;#39;].tolist()[i + 1])
positive_increase_change.append(0)

df.insert(3, &amp;#39;positiveIncreaseDifference&amp;#39;, positive_increase_change, True)
df = df[df[&amp;#39;date&amp;#39;] &amp;gt;= 20200329]


def add_num_days_col():
    &amp;quot;&amp;quot;&amp;quot;Adds a column to dataframe with days for later calculations&amp;quot;&amp;quot;&amp;quot;
    days = []
    for i in range(len(df.index)):
        days.append(i + 1)
    days.reverse()
    df.insert(0, &amp;quot;days&amp;quot;, days, True)


add_num_days_col()

# creating training and eval set
dftrain = df.loc[1:, :].copy()
dfeval = df.loc[0, :].copy()
dftrain, dfeval = dftrain[[&amp;#39;positiveIncrease&amp;#39;,&amp;#39;pending&amp;#39;, &amp;#39;recovered&amp;#39;, &amp;#39;positiveIncreaseDifference&amp;#39;]], dfeval[[&amp;#39;positiveIncrease&amp;#39;,&amp;#39;pending&amp;#39;, &amp;#39;recovered&amp;#39;, &amp;#39;positiveIncreaseDifference&amp;#39;]]
y_train = dftrain.pop(&amp;#39;positiveIncrease&amp;#39;)
y_eval = dfeval.pop(&amp;#39;positiveIncrease&amp;#39;)

dftrain.describe()

# picking columns for use in model
NUMERIC_COLUMNS = [&amp;#39;pending&amp;#39;, &amp;#39;positiveIncreaseDifference&amp;#39;]
feature_columns = []
for feature_name in NUMERIC_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))



def make_input_fn(data_df, label_df, num_epochs=5, shuffle=True, batch_size=32):
    &amp;quot;&amp;quot;&amp;quot;Make TensorFlow input for actual model testing&amp;quot;&amp;quot;&amp;quot;
    def input_function():
        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))
        if shuffle:
            ds = ds.shuffle(1000)
        ds = ds.batch(batch_size).repeat(num_epochs)
        return ds

    return input_function


train_input_fn = make_input_fn(dftrain, y_train)
eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)


linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)

linear_est.train(train_input_fn)
result = linear_est.evaluate(eval_input_fn)

clear_output()
print(result[&amp;#39;accuracy&amp;#39;])

pred_dicts = list(linear_est.predict(eval_input_fn))
print(pred_dicts)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have kinda pinpointed it to the fact that my batch numbers are really large. Other models I&amp;#39;ve seen have batch values of 0 or 1. If anyone knows what&amp;#39;s wrong with my model and can help that would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jn5bq9,True,,bobchickenham,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jn5bq9/training_model_gives_me_an_assertionerror_and_i/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jn5bq9/training_model_gives_me_an_assertionerror_and_i/,22217,1604384386.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
572,,tensorflow,,t2_47jpmh5m,False,,0,False,"Top 38 Python Libraries for Data Science, Data Visualization, and Machine Learning.",[],r/tensorflow,False,6,,0,112.0,,False,t3_jms4fw,False,dark,0.93,,public,21,0,{},140.0,,False,[],,False,False,,{},,False,21,,False,https://a.thumbs.redditmedia.com/s2EAUKT0jFXGZQosci6Twe8IuRV63pgM21ltsTMPhh0.jpg,False,,[],{},,False,,1604367575.0,text,6,,,text,kdnuggets.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jms4fw,True,,ItisAhmad,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jms4fw/top_38_python_libraries_for_data_science_data/,all_ads,False,https://www.kdnuggets.com/2020/11/top-python-libraries-data-science-data-visualization-machine-learning.html,22217,1604338775.0,0,,False,link,https://www.kdnuggets.com/2020/11/top-python-libraries-data-science-data-visualization-machine-learning.html,"{'images': [{'source': {'url': 'https://external-preview.redd.it/9IxVjvwYxrt6v0Qutzl5gdz82k5Z5s1X3QqHxt7HNwU.jpg?auto=webp&amp;s=c6fb9bbc8aa8c9444909c2fb7cf32d515b664982', 'width': 946, 'height': 760}, 'resolutions': [{'url': 'https://external-preview.redd.it/9IxVjvwYxrt6v0Qutzl5gdz82k5Z5s1X3QqHxt7HNwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81a087aa2c199eaebf01253402b825a3bab52c75', 'width': 108, 'height': 86}, {'url': 'https://external-preview.redd.it/9IxVjvwYxrt6v0Qutzl5gdz82k5Z5s1X3QqHxt7HNwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=28181af28138301323e15b5a049a5ba4e8caa506', 'width': 216, 'height': 173}, {'url': 'https://external-preview.redd.it/9IxVjvwYxrt6v0Qutzl5gdz82k5Z5s1X3QqHxt7HNwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac63c2005b3ac44220e65cbce55ebdc6df33e29e', 'width': 320, 'height': 257}, {'url': 'https://external-preview.redd.it/9IxVjvwYxrt6v0Qutzl5gdz82k5Z5s1X3QqHxt7HNwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=34f31971627ea54b35f16b9a21d7449684fde308', 'width': 640, 'height': 514}], 'variants': {}, 'id': 'lU1uDGT7MjnpPPIDAU3WdDOvbz2Ytu_EdoeKlHzOuNU'}], 'enabled': False}",,,,,,
573,,tensorflow,,t2_4srpg3wb,False,,0,False,Animatronic Talking Bookbag uses TensorFlow,[],r/tensorflow,False,6,,0,105.0,,False,t3_jmo0d8,False,dark,0.84,,public,8,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/wPHCFw6XBBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""I built Kimmy Schmidt's Talking Backpack"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/wPHCFw6XBBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ian Charnas', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wPHCFw6XBBk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/iancharnas'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/wPHCFw6XBBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/jmo0d8', 'height': 338}",,False,8,,False,https://b.thumbs.redditmedia.com/n761zChT4k8pzdsVgXIRUEo5NxmGl_Owcpj0CFJ0l6M.jpg,False,,[],{},,False,,1604354903.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jmo0d8,True,,Charnatopia,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jmo0d8/animatronic_talking_bookbag_uses_tensorflow/,all_ads,False,https://www.youtube.com/watch?v=wPHCFw6XBBk,22217,1604326103.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""I built Kimmy Schmidt's Talking Backpack"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/wPHCFw6XBBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ian Charnas', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wPHCFw6XBBk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/iancharnas'}}",False,rich:video,https://www.youtube.com/watch?v=wPHCFw6XBBk,"{'images': [{'source': {'url': 'https://external-preview.redd.it/F1Yr6fpb-5gQ0f4lQuwKdifY003AafJmN67UAp0T7Js.jpg?auto=webp&amp;s=fcd6138b459267714fce8352785576dbfb0b562d', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/F1Yr6fpb-5gQ0f4lQuwKdifY003AafJmN67UAp0T7Js.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=20df4aa7547db2ee159c351b9ac429e7c7ebb899', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/F1Yr6fpb-5gQ0f4lQuwKdifY003AafJmN67UAp0T7Js.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a26a2dd1d2005c7f0fb7167030b17fcafe46d5a2', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/F1Yr6fpb-5gQ0f4lQuwKdifY003AafJmN67UAp0T7Js.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=60973e8188e81133cdf9bef1b33c31c3d4fc3cc3', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'uEhtBiLjrCcwtA9QmIg3qZYt1j2SPo9yqjozZr9Ws_I'}], 'enabled': False}",,,,,,
574,,tensorflow,"Hello, I want to add additional semantic segmentation models to ensemble them with a U-Net model, as the U-Net model alone has quiet poor accuracy. What would be nice model semantic segmentation models to try out besides MaskRCNN. The images that it is trained on are biomedical images.",t2_128ob4,False,,0,False,CNN: What semantic segmentation architecture to ensemble with U-Net,[],r/tensorflow,False,6,,0,,,False,t3_jmebuq,False,dark,0.79,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1604309029.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I want to add additional semantic segmentation models to ensemble them with a U-Net model, as the U-Net model alone has quiet poor accuracy. What would be nice model semantic segmentation models to try out besides MaskRCNN. The images that it is trained on are biomedical images.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jmebuq,True,,darvidas,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jmebuq/cnn_what_semantic_segmentation_architecture_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jmebuq/cnn_what_semantic_segmentation_architecture_to/,22217,1604280229.0,0,,False,,,,,,,,,
575,,tensorflow,"Following is the implementation from the tensorflow Word2Vec documentation:

    class Word2Vec(Model):
      def __init__(self, vocab_size, embedding_dim):
        super(Word2Vec, self).__init__()
        self.target_embedding = Embedding(vocab_size, 
                                          embedding_dim,
                                          input_length=1,
                                          name=""w2v_embedding"", )
        self.context_embedding = Embedding(vocab_size, 
                                           embedding_dim, 
                                           input_length=num_ns+1)
        self.dots = Dot(axes=(3,2))
        self.flatten = Flatten()
    
      def call(self, pair):
        target, context = pair
        we = self.target_embedding(target)
        ce = self.context_embedding(context)
        dots = self.dots([ce, we])
        return self.flatten(dots)

Since the Embedding layer has output of shape (batch\_size, input\_length, embedding\_dim), won't the Dot layer throw index out of range error?

Thank you for the help.",t2_677jd8j,False,,0,False,Tensorflow Word2Vec axes wrong?,[],r/tensorflow,False,6,,0,,,False,t3_jmi632,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1604300346.0,,[],{},,True,,1604325362.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Following is the implementation from the tensorflow Word2Vec documentation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Word2Vec(Model):
  def __init__(self, vocab_size, embedding_dim):
    super(Word2Vec, self).__init__()
    self.target_embedding = Embedding(vocab_size, 
                                      embedding_dim,
                                      input_length=1,
                                      name=&amp;quot;w2v_embedding&amp;quot;, )
    self.context_embedding = Embedding(vocab_size, 
                                       embedding_dim, 
                                       input_length=num_ns+1)
    self.dots = Dot(axes=(3,2))
    self.flatten = Flatten()

  def call(self, pair):
    target, context = pair
    we = self.target_embedding(target)
    ce = self.context_embedding(context)
    dots = self.dots([ce, we])
    return self.flatten(dots)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since the Embedding layer has output of shape (batch_size, input_length, embedding_dim), won&amp;#39;t the Dot layer throw index out of range error?&lt;/p&gt;

&lt;p&gt;Thank you for the help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jmi632,True,,pooplicker88869,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jmi632/tensorflow_word2vec_axes_wrong/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jmi632/tensorflow_word2vec_axes_wrong/,22217,1604296562.0,0,,False,,,,,,,,,
576,,tensorflow,[https://github.com/AbhishekSinhaCoder/Computer-Science-Notes-Only-Source-Code-](https://github.com/AbhishekSinhaCoder/Computer-Science-Notes-Only-Source-Code-),,False,,0,False,I have created a repo which contains only source code for all the classes I took.,[],r/tensorflow,False,6,,0,,,False,t3_jm1gw3,False,dark,0.88,,public,17,0,{},,,False,[],,False,False,,{},Resource,False,17,,,self,False,,,{},,True,,1604262588.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/AbhishekSinhaCoder/Computer-Science-Notes-Only-Source-Code-""&gt;https://github.com/AbhishekSinhaCoder/Computer-Science-Notes-Only-Source-Code-&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jm1gw3,True,,[deleted],,0,True,all_ads,False,[],,dark,/r/tensorflow/comments/jm1gw3/i_have_created_a_repo_which_contains_only_source/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jm1gw3/i_have_created_a_repo_which_contains_only_source/,22217,1604233788.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?auto=webp&amp;s=bb75b99ecd2085cc961af13b17e0e858c36b48e9', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba28a66d7669cebc76a89ec683ef524ca3e9322e', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a72d6d6cf43dd2230f6cbad9a9594429cd27a8f9', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=37b519c19dfb3f42de22ada212e27a88b6f0e8e3', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'qepAXSiUlPglY850-J2TIych-kvJcaU1OSESW2_DLbM'}], 'enabled': False}",,,,,,
577,,tensorflow,"I'm working on a speech command recognition project. The input dataset that I am using consist of wav files. I want to transform these wav files to a spectrogram so I can supply those spectrograms to a CNN. I have figured out how to create these spectrograms:

    def wav_to_spectrogram(path):
            sample_rate, samples = wavfile.read(path)
            frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)
            return spectrogram
    
    

[spectrogram ](https://preview.redd.it/agkizs6fhnw51.png?width=116&amp;format=png&amp;auto=webp&amp;s=3da2378d9021d687b401abde9c92b492c95213a5)

However I am struggeling how to apply this function to each wav file while fitting the network. Since I don't want to generate a spectrogram of all wav files and store them as images on my file system.

&amp;#x200B;

How do I apply this data transformation wav -&gt; picture during training?",t2_61qkwgix,False,,0,False,wav file spectrogram fitting,[],r/tensorflow,False,6,,0,70.0,,False,t3_jm4h6f,False,dark,0.75,,public,2,0,{},70.0,,False,[],,False,False,,{},Question,False,2,,False,https://b.thumbs.redditmedia.com/FscCLvPV6N1iP847UGXvx_y6ptHvUn2RF-SxAEbnGKY.jpg,False,,[],{},,True,,1604274811.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a speech command recognition project. The input dataset that I am using consist of wav files. I want to transform these wav files to a spectrogram so I can supply those spectrograms to a CNN. I have figured out how to create these spectrograms:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def wav_to_spectrogram(path):
        sample_rate, samples = wavfile.read(path)
        frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)
        return spectrogram
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/agkizs6fhnw51.png?width=116&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3da2378d9021d687b401abde9c92b492c95213a5""&gt;spectrogram &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However I am struggeling how to apply this function to each wav file while fitting the network. Since I don&amp;#39;t want to generate a spectrogram of all wav files and store them as images on my file system.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;How do I apply this data transformation wav -&amp;gt; picture during training?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jm4h6f,True,,sleepyleasle,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jm4h6f/wav_file_spectrogram_fitting/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jm4h6f/wav_file_spectrogram_fitting/,22217,1604246011.0,0,,False,,,,,"{'agkizs6fhnw51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 162, 'x': 108, 'u': 'https://preview.redd.it/agkizs6fhnw51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b873f190b6544cebb3e862db210eb00d6558d8d7'}], 's': {'y': 174, 'x': 116, 'u': 'https://preview.redd.it/agkizs6fhnw51.png?width=116&amp;format=png&amp;auto=webp&amp;s=3da2378d9021d687b401abde9c92b492c95213a5'}, 'id': 'agkizs6fhnw51'}}",,,,
578,,tensorflow,"I currently have 13 (I'm going to be reducing this number but it will still be around 8 or 7) classes im segmenting and the algorithm is learning to just focus on the main 3 classes and kind of ignore the others. 

How can I tell it to focus more on the underrepresented classes?
class_weight and sample_weight don't seem to work with segmentation. Or at least the way I understand it it doesn't work.

I think I have to do something with a custom loss function but I'm not sure how to do that.",t2_5wuzf,False,,0,False,How can I weight segmentation training to pay more attention to under represented classes?,[],r/tensorflow,False,6,,0,,,False,t3_jm3pm8,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1604272010.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I currently have 13 (I&amp;#39;m going to be reducing this number but it will still be around 8 or 7) classes im segmenting and the algorithm is learning to just focus on the main 3 classes and kind of ignore the others. &lt;/p&gt;

&lt;p&gt;How can I tell it to focus more on the underrepresented classes?
class_weight and sample_weight don&amp;#39;t seem to work with segmentation. Or at least the way I understand it it doesn&amp;#39;t work.&lt;/p&gt;

&lt;p&gt;I think I have to do something with a custom loss function but I&amp;#39;m not sure how to do that.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jm3pm8,True,,thejeran,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jm3pm8/how_can_i_weight_segmentation_training_to_pay/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jm3pm8/how_can_i_weight_segmentation_training_to_pay/,22217,1604243210.0,0,,False,,,,,,,,,
579,,tensorflow,Should i buy a RTX graphic card for faster Tensorflow use? Anyone who has an idea how much faster it may run compared to older GPU's?,t2_8fl8v3ba,False,,0,False,RTX for Tensorflow?,[],r/tensorflow,False,6,,0,,,False,t3_jljisd,False,dark,0.89,,public,12,0,{},,,False,[],,False,False,,{},,False,12,,False,self,False,,[],{},,True,,1604184192.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Should i buy a RTX graphic card for faster Tensorflow use? Anyone who has an idea how much faster it may run compared to older GPU&amp;#39;s?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jljisd,True,,PythonNoob-pip,,22,True,all_ads,False,[],False,,/r/tensorflow/comments/jljisd/rtx_for_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jljisd/rtx_for_tensorflow/,22217,1604155392.0,0,,False,,,,,,,,,
580,,tensorflow,,t2_2e4fra5g,False,,0,False,"I'm still fiting with building a trading agent. In this video, I had a look at the process of creation and training DQN agent using TF-agents framework.",[],r/tensorflow,False,6,,0,105.0,,False,t3_jlr9y9,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/x0ycf3SZic4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Part VIII. Reinforcement Learning Trading Strategy. DQN: QNetwork, QRNNNetwork', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/x0ycf3SZic4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'CloseToAlgoTrading', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/x0ycf3SZic4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC02enwSCkf5S5GXV3jBwSzg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/x0ycf3SZic4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/jlr9y9', 'height': 338}",Project,False,2,,False,https://b.thumbs.redditmedia.com/HUWxfo1d1rJqLkLzGcx_diBid1FkB6kBdpWQqIcD9wo.jpg,False,,[],{},,False,,1604211364.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jlr9y9,True,,Denis_Vo,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jlr9y9/im_still_fiting_with_building_a_trading_agent_in/,all_ads,False,https://youtu.be/x0ycf3SZic4,22217,1604182564.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Part VIII. Reinforcement Learning Trading Strategy. DQN: QNetwork, QRNNNetwork', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/x0ycf3SZic4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'CloseToAlgoTrading', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/x0ycf3SZic4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC02enwSCkf5S5GXV3jBwSzg'}}",False,rich:video,https://youtu.be/x0ycf3SZic4,"{'images': [{'source': {'url': 'https://external-preview.redd.it/wtOFKqceLzE_fM5u5ejGeEaCjhyaYDubSkSiVYlqt34.jpg?auto=webp&amp;s=624eb593a86093bdec47981df583f4f273924cd9', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/wtOFKqceLzE_fM5u5ejGeEaCjhyaYDubSkSiVYlqt34.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=56bfcf1ff3aac215c1415debf1e3ce7798f1db00', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/wtOFKqceLzE_fM5u5ejGeEaCjhyaYDubSkSiVYlqt34.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6943c90eb26ea36c66399722f918e3447ac2fd86', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/wtOFKqceLzE_fM5u5ejGeEaCjhyaYDubSkSiVYlqt34.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da42bddea95609995f8251a9984a3116dc365125', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'VA-ZpijPy4QYkH12oTm9yqVe7mWjhFPc28wHtbuPeRI'}], 'enabled': False}",,,,,,
581,,tensorflow,My model is hitting a plateau at 80% and I can't figure out how to improve it. Could I just add more filters? Or is there diminishing returns for filters?,t2_5wuzf,False,,0,False,Is there such a thing as too many parameters if your model isn't overfitting?,[],r/tensorflow,False,6,,0,,,False,t3_jl5yys,False,dark,0.94,,public,16,0,{},,,False,[],,False,False,,{},Question,False,16,,False,self,False,,[],{},,True,,1604123196.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My model is hitting a plateau at 80% and I can&amp;#39;t figure out how to improve it. Could I just add more filters? Or is there diminishing returns for filters?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jl5yys,True,,thejeran,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/jl5yys/is_there_such_a_thing_as_too_many_parameters_if/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jl5yys/is_there_such_a_thing_as_too_many_parameters_if/,22217,1604094396.0,0,,False,,,,,,,,,
582,,tensorflow,I'm going to embark on a project generating pictures of myself. I have taken a bunch of similar pictures of myself with varying hair and facial hair lengths. I want to make an application where you can input the amount of hair and facial hair and it will generate a picture of me based on the specified amounts. What resources should I look into (more than the TensorFlow docs on GANs) and/or what should the layers of my network look like?,t2_1qjergeq,False,,0,False,How to structure neural network to generate pictures based off a number,[],r/tensorflow,False,6,,0,,,False,t3_jl848n,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1604130713.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m going to embark on a project generating pictures of myself. I have taken a bunch of similar pictures of myself with varying hair and facial hair lengths. I want to make an application where you can input the amount of hair and facial hair and it will generate a picture of me based on the specified amounts. What resources should I look into (more than the TensorFlow docs on GANs) and/or what should the layers of my network look like?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jl848n,True,,dan-danny-daniel,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jl848n/how_to_structure_neural_network_to_generate/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jl848n/how_to_structure_neural_network_to_generate/,22217,1604101913.0,0,,False,,,,,,,,,
583,,tensorflow,,t2_xt6j8xa,False,,0,False,"I wrote a blog on ""Fairness in AI and AI bias"". I think everyone should read it to understand the limitations of AI and discrimination due to it. Kindly give it a read.",[],r/tensorflow,False,6,,0,77.0,,False,t3_jljkuu,False,dark,0.33,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/fLOz85-NHXUQD_rLyUxJ5qRLIy5jxZx6lqSUVlmfu2w.jpg,False,,[],{},,False,,1604184404.0,text,6,,,text,cleanpegasus.medium.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jljkuu,True,,clean_pegasus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jljkuu/i_wrote_a_blog_on_fairness_in_ai_and_ai_bias_i/,all_ads,False,https://cleanpegasus.medium.com/ai-is-flawed-heres-why-3a7e90c48878,22217,1604155604.0,0,,False,link,https://cleanpegasus.medium.com/ai-is-flawed-heres-why-3a7e90c48878,"{'images': [{'source': {'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?auto=webp&amp;s=764b595a9fe7b34c92dce9ea3812d59bc785b67a', 'width': 1200, 'height': 663}, 'resolutions': [{'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2f30fe72c6eec1d78d244c8df564251632c8ab8', 'width': 108, 'height': 59}, {'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8899c8ad77d9cdbdc51b4ad2a83d285cd96ef3e', 'width': 216, 'height': 119}, {'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b45159ad3b4350582c153be23fb6f238eb0d4c3', 'width': 320, 'height': 176}, {'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=615fbaf159b0ff8427c10988cce7ed3e470f20ec', 'width': 640, 'height': 353}, {'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9383a214a0a34a77791589bf11bffe014c38bc2a', 'width': 960, 'height': 530}, {'url': 'https://external-preview.redd.it/KpuTNsgB2UJOuHqCWSN5WN6Ltb9zElhGCER7r260rEM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=abd0657a69a1d024fee3693a3305fb2fb6a3db32', 'width': 1080, 'height': 596}], 'variants': {}, 'id': '7iduX6uOBx1bl8TVizhAW6afCSCFwvBhBDz3NqZu-zw'}], 'enabled': False}",,,,,,
584,,tensorflow,,t2_4760f5hy,False,,0,False,"I'm trying to make a tensor flow neural network for the MNIST image dataset, but it's always outputting a ""function call stack: train_function"" error(code in comments)",[],r/tensorflow,False,6,,0,140.0,,False,t3_jl6fah,False,dark,0.67,,public,3,0,{},140.0,,False,[],,True,False,,{},Question,False,3,,False,https://a.thumbs.redditmedia.com/5ULetD3V0eelz-Ei_fBpVXpTQUIg24ypYCqDruy6j28.jpg,False,,[],{},,False,,1604124740.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jl6fah,True,,ARNisUsername,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jl6fah/im_trying_to_make_a_tensor_flow_neural_network/,all_ads,False,https://i.redd.it/z53e3k793bw51.png,22217,1604095940.0,0,,False,image,https://i.redd.it/z53e3k793bw51.png,"{'images': [{'source': {'url': 'https://preview.redd.it/z53e3k793bw51.png?auto=webp&amp;s=2fe15b4ba65d99029bc9a6a7ef59101bc6c4dcc3', 'width': 2268, 'height': 2434}, 'resolutions': [{'url': 'https://preview.redd.it/z53e3k793bw51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6f2ba238149e117b4a31f9f7cf89364e5ab28e6', 'width': 108, 'height': 115}, {'url': 'https://preview.redd.it/z53e3k793bw51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c75b59c682ba6ae775ede0ffe1d5a539866bf8b', 'width': 216, 'height': 231}, {'url': 'https://preview.redd.it/z53e3k793bw51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5dddb1d818ee39b9d1ad133cbfda7c8c94fc04cb', 'width': 320, 'height': 343}, {'url': 'https://preview.redd.it/z53e3k793bw51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aef821ccfe2019860d25ef522bdbcc86b170478a', 'width': 640, 'height': 686}, {'url': 'https://preview.redd.it/z53e3k793bw51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=02ebc3c2b867d27b27709339e6c5ee83ddef125b', 'width': 960, 'height': 1030}, {'url': 'https://preview.redd.it/z53e3k793bw51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7b0215e146df7d9d19f353188c0a40ccd2b83bf2', 'width': 1080, 'height': 1159}], 'variants': {}, 'id': '3tuDZF20x11iKFlfXIVbpDaRSjypos6DpjjIqSJa00c'}], 'enabled': True}",,,,,,
585,,tensorflow,,t2_4f410s63,False,,0,False,/r/tensorflow hit 20k subscribers yesterday,[],r/tensorflow,False,6,,0,140.0,,False,t3_jkn9b6,False,dark,0.93,,public,40,0,{},140.0,,False,[],,False,False,,{},,False,40,,False,https://b.thumbs.redditmedia.com/kP3DtNG90CSMppfLhAFaweki7c2JB_pDlmRDHPDP6NI.jpg,False,,[],{},,False,,1604049285.0,text,6,,,text,frontpagemetrics.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jkn9b6,True,,TrendingB0T,,3,False,all_ads,False,[],False,,/r/tensorflow/comments/jkn9b6/rtensorflow_hit_20k_subscribers_yesterday/,all_ads,False,https://frontpagemetrics.com/r/tensorflow,22217,1604020485.0,0,,False,link,https://frontpagemetrics.com/r/tensorflow,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cmk6TfZyjdNsnnHMRPi3vayUndbqJ7noAJN6YQ3bYPQ.jpg?auto=webp&amp;s=098bfafa407df0685d3bea32db6c3b6dceda6df4', 'width': 200, 'height': 200}, 'resolutions': [{'url': 'https://external-preview.redd.it/cmk6TfZyjdNsnnHMRPi3vayUndbqJ7noAJN6YQ3bYPQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f58ea86ce575dc93f120162bf4789fdb803b8a0', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'Ro8VJQzQ0G9W62N2AJCV7OPy0fcbDK_xyuAxbiHzceM'}], 'enabled': False}",,,,,,
586,,tensorflow,"Does anybody here knows if and how I can replace normal Tensorflow with tf-nightly in the Tensorflow Object Detection API?
I have a RTX 3080, which only supports Cuda 11, so I need to use tf-nightly

Edit: I found a solution. I had to change tf-models-official to tf-models-nightly in the setup.py",t2_36ze7ll,False,,0,False,Tensorflow Object Detection API tf-nightly,[],r/tensorflow,False,6,,0,,,False,t3_jkybad,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1604081102.0,,[],{},,True,,1604098718.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anybody here knows if and how I can replace normal Tensorflow with tf-nightly in the Tensorflow Object Detection API?
I have a RTX 3080, which only supports Cuda 11, so I need to use tf-nightly&lt;/p&gt;

&lt;p&gt;Edit: I found a solution. I had to change tf-models-official to tf-models-nightly in the setup.py&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jkybad,True,,nilsii27,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jkybad/tensorflow_object_detection_api_tfnightly/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jkybad/tensorflow_object_detection_api_tfnightly/,22217,1604069918.0,0,,False,,,,,,,,,
587,,tensorflow,"I am working on creating a CNN with custom layers that makes inputs discrete. I plan to test different bit lengths. For now, it is a MLP network and I am writing a dense layer. 

`tf.custom_gradient`

`def fully_connect(x, W, b):def fully_connect(x, W, b):`  
 `#make Weights discrete (non-differentiable)`  
  `Wd = tf.clip_by_value(W, -1, 1)`  
  `Wd = discrete(Wd,256)`  
  `bd = discrete(b, 256) #this does not need to be binary`  
 `#actual operation`  
  `sig = tf.math.add(tf.linalg.matmul(x,Wd), bd) #Wx+b`  
 `#do not need to make output discrete. That is done int the py_sign function`  
 `def py_full_grad(dy):`  
 `print(""Grad Shape: dy"", dy.shape, "" x:"", x.shape, "" W:"", W.shape, "" b:"", b.shape)`  
`d_x = tf.linalg.matmul(dy,tf.transpose(W))`  
`d_W = tf.linalg.matmul(tf.transpose(x),dy) #element wise product`  
`d_b = dy`  
 `return d_x, d_W, d_b`  
 `return sig, py_full_grad #tf.math.sign(tf.math.subtract(tf.random.uniform(tf.shape(x)), sig)),`   


I get the following error when fitting the model:

`var and grad do not have the same shape[512] [128,512]`

128 is the batch size, and 512 is the input size of the last layer (512-&gt;10). The source code is here:

[https://colab.research.google.com/drive/1y\_y0LbN3WXsdvGwaCikPq2iIYedG9wZF?usp=sharing](https://colab.research.google.com/drive/1y_y0LbN3WXsdvGwaCikPq2iIYedG9wZF?usp=sharing)",t2_6pukv2es,False,,0,False,Custom Gradients,[],r/tensorflow,False,6,,0,,,False,t3_jkxaqm,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1604095321.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on creating a CNN with custom layers that makes inputs discrete. I plan to test different bit lengths. For now, it is a MLP network and I am writing a dense layer. &lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.custom_gradient&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;def fully_connect(x, W, b):def fully_connect(x, W, b):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#make Weights discrete (non-differentiable)&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;Wd = tf.clip_by_value(W, -1, 1)&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;Wd = discrete(Wd,256)&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;bd = discrete(b, 256) #this does not need to be binary&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#actual operation&lt;/code&gt;&lt;br/&gt;
  &lt;code&gt;sig = tf.math.add(tf.linalg.matmul(x,Wd), bd) #Wx+b&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;#do not need to make output discrete. That is done int the py_sign function&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;def py_full_grad(dy):&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;print(&amp;quot;Grad Shape: dy&amp;quot;, dy.shape, &amp;quot; x:&amp;quot;, x.shape, &amp;quot; W:&amp;quot;, W.shape, &amp;quot; b:&amp;quot;, b.shape)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;d_x = tf.linalg.matmul(dy,tf.transpose(W))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;d_W = tf.linalg.matmul(tf.transpose(x),dy) #element wise product&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;d_b = dy&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return d_x, d_W, d_b&lt;/code&gt;&lt;br/&gt;
 &lt;code&gt;return sig, py_full_grad #tf.math.sign(tf.math.subtract(tf.random.uniform(tf.shape(x)), sig)),&lt;/code&gt;   &lt;/p&gt;

&lt;p&gt;I get the following error when fitting the model:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;var and grad do not have the same shape[512] [128,512]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;128 is the batch size, and 512 is the input size of the last layer (512-&amp;gt;10). The source code is here:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://colab.research.google.com/drive/1y_y0LbN3WXsdvGwaCikPq2iIYedG9wZF?usp=sharing""&gt;https://colab.research.google.com/drive/1y_y0LbN3WXsdvGwaCikPq2iIYedG9wZF?usp=sharing&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jkxaqm,True,,SnooPears643,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jkxaqm/custom_gradients/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jkxaqm/custom_gradients/,22217,1604066521.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?auto=webp&amp;s=ffc13b63083ce9180bdf2cf28705ee407b659975', 'width': 256, 'height': 256}, 'resolutions': [{'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f53340195fae0f84ec3871625087bf02fd428ab', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6722a649351a89204dede7d65ad009eea43566c', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'mAwt5FN14h93icEvsjkWqFiukRT9FqTVVq54ZHDgaos'}], 'enabled': False}",,,,,,
588,,tensorflow,,t2_79p1h62w,False,,0,False,The Essentials of Machine Learning Data Curation,[],r/tensorflow,False,6,,0,64.0,,False,t3_jkvk8t,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/JVRbEhzXiR1r0724kGeXFy3xkBufANZOg-Db_kKchnY.jpg,False,,[],{},,False,,1604088600.0,text,6,,,text,artiba.org,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jkvk8t,True,,Shradha_Singh,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jkvk8t/the_essentials_of_machine_learning_data_curation/,all_ads,False,https://www.artiba.org/blog/the-essentials-of-machine-learning-data-curation,22217,1604059800.0,0,,False,link,https://www.artiba.org/blog/the-essentials-of-machine-learning-data-curation,"{'images': [{'source': {'url': 'https://external-preview.redd.it/jbTGN0m8fV8uVIkRpFO7jRgFawBgkIBElgYu_kPFfrQ.jpg?auto=webp&amp;s=1535c6119267f128b1874b887be7560dea6913f5', 'width': 800, 'height': 370}, 'resolutions': [{'url': 'https://external-preview.redd.it/jbTGN0m8fV8uVIkRpFO7jRgFawBgkIBElgYu_kPFfrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddedb47afb964e3b25a3e5a33b00ed0e7148c899', 'width': 108, 'height': 49}, {'url': 'https://external-preview.redd.it/jbTGN0m8fV8uVIkRpFO7jRgFawBgkIBElgYu_kPFfrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e176bc0848c99a188de5883da8263b877c80481', 'width': 216, 'height': 99}, {'url': 'https://external-preview.redd.it/jbTGN0m8fV8uVIkRpFO7jRgFawBgkIBElgYu_kPFfrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=490b9591d16621f8b807a1b497ef7e23c8fe9080', 'width': 320, 'height': 148}, {'url': 'https://external-preview.redd.it/jbTGN0m8fV8uVIkRpFO7jRgFawBgkIBElgYu_kPFfrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0162a9be427f6725c37045840fbffd1a042470e4', 'width': 640, 'height': 296}], 'variants': {}, 'id': '3GJemnWb04iNApJJDoouZrcA3ZYUDtEmpspNwN0imyk'}], 'enabled': False}",,,,,,
589,,tensorflow,"Today, I finally got my first ""real"" machine learning project working -- a bot that learns how to play Pokemon using Deep Q learning.

It's, uh... pretty stupid. But it's learning (slowly). Right now I'm feeding it 35 inputs, just based on what I figured were (high-level) the most important parts to know about what's going on. I _do_ have access to more -- a lot more -- but I'm not sure if increasing the number of inputs would cause any issues with a signal:noise ratio or something. Any tips?",t2_6d405,False,,0,False,Are more inputs better?,[],r/tensorflow,False,6,,0,,,False,t3_jksfaf,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,True,self,False,,[],{},,True,,1604072162.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Today, I finally got my first &amp;quot;real&amp;quot; machine learning project working -- a bot that learns how to play Pokemon using Deep Q learning.&lt;/p&gt;

&lt;p&gt;It&amp;#39;s, uh... pretty stupid. But it&amp;#39;s learning (slowly). Right now I&amp;#39;m feeding it 35 inputs, just based on what I figured were (high-level) the most important parts to know about what&amp;#39;s going on. I &lt;em&gt;do&lt;/em&gt; have access to more -- a lot more -- but I&amp;#39;m not sure if increasing the number of inputs would cause any issues with a signal:noise ratio or something. Any tips?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jksfaf,True,,EnglishMobster,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jksfaf/are_more_inputs_better/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jksfaf/are_more_inputs_better/,22217,1604043362.0,0,,False,,,,,,,,,
590,,tensorflow,"When defining the agent, we can define the reward discount factor as `gamma`

[https://github.com/tensorflow/agents/blob/755b43c78bb50e36b1331acc9492be599997a47f/tf\_agents/agents/dqn/dqn\_agent.py#L113](https://github.com/tensorflow/agents/blob/755b43c78bb50e36b1331acc9492be599997a47f/tf_agents/agents/dqn/dqn_agent.py#L113)

In case we define a discount factor for future rewards in the environment itself as

`return ts.transition(np.array([self._state], dtype=np.int32), reward = award, discount=1.0)`, ([link](https://www.tensorflow.org/agents/tutorials/2_environments_tutorial#usage_examples)) which value will be used reward discount factor as both of them (the `gamma` in agent and `discount` in environment) refer to the same value of reward discount factor ?

I am assuming both mean the same thing: how important the agent will perceive the future rewards to be. However, the `discount` as defined in the environment is confusing as I don't see why the environment itself will define a discount.",t2_535590ri,False,,0,False,Difference in the discount factor defined in the tensor flow environment and the agent,[],r/tensorflow,False,6,,0,,,False,t3_jkrcxe,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1604037670.0,,[],{},,True,,1604066252.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When defining the agent, we can define the reward discount factor as &lt;code&gt;gamma&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/tensorflow/agents/blob/755b43c78bb50e36b1331acc9492be599997a47f/tf_agents/agents/dqn/dqn_agent.py#L113""&gt;https://github.com/tensorflow/agents/blob/755b43c78bb50e36b1331acc9492be599997a47f/tf_agents/agents/dqn/dqn_agent.py#L113&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case we define a discount factor for future rewards in the environment itself as&lt;/p&gt;

&lt;p&gt;&lt;code&gt;return ts.transition(np.array([self._state], dtype=np.int32), reward = award, discount=1.0)&lt;/code&gt;, (&lt;a href=""https://www.tensorflow.org/agents/tutorials/2_environments_tutorial#usage_examples""&gt;link&lt;/a&gt;) which value will be used reward discount factor as both of them (the &lt;code&gt;gamma&lt;/code&gt; in agent and &lt;code&gt;discount&lt;/code&gt; in environment) refer to the same value of reward discount factor ?&lt;/p&gt;

&lt;p&gt;I am assuming both mean the same thing: how important the agent will perceive the future rewards to be. However, the &lt;code&gt;discount&lt;/code&gt; as defined in the environment is confusing as I don&amp;#39;t see why the environment itself will define a discount.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jkrcxe,True,,Expensive-Telephone,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jkrcxe/difference_in_the_discount_factor_defined_in_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jkrcxe/difference_in_the_discount_factor_defined_in_the/,22217,1604037452.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
591,,tensorflow,"Given some inputs, how can I make a model that outputs the same constant ""class"" for each prediction?  


so far using stack overflow I got a constant output layer

    def const(tensor):
      batch_size = tensor.shape[0]
      constant = tf.constant([constant_value], dtype=tf.string)
      return tf.broadcast_to(constant, shape=(batch_size,1))

but the output is always a single instance of the constant value, not one value per prediction. Is there something simple I'm missing?  


the input layers are a series of 1d inputs fed into a concatenate layer",t2_ro87l,False,,0,False,How to create a dummy classifier?,[],r/tensorflow,False,6,,0,,,False,t3_jkiob6,False,dark,0.72,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1604034129.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Given some inputs, how can I make a model that outputs the same constant &amp;quot;class&amp;quot; for each prediction?  &lt;/p&gt;

&lt;p&gt;so far using stack overflow I got a constant output layer&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def const(tensor):
  batch_size = tensor.shape[0]
  constant = tf.constant([constant_value], dtype=tf.string)
  return tf.broadcast_to(constant, shape=(batch_size,1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but the output is always a single instance of the constant value, not one value per prediction. Is there something simple I&amp;#39;m missing?  &lt;/p&gt;

&lt;p&gt;the input layers are a series of 1d inputs fed into a concatenate layer&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jkiob6,True,,wbarteck,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jkiob6/how_to_create_a_dummy_classifier/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jkiob6/how_to_create_a_dummy_classifier/,22217,1604005329.0,0,,False,,,,,,,,,
592,,tensorflow,"So maybe I'm just dumb and I don't understand. I know how to code in Python, but I've never really used machine learning before.

My goal is to make a bot that can play Pokemon. I'm able to get the current state of the game as a JSON-formatted string, and I want it to output whether it should use a move or switch Pokemon (for a total of 9 possible combinations on any given turn). Because Pokemon is _nuts_ with how much data actually gets used and how many exceptions there are to the rules, I _don't_ want to have to program their entire battle engine.

In my head, the JSON string representing the ""battle state"" is just an array of bytes, right? And an image is an array of bytes? So I should be able to take that JSON string, run it through Tensorflow, and have Tensorflow output a label 0-8. I can handle it from there easily enough.

I guess another snag is that I don't want the bot to necessarily _play_ like I do; I was thinking more of looking at the end battle state and determining if you won (good, do more of the stuff you did) or lost (bad, change some numbers).

I'm looking at stuff like [the classification tutorial](https://www.tensorflow.org/tutorials/keras/classification) or [the text recognition tutorial](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub) and it all seems to be stuff like ""Oh, yeah, just feed it a bunch of magic data from this magic directory we have and then it just works!"" but doesn't really cover how to do any data that _isn't_ in that magic directory.

It seems like [Online Machine Learning](https://en.wikipedia.org/wiki/Online_machine_learning) will put me in the right direction... but searching ""Tensorflow Online Machine Learning"" just gives me a bunch of classes about how to use Tensorflow.

Am I completely barking up the wrong tree here?",t2_6d405,False,,0,False,"So, this sounds stupid... but how do I _use_ Tensorflow?",[],r/tensorflow,False,6,,0,,,False,t3_jk3hj0,False,dark,0.8,,public,20,0,{},,,False,[],,False,False,,{},Question,False,20,,True,self,False,,[],{},,True,,1603973902.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So maybe I&amp;#39;m just dumb and I don&amp;#39;t understand. I know how to code in Python, but I&amp;#39;ve never really used machine learning before.&lt;/p&gt;

&lt;p&gt;My goal is to make a bot that can play Pokemon. I&amp;#39;m able to get the current state of the game as a JSON-formatted string, and I want it to output whether it should use a move or switch Pokemon (for a total of 9 possible combinations on any given turn). Because Pokemon is &lt;em&gt;nuts&lt;/em&gt; with how much data actually gets used and how many exceptions there are to the rules, I &lt;em&gt;don&amp;#39;t&lt;/em&gt; want to have to program their entire battle engine.&lt;/p&gt;

&lt;p&gt;In my head, the JSON string representing the &amp;quot;battle state&amp;quot; is just an array of bytes, right? And an image is an array of bytes? So I should be able to take that JSON string, run it through Tensorflow, and have Tensorflow output a label 0-8. I can handle it from there easily enough.&lt;/p&gt;

&lt;p&gt;I guess another snag is that I don&amp;#39;t want the bot to necessarily &lt;em&gt;play&lt;/em&gt; like I do; I was thinking more of looking at the end battle state and determining if you won (good, do more of the stuff you did) or lost (bad, change some numbers).&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking at stuff like &lt;a href=""https://www.tensorflow.org/tutorials/keras/classification""&gt;the classification tutorial&lt;/a&gt; or &lt;a href=""https://www.tensorflow.org/tutorials/keras/text_classification_with_hub""&gt;the text recognition tutorial&lt;/a&gt; and it all seems to be stuff like &amp;quot;Oh, yeah, just feed it a bunch of magic data from this magic directory we have and then it just works!&amp;quot; but doesn&amp;#39;t really cover how to do any data that &lt;em&gt;isn&amp;#39;t&lt;/em&gt; in that magic directory.&lt;/p&gt;

&lt;p&gt;It seems like &lt;a href=""https://en.wikipedia.org/wiki/Online_machine_learning""&gt;Online Machine Learning&lt;/a&gt; will put me in the right direction... but searching &amp;quot;Tensorflow Online Machine Learning&amp;quot; just gives me a bunch of classes about how to use Tensorflow.&lt;/p&gt;

&lt;p&gt;Am I completely barking up the wrong tree here?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jk3hj0,True,,EnglishMobster,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jk3hj0/so_this_sounds_stupid_but_how_do_i_use_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jk3hj0/so_this_sounds_stupid_but_how_do_i_use_tensorflow/,22217,1603945102.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
593,,tensorflow,"I have tried to install CUDA by following the steps at https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=2004&amp;target_type=deblocal :

	wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin

	sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600

	wget https://developer.download.nvidia.com/compute/cuda/11.1.1/local_installers/cuda-repo-ubuntu2004-11-1-local_11.1.1-455.32.00-1_amd64.deb

	sudo dpkg -i cuda-repo-ubuntu2004-11-1-local_11.1.1-455.32.00-1_amd64.deb

	sudo apt-key add /var/cuda-repo-ubuntu2004-11-1-local/7fa2af80.pub

	sudo apt-get update

	sudo apt-get -y install cuda

I also tried removing previous CUDA installations by doing:

	sudo rm /etc/apt/sources.list.d/cuda*
	sudo apt remove --autoremove nvidia-cuda-toolkit
	sudo apt remove --autoremove nvidia-*

	sudo apt-get purge nvidia*
	sudo apt-get autoremove
	sudo apt-get autoclean

	sudo rm -rf /usr/local/cuda*

and then reinstalling CUDA

but I always end up having problem as the final step:

    sudo apt-get -y install cuda

where it says `unable to locate package cuda`

Even if I try replacing the `cuda` with `cuda-11-1`, `cuda-11.1`, `cuda-11-0`, `cuda-11.0`, etc

if I try `apt-get install nvidia-cuda-toolkit` the error says

    nvidia-cuda-toolkit depends: nvidia-cuda-dev (= 10.1.243-3) but it is not going to be installed
    recommends: nsight-compute  (= 10.1.243-3) but it is not installable
    unable to correct problems, you have held broken packages

can anyone help?",t2_tpult,False,,0,False,Unable to install CUDA 11 on Ubuntu 20,[],r/tensorflow,False,6,,0,,,False,t3_jkgw02,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1604028666.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have tried to install CUDA by following the steps at &lt;a href=""https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;target_distro=Ubuntu&amp;amp;target_version=2004&amp;amp;target_type=deblocal""&gt;https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;target_distro=Ubuntu&amp;amp;target_version=2004&amp;amp;target_type=deblocal&lt;/a&gt; :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin

sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600

wget https://developer.download.nvidia.com/compute/cuda/11.1.1/local_installers/cuda-repo-ubuntu2004-11-1-local_11.1.1-455.32.00-1_amd64.deb

sudo dpkg -i cuda-repo-ubuntu2004-11-1-local_11.1.1-455.32.00-1_amd64.deb

sudo apt-key add /var/cuda-repo-ubuntu2004-11-1-local/7fa2af80.pub

sudo apt-get update

sudo apt-get -y install cuda
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also tried removing previous CUDA installations by doing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo rm /etc/apt/sources.list.d/cuda*
sudo apt remove --autoremove nvidia-cuda-toolkit
sudo apt remove --autoremove nvidia-*

sudo apt-get purge nvidia*
sudo apt-get autoremove
sudo apt-get autoclean

sudo rm -rf /usr/local/cuda*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and then reinstalling CUDA&lt;/p&gt;

&lt;p&gt;but I always end up having problem as the final step:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get -y install cuda
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where it says &lt;code&gt;unable to locate package cuda&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Even if I try replacing the &lt;code&gt;cuda&lt;/code&gt; with &lt;code&gt;cuda-11-1&lt;/code&gt;, &lt;code&gt;cuda-11.1&lt;/code&gt;, &lt;code&gt;cuda-11-0&lt;/code&gt;, &lt;code&gt;cuda-11.0&lt;/code&gt;, etc&lt;/p&gt;

&lt;p&gt;if I try &lt;code&gt;apt-get install nvidia-cuda-toolkit&lt;/code&gt; the error says&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nvidia-cuda-toolkit depends: nvidia-cuda-dev (= 10.1.243-3) but it is not going to be installed
recommends: nsight-compute  (= 10.1.243-3) but it is not installable
unable to correct problems, you have held broken packages
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;can anyone help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jkgw02,True,,74throwaway,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jkgw02/unable_to_install_cuda_11_on_ubuntu_20/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jkgw02/unable_to_install_cuda_11_on_ubuntu_20/,22217,1603999866.0,0,,False,,,,,,,,,
594,,tensorflow,"There are various tools for measuring, and ultimately bettering, the performance of a deep learning model.

Here, I wanted to take a closer look at **TensorBoard - open source visualization toolkit for deep learning**. I think that it is worth to spend some time to learn more about it, as it let you do many things, like:

1. visualize images,
1. check model weights and biases on TensorBoard,
1. visualize the model’s architecture,
1. send a visual of the confusion matrix to TensorBoard,
1. inspect hyper-parameter tuning results.
1. log metrics from libs outside TF ecosystem, for example PyTorch or XGBoost.

Additionally you can work with **TensorFlow Profiler** and **debugger** in TensorBoard.

To explain all the options mentioned above, we created comprehensive guide that will show you how to do all these! Have a look if you feel it's for you:

[Deep Dive into TensorBoard: Tutorial With Examples](https://neptune.ai/blog/tensorboard-tutorial?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-tensorboard-tutorial&amp;utm_content=tensorflow)

Do you use TensorBoard? What are your experiences? If you feel like discussing, then see you in the comments! :)",t2_5hfacnnv,False,,0,False,Deep Dive into TensorBoard: Tutorial With Examples,[],r/tensorflow,False,6,,0,,,False,t3_jjob97,False,dark,1.0,,public,19,0,{},,,False,[],,False,False,,{},Discussion,False,19,,False,self,False,,[],{},,True,,1603922593.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There are various tools for measuring, and ultimately bettering, the performance of a deep learning model.&lt;/p&gt;

&lt;p&gt;Here, I wanted to take a closer look at &lt;strong&gt;TensorBoard - open source visualization toolkit for deep learning&lt;/strong&gt;. I think that it is worth to spend some time to learn more about it, as it let you do many things, like:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;visualize images,&lt;/li&gt;
&lt;li&gt;check model weights and biases on TensorBoard,&lt;/li&gt;
&lt;li&gt;visualize the model’s architecture,&lt;/li&gt;
&lt;li&gt;send a visual of the confusion matrix to TensorBoard,&lt;/li&gt;
&lt;li&gt;inspect hyper-parameter tuning results.&lt;/li&gt;
&lt;li&gt;log metrics from libs outside TF ecosystem, for example PyTorch or XGBoost.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Additionally you can work with &lt;strong&gt;TensorFlow Profiler&lt;/strong&gt; and &lt;strong&gt;debugger&lt;/strong&gt; in TensorBoard.&lt;/p&gt;

&lt;p&gt;To explain all the options mentioned above, we created comprehensive guide that will show you how to do all these! Have a look if you feel it&amp;#39;s for you:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/tensorboard-tutorial?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-tensorboard-tutorial&amp;amp;utm_content=tensorflow""&gt;Deep Dive into TensorBoard: Tutorial With Examples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do you use TensorBoard? What are your experiences? If you feel like discussing, then see you in the comments! :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jjob97,True,,kk_ai,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jjob97/deep_dive_into_tensorboard_tutorial_with_examples/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jjob97/deep_dive_into_tensorboard_tutorial_with_examples/,22217,1603893793.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?auto=webp&amp;s=216aa49aa6ec6a94cc6fe3269e30f42cf718a97a', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=856318e726f5a062e8a69ff55c8050e667a700df', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=584734ce795a9aded3391783ba0c7971fa528354', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82bb006d21e1ffde087d848fdb8a82c5107a48d9', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=96df80fd2b451906e1446947ec5e8e25d399fb11', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a5155edcb16c07a070920e14a45b01de9a2669ea', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/JfFBM_QwxdDK2DLnR0-Jk_ROoIfVueRSFoDb8suA4yo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1c3d316b03fa34f900ae7be8fe9433f9de2c011e', 'width': 1080, 'height': 774}], 'variants': {}, 'id': '3xuGHlk8u_1EPAhhOoo1ofB8NBiTuSOKJtpelQsOVp8'}], 'enabled': False}",,,,,,
595,,tensorflow,"Hello,

I could not find any good documentation on how to convert a GPU project to TPU. Using the following Object Identification script to train on GPU works well for me:

 !python /content/models/research/object\_detection/model\_main\_tf2.py \\  
    \--pipeline\_config\_path={pipeline\_file} \\  
    \--model\_dir={model\_dir} \\  
    \--alsologtostderr \\  
    \--num\_train\_steps={num\_steps} \\  
    \--sample\_1\_of\_n\_eval\_examples=1 \\  
    \--num\_eval\_steps={num\_eval\_steps}

However, when I add --use\_tpu=true after changing Colab type to TPU, does not work. It seems that I am missing something along the way. It is not just changing the runtime type to TPU and adding --use\_tpu.

Has anyone made a transition like this? 

I appreciate any help you can provide.

Thanks,",t2_7wqbp5z7,False,,0,False,Using TPUs on Google Colab - Need Help,[],r/tensorflow,False,6,,0,,,False,t3_jjzpzw,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1603959194.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I could not find any good documentation on how to convert a GPU project to TPU. Using the following Object Identification script to train on GPU works well for me:&lt;/p&gt;

&lt;p&gt;!python /content/models/research/object_detection/model_main_tf2.py \&lt;br/&gt;
    --pipeline_config_path={pipeline_file} \&lt;br/&gt;
    --model_dir={model_dir} \&lt;br/&gt;
    --alsologtostderr \&lt;br/&gt;
    --num_train_steps={num_steps} \&lt;br/&gt;
    --sample_1_of_n_eval_examples=1 \&lt;br/&gt;
    --num_eval_steps={num_eval_steps}&lt;/p&gt;

&lt;p&gt;However, when I add --use_tpu=true after changing Colab type to TPU, does not work. It seems that I am missing something along the way. It is not just changing the runtime type to TPU and adding --use_tpu.&lt;/p&gt;

&lt;p&gt;Has anyone made a transition like this? &lt;/p&gt;

&lt;p&gt;I appreciate any help you can provide.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jjzpzw,True,,Difficult_Monk7460,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jjzpzw/using_tpus_on_google_colab_need_help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jjzpzw/using_tpus_on_google_colab_need_help/,22217,1603930394.0,0,,False,,,,,,,,,
596,,tensorflow,"I'm trying to implement this loss function [here](https://imgur.com/a/A4G8Bsy) but I don't understand the last line: 

&gt;The value −b/w corresponds with the verification threshold.

What I don't understand is (1) if they are the verification threshold why is it denoted by two different variables and (2) when it says`-b/w` , the negative signs is confusing me here are the two variables supposed to be inverses of each other?",t2_10vrhqvg,False,,0,False,Trying to implement custom loss function,[],r/tensorflow,False,6,,0,,,False,t3_jjjcdw,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1603898654.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to implement this loss function &lt;a href=""https://imgur.com/a/A4G8Bsy""&gt;here&lt;/a&gt; but I don&amp;#39;t understand the last line: &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The value −b/w corresponds with the verification threshold.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What I don&amp;#39;t understand is (1) if they are the verification threshold why is it denoted by two different variables and (2) when it says&lt;code&gt;-b/w&lt;/code&gt; , the negative signs is confusing me here are the two variables supposed to be inverses of each other?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jjjcdw,True,,nopickles_,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jjjcdw/trying_to_implement_custom_loss_function/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jjjcdw/trying_to_implement_custom_loss_function/,22217,1603869854.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?auto=webp&amp;s=2f5e419b2db20ac8a80c0205e06257c8ae3bde13', 'width': 543, 'height': 144}, 'resolutions': [{'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abf97fd880a7c9c58556766be42529490af2c106', 'width': 108, 'height': 28}, {'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8582fa1f0f95b7e91bedd31f43d1192011e70f1a', 'width': 216, 'height': 57}, {'url': 'https://external-preview.redd.it/yst9tmsbv7dOKjEYkgIaAZ0g0ya_HxgtsSX4rj6spOM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=48ef2f25721334c240453df419dbf76c0b01205c', 'width': 320, 'height': 84}], 'variants': {}, 'id': 'bh8HL5RFoaTZL81L_V7CqJ0Q5E03qBZzofaYr1i8EyE'}], 'enabled': False}",,,,,,True
597,,tensorflow,"I'm a beginner and trying to learn Tensorflow Transfer Learning.

Let's say I'm using the model  efficientdet\_d0\_coco17\_tpu-32 trained to identify a person very well but in my new model I want to train it to recognize a person holding a beer can and call it ""beer drinker"".

So I am pushing 500 images of people holding beer cans and another 200 images of just beer cans.

The pattern that I am trying to train is easily recognizable, a person without a beer can should be just ""person"" and the person with a beer can ""beer drinker""

when I do the inference, I am used to creating a label map array with just the ""new"" labels. In this new case should I just append ""person"" label to my label map?

Thank you for your help?",t2_7wqbp5z7,False,,0,False,Transfer Learning using previous labels with new labes,[],r/tensorflow,False,6,,0,,,False,t3_jjbl1h,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1603866739.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a beginner and trying to learn Tensorflow Transfer Learning.&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s say I&amp;#39;m using the model  efficientdet_d0_coco17_tpu-32 trained to identify a person very well but in my new model I want to train it to recognize a person holding a beer can and call it &amp;quot;beer drinker&amp;quot;.&lt;/p&gt;

&lt;p&gt;So I am pushing 500 images of people holding beer cans and another 200 images of just beer cans.&lt;/p&gt;

&lt;p&gt;The pattern that I am trying to train is easily recognizable, a person without a beer can should be just &amp;quot;person&amp;quot; and the person with a beer can &amp;quot;beer drinker&amp;quot;&lt;/p&gt;

&lt;p&gt;when I do the inference, I am used to creating a label map array with just the &amp;quot;new&amp;quot; labels. In this new case should I just append &amp;quot;person&amp;quot; label to my label map?&lt;/p&gt;

&lt;p&gt;Thank you for your help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jjbl1h,True,,Difficult_Monk7460,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/jjbl1h/transfer_learning_using_previous_labels_with_new/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jjbl1h/transfer_learning_using_previous_labels_with_new/,22217,1603837939.0,0,,False,,,,,,,,,
598,,tensorflow,"For my school project, I have to develop an agent to play 'Dots And Boxes' game.

&amp;#x200B;

https://preview.redd.it/u59xej705pv51.png?width=721&amp;format=png&amp;auto=webp&amp;s=44d8771991cacc98e8fa1aacf6f913ed0e67b518

&amp;#x200B;

The base I have is a 'GameManager' which call 2 AIs, each taking a random move to do.

&amp;#x200B;

To make my AI perform, I decided to make a deep RL algorithm.

&amp;#x200B;

Here is how I've designed my solution.

&amp;#x200B;

&amp;#x200B;

1st : the board is a 8x8 board. making \*\*112 possible lines to draw\*\*.

2nd : on each decision, my Agent has to choose 1 line in the remaining one.

3rd : each \*\*decision the Agent take is one among 112\*\* possible.

&amp;#x200B;

I read some codes on the internet, the most relevant for me was a 'CartPole' example, which is a cart we have to slide to prevent a mass to fall.

&amp;#x200B;

I made an architecture which is this one:

a game is simulated:

the board is clean, making all 112 possibilities available.

Our Agent is interroged by the gameManager to make a move passing him the actual state of the game

(\*\*the state shape is a 112\*1 vector of Boolean values\*\*, 1 means a line can be drawn, 0 means there is already a line on this position) 

(\*\*the action shape is a vector of 112\*1 Boolean values\*\*, All values are set to 'False' except the line we want to draw)

So, our Agent return his move decision.

&amp;#x200B;

Each time our agent perform a move, i store the initial state, the action we take, the reward we get performing the action, the state we reach and a boolean to know if the game is done or not.

&amp;#x200B;

The rewards I choose are: 

\+1 if our action make us close a box, 

\-1 if our action make other close a box, 

\+10 if our action make us win the game, 

\-10 if our action make us loose the game

&amp;#x200B;

&amp;#x200B;

The point is it's my 1st Deep learning project and I'm not sure about the mecanism i'm doing.

when i launch a simulation, the Neural Network is running, but the move he does seems not to be better and better.

&amp;#x200B;

I give you the code I've wrote:

&amp;#x200B;

\*\*Here is the gameManager code:\*\*

        while True:
        hasMadeABox = False
        gameIsEnd = False
        rewardFCB = 0
        doneFCB = False
    
    
        if GRAPHIC_MODE:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    pygame.quit()
                    sys.exit()
            disp_board()
    
        if playerTurns==""1"":
            stateFCB = possibilitiesToBoolList(possible_moves[0])
    
        boolArrayPossibleMoves = possibilitiesToBoolList(possible_moves[0])
    
        theAction = players[playerTurns].play(boxes, possible_moves[0], boolArrayPossibleMoves, False)
        #print(possible_moves[0])
        #print(theAction)
        if playerTurns ==""1"":
            actionFCB = theAction
    
        if playerTurns==""1"":
            is_box = move(True, theAction)
    
        elif playerTurns==""2"":
            is_box = move(False, theAction)
    
        if is_box:
            if playerTurns ==""1"":
                #rewardFCB = 1
                rewardFCB = 1
                pass
            else:
                rewardFCB = -1
            hasMadeABox = True
    
        if check_complete():
            gameIsEnd = True
            rewardFCB += 10 if score[0]&gt;score[1] else -10 #does loosing is a reward null or negativ ?
            queueOfLastGame.pop(0)
    
            #Scotch pour affichage winrate
            isWin = 1 if score[0]&gt;score[1] else -1
            queueOfLastGame.append(isWin)
            if queueOfLastGame.count(-1)+queueOfLastGame.count(1) &gt; 0:
                print(queueOfLastGame.count(1)/(queueOfLastGame.count(-1)+queueOfLastGame.count(1)) * 100 , "" % Winrate"")
    
            doneFCB = True
    
    
        if playerTurns==""1"" and hasMadeABox:
            #si c'est notre IA vient de faire un carré
            #on connait directement l'état qui succede
            nextStateFCB = possibilitiesToBoolList(possible_moves[0])
    
        if playerTurns==""2"":
            nextStateFCB = possibilitiesToBoolList(possible_moves[0])
    
    
        if nextStateFCB is not None:
            bufferSARS.append([stateFCB, actionFCB, rewardFCB, nextStateFCB, doneFCB])
            #ai_player_1.remember(stateFCB, actionFCB, rewardFCB, nextStateFCB, doneFCB)
            rewardFCB = 0
            nextStateFCB = None
    
        if gameIsEnd:
            flushBufferSARS()
            reset()
            continue
    
        #switch user to play if game is not end
        if not hasMadeABox:
            playerTurns=""1"" if playerTurns == ""2"" else ""2""

&amp;#x200B;

\*\*And here's my code about the Agent:\*\*

&amp;#x200B;

        class Agent:
    	def __init__(self, name, possibleActions, stateSize, actionSize, isHuman=False, alpha=0.001, alphaDecay=0.01, batchSize=2048, learningRate=0.1, epsilon= 0.9, gamma = 0.996, hasToTrain=True):
    
    		self._memory = deque(maxlen=100000)
    		self._actualEpisode=1
    		self._episodes=7000
    		self._name=name
    		self._possibleAction=possibleActions
    		self._isHuman=isHuman
    		self._epsilon=epsilon
    		self._epsilonDecay = 0.99
    		self._epsilonMin = 0.05
    		self._gamma=gamma
    		self._stateSize=stateSize
    		self._actionSize=actionSize
    		self._alpha=alpha
    		self._alphaDecay=alphaDecay
    		self._hasToTrain=hasToTrain
    		self._batchSize=batchSize
    
    		self._totalIllegalMove = 0
    		self._totalLegalMove = 0
    
    		self._path = ""./modelWeightSave/""
    
    		self._model = self._buildModel()
    
    
    	def save_model(self):
    		self._model.save(self._path)
    
    	def getName(self):
    		return self._name
    
    	def _buildModel(self):
    		model = Sequential()
    
    		model.add(Dense(128, input_dim=self._stateSize, activation='relu'))
    		model.add(Dense(256, kernel_initializer='normal', activation='relu'))
    		model.add(Dense(256, kernel_initializer='normal', activation='relu'))
    		model.add(Dense(256, kernel_initializer='normal', activation='relu'))
    		model.add(Dense(128, kernel_initializer='normal', activation='relu'))
    		model.add(Dense(self._actionSize, kernel_initializer='normal', activation='relu'))
    
    		model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=self._alpha), metrics=['accuracy'])
    		#if os.path.isfile(self._path):
    			#model.load_weights(self._path)
    		return model
    
    	def act(self, UNUSED_state, stateAsBool):
    		playableIndexes = []
    		for i in range(len(stateAsBool[0])):
    			if stateAsBool[0][i] == 1:
    				playableIndexes.append(i)
    		indexForRand = playableIndexes[random.randint(0, len(playableIndexes) - 1)]
    
    		if np.random.random() &lt;= self._epsilon:
    			action= [0]*self._actionSize
    			action[indexForRand]=1
    
    		else:
    			arrayState = np.array(stateAsBool)
    
    			action = self._model.predict(arrayState)
    			#Set index of max esperence to 1, we play this line.
    			tmp=[0]*self._actionSize
    			tmp[np.argmax(action)] = 1
    			action = tmp
    
    			isLegalMove = True
    			if sum(action) != 1:
    				isLegalMove = False
    			for i in range(len(action)):
    				if action[i] == 1:
    					if stateAsBool[0][i] == 0:
    						isLegalMove = False
    						break
    
    			if isLegalMove:
    				pass
    				#print(""Legal move"")
    			else:
    				#print(""Illegal move"")
    				#AI try to play on an already draw line, we choose a random line in remainings
    				self._totalIllegalMove+=1
    				action = [0] * self._actionSize
    				action[indexForRand] = 1
    
    		#print(""My AI took action : "",action)
    		return action
    
    	def remember(self, state, action, reward, nextState, done):
    		self._memory.append((state.copy(), action, reward, nextState, done))
    
    		self._actualEpisode+=1
    		if self._actualEpisode &gt; self._episodes:
    			self._actualEpisode = 0
    			self.replay(self._batchSize)
    
    	def replay(self, batchSize):
    		x_batch, y_batch = [], []
    		minibatch = random.sample(self._memory, min(len(self._memory), self._batchSize))
    		for state, action, reward, next_state, done in minibatch:
    			actionIndex = np.argmax(action)
    			y_target = self._model.predict(state)
    			y_target[0][actionIndex] = reward if done else reward + self._gamma * np.max(self._model.predict(next_state)[0])
    			x_batch.append(state[0])
    			y_batch.append(y_target[0])
    		self._model.fit(np.array(x_batch), np.array(y_batch),epochs=10, batch_size=len(x_batch), verbose=1)
    
    		if self._epsilon &gt; self._epsilonMin:
    			self._epsilon *= self._epsilonDecay
    
    		self.save_model()
    
    	def play(self, board, state, statesAsBool, player):
    		actionTaken= self.act(state, statesAsBool)
    		return actionTaken
    
    	def callBackOnPreviousMove(self, state, action, reward, nextState, done):
    		self.remember(state, action, reward, nextState, done)

&amp;#x200B;

Example of output i have during fit method:

        Epoch 1/10 
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9612 - accuracy: 0.8867
         
        Epoch 2/10 
        
        1/1 [==============================] - 0s 998us/step - loss: 109.9467 - accuracy: 0.8867 
        
        Epoch 3/10 
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9456 - accuracy: 0.8867 
        
        Epoch 4/10 
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9332 - accuracy: 0.8867 
        
        Epoch 5/10 
        
        1/1 [==============================] - 0s 998us/step - loss: 109.9339 - accuracy: 0.8867 
        
        Epoch 6/10 
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9337 - accuracy: 0.8867 
        
        Epoch 7/10 
        
        1/1 [==============================] - 0s 997us/step - loss: 109.9305 - accuracy: 0.8867 
        
        Epoch 8/10 
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9314 - accuracy: 0.8867 
        
        Epoch 9/10 
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9306 - accuracy: 0.8867 
        
        Epoch 10/10
        
        1/1 [==============================] - 0s 0s/step - loss: 109.9301 - accuracy: 0.8867

&amp;#x200B;

\*\*My questions are:\*\*

&amp;#x200B;

1. Is my architecture good 

(inputs = \[0,0,1,1,0,0,1,0.....,1,0\] (112x1 shape) to represent the state, and  

 output = \[0,0,0,0,0,0,0,0,0,1,0,0,0...0,0,0,0\] (112x1 shape with only one '1') )

to represent an action ?

&amp;#x200B;

2. How to nicely choose the architecture of the Neural Network model (self.\_model) (I have only the basics of Neural Network, so I don't really know all activation fonction, how to design the hiden layers, choose a loss...)

&amp;#x200B;

3. To train my NN, is it good to call the 'fit' function with (state, action) as parameter to make it learn?

&amp;#x200B;

4. Is there something really important I forget in my design to make it work?

&amp;#x200B;

&amp;#x200B;",t2_1xf97c1e,False,,0,False,"Deep Q Learning for Dots and boxes game, how to write the Neural Network using keras",[],r/tensorflow,False,6,,0,139.0,,False,t3_jj92lx,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},Project,False,3,,False,https://b.thumbs.redditmedia.com/nQxJWxvENNW7M-3ZVH8mzU_PU57oiyFIjqO7ijKbhnY.jpg,1604406812.0,,[],{},,True,,1603858976.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For my school project, I have to develop an agent to play &amp;#39;Dots And Boxes&amp;#39; game.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/u59xej705pv51.png?width=721&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44d8771991cacc98e8fa1aacf6f913ed0e67b518""&gt;https://preview.redd.it/u59xej705pv51.png?width=721&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44d8771991cacc98e8fa1aacf6f913ed0e67b518&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The base I have is a &amp;#39;GameManager&amp;#39; which call 2 AIs, each taking a random move to do.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;To make my AI perform, I decided to make a deep RL algorithm.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Here is how I&amp;#39;ve designed my solution.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;1st : the board is a 8x8 board. making **112 possible lines to draw**.&lt;/p&gt;

&lt;p&gt;2nd : on each decision, my Agent has to choose 1 line in the remaining one.&lt;/p&gt;

&lt;p&gt;3rd : each **decision the Agent take is one among 112** possible.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I read some codes on the internet, the most relevant for me was a &amp;#39;CartPole&amp;#39; example, which is a cart we have to slide to prevent a mass to fall.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I made an architecture which is this one:&lt;/p&gt;

&lt;p&gt;a game is simulated:&lt;/p&gt;

&lt;p&gt;the board is clean, making all 112 possibilities available.&lt;/p&gt;

&lt;p&gt;Our Agent is interroged by the gameManager to make a move passing him the actual state of the game&lt;/p&gt;

&lt;p&gt;(**the state shape is a 112*1 vector of Boolean values**, 1 means a line can be drawn, 0 means there is already a line on this position) &lt;/p&gt;

&lt;p&gt;(**the action shape is a vector of 112*1 Boolean values**, All values are set to &amp;#39;False&amp;#39; except the line we want to draw)&lt;/p&gt;

&lt;p&gt;So, our Agent return his move decision.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Each time our agent perform a move, i store the initial state, the action we take, the reward we get performing the action, the state we reach and a boolean to know if the game is done or not.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The rewards I choose are: &lt;/p&gt;

&lt;p&gt;+1 if our action make us close a box, &lt;/p&gt;

&lt;p&gt;-1 if our action make other close a box, &lt;/p&gt;

&lt;p&gt;+10 if our action make us win the game, &lt;/p&gt;

&lt;p&gt;-10 if our action make us loose the game&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The point is it&amp;#39;s my 1st Deep learning project and I&amp;#39;m not sure about the mecanism i&amp;#39;m doing.&lt;/p&gt;

&lt;p&gt;when i launch a simulation, the Neural Network is running, but the move he does seems not to be better and better.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I give you the code I&amp;#39;ve wrote:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;**Here is the gameManager code:**&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    while True:
    hasMadeABox = False
    gameIsEnd = False
    rewardFCB = 0
    doneFCB = False


    if GRAPHIC_MODE:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                pygame.quit()
                sys.exit()
        disp_board()

    if playerTurns==&amp;quot;1&amp;quot;:
        stateFCB = possibilitiesToBoolList(possible_moves[0])

    boolArrayPossibleMoves = possibilitiesToBoolList(possible_moves[0])

    theAction = players[playerTurns].play(boxes, possible_moves[0], boolArrayPossibleMoves, False)
    #print(possible_moves[0])
    #print(theAction)
    if playerTurns ==&amp;quot;1&amp;quot;:
        actionFCB = theAction

    if playerTurns==&amp;quot;1&amp;quot;:
        is_box = move(True, theAction)

    elif playerTurns==&amp;quot;2&amp;quot;:
        is_box = move(False, theAction)

    if is_box:
        if playerTurns ==&amp;quot;1&amp;quot;:
            #rewardFCB = 1
            rewardFCB = 1
            pass
        else:
            rewardFCB = -1
        hasMadeABox = True

    if check_complete():
        gameIsEnd = True
        rewardFCB += 10 if score[0]&amp;gt;score[1] else -10 #does loosing is a reward null or negativ ?
        queueOfLastGame.pop(0)

        #Scotch pour affichage winrate
        isWin = 1 if score[0]&amp;gt;score[1] else -1
        queueOfLastGame.append(isWin)
        if queueOfLastGame.count(-1)+queueOfLastGame.count(1) &amp;gt; 0:
            print(queueOfLastGame.count(1)/(queueOfLastGame.count(-1)+queueOfLastGame.count(1)) * 100 , &amp;quot; % Winrate&amp;quot;)

        doneFCB = True


    if playerTurns==&amp;quot;1&amp;quot; and hasMadeABox:
        #si c&amp;#39;est notre IA vient de faire un carré
        #on connait directement l&amp;#39;état qui succede
        nextStateFCB = possibilitiesToBoolList(possible_moves[0])

    if playerTurns==&amp;quot;2&amp;quot;:
        nextStateFCB = possibilitiesToBoolList(possible_moves[0])


    if nextStateFCB is not None:
        bufferSARS.append([stateFCB, actionFCB, rewardFCB, nextStateFCB, doneFCB])
        #ai_player_1.remember(stateFCB, actionFCB, rewardFCB, nextStateFCB, doneFCB)
        rewardFCB = 0
        nextStateFCB = None

    if gameIsEnd:
        flushBufferSARS()
        reset()
        continue

    #switch user to play if game is not end
    if not hasMadeABox:
        playerTurns=&amp;quot;1&amp;quot; if playerTurns == &amp;quot;2&amp;quot; else &amp;quot;2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;**And here&amp;#39;s my code about the Agent:**&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    class Agent:
    def __init__(self, name, possibleActions, stateSize, actionSize, isHuman=False, alpha=0.001, alphaDecay=0.01, batchSize=2048, learningRate=0.1, epsilon= 0.9, gamma = 0.996, hasToTrain=True):

        self._memory = deque(maxlen=100000)
        self._actualEpisode=1
        self._episodes=7000
        self._name=name
        self._possibleAction=possibleActions
        self._isHuman=isHuman
        self._epsilon=epsilon
        self._epsilonDecay = 0.99
        self._epsilonMin = 0.05
        self._gamma=gamma
        self._stateSize=stateSize
        self._actionSize=actionSize
        self._alpha=alpha
        self._alphaDecay=alphaDecay
        self._hasToTrain=hasToTrain
        self._batchSize=batchSize

        self._totalIllegalMove = 0
        self._totalLegalMove = 0

        self._path = &amp;quot;./modelWeightSave/&amp;quot;

        self._model = self._buildModel()


    def save_model(self):
        self._model.save(self._path)

    def getName(self):
        return self._name

    def _buildModel(self):
        model = Sequential()

        model.add(Dense(128, input_dim=self._stateSize, activation=&amp;#39;relu&amp;#39;))
        model.add(Dense(256, kernel_initializer=&amp;#39;normal&amp;#39;, activation=&amp;#39;relu&amp;#39;))
        model.add(Dense(256, kernel_initializer=&amp;#39;normal&amp;#39;, activation=&amp;#39;relu&amp;#39;))
        model.add(Dense(256, kernel_initializer=&amp;#39;normal&amp;#39;, activation=&amp;#39;relu&amp;#39;))
        model.add(Dense(128, kernel_initializer=&amp;#39;normal&amp;#39;, activation=&amp;#39;relu&amp;#39;))
        model.add(Dense(self._actionSize, kernel_initializer=&amp;#39;normal&amp;#39;, activation=&amp;#39;relu&amp;#39;))

        model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;, optimizer=Adam(lr=self._alpha), metrics=[&amp;#39;accuracy&amp;#39;])
        #if os.path.isfile(self._path):
            #model.load_weights(self._path)
        return model

    def act(self, UNUSED_state, stateAsBool):
        playableIndexes = []
        for i in range(len(stateAsBool[0])):
            if stateAsBool[0][i] == 1:
                playableIndexes.append(i)
        indexForRand = playableIndexes[random.randint(0, len(playableIndexes) - 1)]

        if np.random.random() &amp;lt;= self._epsilon:
            action= [0]*self._actionSize
            action[indexForRand]=1

        else:
            arrayState = np.array(stateAsBool)

            action = self._model.predict(arrayState)
            #Set index of max esperence to 1, we play this line.
            tmp=[0]*self._actionSize
            tmp[np.argmax(action)] = 1
            action = tmp

            isLegalMove = True
            if sum(action) != 1:
                isLegalMove = False
            for i in range(len(action)):
                if action[i] == 1:
                    if stateAsBool[0][i] == 0:
                        isLegalMove = False
                        break

            if isLegalMove:
                pass
                #print(&amp;quot;Legal move&amp;quot;)
            else:
                #print(&amp;quot;Illegal move&amp;quot;)
                #AI try to play on an already draw line, we choose a random line in remainings
                self._totalIllegalMove+=1
                action = [0] * self._actionSize
                action[indexForRand] = 1

        #print(&amp;quot;My AI took action : &amp;quot;,action)
        return action

    def remember(self, state, action, reward, nextState, done):
        self._memory.append((state.copy(), action, reward, nextState, done))

        self._actualEpisode+=1
        if self._actualEpisode &amp;gt; self._episodes:
            self._actualEpisode = 0
            self.replay(self._batchSize)

    def replay(self, batchSize):
        x_batch, y_batch = [], []
        minibatch = random.sample(self._memory, min(len(self._memory), self._batchSize))
        for state, action, reward, next_state, done in minibatch:
            actionIndex = np.argmax(action)
            y_target = self._model.predict(state)
            y_target[0][actionIndex] = reward if done else reward + self._gamma * np.max(self._model.predict(next_state)[0])
            x_batch.append(state[0])
            y_batch.append(y_target[0])
        self._model.fit(np.array(x_batch), np.array(y_batch),epochs=10, batch_size=len(x_batch), verbose=1)

        if self._epsilon &amp;gt; self._epsilonMin:
            self._epsilon *= self._epsilonDecay

        self.save_model()

    def play(self, board, state, statesAsBool, player):
        actionTaken= self.act(state, statesAsBool)
        return actionTaken

    def callBackOnPreviousMove(self, state, action, reward, nextState, done):
        self.remember(state, action, reward, nextState, done)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Example of output i have during fit method:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    Epoch 1/10 

    1/1 [==============================] - 0s 0s/step - loss: 109.9612 - accuracy: 0.8867

    Epoch 2/10 

    1/1 [==============================] - 0s 998us/step - loss: 109.9467 - accuracy: 0.8867 

    Epoch 3/10 

    1/1 [==============================] - 0s 0s/step - loss: 109.9456 - accuracy: 0.8867 

    Epoch 4/10 

    1/1 [==============================] - 0s 0s/step - loss: 109.9332 - accuracy: 0.8867 

    Epoch 5/10 

    1/1 [==============================] - 0s 998us/step - loss: 109.9339 - accuracy: 0.8867 

    Epoch 6/10 

    1/1 [==============================] - 0s 0s/step - loss: 109.9337 - accuracy: 0.8867 

    Epoch 7/10 

    1/1 [==============================] - 0s 997us/step - loss: 109.9305 - accuracy: 0.8867 

    Epoch 8/10 

    1/1 [==============================] - 0s 0s/step - loss: 109.9314 - accuracy: 0.8867 

    Epoch 9/10 

    1/1 [==============================] - 0s 0s/step - loss: 109.9306 - accuracy: 0.8867 

    Epoch 10/10

    1/1 [==============================] - 0s 0s/step - loss: 109.9301 - accuracy: 0.8867
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;**My questions are:**&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is my architecture good &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(inputs = [0,0,1,1,0,0,1,0.....,1,0] (112x1 shape) to represent the state, and  &lt;/p&gt;

&lt;p&gt;output = [0,0,0,0,0,0,0,0,0,1,0,0,0...0,0,0,0] (112x1 shape with only one &amp;#39;1&amp;#39;) )&lt;/p&gt;

&lt;p&gt;to represent an action ?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How to nicely choose the architecture of the Neural Network model (self._model) (I have only the basics of Neural Network, so I don&amp;#39;t really know all activation fonction, how to design the hiden layers, choose a loss...)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;To train my NN, is it good to call the &amp;#39;fit&amp;#39; function with (state, action) as parameter to make it learn?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is there something really important I forget in my design to make it work?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jj92lx,True,,MarataWP,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jj92lx/deep_q_learning_for_dots_and_boxes_game_how_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jj92lx/deep_q_learning_for_dots_and_boxes_game_how_to/,22217,1603830176.0,0,,False,,,,,"{'u59xej705pv51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 107, 'x': 108, 'u': 'https://preview.redd.it/u59xej705pv51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7873597f66a115aebd975d9f522d48bcccd5682'}, {'y': 215, 'x': 216, 'u': 'https://preview.redd.it/u59xej705pv51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f54a1c8a237a10197b50e43bace516b6dffde20'}, {'y': 319, 'x': 320, 'u': 'https://preview.redd.it/u59xej705pv51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b7cb057a06d1ce23d9970873514ff7b8737b7aec'}, {'y': 638, 'x': 640, 'u': 'https://preview.redd.it/u59xej705pv51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d977bb8f78cfcb4d39bcd09bc46aad1c98edd8d3'}], 's': {'y': 719, 'x': 721, 'u': 'https://preview.redd.it/u59xej705pv51.png?width=721&amp;format=png&amp;auto=webp&amp;s=44d8771991cacc98e8fa1aacf6f913ed0e67b518'}, 'id': 'u59xej705pv51'}}",,,,
599,,tensorflow,"If I understand correctly we can use Tensorflow to run on multiple GPU's on the same machine (for example using tf.distribute.MirroredStrategy) in the following way:

1. Split the data into N sub-batches, where N is equal to number of GPU's
2. Per GPU we do the following:
   1. Run the data through the network
   2. Calculate the loss function
   3. Back-propagate the gradients
3. The gradients are shared and summed across all GPU's and thus every GPU can apply the same update to the weights

However I am not able to find if there is a way to calculate the loss function over all data, instead of over a sub-batch, for example by sending the outputs of the network to one GPU (or perhaps to the CPU), calculating the loss function over all data, and then returning the loss to every GPU.

This would be very useful for contrastive learning, where we want to compare all samples in a batch, not just within a sub-batch. Does anyone know if this is currently possible?",t2_8n7izmb1,False,,0,False,Tensorflow Multi-GPU but single GPU or CPU calculation of loss function,[],r/tensorflow,False,6,,0,,,False,t3_jj127v,False,dark,0.88,,public,12,0,{},,,False,[],,False,False,,{},,False,12,,False,self,False,,[],{},,True,,1603833942.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I understand correctly we can use Tensorflow to run on multiple GPU&amp;#39;s on the same machine (for example using tf.distribute.MirroredStrategy) in the following way:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Split the data into N sub-batches, where N is equal to number of GPU&amp;#39;s&lt;/li&gt;
&lt;li&gt;Per GPU we do the following:

&lt;ol&gt;
&lt;li&gt;Run the data through the network&lt;/li&gt;
&lt;li&gt;Calculate the loss function&lt;/li&gt;
&lt;li&gt;Back-propagate the gradients&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;The gradients are shared and summed across all GPU&amp;#39;s and thus every GPU can apply the same update to the weights&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;However I am not able to find if there is a way to calculate the loss function over all data, instead of over a sub-batch, for example by sending the outputs of the network to one GPU (or perhaps to the CPU), calculating the loss function over all data, and then returning the loss to every GPU.&lt;/p&gt;

&lt;p&gt;This would be very useful for contrastive learning, where we want to compare all samples in a batch, not just within a sub-batch. Does anyone know if this is currently possible?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jj127v,True,,3e60C9lUiH58qiKO,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jj127v/tensorflow_multigpu_but_single_gpu_or_cpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jj127v/tensorflow_multigpu_but_single_gpu_or_cpu/,22217,1603805142.0,0,,False,,,,,,,,,
600,,tensorflow,,t2_7f71agho,False,,0,False,Will tensorflow completely ditch graph execution?,[],r/tensorflow,False,6,,0,,,False,t3_jit7xb,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},Question,False,9,,False,self,False,,[],{},,True,,1603795760.0,text,6,,,text,self.tensorflow,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jit7xb,True,,DrAsgardian,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jit7xb/will_tensorflow_completely_ditch_graph_execution/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jit7xb/will_tensorflow_completely_ditch_graph_execution/,22217,1603766960.0,0,,False,,,,,,,,,
601,,tensorflow,"I am interested in contributing code to tensorflow but as a student I have really have trouble in understanding huge code bases. So first I would like to learn concepts behind tensorflow. By concepts I don't mean ML algos I mean how automatic differentiation is implemented in C++ such kind of things.

I have tried to search about it but I have found no use..

I have a solid base in c++ and python. Can you guys guide me what to do?  Book recommendation are also welcome.",t2_7f71agho,False,,0,False,Contributing code to tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_ji8i3i,False,dark,0.96,,public,23,0,{},,,False,[],,False,False,,{},Question,False,23,,False,self,False,,[],{},,True,,1603716641.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am interested in contributing code to tensorflow but as a student I have really have trouble in understanding huge code bases. So first I would like to learn concepts behind tensorflow. By concepts I don&amp;#39;t mean ML algos I mean how automatic differentiation is implemented in C++ such kind of things.&lt;/p&gt;

&lt;p&gt;I have tried to search about it but I have found no use..&lt;/p&gt;

&lt;p&gt;I have a solid base in c++ and python. Can you guys guide me what to do?  Book recommendation are also welcome.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,ji8i3i,True,,DrAsgardian,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ji8i3i/contributing_code_to_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ji8i3i/contributing_code_to_tensorflow/,22217,1603687841.0,0,,False,,,,,,,,,
602,,tensorflow,,t2_6fgqhah1,False,,0,False,Significant lower accruacy when using empty ImageDataGenerator in Tensorflow Keras,[],r/tensorflow,False,6,,0,140.0,,False,t3_jinom5,False,dark,0.6,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/tYtOdS0U5f5A9t6jE9mXLEfX6SuJVf6e4Uol5zID73o.jpg,False,,[],{},,False,,1603776354.0,text,6,,,text,stackoverflow.com,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jinom5,True,,jebeszivot,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jinom5/significant_lower_accruacy_when_using_empty/,all_ads,False,https://stackoverflow.com/questions/64545128/significant-lower-accruacy-when-using-empty-imagedatagenerator-in-tensorflow-ker,22217,1603747554.0,0,,False,link,https://stackoverflow.com/questions/64545128/significant-lower-accruacy-when-using-empty-imagedatagenerator-in-tensorflow-ker,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
603,,tensorflow,,t2_4760f5hy,False,,0,False,"I made my first text classification model with tensorflow, but the accuracy is low. How do I make it better?",[],r/tensorflow,False,6,,0,113.0,,False,t3_jhxizw,False,dark,0.93,,public,37,1,{},140.0,,False,[],,True,False,,{},Question,False,37,,False,https://b.thumbs.redditmedia.com/Bwe-Kt7x8GV1aEX3Ee9OC5H73BbKmyrKhwtLoQd_EQg.jpg,False,,[],{},,False,,1603676663.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 50, 'id': 'award_02d9ab2c-162e-4c01-8438-317a016ed3d9', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""I'm in this with you."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Take My Energy', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png'}]",[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jhxizw,True,,ARNisUsername,,35,True,all_ads,False,[],False,,/r/tensorflow/comments/jhxizw/i_made_my_first_text_classification_model_with/,all_ads,False,https://i.redd.it/jybm5q1v2av51.png,22217,1603647863.0,0,,False,image,https://i.redd.it/jybm5q1v2av51.png,"{'images': [{'source': {'url': 'https://preview.redd.it/jybm5q1v2av51.png?auto=webp&amp;s=9979ae605da13aee8766807ba29540e8e2376877', 'width': 2268, 'height': 1844}, 'resolutions': [{'url': 'https://preview.redd.it/jybm5q1v2av51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9199f8995cd46a24adee741f1160f8f53356a6a0', 'width': 108, 'height': 87}, {'url': 'https://preview.redd.it/jybm5q1v2av51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d9c6db4f10f4948c42b6aba4c155ef847470e62', 'width': 216, 'height': 175}, {'url': 'https://preview.redd.it/jybm5q1v2av51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3101017fbc912e51827fe056967365e1eba5c406', 'width': 320, 'height': 260}, {'url': 'https://preview.redd.it/jybm5q1v2av51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe20975b3b8e8f5bef5f9682c19598525b9dbe8b', 'width': 640, 'height': 520}, {'url': 'https://preview.redd.it/jybm5q1v2av51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=591c5c78a0ec5a3268ccbfa7a4eddc897a104851', 'width': 960, 'height': 780}, {'url': 'https://preview.redd.it/jybm5q1v2av51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b225a55cdf21fb2fa2c0c7873e9cfd7f1c85bfbf', 'width': 1080, 'height': 878}], 'variants': {}, 'id': 'kcKcoRi53x8H_ghwMlbVn-eqkOMMUvx8m2DGeND71C0'}], 'enabled': True}",,,,,,
604,,tensorflow,,t2_6fhn24i6,False,,0,False,"I made this python module that allow create image databases on demand scraping search engines like Google or DuckDuckGo, using tor network.",[],r/tensorflow,False,6,,0,140.0,,False,t3_ji1ebn,False,dark,1.0,,public,9,0,{},140.0,,False,[],,False,False,,{},Project,False,9,,False,https://b.thumbs.redditmedia.com/rL64Mx74robz8pNfctr1SSqP9YzgX4Z-u4kRgrGOYVM.jpg,False,,[],{},,False,,1603689448.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,ji1ebn,True,,horaizonBreaker,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ji1ebn/i_made_this_python_module_that_allow_create_image/,all_ads,False,https://github.com/ehoraizon/engineCrawler,22217,1603660648.0,0,,False,link,https://github.com/ehoraizon/engineCrawler,"{'images': [{'source': {'url': 'https://external-preview.redd.it/d3y8vpI9mwZYkWElRT5JLwZvlgJtUdIiG1KNmfGoivU.jpg?auto=webp&amp;s=5be0cc7386ec2f6e20797c955d2c0750ebbb6f33', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/d3y8vpI9mwZYkWElRT5JLwZvlgJtUdIiG1KNmfGoivU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=80133834a191237a97680ae949aead2f84e79fc1', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/d3y8vpI9mwZYkWElRT5JLwZvlgJtUdIiG1KNmfGoivU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=27e9e79c0e53e7b86e58d9245ec34cf3846a4285', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/d3y8vpI9mwZYkWElRT5JLwZvlgJtUdIiG1KNmfGoivU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c44484ebdea0fed76fc3084a101fe67d660c5ad', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'zudrIxYpUqG2-20xIiW4F4jXdlqkZgFFKBme6jkL5UM'}], 'enabled': False}",,,,,,
605,,tensorflow,,t2_toatvig,False,,0,False,"Introduction to TensorFlow for AI, Machine Learning, and Deep Learning",[],r/tensorflow,False,6,,0,82.0,,False,t3_jh7lvk,False,dark,0.81,,public,13,0,{},140.0,,False,[],,False,False,,{},Discussion,False,13,,False,https://b.thumbs.redditmedia.com/zRgcSc1k8009aueIHPewAHiCZssS974cOnD_dhEKJAc.jpg,False,,[],{},,False,,1603568982.0,text,6,,,text,medium.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jh7lvk,True,,frenchdic,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jh7lvk/introduction_to_tensorflow_for_ai_machine/,all_ads,False,https://medium.com/@codinggeeks/introduction-to-tensorflow-for-ai-machine-learning-and-deep-learning-8c62148d4c7b,22217,1603540182.0,0,,False,link,https://medium.com/@codinggeeks/introduction-to-tensorflow-for-ai-machine-learning-and-deep-learning-8c62148d4c7b,"{'images': [{'source': {'url': 'https://external-preview.redd.it/F7hOo1aKJ21XvK2haoMjDqgwafVWfjk5dSJ7QdW0fe0.jpg?auto=webp&amp;s=29563e66d380462dd01493f32b6463061c469e2e', 'width': 509, 'height': 301}, 'resolutions': [{'url': 'https://external-preview.redd.it/F7hOo1aKJ21XvK2haoMjDqgwafVWfjk5dSJ7QdW0fe0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5aeac25f39405bd62077de3f85aea04930111672', 'width': 108, 'height': 63}, {'url': 'https://external-preview.redd.it/F7hOo1aKJ21XvK2haoMjDqgwafVWfjk5dSJ7QdW0fe0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d652040ec6d762f00b03531ea2f3329248a6d7af', 'width': 216, 'height': 127}, {'url': 'https://external-preview.redd.it/F7hOo1aKJ21XvK2haoMjDqgwafVWfjk5dSJ7QdW0fe0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba8e274e8c121ac25fa40bdf5acc47dffa5c1c77', 'width': 320, 'height': 189}], 'variants': {}, 'id': 'Zq8hgUQHhDSp6R3cetVS1xXVX7TXKOF8pVyDOtoOX6o'}], 'enabled': False}",,,,,,
606,,tensorflow,"I am trying to do sentence generator using 50D word embedding. If my training sentence is ""hello my name is abc"" here max words is 5. So my first training x is \[0,0,0,0,hello\]and target is \[my\] second x would be \[0,0,0,hello,my\]target is \[name\]and so on...

To generate given sentence should I give \[hello\]or with padding \[0,0,0,0,hello\]?",t2_7f71agho,False,,0,False,Is masking needed for prediction in LSTM keras,[],r/tensorflow,False,6,,0,,,False,t3_jhc473,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1603586648.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to do sentence generator using 50D word embedding. If my training sentence is &amp;quot;hello my name is abc&amp;quot; here max words is 5. So my first training x is [0,0,0,0,hello]and target is [my] second x would be [0,0,0,hello,my]target is [name]and so on...&lt;/p&gt;

&lt;p&gt;To generate given sentence should I give [hello]or with padding [0,0,0,0,hello]?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jhc473,True,,DrAsgardian,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jhc473/is_masking_needed_for_prediction_in_lstm_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jhc473/is_masking_needed_for_prediction_in_lstm_keras/,22217,1603557848.0,0,,False,,,,,,,,,
607,,tensorflow,"Today, and after more than 9 weeks of study , I passed the TensorFlow Certificate exam. I have not received my certificate yet, but I couldn't wait until then to announce about it :)

I am the first person to acquire this certificate in my country! 

I wrote an article on [on Medium](https://s-badran.medium.com/from-zero-to-hero-how-i-passed-the-tensorflow-developer-certificate-exam-14d1c6d6173e ) about how I passed the exam and tips for anyone who plans to take it. Many of which I didn't see anywhere during my search before I take the certificate, so I hope you will find them helpful.",t2_gvt73wh,False,,0,False,I passed the TensorFlow Developer Certificate exam!,[],r/tensorflow,False,6,,0,,,False,t3_jgth3n,False,dark,0.96,,public,43,0,{},,,False,[],,False,False,,{},Discussion,False,43,,False,self,1603565978.0,,[],{},,True,,1603508577.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Today, and after more than 9 weeks of study , I passed the TensorFlow Certificate exam. I have not received my certificate yet, but I couldn&amp;#39;t wait until then to announce about it :)&lt;/p&gt;

&lt;p&gt;I am the first person to acquire this certificate in my country! &lt;/p&gt;

&lt;p&gt;I wrote an article on &lt;a href=""https://s-badran.medium.com/from-zero-to-hero-how-i-passed-the-tensorflow-developer-certificate-exam-14d1c6d6173e""&gt;on Medium&lt;/a&gt; about how I passed the exam and tips for anyone who plans to take it. Many of which I didn&amp;#39;t see anywhere during my search before I take the certificate, so I hope you will find them helpful.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jgth3n,True,,salouri,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/jgth3n/i_passed_the_tensorflow_developer_certificate_exam/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jgth3n/i_passed_the_tensorflow_developer_certificate_exam/,22217,1603479777.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Dnu-KY7Poiugnn2MivG26iguwLM38Y2eWBF3SxO18bY.jpg?auto=webp&amp;s=fea758c180ae8425bd15736576221804c7188b82', 'width': 700, 'height': 263}, 'resolutions': [{'url': 'https://external-preview.redd.it/Dnu-KY7Poiugnn2MivG26iguwLM38Y2eWBF3SxO18bY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a09fe66c29510b28eed5b94f3cf545611a77a21f', 'width': 108, 'height': 40}, {'url': 'https://external-preview.redd.it/Dnu-KY7Poiugnn2MivG26iguwLM38Y2eWBF3SxO18bY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=06cc778c199de5ebc77e89f6166fbc59c258420a', 'width': 216, 'height': 81}, {'url': 'https://external-preview.redd.it/Dnu-KY7Poiugnn2MivG26iguwLM38Y2eWBF3SxO18bY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da982de4fff24305b461a9dbc9fab2e346e738fa', 'width': 320, 'height': 120}, {'url': 'https://external-preview.redd.it/Dnu-KY7Poiugnn2MivG26iguwLM38Y2eWBF3SxO18bY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=949884254e997c4db1f99a09393aa65df361a1ea', 'width': 640, 'height': 240}], 'variants': {}, 'id': 'lwX9J4YiatH9SSu-FO-AzD93w0QWPyfyx1IAYUK97Qg'}], 'enabled': False}",,,,,,
608,,tensorflow,"[https://www.tensorflow.org/tutorials/estimator/linear](https://www.tensorflow.org/tutorials/estimator/linear)

I am following the Tensorflow documentation to implement a Linear Classifier but I like to use my own data instead of the tutorial set. I just have a few general questions. 

My dataset is as follows. It's not a time series.

row\[0\] - float (changed to binary, 0 = negative, 1 = positive) VALUE TO ESTIMATE

row\[1\] - string (categorical, changed to vocabulary, ints 1,2,3,4,5,6,7,8,9)

row\[2-19\] - float (positive and negative)

row\[20-60\] - ints (percentile ranks, ints 10,20,30,40,50,60,70,80,90)

row\[61-95\] - ints (binary 1, 0)

&amp;#x200B;

 I started by using 50k (45k training) rows of data and num\_epochs=100, batch\_size=256.

 {'accuracy': 0.8912, 'accuracy\_baseline': 0.8932, 'auc': 0.7101819, 'auc\_precision\_recall': 0.2830853, 'average\_loss': 0.30982444, 'label/mean': 0.1068, 'loss': 0.31013006, 'precision': 0.4537037, 'prediction/mean': 0.11840516, 'recall': 0.0917603, 'global\_step': 17600} 

&amp;#x200B;

1. Does the column I want to estimate need to be a column of binaries for this model? 

2. Is it a bad idea to mix data types like this? Would it be necessary to normalize the data using something like  `preprocessing.Normalization` ?

3. Should I alter the epochs/batch if I want to use more data?

4. The accuracy seems high but the loss also seems quite high, why is that?

5. Any other suggestions?

&amp;#x200B;

Thanks for any help or advice.",t2_8lr62fjg,False,,0,False,"Tensorflow Beginner, Questions On Linear Model",[],r/tensorflow,False,6,,0,,,False,t3_jh4mfw,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1603551991.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.tensorflow.org/tutorials/estimator/linear""&gt;https://www.tensorflow.org/tutorials/estimator/linear&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am following the Tensorflow documentation to implement a Linear Classifier but I like to use my own data instead of the tutorial set. I just have a few general questions. &lt;/p&gt;

&lt;p&gt;My dataset is as follows. It&amp;#39;s not a time series.&lt;/p&gt;

&lt;p&gt;row[0] - float (changed to binary, 0 = negative, 1 = positive) VALUE TO ESTIMATE&lt;/p&gt;

&lt;p&gt;row[1] - string (categorical, changed to vocabulary, ints 1,2,3,4,5,6,7,8,9)&lt;/p&gt;

&lt;p&gt;row[2-19] - float (positive and negative)&lt;/p&gt;

&lt;p&gt;row[20-60] - ints (percentile ranks, ints 10,20,30,40,50,60,70,80,90)&lt;/p&gt;

&lt;p&gt;row[61-95] - ints (binary 1, 0)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I started by using 50k (45k training) rows of data and num_epochs=100, batch_size=256.&lt;/p&gt;

&lt;p&gt;{&amp;#39;accuracy&amp;#39;: 0.8912, &amp;#39;accuracy_baseline&amp;#39;: 0.8932, &amp;#39;auc&amp;#39;: 0.7101819, &amp;#39;auc_precision_recall&amp;#39;: 0.2830853, &amp;#39;average_loss&amp;#39;: 0.30982444, &amp;#39;label/mean&amp;#39;: 0.1068, &amp;#39;loss&amp;#39;: 0.31013006, &amp;#39;precision&amp;#39;: 0.4537037, &amp;#39;prediction/mean&amp;#39;: 0.11840516, &amp;#39;recall&amp;#39;: 0.0917603, &amp;#39;global_step&amp;#39;: 17600} &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Does the column I want to estimate need to be a column of binaries for this model? &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Is it a bad idea to mix data types like this? Would it be necessary to normalize the data using something like  &lt;code&gt;preprocessing.Normalization&lt;/code&gt; ?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Should I alter the epochs/batch if I want to use more data?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The accuracy seems high but the loss also seems quite high, why is that?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Any other suggestions?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for any help or advice.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jh4mfw,True,,chungmuro,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jh4mfw/tensorflow_beginner_questions_on_linear_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jh4mfw/tensorflow_beginner_questions_on_linear_model/,22217,1603523191.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
609,,tensorflow,"\#help\_needed

\#long\_post

Hello y'all,

I have been trying to train an object detection model for past 2 months and have finally succeeded by following this [tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/).

Here is my [colab](https://colab.research.google.com/drive/1Dn3bgYkialkPXImM1XWaYqjgVNTGI9Fn?usp=sharing) which contains all my work.

The problem is, the training loss is shown, and it is decreasing on average, but the validation loss is not.

In the `pipeline.config` file, I did input the evaluation TFRecord file (which I assumed to be the validation data input) , like this:

&gt;eval\_config {    
&gt;  
&gt;  metrics\_set: ""coco\_detection\_metrics""   
&gt;  
&gt;  use\_moving\_averages: false  
&gt;  
&gt;}   
&gt;  
&gt;eval\_input\_reader {    
&gt;  
&gt;  label\_map\_path: ""annotations/label\_map.pbtxt""  
&gt;  
&gt;  shuffle: false   
&gt;  
&gt;  num\_epochs: 1   
&gt;  
&gt;  tf\_record\_input\_reader {    
&gt;  
&gt;input\_path: ""annotations/test.record""  
&gt;  
&gt;  }   
&gt;  
&gt;} 

and I read through [model\_main\_tf2.py](https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py), which does not seem to evaluation while training, but only evaluates when the checkpoint\_dir is mentioned.

Hence, I have only been able to monitor the loss on the training set and not the loss on the validation set.

As a result, I have no clue about over or under fitting.

**Have any of you managed to use model\_main\_tf2.py successfully to view validation loss?**

Also, it would be nice to see the mAP score with training.

I know keras training allows all these things to be seen on tensorboard, but OD API seems to be much harder.

Thank you for your time, if you are still confused about something please let me know.",t2_81y6dvxz,False,,0,False,TF2 Object Detection API: model_main_tf2.py - validation loss?,[],r/tensorflow,False,6,,0,,,False,t3_jh48wx,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1603549954.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;#help_needed&lt;/p&gt;

&lt;p&gt;#long_post&lt;/p&gt;

&lt;p&gt;Hello y&amp;#39;all,&lt;/p&gt;

&lt;p&gt;I have been trying to train an object detection model for past 2 months and have finally succeeded by following this &lt;a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/""&gt;tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here is my &lt;a href=""https://colab.research.google.com/drive/1Dn3bgYkialkPXImM1XWaYqjgVNTGI9Fn?usp=sharing""&gt;colab&lt;/a&gt; which contains all my work.&lt;/p&gt;

&lt;p&gt;The problem is, the training loss is shown, and it is decreasing on average, but the validation loss is not.&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;pipeline.config&lt;/code&gt; file, I did input the evaluation TFRecord file (which I assumed to be the validation data input) , like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;eval_config {    &lt;/p&gt;

&lt;p&gt;metrics_set: &amp;quot;coco_detection_metrics&amp;quot;   &lt;/p&gt;

&lt;p&gt;use_moving_averages: false  &lt;/p&gt;

&lt;p&gt;}   &lt;/p&gt;

&lt;p&gt;eval_input_reader {    &lt;/p&gt;

&lt;p&gt;label_map_path: &amp;quot;annotations/label_map.pbtxt&amp;quot;  &lt;/p&gt;

&lt;p&gt;shuffle: false   &lt;/p&gt;

&lt;p&gt;num_epochs: 1   &lt;/p&gt;

&lt;p&gt;tf_record_input_reader {    &lt;/p&gt;

&lt;p&gt;input_path: &amp;quot;annotations/test.record&amp;quot;  &lt;/p&gt;

&lt;p&gt;}   &lt;/p&gt;

&lt;p&gt;} &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and I read through &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py""&gt;model_main_tf2.py&lt;/a&gt;, which does not seem to evaluation while training, but only evaluates when the checkpoint_dir is mentioned.&lt;/p&gt;

&lt;p&gt;Hence, I have only been able to monitor the loss on the training set and not the loss on the validation set.&lt;/p&gt;

&lt;p&gt;As a result, I have no clue about over or under fitting.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Have any of you managed to use model_main_tf2.py successfully to view validation loss?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Also, it would be nice to see the mAP score with training.&lt;/p&gt;

&lt;p&gt;I know keras training allows all these things to be seen on tensorboard, but OD API seems to be much harder.&lt;/p&gt;

&lt;p&gt;Thank you for your time, if you are still confused about something please let me know.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jh48wx,True,,yasserius,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jh48wx/tf2_object_detection_api_model_main_tf2py/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jh48wx/tf2_object_detection_api_model_main_tf2py/,22217,1603521154.0,1,,False,,,,,,,,,
610,,tensorflow,,t2_44mbtmjy,False,,0,False,Dynamic Sky Replacement and Harmonization in Videos,[],r/tensorflow,False,6,,0,104.0,,False,t3_jh1p0c,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/1WO_qN-kUsQZlrZ1gp2PFSk7kXTtxhKVcCrRPltBedI.jpg,False,,[],{},,False,,1603537913.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jh1p0c,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jh1p0c/dynamic_sky_replacement_and_harmonization_in/,all_ads,False,/r/LatestInML/comments/jh15yw/dynamic_sky_replacement_and_harmonization_in/,22217,1603509113.0,0,,False,link,/r/LatestInML/comments/jh15yw/dynamic_sky_replacement_and_harmonization_in/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?auto=webp&amp;s=175881828ac4155675f6283ecb09f5d5855c05dd', 'width': 550, 'height': 412}, 'resolutions': [{'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1862d1421fde20de23060073b1e098feff692f70', 'width': 108, 'height': 80}, {'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=422fec0a0920518fb5cf6d6497a63a124421ac25', 'width': 216, 'height': 161}, {'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c280cb24b3aeb425b7e99044cda5cf757bd3c1f', 'width': 320, 'height': 239}], 'variants': {}, 'id': 'uZVOFw10-mSgqLolCEIiz_PG4m12LL_kcRCnxFSox5c'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/expert/API requests: [click here](https://www.catalyzex.com/paper/arxiv:2010.11800)\n\nhttps://reddit.com/link/jh15yw/video/upftd71ofyu51/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Dynamic Sky Replacement and Harmonization in Videos', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 104, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'upftd71ofyu51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/jh15yw/asset/upftd71ofyu51/DASHPlaylist.mpd?a=1618044797%2CYTJmZWIzZTNjNGE1OGFkOTVmNDQ2ZjdiZTg4MGNlNGM5OWZjZGRlZWE2M2ViOWYwZmRhYzQwYjhjZGQ4YThkZg%3D%3D&amp;v=1&amp;f=sd', 'x': 426, 'y': 206, 'hlsUrl': 'https://v.redd.it/link/jh15yw/asset/upftd71ofyu51/HLSPlaylist.m3u8?a=1618044797%2CMGQ4NGM1YzlhMTU5MGUyNzQ2NmM3NzQxYTNjMmRkOTk0YWI1MzI1NmFhMmQyODU0NTFmZDU0YjUwYTg1NDQ4Ng%3D%3D&amp;v=1&amp;f=sd', 'id': 'upftd71ofyu51', 'isGif': False}}, 'name': 't3_jh15yw', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 12, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 12, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/1WO_qN-kUsQZlrZ1gp2PFSk7kXTtxhKVcCrRPltBedI.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1603535671.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/expert/API requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2010.11800""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/jh15yw/video/upftd71ofyu51/player""&gt;https://reddit.com/link/jh15yw/video/upftd71ofyu51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?auto=webp&amp;s=175881828ac4155675f6283ecb09f5d5855c05dd', 'width': 550, 'height': 412}, 'resolutions': [{'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1862d1421fde20de23060073b1e098feff692f70', 'width': 108, 'height': 80}, {'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=422fec0a0920518fb5cf6d6497a63a124421ac25', 'width': 216, 'height': 161}, {'url': 'https://external-preview.redd.it/qEb34SXKMzgHdUpjardQMBC4I7nDCz81FW9m99Bmuws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c280cb24b3aeb425b7e99044cda5cf757bd3c1f', 'width': 320, 'height': 239}], 'variants': {}, 'id': 'uZVOFw10-mSgqLolCEIiz_PG4m12LL_kcRCnxFSox5c'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'jh15yw', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/jh15yw/dynamic_sky_replacement_and_harmonization_in/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/jh15yw/dynamic_sky_replacement_and_harmonization_in/', 'subreddit_subscribers': 6676, 'created_utc': 1603506871.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_jh15yw,
611,,tensorflow,"[https://github.com/ben-arnao/Radabelief/blob/main/radabelief.py](https://github.com/ben-arnao/Radabelief/blob/main/radabelief.py)

Basically I use `tf.square(grad - m_t)` instead of `tf.square(m_t)` for the second moment (Adabelief)

I also use a rectification by adding warmup into the optimizer however, I do not do the decay steps as well like the tf\_addons implementation. This is so that we can use a callback like ReduceLrOnPlateau instead of having to define your decay schedule here.

Epsilon is set higher by default (as it should be). Lr is also set to 1e-4 instead of 1e-3.

Seems to work pretty well for me. Lmk if anyone else has success",t2_6qvny,False,,0,False,"I made a TF/Keras implementation of ""radabelief"" Radam + Adabelief, for anyone who might interested",[],r/tensorflow,False,6,,0,,,False,t3_jgn7jo,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1603488877.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/ben-arnao/Radabelief/blob/main/radabelief.py""&gt;https://github.com/ben-arnao/Radabelief/blob/main/radabelief.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Basically I use &lt;code&gt;tf.square(grad - m_t)&lt;/code&gt; instead of &lt;code&gt;tf.square(m_t)&lt;/code&gt; for the second moment (Adabelief)&lt;/p&gt;

&lt;p&gt;I also use a rectification by adding warmup into the optimizer however, I do not do the decay steps as well like the tf_addons implementation. This is so that we can use a callback like ReduceLrOnPlateau instead of having to define your decay schedule here.&lt;/p&gt;

&lt;p&gt;Epsilon is set higher by default (as it should be). Lr is also set to 1e-4 instead of 1e-3.&lt;/p&gt;

&lt;p&gt;Seems to work pretty well for me. Lmk if anyone else has success&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jgn7jo,True,,Yogi_DMT,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jgn7jo/i_made_a_tfkeras_implementation_of_radabelief/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jgn7jo/i_made_a_tfkeras_implementation_of_radabelief/,22217,1603460077.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/7g1VD4U2K7JfZvRXZ4dgcRAeNd_Ono32Lp2h8Ue_hog.jpg?auto=webp&amp;s=8234f5d42d5ac65af1e772e0dfb7de68888c3cbe', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/7g1VD4U2K7JfZvRXZ4dgcRAeNd_Ono32Lp2h8Ue_hog.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a1412110d5bd29193dae032cd54c3dbe86ad6af', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/7g1VD4U2K7JfZvRXZ4dgcRAeNd_Ono32Lp2h8Ue_hog.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=174f195530b8a448316d41d9d6c7ca2e1fcf4240', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/7g1VD4U2K7JfZvRXZ4dgcRAeNd_Ono32Lp2h8Ue_hog.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7a063500f651d30d94132db72e9e094b3429e82', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'FmqY3Nnqzd97eBUumaBzQ4OR13q7RSQvfbu1UE3xEv8'}], 'enabled': False}",,,,,,
612,,tensorflow,[https://github.com/AbhishekSinhaCoder/Complete-ML-Coursework](https://github.com/AbhishekSinhaCoder/Complete-ML-Coursework),,False,,0,False,I have created a repo for people who wanted to get started in Machine learning.,[],r/tensorflow,False,6,,0,,,False,t3_jg3otp,False,dark,0.95,,public,57,0,{},,,False,[],,False,False,,{},Project,False,57,,,self,False,,,{},,True,,1603415054.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/AbhishekSinhaCoder/Complete-ML-Coursework""&gt;https://github.com/AbhishekSinhaCoder/Complete-ML-Coursework&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jg3otp,True,,[deleted],,4,True,all_ads,False,[],,dark,/r/tensorflow/comments/jg3otp/i_have_created_a_repo_for_people_who_wanted_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jg3otp/i_have_created_a_repo_for_people_who_wanted_to/,22217,1603386254.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?auto=webp&amp;s=bb75b99ecd2085cc961af13b17e0e858c36b48e9', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba28a66d7669cebc76a89ec683ef524ca3e9322e', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a72d6d6cf43dd2230f6cbad9a9594429cd27a8f9', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/WNn7aAVzo_ggiXOWRFI6PNriHL4h9xoViF_LL3wuHQM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=37b519c19dfb3f42de22ada212e27a88b6f0e8e3', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'qepAXSiUlPglY850-J2TIych-kvJcaU1OSESW2_DLbM'}], 'enabled': False}",,,,,,
613,,tensorflow,"I still haven't found any clear explanation of how the Iterations &amp; Batch size parameters work and how they affect quality and training time, could someone help...

Do they relate to each other?

Does Batch size relate to my image dataset (I'm using train214)

How do I know when a model will finishing training?

How would I estimate how a long a model would take to train - could I do a small test - and judge by how long this takes, know what the full training would take?

The [style.py](https://style.py) I'm using creates a useful test pic every iteration - so seeing something about every 30 mins would be useful.

What's a good setting for good results?

(I'm using google colab GPU btw)

Thanks!",t2_3rv4g,False,,0,False,Some style transfer training questions...,[],r/tensorflow,False,6,,0,,,False,t3_jgiw54,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1603441692.0,,[],{},,True,,1603468940.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I still haven&amp;#39;t found any clear explanation of how the Iterations &amp;amp; Batch size parameters work and how they affect quality and training time, could someone help...&lt;/p&gt;

&lt;p&gt;Do they relate to each other?&lt;/p&gt;

&lt;p&gt;Does Batch size relate to my image dataset (I&amp;#39;m using train214)&lt;/p&gt;

&lt;p&gt;How do I know when a model will finishing training?&lt;/p&gt;

&lt;p&gt;How would I estimate how a long a model would take to train - could I do a small test - and judge by how long this takes, know what the full training would take?&lt;/p&gt;

&lt;p&gt;The &lt;a href=""https://style.py""&gt;style.py&lt;/a&gt; I&amp;#39;m using creates a useful test pic every iteration - so seeing something about every 30 mins would be useful.&lt;/p&gt;

&lt;p&gt;What&amp;#39;s a good setting for good results?&lt;/p&gt;

&lt;p&gt;(I&amp;#39;m using google colab GPU btw)&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jgiw54,True,,glenniszen,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jgiw54/some_style_transfer_training_questions/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jgiw54/some_style_transfer_training_questions/,22217,1603440140.0,0,,False,,,,,,,,,
614,,tensorflow,"Guys  I am trying to read about quantization in the context of neural  networks and deep learning models. Any tutorial to get me started on its  theory of how to quantize a model after it has been trained and also it's related code?  Preferably in TF2.

I was reading  about ""Deep Compression"" by Han et al. and want to quantize the default  32 bit floating point weights and activations to 8 bits.

Thanks !",t2_2mmql89p,False,,0,False,Quantization Tutorial,[],r/tensorflow,False,6,,0,,,False,t3_jgk5ud,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1603475593.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Guys  I am trying to read about quantization in the context of neural  networks and deep learning models. Any tutorial to get me started on its  theory of how to quantize a model after it has been trained and also it&amp;#39;s related code?  Preferably in TF2.&lt;/p&gt;

&lt;p&gt;I was reading  about &amp;quot;Deep Compression&amp;quot; by Han et al. and want to quantize the default  32 bit floating point weights and activations to 8 bits.&lt;/p&gt;

&lt;p&gt;Thanks !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jgk5ud,True,,grid_world,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jgk5ud/quantization_tutorial/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jgk5ud/quantization_tutorial/,22217,1603446793.0,0,,False,,,,,,,,,
615,,tensorflow,"Are there any good resources out there for this? Have to be in the 'checkpoint' format, 

thanks!",t2_3rv4g,False,,0,False,Looking for style transfer pre trained models for download,[],r/tensorflow,False,6,,0,,,False,t3_jgj545,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1603470222.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are there any good resources out there for this? Have to be in the &amp;#39;checkpoint&amp;#39; format, &lt;/p&gt;

&lt;p&gt;thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jgj545,True,,glenniszen,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jgj545/looking_for_style_transfer_pre_trained_models_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jgj545/looking_for_style_transfer_pre_trained_models_for/,22217,1603441422.0,0,,False,,,,,,,,,
616,,tensorflow,"I am ""translating"" a notebook made in Pytorch to one made in Keras.  And they use that app to pack the data from a tensor into the dataset that will be used for the network. But I can't find something that fulfills that function. I would greatly appreciate the help! 

Pytorch documentation says that torch.utils.data.TensorDataset (* tensors) does: 

""Dataset wrapping tensors. 
Each sample will be retrieved by indexing Tensor a along the first dimension.""

Thank you everybody!",t2_8g5s5gb,False,,0,False,Is there something like torch.utils.data.TensorDataset (* tensors) in TensorFlow/Keras?,[],r/tensorflow,False,6,,0,,,False,t3_jgigng,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1603466838.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am &amp;quot;translating&amp;quot; a notebook made in Pytorch to one made in Keras.  And they use that app to pack the data from a tensor into the dataset that will be used for the network. But I can&amp;#39;t find something that fulfills that function. I would greatly appreciate the help! &lt;/p&gt;

&lt;p&gt;Pytorch documentation says that torch.utils.data.TensorDataset (* tensors) does: &lt;/p&gt;

&lt;p&gt;&amp;quot;Dataset wrapping tensors. 
Each sample will be retrieved by indexing Tensor a along the first dimension.&amp;quot;&lt;/p&gt;

&lt;p&gt;Thank you everybody!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jgigng,True,,aguillarcanus97,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jgigng/is_there_something_like/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jgigng/is_there_something_like/,22217,1603438038.0,0,,False,,,,,,,,,
617,,tensorflow,"Keras is nice and all, but I'm comfortable with my level to look stuff up and understand the code, but I want to make the next step towards actually understanding the lower level components so I have more flexibility in my models.  It seems pretty intimidating, but I really want to make the change so I can start to look at more complex neural networks and RL.",t2_5jo16juy,False,,0,False,How do you go from understanding Keras and ML fundamentals to being good at the lower level TensorFlow for more model flexability?,[],r/tensorflow,False,6,,0,,,False,t3_jga2y3,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1603434155.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Keras is nice and all, but I&amp;#39;m comfortable with my level to look stuff up and understand the code, but I want to make the next step towards actually understanding the lower level components so I have more flexibility in my models.  It seems pretty intimidating, but I really want to make the change so I can start to look at more complex neural networks and RL.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jga2y3,True,,CauchySchwartzDaddy,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jga2y3/how_do_you_go_from_understanding_keras_and_ml/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jga2y3/how_do_you_go_from_understanding_keras_and_ml/,22217,1603405355.0,0,,False,,,,,,,,,
618,,tensorflow,"I just finished Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. What should be my next step? Any book or course you can recommend?",t2_6lquq1dr,False,,0,False,Next Step!,[],r/tensorflow,False,6,,0,,,False,t3_jg0dai,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1603404751.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just finished Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. What should be my next step? Any book or course you can recommend?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jg0dai,True,,mk1817,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/jg0dai/next_step/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jg0dai/next_step/,22217,1603375951.0,0,,False,,,,,,,,,
619,,tensorflow,,t2_eimnl,False,,0,False,Art Review Generator: Deploying a Tensorflow text generator without a GPU,[],r/tensorflow,False,6,,0,73.0,,False,t3_jftqyp,False,dark,0.88,,public,6,0,{},140.0,,False,[],,False,False,,{},Project,False,6,,False,https://b.thumbs.redditmedia.com/QLlI7NNJH-FWL4osirqGn437qG4UXmxj9dgLNZIJWlk.jpg,False,,[],{},,False,,1603373506.0,text,6,,,text,lucidbeaming.com,False,,,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jftqyp,True,,ogou,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jftqyp/art_review_generator_deploying_a_tensorflow_text/,all_ads,False,https://lucidbeaming.com/blog/fine-tuning-a-gpt-2-language-model-and-generating-text-with-a-flask-web-app/,22217,1603344706.0,0,,False,link,https://lucidbeaming.com/blog/fine-tuning-a-gpt-2-language-model-and-generating-text-with-a-flask-web-app/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/zyAXLVjz_sSyJ7hGcdQfFWo5WmFGmpSd4M_US1KHT2w.jpg?auto=webp&amp;s=29039b660898ebe0c73430ad59f3dd9968d43b8e', 'width': 600, 'height': 314}, 'resolutions': [{'url': 'https://external-preview.redd.it/zyAXLVjz_sSyJ7hGcdQfFWo5WmFGmpSd4M_US1KHT2w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c51b215f900b61d9300a9ea2068679d76a48bf93', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/zyAXLVjz_sSyJ7hGcdQfFWo5WmFGmpSd4M_US1KHT2w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=16ce4a16e580eadcefc2d279111f0e970b630ed4', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/zyAXLVjz_sSyJ7hGcdQfFWo5WmFGmpSd4M_US1KHT2w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3590351ad6520818678feb480e4c9c5997e94f6c', 'width': 320, 'height': 167}], 'variants': {}, 'id': '85Ufc2QR4u0rpW5bEcN2DbsQ33NeIImrwN9l3ozg1sM'}], 'enabled': False}",,,,,,
620,,tensorflow,"I want to learn to code with TF2 in OOP style, but i can't find any in-depth guide/tutorials. The only article that i found is [this one](https://danijar.com/structuring-your-tensorflow-models/), but it isn't really detailed. Do you have any advice?  


By the way, i'm just a beginner and i really like to create things on my own.",t2_xjz63xe,False,,0,False,Structuring Tensorflow models code,[],r/tensorflow,False,6,,0,,,False,t3_jfyb76,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1603397012.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to learn to code with TF2 in OOP style, but i can&amp;#39;t find any in-depth guide/tutorials. The only article that i found is &lt;a href=""https://danijar.com/structuring-your-tensorflow-models/""&gt;this one&lt;/a&gt;, but it isn&amp;#39;t really detailed. Do you have any advice?  &lt;/p&gt;

&lt;p&gt;By the way, i&amp;#39;m just a beginner and i really like to create things on my own.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jfyb76,True,,wickedSandro,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/jfyb76/structuring_tensorflow_models_code/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jfyb76/structuring_tensorflow_models_code/,22217,1603368212.0,0,,False,,,,,,,,,
621,,tensorflow,,t2_xt6j8xa,False,,0,False,A Must-Have Tool for Every Data Scientist,[],r/tensorflow,False,6,,0,93.0,,False,t3_jfdpv1,False,dark,0.96,,public,26,0,{},140.0,,False,[],,False,False,,{},,False,26,,False,https://b.thumbs.redditmedia.com/w6ZHTRAl5dosoIkk1Y5s3N8fgZrCEJWmsU21EAiGIjc.jpg,False,,[],{},,False,,1603318821.0,text,6,,,text,towardsdatascience.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jfdpv1,True,,clean_pegasus,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jfdpv1/a_musthave_tool_for_every_data_scientist/,all_ads,False,https://towardsdatascience.com/a-must-have-tool-for-every-data-scientist-5e7c76f1916f,22217,1603290021.0,0,,False,link,https://towardsdatascience.com/a-must-have-tool-for-every-data-scientist-5e7c76f1916f,"{'images': [{'source': {'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?auto=webp&amp;s=5970f23abf6810100a647a9a1c1d48e784b7d535', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c7ac6919664ccec54a94b28e6ac47a7317d8a86', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8fa453632d675c0f0d5d6a79448633d85297910c', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=330c1972adeeef4820dfeb7424f8d8651b385645', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e43425222b9e93fbec24cae43c456dac91fd2633', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=afa8c6e0c6f5260a4f55b29cbe1cb8b59719ae78', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/dcLv8MeMfQD9YYJiSY5Uga4RCzXHQKvWBOzP9xibkU8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f43d2cdcda037897f05dc796e77f57d0e709d598', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'lZ93XNKfRuTn6bKqxcT_U4XA6TyEWl8bc4w5-iQfpfA'}], 'enabled': False}",,,,,,
622,,tensorflow,,t2_44mbtmjy,False,,0,False,Image-Driven Furniture Style for Interactive 3D Scene Modeling,[],r/tensorflow,False,6,,0,45.0,,False,t3_jfruzf,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/sP1y86YxjgPSIsUUNH7UKr16CvMA1cus8m51GfnxDCU.jpg,False,,[],{},,False,,1603365294.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jfruzf,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jfruzf/imagedriven_furniture_style_for_interactive_3d/,all_ads,False,/r/LatestInML/comments/jfruc6/imagedriven_furniture_style_for_interactive_3d/,22217,1603336494.0,0,,False,link,/r/LatestInML/comments/jfruc6/imagedriven_furniture_style_for_interactive_3d/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and expert/code/API requests: [click here](https://www.catalyzex.com/paper/arxiv:2010.10557)\n\nhttps://preview.redd.it/5yxdv9dtcku51.jpg?width=1836&amp;format=pjpg&amp;auto=webp&amp;s=e8cd0de11a0335a35928bc540bcdd580f7c604ea', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Image-Driven Furniture Style for Interactive 3D Scene Modeling', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 45, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'5yxdv9dtcku51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 35, 'x': 108, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=624335551b40e348450ce8999dbe39db0c39ecac'}, {'y': 70, 'x': 216, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=906dd5901914c2c634ca8e6513ac7d4556e93d0e'}, {'y': 104, 'x': 320, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d9d36f8617feafd854e62c8b4944845b1de33e3'}, {'y': 209, 'x': 640, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5ca5278f1688815a9a17f87613b0d582544fe04'}, {'y': 314, 'x': 960, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8415f08f2b12fb2132092e66d827bfafc7feaaf8'}, {'y': 354, 'x': 1080, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5b5869d889b9b61ed493c6f524bd464bb9c59980'}], 's': {'y': 602, 'x': 1836, 'u': 'https://preview.redd.it/5yxdv9dtcku51.jpg?width=1836&amp;format=pjpg&amp;auto=webp&amp;s=e8cd0de11a0335a35928bc540bcdd580f7c604ea'}, 'id': '5yxdv9dtcku51'}}, 'name': 't3_jfruc6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 15, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 15, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/sP1y86YxjgPSIsUUNH7UKr16CvMA1cus8m51GfnxDCU.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1603365219.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and expert/code/API requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2010.10557""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/5yxdv9dtcku51.jpg?width=1836&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e8cd0de11a0335a35928bc540bcdd580f7c604ea""&gt;https://preview.redd.it/5yxdv9dtcku51.jpg?width=1836&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e8cd0de11a0335a35928bc540bcdd580f7c604ea&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'jfruc6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/jfruc6/imagedriven_furniture_style_for_interactive_3d/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/jfruc6/imagedriven_furniture_style_for_interactive_3d/', 'subreddit_subscribers': 6676, 'created_utc': 1603336419.0, 'num_crossposts': 14, 'media': None, 'is_video': False}]",t3_jfruc6,
623,,tensorflow,"I made a simple Tensorflow program that analyzes images from the fashion.mnist that Keras made, and tries to identify what article of clothing the image shown is. The code takes an input of a number that's supposed to represent an image. Where do I see a list of what the number means?

&amp;#x200B;

I started learning Tensorflow 2 weeks ago, so I'm sorry if this post made no sense.",t2_45m1tetb,False,,0,False,"I'm new to Tensorflow, how do I check the images of from the Keras mnist?",[],r/tensorflow,False,6,,0,,,False,t3_jfnnit,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1603349618.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I made a simple Tensorflow program that analyzes images from the fashion.mnist that Keras made, and tries to identify what article of clothing the image shown is. The code takes an input of a number that&amp;#39;s supposed to represent an image. Where do I see a list of what the number means?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I started learning Tensorflow 2 weeks ago, so I&amp;#39;m sorry if this post made no sense.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jfnnit,True,,Datemshop,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jfnnit/im_new_to_tensorflow_how_do_i_check_the_images_of/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jfnnit/im_new_to_tensorflow_how_do_i_check_the_images_of/,22217,1603320818.0,0,,False,,,,,,,,,
624,,tensorflow,,t2_683tvs22,False,,0,False,Editing Erlind Haaland's face with StyleGAN2-ADA,[],r/tensorflow,False,6,,0,105.0,,False,t3_jfecqd,False,dark,0.83,,public,8,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/4b4nnqf3Ctc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Editing Erling Haaland's Face With AI (StyleGAN2)"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/4b4nnqf3Ctc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/4b4nnqf3Ctc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/4b4nnqf3Ctc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/jfecqd', 'height': 338}",,False,8,,False,https://b.thumbs.redditmedia.com/a8HPg2OBVP-WKd2wwOgwBBWOygKUouQLgy6p4tCJqhc.jpg,False,,[],{},,False,,1603320857.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jfecqd,True,,N2AI,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jfecqd/editing_erlind_haalands_face_with_stylegan2ada/,all_ads,False,https://youtu.be/4b4nnqf3Ctc,22217,1603292057.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Editing Erling Haaland's Face With AI (StyleGAN2)"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/4b4nnqf3Ctc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/4b4nnqf3Ctc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,rich:video,https://youtu.be/4b4nnqf3Ctc,"{'images': [{'source': {'url': 'https://external-preview.redd.it/LAevROYTtBSAQm5wt_yrpFc07Wwof2KZppyKSdEfJTo.jpg?auto=webp&amp;s=411311eebb8550de2f470a8e6e2a761c5e43788b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/LAevROYTtBSAQm5wt_yrpFc07Wwof2KZppyKSdEfJTo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=059fc08778189b23582947a74f8e264ccc8a3791', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/LAevROYTtBSAQm5wt_yrpFc07Wwof2KZppyKSdEfJTo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8bf3f72c9b1190e74e1399ca7f13be28b89f65b8', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/LAevROYTtBSAQm5wt_yrpFc07Wwof2KZppyKSdEfJTo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=86532fe3459eca7a01cb028ef31a21c7f6f70a3b', 'width': 320, 'height': 240}], 'variants': {}, 'id': '7kkSeK1TzKrWSLODBcypoIdrsV8IFBzThqnnT8gISkw'}], 'enabled': False}",,,,,,
625,,tensorflow,"I'm doing a project for my uni course which is to create an image classification NN and experiment on starting parameters. To see if it's possible to determine optimal training setups for specific datasets, such as datasets with background clutter or intra-class variation.

I'm not sure which framework to use to approach it though? I'm not a python guy (I come from javascript) however I am learning it at the same time for a separate module. I'm trying to find a balance between ease of use as well as allowing me more control over the model.

If I go down a tensorflow with Keras route will it still give me the freedom to experiment or is it quite strict?

Thanks.",,False,,0,False,"Uni project - Tensorflow, Keras or pytorch",[],r/tensorflow,False,6,,0,,,False,t3_jfi487,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,,self,1603304691.0,,,{},,True,,1603332298.0,text,6,,,,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m doing a project for my uni course which is to create an image classification NN and experiment on starting parameters. To see if it&amp;#39;s possible to determine optimal training setups for specific datasets, such as datasets with background clutter or intra-class variation.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not sure which framework to use to approach it though? I&amp;#39;m not a python guy (I come from javascript) however I am learning it at the same time for a separate module. I&amp;#39;m trying to find a balance between ease of use as well as allowing me more control over the model.&lt;/p&gt;

&lt;p&gt;If I go down a tensorflow with Keras route will it still give me the freedom to experiment or is it quite strict?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jfi487,True,,[deleted],,1,True,all_ads,False,[],,dark,/r/tensorflow/comments/jfi487/uni_project_tensorflow_keras_or_pytorch/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jfi487/uni_project_tensorflow_keras_or_pytorch/,22217,1603303498.0,0,,False,,,,,,,,,
626,,tensorflow,"Hi

I'm trying to train my own model based on this,

[https://www.youtube.com/watch?v=STHRNIJc-vI](https://www.youtube.com/watch?v=STHRNIJc-vI)

But rather than use Spell which is costly - I want to train locally on my own computer's GPU.

I've tried so many versions of style transfer GitHub repos, different pip versions of all the modules needed (tensorflow etc), different Python versions - but when I go to run the style training there's always some kind of error.

Does anyone have a boilerplate template of all the correct versions of stuff that will work together when I install them, or some kind of advice to get things working.  My understanding is quite limited in this area.

There's a Docker that someone made - but it won't run on Windows.

I really want to get this working so I can use P5.js and ML5.js for style transfer.

Thx.

&amp;#x200B;

&amp;#x200B;

I",t2_3rv4g,False,,0,False,Need help getting style transfer training working on my GPU,[],r/tensorflow,False,6,,0,,,False,t3_jfgqam,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1603328155.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to train my own model based on this,&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=STHRNIJc-vI""&gt;https://www.youtube.com/watch?v=STHRNIJc-vI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But rather than use Spell which is costly - I want to train locally on my own computer&amp;#39;s GPU.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve tried so many versions of style transfer GitHub repos, different pip versions of all the modules needed (tensorflow etc), different Python versions - but when I go to run the style training there&amp;#39;s always some kind of error.&lt;/p&gt;

&lt;p&gt;Does anyone have a boilerplate template of all the correct versions of stuff that will work together when I install them, or some kind of advice to get things working.  My understanding is quite limited in this area.&lt;/p&gt;

&lt;p&gt;There&amp;#39;s a Docker that someone made - but it won&amp;#39;t run on Windows.&lt;/p&gt;

&lt;p&gt;I really want to get this working so I can use P5.js and ML5.js for style transfer.&lt;/p&gt;

&lt;p&gt;Thx.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jfgqam,True,,glenniszen,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jfgqam/need_help_getting_style_transfer_training_working/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jfgqam/need_help_getting_style_transfer_training_working/,22217,1603299355.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Z1KUs6xSzA8dYeA5gJget-wrRXr5DikMUCkQSW9T208.jpg?auto=webp&amp;s=e802ff632fd323afd02eafdc2eb91bb33bf37527', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/Z1KUs6xSzA8dYeA5gJget-wrRXr5DikMUCkQSW9T208.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cccdbc75a18461f70c23deb81f536e7b252bf815', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/Z1KUs6xSzA8dYeA5gJget-wrRXr5DikMUCkQSW9T208.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13132a61cb6127ad3d2cf75540cae9e387c517a1', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/Z1KUs6xSzA8dYeA5gJget-wrRXr5DikMUCkQSW9T208.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb96990bfc0987b5e16f7cdad098edf66bcc2c56', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'YO8W1mTT2i8_yvBc-PRfnFn7_BlPceY8jwkNecLYX0M'}], 'enabled': False}",,,,,,
627,,tensorflow,"Hey everyone  


I am a bit lost. I recently wrote a custom keras model (custom layers but all functionality inherited from the keras model class). However now I want to extract and save a fixed graph of the trained model. I know there is \`freeze\_graph.py \` however I still dont get how to do it...  


Assuming we have some sort of sequential Keras model named \`Model\`.

  
How would you then proceed to get the frozen graph from Model?  


Any help is appreciated",t2_3x35qwjy,False,,0,False,Freeze graph with tf 2.x keras custom model,[],r/tensorflow,False,6,,0,,,False,t3_jfc3pj,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1603313160.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone  &lt;/p&gt;

&lt;p&gt;I am a bit lost. I recently wrote a custom keras model (custom layers but all functionality inherited from the keras model class). However now I want to extract and save a fixed graph of the trained model. I know there is `freeze_graph.py ` however I still dont get how to do it...  &lt;/p&gt;

&lt;p&gt;Assuming we have some sort of sequential Keras model named `Model`.&lt;/p&gt;

&lt;p&gt;How would you then proceed to get the frozen graph from Model?  &lt;/p&gt;

&lt;p&gt;Any help is appreciated&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jfc3pj,True,,Dovahlinsl,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jfc3pj/freeze_graph_with_tf_2x_keras_custom_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jfc3pj/freeze_graph_with_tf_2x_keras_custom_model/,22217,1603284360.0,0,,False,,,,,,,,,
628,,tensorflow,"I am new to machine learning, i have worked on some projects on kaggle, but now i thought to do all by myself, i made created virtual environment, downloaded image data in my pc, but now i do not know how to load that data from downloads folder in my code. Can you guys please guide me, I have searched  lot on internet but could not find any desirable solution.",t2_1irfskew,False,,0,False,Images data loading,[],r/tensorflow,False,6,,0,,,False,t3_jfa073,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1603303270.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am new to machine learning, i have worked on some projects on kaggle, but now i thought to do all by myself, i made created virtual environment, downloaded image data in my pc, but now i do not know how to load that data from downloads folder in my code. Can you guys please guide me, I have searched  lot on internet but could not find any desirable solution.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jfa073,True,,itisfor,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jfa073/images_data_loading/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jfa073/images_data_loading/,22217,1603274470.0,0,,False,,,,,,,,,
629,,tensorflow,"I managed to get tensorflow GPU running in an anaconda environment yesterday. 

Went into the same environment today and I'm now getting errors even though nothing has changed since yesterday. 

    import tensorflow as tf
    
    2020-10-20 16:35:30.814209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
    Error in callback &lt;bound method AutoreloadMagics.post_execute_hook of &lt;autoreload.AutoreloadMagics object at 0x000001B7108A7A90&gt;&gt; (for post_execute):
    Traceback (most recent call last):
    
      File ""C:\Users\anaconda3\envs\tf\lib\site-packages\IPython\extensions\autoreload.py"", line 538, in post_execute_hook
        _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])
    
      File ""C:\Users\anaconda3\envs\tf\lib\site-packages\IPython\extensions\autoreload.py"", line 184, in filename_and_mtime
        if not hasattr(module, '__file__') or module.__file__ is None:
    
      File ""C:\Users\anaconda3\envs\tf\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
        module = self._load()
    
      File ""C:\Users\anaconda3\envs\tf\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
        module = _importlib.import_module(self.__name__)
    
      File ""C:\Users\anaconda3\envs\tf\lib\importlib\__init__.py"", line 126, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
    
      File ""&lt;frozen importlib._bootstrap&gt;"", line 994, in _gcd_import
    
      File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load
    
      File ""&lt;frozen importlib._bootstrap&gt;"", line 953, in _find_and_load_unlocked
    
    ModuleNotFoundError: No module named 'tensorflow_core.estimator'


From the TF github the top advice seems to be to pip install the missing tensorflow_core.estimator, I checked my conda list and it was already there. I even installed the gpu version just to be sure but I still get the same error.

    tensorboard               2.2.1              pyh532a8cf_0
    tensorboard-plugin-wit    1.6.0                      py_0
    tensorflow                2.1.0           gpu_py36h3346743_0
    tensorflow-base           2.1.0           gpu_py36h55f5790_0
    tensorflow-estimator      2.1.0              pyhd54b08b_0
    tensorflow-gpu            2.1.0                h0d30ee6_0
    tensorflow-gpu-estimator  2.1.0                    pypi_0    pypi


I also tried uninstalling and reinstalling but I still get the same Module not found error. Weirdly enough my base tf_gpu environment which the above environment is cloned from still works fine. 

Could anyone tell why its stopped working and how to fix this?
Thanks in advance",t2_72rwe,False,,0,False,"How to resolve ""No module named 'tensorflow_core.estimator'"" error?",[],r/tensorflow,False,6,,0,,,False,t3_jesmaq,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,1603979609.0,,[],{},,True,,1603239018.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I managed to get tensorflow GPU running in an anaconda environment yesterday. &lt;/p&gt;

&lt;p&gt;Went into the same environment today and I&amp;#39;m now getting errors even though nothing has changed since yesterday. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf

2020-10-20 16:35:30.814209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
Error in callback &amp;lt;bound method AutoreloadMagics.post_execute_hook of &amp;lt;autoreload.AutoreloadMagics object at 0x000001B7108A7A90&amp;gt;&amp;gt; (for post_execute):
Traceback (most recent call last):

  File &amp;quot;C:\Users\anaconda3\envs\tf\lib\site-packages\IPython\extensions\autoreload.py&amp;quot;, line 538, in post_execute_hook
    _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])

  File &amp;quot;C:\Users\anaconda3\envs\tf\lib\site-packages\IPython\extensions\autoreload.py&amp;quot;, line 184, in filename_and_mtime
    if not hasattr(module, &amp;#39;__file__&amp;#39;) or module.__file__ is None:

  File &amp;quot;C:\Users\anaconda3\envs\tf\lib\site-packages\tensorflow\__init__.py&amp;quot;, line 50, in __getattr__
    module = self._load()

  File &amp;quot;C:\Users\anaconda3\envs\tf\lib\site-packages\tensorflow\__init__.py&amp;quot;, line 44, in _load
    module = _importlib.import_module(self.__name__)

  File &amp;quot;C:\Users\anaconda3\envs\tf\lib\importlib\__init__.py&amp;quot;, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)

  File &amp;quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&amp;quot;, line 994, in _gcd_import

  File &amp;quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&amp;quot;, line 971, in _find_and_load

  File &amp;quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&amp;quot;, line 953, in _find_and_load_unlocked

ModuleNotFoundError: No module named &amp;#39;tensorflow_core.estimator&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From the TF github the top advice seems to be to pip install the missing tensorflow_core.estimator, I checked my conda list and it was already there. I even installed the gpu version just to be sure but I still get the same error.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorboard               2.2.1              pyh532a8cf_0
tensorboard-plugin-wit    1.6.0                      py_0
tensorflow                2.1.0           gpu_py36h3346743_0
tensorflow-base           2.1.0           gpu_py36h55f5790_0
tensorflow-estimator      2.1.0              pyhd54b08b_0
tensorflow-gpu            2.1.0                h0d30ee6_0
tensorflow-gpu-estimator  2.1.0                    pypi_0    pypi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also tried uninstalling and reinstalling but I still get the same Module not found error. Weirdly enough my base tf_gpu environment which the above environment is cloned from still works fine. &lt;/p&gt;

&lt;p&gt;Could anyone tell why its stopped working and how to fix this?
Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jesmaq,True,,nuusain,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jesmaq/how_to_resolve_no_module_named_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jesmaq/how_to_resolve_no_module_named_tensorflow/,22217,1603210218.0,0,,False,,,,,,,,,
630,,tensorflow,I am student so I have difficulty in understanding source code however I could understand  implementation of unrolling version. I want to know how graphs is constructed when unrolling=False,t2_7f71agho,False,,0,False,Can someone tell how RNNs are implemented in keras?,[],r/tensorflow,False,6,,0,,,False,t3_jehbbp,False,dark,0.95,,public,18,0,{},,,False,[],,False,False,,{},Question,False,18,,False,self,False,,[],{},,True,,1603192118.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am student so I have difficulty in understanding source code however I could understand  implementation of unrolling version. I want to know how graphs is constructed when unrolling=False&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jehbbp,True,,DrAsgardian,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jehbbp/can_someone_tell_how_rnns_are_implemented_in_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jehbbp/can_someone_tell_how_rnns_are_implemented_in_keras/,22217,1603163318.0,0,,False,,,,,,,,,
631,,tensorflow,"The process of putting and managing ML models in a production environment is a combination of numerous tasks each important in its own right.

Here, we have prepared some best practices that will suggest how to work with TF Serving and Docker, for example:

- Introduce model version control,
- Ensure code separation,
- Spot inefficient model inference,
- API Endpoints: REST vs. gRPC. When to use each.

Hope you will like it!

Would be great to hear expert comments on the model serving matter. What do you do? How are your views different from the practices I mentioned?

[Serve Machine Learning Models](https://neptune.ai/blog/how-to-serve-machine-learning-models-with-tensorflow-serving-and-docker?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-how-to-serve-machine-learning-models-with-tensorflow-serving-and-docker)",t2_5hfacnnv,False,,0,False,Do you Handle ML Models in Prod? Few Best Practices for Using Tensorflow Serving,[],r/tensorflow,False,6,,0,,,False,t3_je7w6f,False,dark,1.0,,public,15,0,{},,,False,[],,False,False,,{},Discussion,False,15,,False,self,False,,[],{},,True,,1603162211.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The process of putting and managing ML models in a production environment is a combination of numerous tasks each important in its own right.&lt;/p&gt;

&lt;p&gt;Here, we have prepared some best practices that will suggest how to work with TF Serving and Docker, for example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Introduce model version control,&lt;/li&gt;
&lt;li&gt;Ensure code separation,&lt;/li&gt;
&lt;li&gt;Spot inefficient model inference,&lt;/li&gt;
&lt;li&gt;API Endpoints: REST vs. gRPC. When to use each.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hope you will like it!&lt;/p&gt;

&lt;p&gt;Would be great to hear expert comments on the model serving matter. What do you do? How are your views different from the practices I mentioned?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/how-to-serve-machine-learning-models-with-tensorflow-serving-and-docker?utm_source=reddit&amp;amp;utm_medium=post&amp;amp;utm_campaign=blog-how-to-serve-machine-learning-models-with-tensorflow-serving-and-docker""&gt;Serve Machine Learning Models&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,je7w6f,True,,kk_ai,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/je7w6f/do_you_handle_ml_models_in_prod_few_best/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/je7w6f/do_you_handle_ml_models_in_prod_few_best/,22217,1603133411.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?auto=webp&amp;s=54ac07954fc7b13b0c12c06dd8dc5f42ad5ea5d7', 'width': 1920, 'height': 1377}, 'resolutions': [{'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b805e37c2382497337a71effbb3e0a4353a6932', 'width': 108, 'height': 77}, {'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=718a2a8d077dfae7bfb414cfa858a791d3673233', 'width': 216, 'height': 154}, {'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ba6b2f245e1fab3dd0405a838ff539280ea3ce6', 'width': 320, 'height': 229}, {'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe4588e1234d637cda930d1cd88325e0278b3397', 'width': 640, 'height': 459}, {'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=792d8fc834a0f2f656a278df83b0d9d7792226a8', 'width': 960, 'height': 688}, {'url': 'https://external-preview.redd.it/3uzxI17fzivwFN2CLnDVOSuEMWdG7nFv8t-I6qDbgR8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87c98143305e43ad9a7433524ce39fef3324fdf2', 'width': 1080, 'height': 774}], 'variants': {}, 'id': 'W4u4IXKw4PFu2tMaIaG_aHpQchI3pN9Z5tOxjY_geoI'}], 'enabled': False}",,,,,,
632,,tensorflow,"It say that it applied a function to the elements of the dataset and flattens the results (it must return a Dataset object) but what does ""flatten"" mean exactly?",t2_10vrhqvg,False,,0,False,Can someone explain what does tf.data.Dataset.flat_map() do exactly?,[],r/tensorflow,False,6,,0,,,False,t3_jeibm3,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1603196039.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It say that it applied a function to the elements of the dataset and flattens the results (it must return a Dataset object) but what does &amp;quot;flatten&amp;quot; mean exactly?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jeibm3,True,,nopickles_,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jeibm3/can_someone_explain_what_does_tfdatadatasetflat/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jeibm3/can_someone_explain_what_does_tfdatadatasetflat/,22217,1603167239.0,0,,False,,,,,,,,,True
633,,tensorflow,"hello people, I have a question about the approach I need to take to a projectwe have to make a neural network with tensorflow that predicts what subjects students will take we have data but

what approach should we take?

thanks,",t2_71d44tjk,False,,0,False,"hello people, I have a question about the approach I need to take to a project",[],r/tensorflow,False,6,,0,,,False,t3_jefikv,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1603185524.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hello people, I have a question about the approach I need to take to a projectwe have to make a neural network with tensorflow that predicts what subjects students will take we have data but&lt;/p&gt;

&lt;p&gt;what approach should we take?&lt;/p&gt;

&lt;p&gt;thanks,&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jefikv,True,,Frodoro710,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jefikv/hello_people_i_have_a_question_about_the_approach/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jefikv/hello_people_i_have_a_question_about_the_approach/,22217,1603156724.0,0,,False,,,,,,,,,
634,,tensorflow,"In my new tutorial, you can learn how to extract Spectral Centroid and Spectral Bandwidth from audio data using the Python library librosa. I also show how these features vary depending on music genre.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

\#musictech #audioprocessing #audioDSP #machinelearning #deeplearning #aiaudio #aimusic

Here’s the video:

[https://www.youtube.com/watch?v=j6NTatoi928&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=23](https://www.youtube.com/watch?v=j6NTatoi928&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=23)",t2_12ahau,False,,0,False,I published a tutorial showing how to extract spectral centroid and bandwidth from audio data using Python,[],r/tensorflow,False,6,,0,,,False,t3_jdzxk5,False,dark,0.93,,public,12,0,{},,,False,[],,False,False,,{},Project,False,12,,False,self,False,,[],{},,True,,1603135925.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new tutorial, you can learn how to extract Spectral Centroid and Spectral Bandwidth from audio data using the Python library librosa. I also show how these features vary depending on music genre.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;#musictech #audioprocessing #audioDSP #machinelearning #deeplearning #aiaudio #aimusic&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=j6NTatoi928&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=23""&gt;https://www.youtube.com/watch?v=j6NTatoi928&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=23&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jdzxk5,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jdzxk5/i_published_a_tutorial_showing_how_to_extract/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdzxk5/i_published_a_tutorial_showing_how_to_extract/,22217,1603107125.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/S4QQif8PnDmLHubxJ1ldKG2K1HKW-9b7qU6nNLJR_Rs.jpg?auto=webp&amp;s=ffb1d999a5061a9feba783d4ae41aa25c9df5ec0', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/S4QQif8PnDmLHubxJ1ldKG2K1HKW-9b7qU6nNLJR_Rs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=299eba3661d7993adc576be587d4663550b836db', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/S4QQif8PnDmLHubxJ1ldKG2K1HKW-9b7qU6nNLJR_Rs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=12acbd4f8730c89d4190a5b229ac8bc7eff6327b', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/S4QQif8PnDmLHubxJ1ldKG2K1HKW-9b7qU6nNLJR_Rs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb6bf81f8dc643c9a3e55dc1e6afdb79ebcd9711', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'MF5otOIjbuGkPWAXtNBzj5Zf-Ms14h7_sOy8AKgdFPM'}], 'enabled': False}",,,,,,
635,,tensorflow," 

Hey everyone,

so I'm pretty new to machine learning and all, and I have sucessfully build my first image classification model. Now I want to build a model that not only tells me what object is in the Image but also where it is via a bounding box. Therefore, I read a few tutorials about how to build a model with multiple outputs and now I try to build my own model.

I'm currently trying to make a model with 1 input and 2 outputs. The input is a image that get passed through multiple Conv2D layers with MaxPooling and based on this result,

output 1 should guess the class

and output 2 should guess the position of the guess object based on the result of output 1 as well as the results from the input Conv layers.

This is the code for the model I have right now:

`def build_bbox_v2_model(NUM_CLASSES):`

`inp = keras.layers.Input(shape=(200, 200, 3))`  
`inputs = Conv2D(32, (3,3), activation=tf.nn.relu, padding='same')(inp)`  
`inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)`  
`inputs = BatchNormalization()(inputs)`  
`inputs = Conv2D(64, (3,3), activation=tf.nn.relu, padding='same')(inputs)`  
`inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)`  
`inputs = BatchNormalization()(inputs)`  
`inputs = Conv2D(128, (3,3), activation=tf.nn.relu, padding='same')(inputs)`  
`inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)`  
`inputs = BatchNormalization()(inputs)`  
`inputs = Conv2D(256, (3,3), activation=tf.nn.relu, padding='same')(inputs)`  
`inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)`  
`inputs = BatchNormalization()(inputs)`  
`inputs = Flatten()(inputs)`  
`label = Dense(128, activation='relu')(inputs)`  
`label = Dropout(0.3)(label)`  
`label = BatchNormalization()(label)`  
`label = Dense(128, activation='relu')(label)`  
`label = BatchNormalization()(label)`  
`label = Dense(NUM_CLASSES)(label)`  
`label = Activation('softmax', name='label')(label)`

`bbox = Concatenate(axis=1)([inputs, label])`  
`bbox = Dense(128, activation='relu')(bbox)`  
`bbox = Dense(64, activation='relu')(bbox)`  
`bbox = Dense(32, activation='relu')(bbox)`  
`bbox = Dense(4)(bbox)`  
`bbox = Activation('sigmoid', name='bbox')(bbox)`  
`model = keras.models.Model(inputs=inputs, outputs=[label, bbox])`

`losses = {`  
`'label': 'sparse_categorical_crossentropy',`  
`'bbox': 'mse'`  
`}`  
`lossWeights = {`  
`'label': 1.0,`  
`'bbox': 1.0`  
`}`  
`adam = keras.optimizers.Adam(learning_rate=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)`  
`model.compile(`  
`optimizer=adam,`  
`loss=losses,`  
`loss_weights = lossWeights,`  
`metrics=['accuracy']`  
`)`  
`return model`

However, if I try to start training, it throws this error: ""ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""input\_1:0"", shape=(?, 200, 200, 3), dtype=float32) at layer ""input\_1"". The following previous layers were accessed without issue: \[\]"". How do I fix that?

Any help would be greatly appreciated!",t2_6pdw49i0,False,,0,False,How to build keras model with multiple outputs?,[],r/tensorflow,False,6,,0,,,False,t3_jdzekw,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1603133260.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;

&lt;p&gt;so I&amp;#39;m pretty new to machine learning and all, and I have sucessfully build my first image classification model. Now I want to build a model that not only tells me what object is in the Image but also where it is via a bounding box. Therefore, I read a few tutorials about how to build a model with multiple outputs and now I try to build my own model.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently trying to make a model with 1 input and 2 outputs. The input is a image that get passed through multiple Conv2D layers with MaxPooling and based on this result,&lt;/p&gt;

&lt;p&gt;output 1 should guess the class&lt;/p&gt;

&lt;p&gt;and output 2 should guess the position of the guess object based on the result of output 1 as well as the results from the input Conv layers.&lt;/p&gt;

&lt;p&gt;This is the code for the model I have right now:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;def build_bbox_v2_model(NUM_CLASSES):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;inp = keras.layers.Input(shape=(200, 200, 3))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = Conv2D(32, (3,3), activation=tf.nn.relu, padding=&amp;#39;same&amp;#39;)(inp)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = BatchNormalization()(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = Conv2D(64, (3,3), activation=tf.nn.relu, padding=&amp;#39;same&amp;#39;)(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = BatchNormalization()(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = Conv2D(128, (3,3), activation=tf.nn.relu, padding=&amp;#39;same&amp;#39;)(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = BatchNormalization()(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = Conv2D(256, (3,3), activation=tf.nn.relu, padding=&amp;#39;same&amp;#39;)(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = BatchNormalization()(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;inputs = Flatten()(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = Dense(128, activation=&amp;#39;relu&amp;#39;)(inputs)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = Dropout(0.3)(label)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = BatchNormalization()(label)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = Dense(128, activation=&amp;#39;relu&amp;#39;)(label)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = BatchNormalization()(label)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = Dense(NUM_CLASSES)(label)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;label = Activation(&amp;#39;softmax&amp;#39;, name=&amp;#39;label&amp;#39;)(label)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bbox = Concatenate(axis=1)([inputs, label])&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bbox = Dense(128, activation=&amp;#39;relu&amp;#39;)(bbox)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bbox = Dense(64, activation=&amp;#39;relu&amp;#39;)(bbox)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bbox = Dense(32, activation=&amp;#39;relu&amp;#39;)(bbox)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bbox = Dense(4)(bbox)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;bbox = Activation(&amp;#39;sigmoid&amp;#39;, name=&amp;#39;bbox&amp;#39;)(bbox)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model = keras.models.Model(inputs=inputs, outputs=[label, bbox])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;losses = {&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;&amp;#39;label&amp;#39;: &amp;#39;sparse_categorical_crossentropy&amp;#39;,&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;&amp;#39;bbox&amp;#39;: &amp;#39;mse&amp;#39;&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;}&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;lossWeights = {&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;&amp;#39;label&amp;#39;: 1.0,&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;&amp;#39;bbox&amp;#39;: 1.0&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;}&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;adam = keras.optimizers.Adam(learning_rate=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.compile(&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;optimizer=adam,&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;loss=losses,&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;loss_weights = lossWeights,&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;metrics=[&amp;#39;accuracy&amp;#39;]&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;)&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;return model&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;However, if I try to start training, it throws this error: &amp;quot;ValueError: Graph disconnected: cannot obtain value for tensor Tensor(&amp;quot;input_1:0&amp;quot;, shape=(?, 200, 200, 3), dtype=float32) at layer &amp;quot;input_1&amp;quot;. The following previous layers were accessed without issue: []&amp;quot;. How do I fix that?&lt;/p&gt;

&lt;p&gt;Any help would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jdzekw,True,,Morica_,,14,True,all_ads,False,[],False,,/r/tensorflow/comments/jdzekw/how_to_build_keras_model_with_multiple_outputs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdzekw/how_to_build_keras_model_with_multiple_outputs/,22217,1603104460.0,0,,False,,,,,,,,,
636,,tensorflow,"I have a working tensforflow model using python and I want to put it online. My idea is just simple input-output, two input for the model and one output from it. 
I have tried PythonAnywhere.com service. I tried it because it was easy to setup and with just a little example I can build it. But it turn out they can't run tensorflow.

Do you have another suggestion?",t2_6qlp70f3,False,,0,False,Web hosting for tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_je2tqd,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1603147155.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a working tensforflow model using python and I want to put it online. My idea is just simple input-output, two input for the model and one output from it. 
I have tried PythonAnywhere.com service. I tried it because it was easy to setup and with just a little example I can build it. But it turn out they can&amp;#39;t run tensorflow.&lt;/p&gt;

&lt;p&gt;Do you have another suggestion?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,je2tqd,True,,googladoo,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/je2tqd/web_hosting_for_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/je2tqd/web_hosting_for_tensorflow/,22217,1603118355.0,0,,False,,,,,,,,,
637,,tensorflow,,,False,,0,False,Getting Inference when no object is detected. Please find the details in comment.,[],r/tensorflow,False,6,,0,140.0,,False,t3_jdy2mc,False,dark,0.6,,public,1,0,{},140.0,,False,[],"{'reddit_video': {'fallback_url': 'https://v.redd.it/wik7g1zsk0u51/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 608, 'scrubber_media_url': 'https://v.redd.it/wik7g1zsk0u51/DASH_96.mp4', 'dash_url': 'https://v.redd.it/wik7g1zsk0u51/DASHPlaylist.mpd?a=1618044806%2CYzgxYmNmNjEzODlmZDM1ZjViNDg2MTA1ODM3YzMwYTM5ODE2MTk1NTNhNmQ0ZjdhOGU2NjE1MmI3OTA4NzQ2OQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 7, 'hls_url': 'https://v.redd.it/wik7g1zsk0u51/HLSPlaylist.m3u8?a=1618044806%2CM2JkMWY2MzQxNWYyMzRiZTJhOGYwZjU2YzU2NmZjNGRlNGQ2MTNhZGE4OThlZGFkOTY3NjMwZWMwZDBmZDllMA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},Question,False,1,,,https://b.thumbs.redditmedia.com/WqVSOpLt3LBXL3BMNXmNeUD42uQrPrCy_0df_ugVMkk.jpg,False,,,{},,False,,1603125817.0,text,6,,,,v.redd.it,False,,,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jdy2mc,True,,[deleted],,7,True,all_ads,False,[],,dark,/r/tensorflow/comments/jdy2mc/getting_inference_when_no_object_is_detected/,all_ads,False,https://v.redd.it/wik7g1zsk0u51,22217,1603097017.0,0,"{'reddit_video': {'fallback_url': 'https://v.redd.it/wik7g1zsk0u51/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 608, 'scrubber_media_url': 'https://v.redd.it/wik7g1zsk0u51/DASH_96.mp4', 'dash_url': 'https://v.redd.it/wik7g1zsk0u51/DASHPlaylist.mpd?a=1618044806%2CYzgxYmNmNjEzODlmZDM1ZjViNDg2MTA1ODM3YzMwYTM5ODE2MTk1NTNhNmQ0ZjdhOGU2NjE1MmI3OTA4NzQ2OQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 7, 'hls_url': 'https://v.redd.it/wik7g1zsk0u51/HLSPlaylist.m3u8?a=1618044806%2CM2JkMWY2MzQxNWYyMzRiZTJhOGYwZjU2YzU2NmZjNGRlNGQ2MTNhZGE4OThlZGFkOTY3NjMwZWMwZDBmZDllMA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/wik7g1zsk0u51,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ogduLVvMh8TFv4M33ENV7e6QJHFPXNUwbX62yxg5P3I.png?format=pjpg&amp;auto=webp&amp;s=2a67bdcfa8172bb726d7d0843322dba30c25bff4', 'width': 640, 'height': 1136}, 'resolutions': [{'url': 'https://external-preview.redd.it/ogduLVvMh8TFv4M33ENV7e6QJHFPXNUwbX62yxg5P3I.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b81a2b745c7b30624f17c5957655ba333cd160cc', 'width': 108, 'height': 191}, {'url': 'https://external-preview.redd.it/ogduLVvMh8TFv4M33ENV7e6QJHFPXNUwbX62yxg5P3I.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6bcdfc9868d69190961b81463d7ead940554eb11', 'width': 216, 'height': 383}, {'url': 'https://external-preview.redd.it/ogduLVvMh8TFv4M33ENV7e6QJHFPXNUwbX62yxg5P3I.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1602c79f1b8ee67a99952b95bfc939fa73eb27d1', 'width': 320, 'height': 568}, {'url': 'https://external-preview.redd.it/ogduLVvMh8TFv4M33ENV7e6QJHFPXNUwbX62yxg5P3I.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=77cef2fee746d49d2eb16e9a408fd5acbba6374b', 'width': 640, 'height': 1136}], 'variants': {}, 'id': 'ZNhA_L0PNEeKUi9hOsMCt_P6N-PM6m3DEcMrhXRo9Cw'}], 'enabled': False}",,,,,,
638,,tensorflow,"num\_classes = np.max(y\_train) + 1 

model = models.Sequential()

model.add(layers.Dense(512, input\_shape=(max\_words,)))

model.add(layers.Activation('relu'))

model.add(layers.Dense(num\_classes))

model.add(layers.Activation('softmax'))

model.compile(loss='categorical\_crossentropy', optimizer='adam', metrics=\['accuracy'\])",t2_4760f5hy,False,,0,False,"I am a beginner with tensorflow, and I want to know what this code that I found does in some detail",[],r/tensorflow,False,6,,0,,,False,t3_jdtpj7,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,1603075869.0,,[],{},,True,,1603104303.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;num_classes = np.max(y_train) + 1 &lt;/p&gt;

&lt;p&gt;model = models.Sequential()&lt;/p&gt;

&lt;p&gt;model.add(layers.Dense(512, input_shape=(max_words,)))&lt;/p&gt;

&lt;p&gt;model.add(layers.Activation(&amp;#39;relu&amp;#39;))&lt;/p&gt;

&lt;p&gt;model.add(layers.Dense(num_classes))&lt;/p&gt;

&lt;p&gt;model.add(layers.Activation(&amp;#39;softmax&amp;#39;))&lt;/p&gt;

&lt;p&gt;model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;, optimizer=&amp;#39;adam&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jdtpj7,True,,ARNisUsername,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jdtpj7/i_am_a_beginner_with_tensorflow_and_i_want_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdtpj7/i_am_a_beginner_with_tensorflow_and_i_want_to/,22217,1603075503.0,0,,False,,,,,,,,,
639,,tensorflow,"Hi. I'm starting to learn programming stuff. I'm diving into Tensorflow and Keras right now. I would like to create a kind of ""blog"" to write the knowledge I will start learning and share it with everyone.

I'm thinking about WordPress, or Github. Do u guys have a few recommendations?",t2_8j7r2g6i,False,,0,False,"Recommended sites to start a programming ""blog""?",[],r/tensorflow,False,6,,0,,,False,t3_jdku0b,False,dark,0.84,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1603072556.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I&amp;#39;m starting to learn programming stuff. I&amp;#39;m diving into Tensorflow and Keras right now. I would like to create a kind of &amp;quot;blog&amp;quot; to write the knowledge I will start learning and share it with everyone.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m thinking about WordPress, or Github. Do u guys have a few recommendations?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jdku0b,True,,rampa_97,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jdku0b/recommended_sites_to_start_a_programming_blog/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdku0b/recommended_sites_to_start_a_programming_blog/,22217,1603043756.0,0,,False,,,,,,,,,
640,,tensorflow,"Hello, I'm creating a dataset to feed an LSTM or maybe a few models that predict several metrics so I was thinking maybe use many stock signs historical data to create a tfrecord in a way that each stock sign data counts as a single `tf.train.Example()` and features including several indicators and possibly sentiment analysis for news articles / any relevant text, so what are your suggestions? is there a better way of creating a dataset for best results?",t2_4jbcsgd0,False,,0,False,Using tfrecords with timeseries stock ohlcv data,[],r/tensorflow,False,6,,0,,,False,t3_jdpz96,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1603089625.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I&amp;#39;m creating a dataset to feed an LSTM or maybe a few models that predict several metrics so I was thinking maybe use many stock signs historical data to create a tfrecord in a way that each stock sign data counts as a single &lt;code&gt;tf.train.Example()&lt;/code&gt; and features including several indicators and possibly sentiment analysis for news articles / any relevant text, so what are your suggestions? is there a better way of creating a dataset for best results?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jdpz96,True,,emadboctor,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jdpz96/using_tfrecords_with_timeseries_stock_ohlcv_data/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdpz96/using_tfrecords_with_timeseries_stock_ohlcv_data/,22217,1603060825.0,0,,False,,,,,,,,,
641,,tensorflow,"(Very new to all of this)

I have actually found that the code for the following example is \~3X faster with **one** GPU.  Clearly I am doing something fantastically wrong.

**Code**

Set up (from example in Chapter 3 of ""Deep Learning with Python""

    # Now we are seeking a continuous value instead of a discrete label
    from keras.datasets import boston_housing 
    from keras import models 
    from keras import layers 
    import numpy as np 
    import tensorflow as tf 
    (train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()
    mean = train_data.mean(axis=0)
    train_data -= mean
    std = train_data.std(axis=0)
    train_data /= std
    
    test_data -= mean
    test_data /= std

**ONE GPU**

    #Compare a single GPU's performance.
    #small data set -&gt; use fewer hidden layers to reduce overfitting
    start_time = time.time()
    
    def build_model():
        model = models.Sequential()
        model.add(layers.Dense(64, activation = 'relu', input_shape = (train_data.shape[1],)))
        model.add(layers.Dense(64, activation='relu'))
        model.compile(optimizer='rmsprop',loss='mse', metrics=['mae'])
        return model
    
    k = 4
    num_val_samples = len(train_data) // k
    num_epochs = 100
    all_scores = []
    
    for i in range(k):
        print('processing fold #', i)
        val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]
        val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]
        partial_train_data = np.concatenate(
            [train_data[:i*num_val_samples],train_data[(i+1)*num_val_samples:]],axis=0)
        partial_train_targets = np.concatenate(
            [train_targets[:i*num_val_samples],train_targets[(i+1)*num_val_samples:]],axis=0)
        model = build_model()
        model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size = 1, verbose = 0)
        val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 0)
        all_scores.append(val_mae)
    #In contrast to the classification examples, here the final layer has no activation function - it is linear.
    #We are not choosing to limit the values to a particular value
    print(""--- %s seconds ---"" % (time.time() - start_time))

\--- 122.94453263282776 seconds ---

**TWO GPUs**

    import time
    start_time = time.time()
    strategy = tf.distribute.MirroredStrategy()
    def build_model():
        model = models.Sequential()
        model.add(layers.Dense(64, activation = 'relu', input_shape = (train_data.shape[1],)))
        model.add(layers.Dense(64, activation='relu'))
        model.compile(optimizer='rmsprop',loss='mse', metrics=['mae'])
        return model
    k = 4
    num_val_samples = len(train_data) // k
    num_epochs = 100
    all_scores = []
    
    for i in range(k):
        print('processing fold #', i)
        val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]
        val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]
        partial_train_data = np.concatenate(
            [train_data[:i*num_val_samples],train_data[(i+1)*num_val_samples:]],axis=0)
        partial_train_targets = np.concatenate(
            [train_targets[:i*num_val_samples],train_targets[(i+1)*num_val_samples:]],axis=0)
        with strategy.scope():
            model = build_model()
        model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size = 1, verbose = 0)
        val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 0)
        all_scores.append(val_mae)
    print(""--- %s seconds ---"" % (time.time() - start_time))

\--- 369.09394359588623 seconds ---

**A few other questions for you kind souls:**

I noticed that the MCLK speed is substantially slower for the second card - from rocm-smi I get the following output:

    ========================ROCm System Management Interface========================
    ================================================================================
    GPU  Temp   AvgPwr  SCLK    MCLK    Fan     Perf  PwrCap  VRAM%  GPU%  
    0    59.0c  15.0W   852Mhz  945Mhz  14.9%   auto  220.0W   95%   37%   
    1    56.0c  19.0W   852Mhz  167Mhz  13.73%  auto  220.0W   99%   35%   
    ================================================================================
    ==============================End of ROCm SMI Log ==============================

When both cards are idle (before beginning training) I noticed that both values sat at about 167 Mhz.  However, when I begin training, only one card sees increased MCLK, as you can see.

I also noticed that VRAM% seems to persist at close to 100% even after the training is done.  Any explanation for why that might be the case?

Thanks in advance.",t2_4onunrh3,False,,0,False,"Performance with 2 GPUs is worse than 1 GPU! (AMD Vega 64/Frontier, ROCm)",[],r/tensorflow,False,6,,0,,,False,t3_jdikas,False,dark,0.75,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,1603036779.0,,[],{},,True,,1603064940.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;(Very new to all of this)&lt;/p&gt;

&lt;p&gt;I have actually found that the code for the following example is ~3X faster with &lt;strong&gt;one&lt;/strong&gt; GPU.  Clearly I am doing something fantastically wrong.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Set up (from example in Chapter 3 of &amp;quot;Deep Learning with Python&amp;quot;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Now we are seeking a continuous value instead of a discrete label
from keras.datasets import boston_housing 
from keras import models 
from keras import layers 
import numpy as np 
import tensorflow as tf 
(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()
mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(axis=0)
train_data /= std

test_data -= mean
test_data /= std
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;ONE GPU&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#Compare a single GPU&amp;#39;s performance.
#small data set -&amp;gt; use fewer hidden layers to reduce overfitting
start_time = time.time()

def build_model():
    model = models.Sequential()
    model.add(layers.Dense(64, activation = &amp;#39;relu&amp;#39;, input_shape = (train_data.shape[1],)))
    model.add(layers.Dense(64, activation=&amp;#39;relu&amp;#39;))
    model.compile(optimizer=&amp;#39;rmsprop&amp;#39;,loss=&amp;#39;mse&amp;#39;, metrics=[&amp;#39;mae&amp;#39;])
    return model

k = 4
num_val_samples = len(train_data) // k
num_epochs = 100
all_scores = []

for i in range(k):
    print(&amp;#39;processing fold #&amp;#39;, i)
    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]
    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]
    partial_train_data = np.concatenate(
        [train_data[:i*num_val_samples],train_data[(i+1)*num_val_samples:]],axis=0)
    partial_train_targets = np.concatenate(
        [train_targets[:i*num_val_samples],train_targets[(i+1)*num_val_samples:]],axis=0)
    model = build_model()
    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size = 1, verbose = 0)
    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 0)
    all_scores.append(val_mae)
#In contrast to the classification examples, here the final layer has no activation function - it is linear.
#We are not choosing to limit the values to a particular value
print(&amp;quot;--- %s seconds ---&amp;quot; % (time.time() - start_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;--- 122.94453263282776 seconds ---&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TWO GPUs&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import time
start_time = time.time()
strategy = tf.distribute.MirroredStrategy()
def build_model():
    model = models.Sequential()
    model.add(layers.Dense(64, activation = &amp;#39;relu&amp;#39;, input_shape = (train_data.shape[1],)))
    model.add(layers.Dense(64, activation=&amp;#39;relu&amp;#39;))
    model.compile(optimizer=&amp;#39;rmsprop&amp;#39;,loss=&amp;#39;mse&amp;#39;, metrics=[&amp;#39;mae&amp;#39;])
    return model
k = 4
num_val_samples = len(train_data) // k
num_epochs = 100
all_scores = []

for i in range(k):
    print(&amp;#39;processing fold #&amp;#39;, i)
    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]
    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]
    partial_train_data = np.concatenate(
        [train_data[:i*num_val_samples],train_data[(i+1)*num_val_samples:]],axis=0)
    partial_train_targets = np.concatenate(
        [train_targets[:i*num_val_samples],train_targets[(i+1)*num_val_samples:]],axis=0)
    with strategy.scope():
        model = build_model()
    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size = 1, verbose = 0)
    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 0)
    all_scores.append(val_mae)
print(&amp;quot;--- %s seconds ---&amp;quot; % (time.time() - start_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;--- 369.09394359588623 seconds ---&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A few other questions for you kind souls:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I noticed that the MCLK speed is substantially slower for the second card - from rocm-smi I get the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;========================ROCm System Management Interface========================
================================================================================
GPU  Temp   AvgPwr  SCLK    MCLK    Fan     Perf  PwrCap  VRAM%  GPU%  
0    59.0c  15.0W   852Mhz  945Mhz  14.9%   auto  220.0W   95%   37%   
1    56.0c  19.0W   852Mhz  167Mhz  13.73%  auto  220.0W   99%   35%   
================================================================================
==============================End of ROCm SMI Log ==============================
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When both cards are idle (before beginning training) I noticed that both values sat at about 167 Mhz.  However, when I begin training, only one card sees increased MCLK, as you can see.&lt;/p&gt;

&lt;p&gt;I also noticed that VRAM% seems to persist at close to 100% even after the training is done.  Any explanation for why that might be the case?&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jdikas,True,,wentdot,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jdikas/performance_with_2_gpus_is_worse_than_1_gpu_amd/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdikas/performance_with_2_gpus_is_worse_than_1_gpu_amd/,22217,1603036140.0,0,,False,,,,,,,,,
642,,tensorflow,"Hello!

I have a Python personal project that requires me to set up a neural net with 6 input nodes, a few hidden layers, and output nodes that I can set ground truth values for. I’ve tried looking at deconstructing existing online projects but I am still lost. Can anyone help me with this or point me in the right direction?",t2_2u8w365e,False,,0,False,How to get started with a neural net- python?,[],r/tensorflow,False,6,,0,,,False,t3_jdk30n,False,dark,1.0,,public,2,1,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1603070062.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;I have a Python personal project that requires me to set up a neural net with 6 input nodes, a few hidden layers, and output nodes that I can set ground truth values for. I’ve tried looking at deconstructing existing online projects but I am still lost. Can anyone help me with this or point me in the right direction?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jdk30n,True,,Xpokemon45,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jdk30n/how_to_get_started_with_a_neural_net_python/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jdk30n/how_to_get_started_with_a_neural_net_python/,22217,1603041262.0,0,,False,,,,,,,,,
643,,tensorflow,"Hi!  After completing some Tensorflow 2.0 courses I decided to try to build my first model with my own data, I uploaded a short collab with my code and everything related to this question (the error can be reproduced there):

[https://colab.research.google.com/drive/1XKyBYLby7UFgxKjcCAtNT1Z5PVz7Wzgf?usp=sharing](https://colab.research.google.com/drive/1XKyBYLby7UFgxKjcCAtNT1Z5PVz7Wzgf?usp=sharing)

file with data:

[https://1drv.ms/u/s!AjDTglh7mlKPgpM6RlUtqo3Yh6zm9w?e=SoeRuz](https://1drv.ms/u/s!AjDTglh7mlKPgpM6RlUtqo3Yh6zm9w?e=SoeRuz)

one drive seems to put all the data together, locally there is 3 columns (screenshot of data):  
[https://1drv.ms/u/s!AjDTglh7mlKPgpM8JmLzdFRovHcAdw?e=butoGl](https://1drv.ms/u/s!AjDTglh7mlKPgpM8JmLzdFRovHcAdw?e=butoGl)

visual representation of data (blue is target and source, green are the positions on movement table), each row produces a graph like this:

[https://1drv.ms/u/s!AjDTglh7mlKPgpM4SUGwPFlbMRAyXQ?e=7Q3v2F](https://1drv.ms/u/s!AjDTglh7mlKPgpM4SUGwPFlbMRAyXQ?e=7Q3v2F)

Things were going well until I reached the end with a message ""UnimplementedError: Cast string to float is not supported"".

I think that I understand that the reason of that error is me trying to use an array on the last column:  I have 3 columns, Source (tuple with X,Y coordinates), Target(tuple with X,Y coordinates) and Movements(array of tuples with with X,Y coordinates). ""Source"" is the initial position, ""Target"" is the targeted position and Movements are all the movements to get from source to target (the movement is always 10 units in a ""+"" shape x: up,down and y: left,right, think about it like a chess board where each movement is one square).

I struggled with how to add the movements data to my model, all the models that I see are pretty straight forward: you have 1 row with all the data, 1 value per row, but I don't know how I could fit all the movements in that format (to reach a position it may need to move 1 times, 0, 15 etc...), I was hopping that this would work but seeing the exception about a string when there is no strings (as far as I know) I assume that last column is triggering the exception and I shouldn't have an array there (if I remove that array and just have a tuple on that last column the error goes away) but if I put one movement per column the shape is totally irregular and the model is not valid

at this point after many hours I still don't know how I should handle this situation, hours of googling doesn't seem to be taking me anywhere",t2_15aiuz,False,,0,False,How can I add a column of arrays to my model,[],r/tensorflow,False,6,,0,,,False,t3_jddck3,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,1603032739.0,,[],{},,True,,1603041894.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!  After completing some Tensorflow 2.0 courses I decided to try to build my first model with my own data, I uploaded a short collab with my code and everything related to this question (the error can be reproduced there):&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://colab.research.google.com/drive/1XKyBYLby7UFgxKjcCAtNT1Z5PVz7Wzgf?usp=sharing""&gt;https://colab.research.google.com/drive/1XKyBYLby7UFgxKjcCAtNT1Z5PVz7Wzgf?usp=sharing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;file with data:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://1drv.ms/u/s!AjDTglh7mlKPgpM6RlUtqo3Yh6zm9w?e=SoeRuz""&gt;https://1drv.ms/u/s!AjDTglh7mlKPgpM6RlUtqo3Yh6zm9w?e=SoeRuz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;one drive seems to put all the data together, locally there is 3 columns (screenshot of data):&lt;br/&gt;
&lt;a href=""https://1drv.ms/u/s!AjDTglh7mlKPgpM8JmLzdFRovHcAdw?e=butoGl""&gt;https://1drv.ms/u/s!AjDTglh7mlKPgpM8JmLzdFRovHcAdw?e=butoGl&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;visual representation of data (blue is target and source, green are the positions on movement table), each row produces a graph like this:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://1drv.ms/u/s!AjDTglh7mlKPgpM4SUGwPFlbMRAyXQ?e=7Q3v2F""&gt;https://1drv.ms/u/s!AjDTglh7mlKPgpM4SUGwPFlbMRAyXQ?e=7Q3v2F&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Things were going well until I reached the end with a message &amp;quot;UnimplementedError: Cast string to float is not supported&amp;quot;.&lt;/p&gt;

&lt;p&gt;I think that I understand that the reason of that error is me trying to use an array on the last column:  I have 3 columns, Source (tuple with X,Y coordinates), Target(tuple with X,Y coordinates) and Movements(array of tuples with with X,Y coordinates). &amp;quot;Source&amp;quot; is the initial position, &amp;quot;Target&amp;quot; is the targeted position and Movements are all the movements to get from source to target (the movement is always 10 units in a &amp;quot;+&amp;quot; shape x: up,down and y: left,right, think about it like a chess board where each movement is one square).&lt;/p&gt;

&lt;p&gt;I struggled with how to add the movements data to my model, all the models that I see are pretty straight forward: you have 1 row with all the data, 1 value per row, but I don&amp;#39;t know how I could fit all the movements in that format (to reach a position it may need to move 1 times, 0, 15 etc...), I was hopping that this would work but seeing the exception about a string when there is no strings (as far as I know) I assume that last column is triggering the exception and I shouldn&amp;#39;t have an array there (if I remove that array and just have a tuple on that last column the error goes away) but if I put one movement per column the shape is totally irregular and the model is not valid&lt;/p&gt;

&lt;p&gt;at this point after many hours I still don&amp;#39;t know how I should handle this situation, hours of googling doesn&amp;#39;t seem to be taking me anywhere&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jddck3,True,,Dr4WasTaken,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jddck3/how_can_i_add_a_column_of_arrays_to_my_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jddck3/how_can_i_add_a_column_of_arrays_to_my_model/,22217,1603013094.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?auto=webp&amp;s=ffc13b63083ce9180bdf2cf28705ee407b659975', 'width': 256, 'height': 256}, 'resolutions': [{'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f53340195fae0f84ec3871625087bf02fd428ab', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6722a649351a89204dede7d65ad009eea43566c', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'mAwt5FN14h93icEvsjkWqFiukRT9FqTVVq54ZHDgaos'}], 'enabled': False}",,,,,,
644,,tensorflow,"I'm having an odd issue - when I'm training a basic GAN (on MNIST), after several epochs, almost all of my RAM is used up. I've read that memory leakage in training loops is a known issue in Tensorflow 2+, but I'm not sure how to solve the issue. For reference, I'm using Tensorflow 2.3 with 32 GB RAM, and an RTX 2060 S. I don't want to post all the code here because it gets messy and hard to read, so I'll just paste the training loop, and provide a link to the full notebook on Google Drive. Any help is appreciated!

Notebook: [https://drive.google.com/file/d/1\_hYIBHSvU0C6ZrkT7S1xJdDxlSNkU3EL/view?usp=sharing](https://drive.google.com/file/d/1_hYIBHSvU0C6ZrkT7S1xJdDxlSNkU3EL/view?usp=sharing)

Training loop:

    seed = tf.random.normal(shape =[batch_size, latent_dim]) 
    
    def train_gan(gan,dataset,batch_size,epochs):
        generator,discriminator = gan.layers
        for epoch in tqdm(range(epochs)): 
            print(""Epoch {}/{}"".format(epoch + 1, epochs)) 
            for X_batch in dataset:
                noise = tf.random.normal(shape =[batch_size, latent_dim]) 
                generated_images = generator(noise)
                
                X_both = tf.concat([generated_images, X_batch], axis = 0)
                y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size) 
                discriminator.trainable = True
                discriminator.train_on_batch(X_both, y1)
                
                noise = tf.random.normal(shape =[batch_size, latent_dim]) 
                y2 = tf.constant([[1.]] * batch_size) 
                discriminator.trainable = False
                gan.train_on_batch(noise,y2)
                
                generate_and_save_images(generator, epoch + 1, seed) 
                
                if psutil.virtual_memory().percent &gt; 70:
                    print(psutil.virtual_memory().percent)
                    print('MEMORY')
                    break
            if psutil.virtual_memory().percent &gt; 70:
                    print('MEMORY')
                    break
            print('ONE EPOCH DONE!')",t2_kau8d0d,False,,0,False,Tensorflow Keras Memory Leak Issue When Training Simple GAN,[],r/tensorflow,False,6,,0,,,False,t3_jd0oqw,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1602989099.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m having an odd issue - when I&amp;#39;m training a basic GAN (on MNIST), after several epochs, almost all of my RAM is used up. I&amp;#39;ve read that memory leakage in training loops is a known issue in Tensorflow 2+, but I&amp;#39;m not sure how to solve the issue. For reference, I&amp;#39;m using Tensorflow 2.3 with 32 GB RAM, and an RTX 2060 S. I don&amp;#39;t want to post all the code here because it gets messy and hard to read, so I&amp;#39;ll just paste the training loop, and provide a link to the full notebook on Google Drive. Any help is appreciated!&lt;/p&gt;

&lt;p&gt;Notebook: &lt;a href=""https://drive.google.com/file/d/1_hYIBHSvU0C6ZrkT7S1xJdDxlSNkU3EL/view?usp=sharing""&gt;https://drive.google.com/file/d/1_hYIBHSvU0C6ZrkT7S1xJdDxlSNkU3EL/view?usp=sharing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Training loop:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;seed = tf.random.normal(shape =[batch_size, latent_dim]) 

def train_gan(gan,dataset,batch_size,epochs):
    generator,discriminator = gan.layers
    for epoch in tqdm(range(epochs)): 
        print(&amp;quot;Epoch {}/{}&amp;quot;.format(epoch + 1, epochs)) 
        for X_batch in dataset:
            noise = tf.random.normal(shape =[batch_size, latent_dim]) 
            generated_images = generator(noise)

            X_both = tf.concat([generated_images, X_batch], axis = 0)
            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size) 
            discriminator.trainable = True
            discriminator.train_on_batch(X_both, y1)

            noise = tf.random.normal(shape =[batch_size, latent_dim]) 
            y2 = tf.constant([[1.]] * batch_size) 
            discriminator.trainable = False
            gan.train_on_batch(noise,y2)

            generate_and_save_images(generator, epoch + 1, seed) 

            if psutil.virtual_memory().percent &amp;gt; 70:
                print(psutil.virtual_memory().percent)
                print(&amp;#39;MEMORY&amp;#39;)
                break
        if psutil.virtual_memory().percent &amp;gt; 70:
                print(&amp;#39;MEMORY&amp;#39;)
                break
        print(&amp;#39;ONE EPOCH DONE!&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jd0oqw,True,,zarif101,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jd0oqw/tensorflow_keras_memory_leak_issue_when_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jd0oqw/tensorflow_keras_memory_leak_issue_when_training/,22217,1602960299.0,0,,False,,,,,,,,,
645,,tensorflow,"Hello community , this is kind of a weird question . I want to embed N images into M images where M &lt; N.

I think that I can do it easily using a classical Autoencoder , and just taking the latent representation of the encoder part.

But I want to do it using a variational autoencoder . Im thinking  about having M differents distribution using the mean and the std deviation of M latent representation Z. 
Next , I will  sample every distribution  Z to result into  M generative image from M distributions.
What do you think about this approach ?",t2_7l9ti89m,False,,0,False,Compressing a bunch of images into one image using VAE,[],r/tensorflow,False,6,,0,,,False,t3_jd2frt,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1602995022.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community , this is kind of a weird question . I want to embed N images into M images where M &amp;lt; N.&lt;/p&gt;

&lt;p&gt;I think that I can do it easily using a classical Autoencoder , and just taking the latent representation of the encoder part.&lt;/p&gt;

&lt;p&gt;But I want to do it using a variational autoencoder . Im thinking  about having M differents distribution using the mean and the std deviation of M latent representation Z. 
Next , I will  sample every distribution  Z to result into  M generative image from M distributions.
What do you think about this approach ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jd2frt,True,,rayanaay,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jd2frt/compressing_a_bunch_of_images_into_one_image/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jd2frt/compressing_a_bunch_of_images_into_one_image/,22217,1602966222.0,0,,False,,,,,,,,,
646,,tensorflow,"Hello community , I’m training an Autoencoder but I have too less images (321 images ) which makes my loss explodes as I don’t have enough data .
I heard about data augmentation , but does it add to my dataset images ? Ie :instead of 321 images for example I will train 2000 images which are simply a zoom / crop etc of my initial images .
Thank you",t2_7l9ti89m,False,,0,False,Data augmentation with images,[],r/tensorflow,False,6,,0,,,False,t3_jcwagw,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1602974497.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community , I’m training an Autoencoder but I have too less images (321 images ) which makes my loss explodes as I don’t have enough data .
I heard about data augmentation , but does it add to my dataset images ? Ie :instead of 321 images for example I will train 2000 images which are simply a zoom / crop etc of my initial images .
Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jcwagw,True,,rayanaay,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jcwagw/data_augmentation_with_images/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jcwagw/data_augmentation_with_images/,22217,1602945697.0,0,,False,,,,,,,,,
647,,tensorflow,"I try to convert [the tensorflow offical image caption model ](https://www.tensorflow.org/tutorials/text/image_captioning?hl=en)to TFLite model. 

I have some [problems](https://github.com/tensorflow/tensorflow/issues/43753) .And Here is the [Colab Link](https://colab.research.google.com/gist/amahendrakar/8b910c4d8a0839068d1cbb07d0da049f/43753.ipynb).Any one can help me?",t2_89e2jrd0,False,,0,False,convert the tensorflow offical image caption model to TFLite model,[],r/tensorflow,False,6,,0,,,False,t3_jct682,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1602961140.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I try to convert &lt;a href=""https://www.tensorflow.org/tutorials/text/image_captioning?hl=en""&gt;the tensorflow offical image caption model &lt;/a&gt;to TFLite model. &lt;/p&gt;

&lt;p&gt;I have some &lt;a href=""https://github.com/tensorflow/tensorflow/issues/43753""&gt;problems&lt;/a&gt; .And Here is the &lt;a href=""https://colab.research.google.com/gist/amahendrakar/8b910c4d8a0839068d1cbb07d0da049f/43753.ipynb""&gt;Colab Link&lt;/a&gt;.Any one can help me?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jct682,True,,David_Black_a17,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jct682/convert_the_tensorflow_offical_image_caption/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jct682/convert_the_tensorflow_offical_image_caption/,22217,1602932340.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
648,,tensorflow,"Uber Technologies uses machine learning models to perform a diversity of tasks, from improving our maps to streamlining chat communications and even preventing fraud. To manage and train and test those models, Uber uses a code-free platform called **Ludwig.**

Now, Uber [open sources Ludwig 0.3](https://ludwig-ai.github.io/ludwig-docs/?from=%40), the third update to its code-free Deep Learning toolbox built on top of TensorFlow.

Summary: [https://www.marktechpost.com/2020/10/16/uber-open-sources-ludwig-v0-3-the-third-update-to-its-code-free-deep-learning-toolbox-built-on-top-of-tensorflow/](https://www.marktechpost.com/2020/10/16/uber-open-sources-ludwig-v0-3-the-third-update-to-its-code-free-deep-learning-toolbox-built-on-top-of-tensorflow/)

Github: [https://ludwig-ai.github.io/ludwig-docs/?from=%40](https://ludwig-ai.github.io/ludwig-docs/?from=%40) 

Tutorial: [https://www.youtube.com/watch?v=OGweVw57kus](https://www.youtube.com/watch?v=OGweVw57kus)",t2_2wsvqwhg,False,,0,False,Uber Open-Sources Ludwig v0.3: The Third Update To Its Code-Free Deep Learning Toolbox Built On Top Of TensorFlow,[],r/tensorflow,False,6,,0,,,False,t3_jcc00w,False,dark,1.0,,public,18,0,{},,,False,[],,False,False,,{},Discussion,False,18,,False,self,False,,[],{},,True,,1602891307.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Uber Technologies uses machine learning models to perform a diversity of tasks, from improving our maps to streamlining chat communications and even preventing fraud. To manage and train and test those models, Uber uses a code-free platform called &lt;strong&gt;Ludwig.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now, Uber &lt;a href=""https://ludwig-ai.github.io/ludwig-docs/?from=%40""&gt;open sources Ludwig 0.3&lt;/a&gt;, the third update to its code-free Deep Learning toolbox built on top of TensorFlow.&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/10/16/uber-open-sources-ludwig-v0-3-the-third-update-to-its-code-free-deep-learning-toolbox-built-on-top-of-tensorflow/""&gt;https://www.marktechpost.com/2020/10/16/uber-open-sources-ludwig-v0-3-the-third-update-to-its-code-free-deep-learning-toolbox-built-on-top-of-tensorflow/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://ludwig-ai.github.io/ludwig-docs/?from=%40""&gt;https://ludwig-ai.github.io/ludwig-docs/?from=%40&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Tutorial: &lt;a href=""https://www.youtube.com/watch?v=OGweVw57kus""&gt;https://www.youtube.com/watch?v=OGweVw57kus&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,#ffb000,jcc00w,True,,ai-lover,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jcc00w/uber_opensources_ludwig_v03_the_third_update_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jcc00w/uber_opensources_ludwig_v03_the_third_update_to/,22217,1602862507.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/t4dnZMLn6J4tg9AL4xnScDlYmcCf4sL5rIgIVF4SsSg.jpg?auto=webp&amp;s=c596d2d9bdfa3bab3731b2ba8e6bb3f271db62a8', 'width': 852, 'height': 446}, 'resolutions': [{'url': 'https://external-preview.redd.it/t4dnZMLn6J4tg9AL4xnScDlYmcCf4sL5rIgIVF4SsSg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9e0d6a44d4f23a5bd3f76e0b9e97ce9accb64d2', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/t4dnZMLn6J4tg9AL4xnScDlYmcCf4sL5rIgIVF4SsSg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f02ad6e8cd22ba776e8b5a1adebbbc757e02514', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/t4dnZMLn6J4tg9AL4xnScDlYmcCf4sL5rIgIVF4SsSg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b48fca3e75c92542bcfb71a0e8857987bb3b403', 'width': 320, 'height': 167}, {'url': 'https://external-preview.redd.it/t4dnZMLn6J4tg9AL4xnScDlYmcCf4sL5rIgIVF4SsSg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b3271df8029f3f9fa2543d99a029cd02070447e', 'width': 640, 'height': 335}], 'variants': {}, 'id': 'm1DOZhQlmQYguwLDF6KDejhu-3dkoCcZViGljiknaZg'}], 'enabled': False}",,,,,,
649,,tensorflow,"Hi everybody! 

I'm using tensorflow 2.3 and I'm having an issue when i try to call a function that returns a keras.Model .

&amp;#x200B;

     AttributeError: 'Tensor' object has no attribute 'numpy' Tensorflow 2.3

I write here a snippet of my model

    inputs = Input(shape=(n_ch, height, width), batch_size=batchSize)
    
        conv_1 = Conv2D(16, (5, 5), kernel_initializer='he_normal', padding='same',data_format='channels_first')(inputs)
        conv_1 = BatchNormalization(axis=1)(conv_1)
        conv_1 = Activation(""relu"")(conv_1)
        conv_2 = Conv2D(16, (5, 5), kernel_initializer='he_normal', padding='same',data_format='channels_first')(conv_1)
    
        conv_2 = BatchNormalization(axis=1)(conv_2)
        conv_2 = Activation(""relu"")(conv_2)
    
    
        pool_1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv_2)
    
    
        unpool_1 = Lambda(unpool)(pool_1)
    
        conv_25 = Conv2D(16, (5, 5), kernel_initializer='he_normal', padding='same',data_format='channels_first')(unpool_1)
        conv_25 = BatchNormalization(axis=1)(conv_25)
        conv_25 = Activation(""relu"")(conv_25)
        conv_26 = Conv2D(1, (1, 1),data_format=""channels_first"",activation=""sigmoid"")(conv_25)
        print(""Build decoder done.."")
    
        model = Model(inputs=inputs, outputs=conv_26, name=""SegNet"")
    
        return model

So i call a function that returns me this and I get the AttributeError because of this other function used by Lambda layers:

    def unpool(pool):
        updates = pool.numpy()

**It says that pool is a Tensor object but I don't understand why**.

I want to use eager mode and tf.executing\_eagerly() returns True.

I also tried to set run\_eagerly=True and/or tf.config.run\_functions\_eagerly(True) but nothing.

&amp;#x200B;

Any suggestions? Thank you",t2_3qwwyxi8,False,,0,False,Tensorflow 2.3 - AttributeError: 'Tensor' object has no attribute 'numpy' with eager mode enabled,[],r/tensorflow,False,6,,0,,,False,t3_jcgz7y,False,dark,0.89,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1602906851.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everybody! &lt;/p&gt;

&lt;p&gt;I&amp;#39;m using tensorflow 2.3 and I&amp;#39;m having an issue when i try to call a function that returns a keras.Model .&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; AttributeError: &amp;#39;Tensor&amp;#39; object has no attribute &amp;#39;numpy&amp;#39; Tensorflow 2.3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I write here a snippet of my model&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;inputs = Input(shape=(n_ch, height, width), batch_size=batchSize)

    conv_1 = Conv2D(16, (5, 5), kernel_initializer=&amp;#39;he_normal&amp;#39;, padding=&amp;#39;same&amp;#39;,data_format=&amp;#39;channels_first&amp;#39;)(inputs)
    conv_1 = BatchNormalization(axis=1)(conv_1)
    conv_1 = Activation(&amp;quot;relu&amp;quot;)(conv_1)
    conv_2 = Conv2D(16, (5, 5), kernel_initializer=&amp;#39;he_normal&amp;#39;, padding=&amp;#39;same&amp;#39;,data_format=&amp;#39;channels_first&amp;#39;)(conv_1)

    conv_2 = BatchNormalization(axis=1)(conv_2)
    conv_2 = Activation(&amp;quot;relu&amp;quot;)(conv_2)


    pool_1 = MaxPooling2D(pool_size=(2, 2), data_format=&amp;#39;channels_first&amp;#39;)(conv_2)


    unpool_1 = Lambda(unpool)(pool_1)

    conv_25 = Conv2D(16, (5, 5), kernel_initializer=&amp;#39;he_normal&amp;#39;, padding=&amp;#39;same&amp;#39;,data_format=&amp;#39;channels_first&amp;#39;)(unpool_1)
    conv_25 = BatchNormalization(axis=1)(conv_25)
    conv_25 = Activation(&amp;quot;relu&amp;quot;)(conv_25)
    conv_26 = Conv2D(1, (1, 1),data_format=&amp;quot;channels_first&amp;quot;,activation=&amp;quot;sigmoid&amp;quot;)(conv_25)
    print(&amp;quot;Build decoder done..&amp;quot;)

    model = Model(inputs=inputs, outputs=conv_26, name=&amp;quot;SegNet&amp;quot;)

    return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So i call a function that returns me this and I get the AttributeError because of this other function used by Lambda layers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def unpool(pool):
    updates = pool.numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;It says that pool is a Tensor object but I don&amp;#39;t understand why&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I want to use eager mode and tf.executing_eagerly() returns True.&lt;/p&gt;

&lt;p&gt;I also tried to set run_eagerly=True and/or tf.config.run_functions_eagerly(True) but nothing.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any suggestions? Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jcgz7y,True,,gengis_diokhan,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/jcgz7y/tensorflow_23_attributeerror_tensor_object_has_no/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jcgz7y/tensorflow_23_attributeerror_tensor_object_has_no/,22217,1602878051.0,0,,False,,,,,,,,,
650,,tensorflow,,t2_44mbtmjy,False,,0,False,Groundbreaking research from UWashington researchers: Remove any background noise/voice when in a video call! (See video),[],r/tensorflow,False,6,,0,140.0,,False,t3_jcnlpy,False,dark,0.4,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/pgWrcw35V8jNDmIEwWSr_XZlYtVgexbffnGo_jk2eSU.jpg,False,,[],{},,False,,1602931902.0,text,6,,,text,self.LatestInML,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jcnlpy,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jcnlpy/groundbreaking_research_from_uwashington/,all_ads,False,/r/LatestInML/comments/jcn81a/groundbreaking_research_from_uwashington/,22217,1602903102.0,0,,False,link,/r/LatestInML/comments/jcn81a/groundbreaking_research_from_uwashington/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'Groundbreaking research from UWashington researchers: Remove any background noise/voice when in a video call! (See video)\n\nFor project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2010.06007)\n\n&amp;#x200B;\n\nhttps://reddit.com/link/jcn81a/video/8r72gm0dfkt51/player\n\nExperiments demonstrate state-of-the-art performance for both source separation and source localization, particularly in high levels of background noise.', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Groundbreaking research from UWashington researchers: Remove any background noise/voice when in a video call! (See video)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'8r72gm0dfkt51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/jcn81a/asset/8r72gm0dfkt51/DASHPlaylist.mpd?a=1618044806%2CM2IwNTI1YjZkN2VkNjliMzhlOWI0Yjk2NDQ2ZDdiMWNmMmZlMmQ4NWExNDhkZjc2ZjQ3NWE3MzY4NjI1ZWVjYQ%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/jcn81a/asset/8r72gm0dfkt51/HLSPlaylist.m3u8?a=1618044806%2COTNjNTQ4NDNhNjIxZjEwMTFmM2Y1MzIzZTFlZmFjOTFlNTdmOWY0N2IxZmYwM2EzMzNjZTNhYWVkODg4YWMyYg%3D%3D&amp;v=1&amp;f=sd', 'id': '8r72gm0dfkt51', 'isGif': False}}, 'name': 't3_jcn81a', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 54, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 54, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/pgWrcw35V8jNDmIEwWSr_XZlYtVgexbffnGo_jk2eSU.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1602930223.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Groundbreaking research from UWashington researchers: Remove any background noise/voice when in a video call! (See video)&lt;/p&gt;\n\n&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2010.06007""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/jcn81a/video/8r72gm0dfkt51/player""&gt;https://reddit.com/link/jcn81a/video/8r72gm0dfkt51/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Experiments demonstrate state-of-the-art performance for both source separation and source localization, particularly in high levels of background noise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'jcn81a', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/jcn81a/groundbreaking_research_from_uwashington/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/jcn81a/groundbreaking_research_from_uwashington/', 'subreddit_subscribers': 6676, 'created_utc': 1602901423.0, 'num_crossposts': 13, 'media': None, 'is_video': False}]",t3_jcn81a,
651,,tensorflow,"This is my first time trying to go learn TensorFlow, for a school project. I have gone through [this video](https://www.youtube.com/watch?v=Gf5DO6br0ts&amp;list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&amp;index=14) and to make some modifications from [this article](https://towardsdatascience.com/understanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa). However, I would like to try to parallelize the training portion (line 96 in the first link). I have found this link from [TensorFlow documentation](https://www.tensorflow.org/guide/distributed_training), which led me to the [tf.distributed.MirroredStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy) but I can't make heads or tails of it. 

Can anyone help me with what I thought would be a simple procedure? Maybe this is simple, and I need to do more reading",t2_18a6tqmk,False,,0,False,How to parallelize training?,[],r/tensorflow,False,6,,0,,,False,t3_jcibsp,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1602911775.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is my first time trying to go learn TensorFlow, for a school project. I have gone through &lt;a href=""https://www.youtube.com/watch?v=Gf5DO6br0ts&amp;amp;list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&amp;amp;index=14""&gt;this video&lt;/a&gt; and to make some modifications from &lt;a href=""https://towardsdatascience.com/understanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa""&gt;this article&lt;/a&gt;. However, I would like to try to parallelize the training portion (line 96 in the first link). I have found this link from &lt;a href=""https://www.tensorflow.org/guide/distributed_training""&gt;TensorFlow documentation&lt;/a&gt;, which led me to the &lt;a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy""&gt;tf.distributed.MirroredStrategy&lt;/a&gt; but I can&amp;#39;t make heads or tails of it. &lt;/p&gt;

&lt;p&gt;Can anyone help me with what I thought would be a simple procedure? Maybe this is simple, and I need to do more reading&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jcibsp,True,,go-fireworks,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jcibsp/how_to_parallelize_training/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jcibsp/how_to_parallelize_training/,22217,1602882975.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/V_ucgr8j9VdEl_ymi-NZrWq5wa3JL7v0RlXvgmbjyz4.jpg?auto=webp&amp;s=c2454ed611168082e135dea70a061c4f2261fddc', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/V_ucgr8j9VdEl_ymi-NZrWq5wa3JL7v0RlXvgmbjyz4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da9bdd907cfa3ae97d2ee9438d32457d8e37685d', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/V_ucgr8j9VdEl_ymi-NZrWq5wa3JL7v0RlXvgmbjyz4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6b81dba70f6194694b8376c1438f61ad1692f622', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/V_ucgr8j9VdEl_ymi-NZrWq5wa3JL7v0RlXvgmbjyz4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f96619ca295902f619f89c19ae7800e3e5834932', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Ce-8HBM2Hii1b5MavVQ5qAQ9-AKvLLHWl5ASTsMJS2U'}], 'enabled': False}",,,,,,
652,,tensorflow,"I am trying to utilize the tensorflow library to be able to use tensorflow sessions but **hurt** the output precision of the weights for neurons in my model to be able to model a Processing in Memory architecture that has decreased output precision.

I was wondering if anyone knew where the back propogation or neuron weights are in tensorflow so I can decrease the weight and output precision by 2-3 bits. 

Guidance would be greatly appreciated.",t2_4pz8pt88,False,,0,False,Modifying Back Propogation Code in Tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_jcicxu,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1602911834.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to utilize the tensorflow library to be able to use tensorflow sessions but &lt;strong&gt;hurt&lt;/strong&gt; the output precision of the weights for neurons in my model to be able to model a Processing in Memory architecture that has decreased output precision.&lt;/p&gt;

&lt;p&gt;I was wondering if anyone knew where the back propogation or neuron weights are in tensorflow so I can decrease the weight and output precision by 2-3 bits. &lt;/p&gt;

&lt;p&gt;Guidance would be greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jcicxu,True,,coder_et,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jcicxu/modifying_back_propogation_code_in_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jcicxu/modifying_back_propogation_code_in_tensorflow/,22217,1602883034.0,0,,False,,,,,,,,,
653,,tensorflow,"Error: `tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [[0.956730783]] [[0.896634638]] [[{{node Assert/AssertGuard/else/_25/Assert/AssertGuard/Assert}}]] [[MultiDeviceIteratorGetNextFromShard]] [[RemoteCall]]`

This is happening when training using TensorFlow Object Detection API V2

I am using Vehicles Data from RoboFlow and I converted its PASCAL VOC XML format to TFRecords through TensorFlow's official script and every time I use my data, this error shows up but if use the ones RoboFlow directly gives you then the error doesn't show up at all. A similar error is already reported on TensorFlow issues but it got closed and I tried that solution but It doesn't work for me which involved making sure all my values of label heights and widths were positive",t2_scyx6,False,,0,False,I keep running into this error if I use my custom TF Records when training the Model,[],r/tensorflow,False,6,,0,,,False,t3_jcdbas,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1602866823.0,,[],{},,True,,1602895376.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Error: &lt;code&gt;tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [[0.956730783]] [[0.896634638]] [[{{node Assert/AssertGuard/else/_25/Assert/AssertGuard/Assert}}]] [[MultiDeviceIteratorGetNextFromShard]] [[RemoteCall]]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is happening when training using TensorFlow Object Detection API V2&lt;/p&gt;

&lt;p&gt;I am using Vehicles Data from RoboFlow and I converted its PASCAL VOC XML format to TFRecords through TensorFlow&amp;#39;s official script and every time I use my data, this error shows up but if use the ones RoboFlow directly gives you then the error doesn&amp;#39;t show up at all. A similar error is already reported on TensorFlow issues but it got closed and I tried that solution but It doesn&amp;#39;t work for me which involved making sure all my values of label heights and widths were positive&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jcdbas,True,,AliButtar,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jcdbas/i_keep_running_into_this_error_if_i_use_my_custom/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jcdbas/i_keep_running_into_this_error_if_i_use_my_custom/,22217,1602866576.0,0,,False,,,,,,,,,
654,,tensorflow,"I am trying to load an image dataset consisting of positive and negative examples. 

`-- data`

`| - N`

`| - P`

N contains negative examples and P contains positive examples.

I tried using tfds.ImageFolder, the documentation is very unclear about how to structure the data. When I run it, it throws `module 'tensorflow_datasets' has no attribute 'folder_dataset'`

I am not able to fix this error... Is the way I am loading images correct ? or should I use some other method to load the data ?",t2_3mk0mgw8,False,,0,False,Help in using a custom image dataset,[],r/tensorflow,False,6,,0,,,False,t3_jc4amp,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1602856029.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to load an image dataset consisting of positive and negative examples. &lt;/p&gt;

&lt;p&gt;&lt;code&gt;-- data&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;| - N&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;| - P&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;N contains negative examples and P contains positive examples.&lt;/p&gt;

&lt;p&gt;I tried using tfds.ImageFolder, the documentation is very unclear about how to structure the data. When I run it, it throws &lt;code&gt;module &amp;#39;tensorflow_datasets&amp;#39; has no attribute &amp;#39;folder_dataset&amp;#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;I am not able to fix this error... Is the way I am loading images correct ? or should I use some other method to load the data ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jc4amp,True,,Buggi_San,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jc4amp/help_in_using_a_custom_image_dataset/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jc4amp/help_in_using_a_custom_image_dataset/,22217,1602827229.0,0,,False,,,,,,,,,
655,,tensorflow,,t2_xt6j8xa,False,,0,False,Graph Neural Networks are incredibly powerful and is growing exponentially in popularity. I wrote a blog on Graph Neural Networks. I hope you like it.,[],r/tensorflow,False,6,,0,93.0,,False,t3_jbnaom,False,dark,1.0,,public,33,0,{},140.0,,False,[],,False,False,,{},,False,33,,False,https://a.thumbs.redditmedia.com/NuS7raDQrwAgyQnwjBRRlMLkkt9XuYK1-f9bL7rLqo4.jpg,False,,[],{},,False,,1602796446.0,text,6,,,text,towardsdatascience.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jbnaom,True,,clean_pegasus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jbnaom/graph_neural_networks_are_incredibly_powerful_and/,all_ads,False,https://towardsdatascience.com/an-introduction-to-graph-neural-networks-part-1-57335bca9a79?source=friends_link&amp;sk=18926692949fc2bc6fc580f9c4c41a90,22217,1602767646.0,0,,False,link,https://towardsdatascience.com/an-introduction-to-graph-neural-networks-part-1-57335bca9a79?source=friends_link&amp;sk=18926692949fc2bc6fc580f9c4c41a90,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?auto=webp&amp;s=4be7295050c11c5e1877925da54a3f1382d13e53', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=111a23ebcd1558567ccafd109ad5701fc0366fae', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=876a180ed4b396755b25d34e85e380c6f40e2729', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c85bd159ee3c30d45e95c06235b044d86f67e3f', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=557a67b22462f2716140553de46c4d7f6e4238ae', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=08c494b2ad2026d6e6285b46b13ef34e23e1e1c3', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/-l9T9F8FJQAri_5gMEN9ssZuigoJGs5GK2nJEOXQYvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1485e6272415d633d0877d99d9dd6a456e657469', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'ZEZU262P6ICorUpsSMOSMMKduafh7OexlTOk2lBRkbc'}], 'enabled': False}",,,,,,
656,,tensorflow,"I'm doing image segmentation on satellite data to identify agricultural fields. So each pixel is either 1 or 0. So my output layer is 256,256,1. Should I be using a softmax, is that fine?

And i'm using binary_crossentropy, thats the best loss for this situatioon too right?",t2_5wuzf,False,,0,False,Should I use softmax as my output layer for a binary image segmentation?,[],r/tensorflow,False,6,,0,,,False,t3_jbnh96,False,dark,0.91,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1602797098.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m doing image segmentation on satellite data to identify agricultural fields. So each pixel is either 1 or 0. So my output layer is 256,256,1. Should I be using a softmax, is that fine?&lt;/p&gt;

&lt;p&gt;And i&amp;#39;m using binary_crossentropy, thats the best loss for this situatioon too right?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jbnh96,True,,thejeran,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/jbnh96/should_i_use_softmax_as_my_output_layer_for_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jbnh96/should_i_use_softmax_as_my_output_layer_for_a/,22217,1602768298.0,0,,False,,,,,,,,,
657,,tensorflow,"Hello community , what is the difference between the probabilistic layers and the classical layers (Conv ,dense ..) ? Can we add a probabilistic layer with classic Layers ? What would be the purpose in this case ?",t2_7l9ti89m,False,,0,False,TF.2-0 Probabilistic Layers vs classic Layer,[],r/tensorflow,False,6,,0,,,False,t3_jbzas4,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1602835384.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community , what is the difference between the probabilistic layers and the classical layers (Conv ,dense ..) ? Can we add a probabilistic layer with classic Layers ? What would be the purpose in this case ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jbzas4,True,,rayanaay,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jbzas4/tf20_probabilistic_layers_vs_classic_layer/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jbzas4/tf20_probabilistic_layers_vs_classic_layer/,22217,1602806584.0,0,,False,,,,,,,,,
658,,tensorflow,"Dear reddit,

I just installed my new RTX 3080, reinstall drivers, cuda, cdnn etc. I am trying to run a simple model initialization and it takes at least 10 mins (with cpu its 1 sec). Can someone help me? 

I already tried setting max cuda cachesize in environmental variables of the system but it doesn't work.",t2_aa5s6ix,False,,0,False,Tensorflow with RTX 3080 extremely slow,[],r/tensorflow,False,6,,0,,,False,t3_jbp2sh,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1602802554.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear reddit,&lt;/p&gt;

&lt;p&gt;I just installed my new RTX 3080, reinstall drivers, cuda, cdnn etc. I am trying to run a simple model initialization and it takes at least 10 mins (with cpu its 1 sec). Can someone help me? &lt;/p&gt;

&lt;p&gt;I already tried setting max cuda cachesize in environmental variables of the system but it doesn&amp;#39;t work.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,#ea0027,jbp2sh,True,,cryptoel,,20,True,all_ads,False,[],False,,/r/tensorflow/comments/jbp2sh/tensorflow_with_rtx_3080_extremely_slow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jbp2sh/tensorflow_with_rtx_3080_extremely_slow/,22217,1602773754.0,0,,False,,,,,,,,,
659,,tensorflow,"New tutorial out 🚀 🚀 This time you can learn how to implement band energy ratio from scratch in Python. I also show how this feature differs for music in different genres. 

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=8UJ8ZDR7yUs&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=22](https://www.youtube.com/watch?v=8UJ8ZDR7yUs&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=22)",t2_12ahau,False,,0,False,I published a tutorial implementing the band energy ratio feature for audio data from scratch,[],r/tensorflow,False,6,,0,,,False,t3_jbnhm9,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Project,False,2,,False,self,False,,[],{},,True,,1602797136.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;New tutorial out 🚀 🚀 This time you can learn how to implement band energy ratio from scratch in Python. I also show how this feature differs for music in different genres. &lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=8UJ8ZDR7yUs&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=22""&gt;https://www.youtube.com/watch?v=8UJ8ZDR7yUs&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=22&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,581365a4-0ec1-11eb-8b84-0efaac771c2d,False,False,False,,[],False,,,,t5_3alkk,,,#ff4500,jbnhm9,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jbnhm9/i_published_a_tutorial_implementing_the_band/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jbnhm9/i_published_a_tutorial_implementing_the_band/,22217,1602768336.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/F3SOzQ4QkSBPNgy30Uqm1bqbQ_DiyUfdQjkzWlp6lXw.jpg?auto=webp&amp;s=f269f2c8b11ebc8e5ead2f5da1380386ae415982', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/F3SOzQ4QkSBPNgy30Uqm1bqbQ_DiyUfdQjkzWlp6lXw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a0978fcb287ceaf40f7f6d43e6065d0783b7655', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/F3SOzQ4QkSBPNgy30Uqm1bqbQ_DiyUfdQjkzWlp6lXw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61b0b6f06501a070dcd460cc9c812132e649eca2', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/F3SOzQ4QkSBPNgy30Uqm1bqbQ_DiyUfdQjkzWlp6lXw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=87f5912a8ce67ddcc59cc821d7e761f3fc76d6b7', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'eoy041A6AU8QkFGQL6_p0Wf5DesM5vNOQCgVVT8uJ7U'}], 'enabled': False}",,,,,,
660,,tensorflow,"Here's my code:

import discord

from textgenrnn import textgenrnn

from discord.ext import commands

import string

import requests

import time, threading

import asyncio

from pathlib import Path

my\_file = Path('/textgenrnn\_weights.hdf5')

prefix = ""?""

bot = [commands.Bot](https://commands.Bot)(command\_prefix = prefix)

async def textgenerator():

await bot.wait\_until\_ready()

channel = bot.get\_channel(channel id not showing)

while not bot.is\_closed():

if my\_file.exists():

t = textgenrnn('textgenrnn\_weights.hdf5')

else:

t = textgenrnn()

t.train\_from\_file('index.txt', num\_epochs = 1)

generation = (t.generate(1, temperature = 0.5, return\_as\_list=True,)\[0\])

embed=discord.Embed(title=""Text Generation"", description = generation, color = (0xF48D1))

await channel.send(embed=embed)

await asyncio.sleep(1800)

bot.loop.create\_task(textgenerator())

[bot.run](https://bot.run)('discord token not gonna show that')

&amp;#x200B;

Here's the traceback

&amp;#x200B;

Traceback (most recent call last):

  File ""[index.py](https://index.py)"", line 17, in textgenerator

t.train\_from\_file('index.txt', num\_epochs = 1)

  File ""C:\\Users\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\textgenrnn\\[textgenrnn.py](https://textgenrnn.py)"", line 367, in train\_from\_file

self.train\_on\_texts(texts, context\_labels=context\_labels, \*\*kwargs)

  File ""C:\\Users\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\textgenrnn\\[textgenrnn.py](https://textgenrnn.py)"", line 160, in train\_on\_texts

indices\_list\_o = np.block(indices\_list\[0\])

IndexError: list index out of range

unsure how to fix this",t2_16zb30,False,,0,False,Unsure what to fix,[],r/tensorflow,False,6,,0,,,False,t3_jbnb57,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1602796491.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Here&amp;#39;s my code:&lt;/p&gt;

&lt;p&gt;import discord&lt;/p&gt;

&lt;p&gt;from textgenrnn import textgenrnn&lt;/p&gt;

&lt;p&gt;from discord.ext import commands&lt;/p&gt;

&lt;p&gt;import string&lt;/p&gt;

&lt;p&gt;import requests&lt;/p&gt;

&lt;p&gt;import time, threading&lt;/p&gt;

&lt;p&gt;import asyncio&lt;/p&gt;

&lt;p&gt;from pathlib import Path&lt;/p&gt;

&lt;p&gt;my_file = Path(&amp;#39;/textgenrnn_weights.hdf5&amp;#39;)&lt;/p&gt;

&lt;p&gt;prefix = &amp;quot;?&amp;quot;&lt;/p&gt;

&lt;p&gt;bot = &lt;a href=""https://commands.Bot""&gt;commands.Bot&lt;/a&gt;(command_prefix = prefix)&lt;/p&gt;

&lt;p&gt;async def textgenerator():&lt;/p&gt;

&lt;p&gt;await bot.wait_until_ready()&lt;/p&gt;

&lt;p&gt;channel = bot.get_channel(channel id not showing)&lt;/p&gt;

&lt;p&gt;while not bot.is_closed():&lt;/p&gt;

&lt;p&gt;if my_file.exists():&lt;/p&gt;

&lt;p&gt;t = textgenrnn(&amp;#39;textgenrnn_weights.hdf5&amp;#39;)&lt;/p&gt;

&lt;p&gt;else:&lt;/p&gt;

&lt;p&gt;t = textgenrnn()&lt;/p&gt;

&lt;p&gt;t.train_from_file(&amp;#39;index.txt&amp;#39;, num_epochs = 1)&lt;/p&gt;

&lt;p&gt;generation = (t.generate(1, temperature = 0.5, return_as_list=True,)[0])&lt;/p&gt;

&lt;p&gt;embed=discord.Embed(title=&amp;quot;Text Generation&amp;quot;, description = generation, color = (0xF48D1))&lt;/p&gt;

&lt;p&gt;await channel.send(embed=embed)&lt;/p&gt;

&lt;p&gt;await asyncio.sleep(1800)&lt;/p&gt;

&lt;p&gt;bot.loop.create_task(textgenerator())&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://bot.run""&gt;bot.run&lt;/a&gt;(&amp;#39;discord token not gonna show that&amp;#39;)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s the traceback&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Traceback (most recent call last):&lt;/p&gt;

&lt;p&gt;File &amp;quot;&lt;a href=""https://index.py""&gt;index.py&lt;/a&gt;&amp;quot;, line 17, in textgenerator&lt;/p&gt;

&lt;p&gt;t.train_from_file(&amp;#39;index.txt&amp;#39;, num_epochs = 1)&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\AppData\Local\Programs\Python\Python36\lib\site-packages\textgenrnn\&lt;a href=""https://textgenrnn.py""&gt;textgenrnn.py&lt;/a&gt;&amp;quot;, line 367, in train_from_file&lt;/p&gt;

&lt;p&gt;self.train_on_texts(texts, context_labels=context_labels, **kwargs)&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\AppData\Local\Programs\Python\Python36\lib\site-packages\textgenrnn\&lt;a href=""https://textgenrnn.py""&gt;textgenrnn.py&lt;/a&gt;&amp;quot;, line 160, in train_on_texts&lt;/p&gt;

&lt;p&gt;indices_list_o = np.block(indices_list[0])&lt;/p&gt;

&lt;p&gt;IndexError: list index out of range&lt;/p&gt;

&lt;p&gt;unsure how to fix this&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jbnb57,True,,TheJb3403,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jbnb57/unsure_what_to_fix/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jbnb57/unsure_what_to_fix/,22217,1602767691.0,0,,False,,,,,,,,,
661,,tensorflow,"I’ve been trying to build a NN tokenizer using tf2, where the inputs would be chars and the outputs, tokens. 

But it is not clear to me how this kind of model should work in terms of the output format. If the outputs are tokens, they could be relresented as embeddings, one-hot or maybe indices/ints extracted from the embeddings? 

Source codes I found doing something similar are either old or not that straightforward for learning. Some of my questions are:

Can you describe the shape and meaning of the inputs and outputs for such model?

Is it possible to use an embedded output (or the inverse of an embedding layer to output an integer representing a token)?

If the output is one-hot, doesn’t it get too heavy since the total number of tokens would be around 100k to 1m (number of possible english words)?

Are there some tutorials or examples you’d recommend of a tokenizer being trained using keras/tensorflow (hopefully 2.0)?",t2_1rfg9tf5,False,,0,False,How do neural tokenizers work?,[],r/tensorflow,False,6,,0,,,False,t3_jbilh6,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1602773374.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve been trying to build a NN tokenizer using tf2, where the inputs would be chars and the outputs, tokens. &lt;/p&gt;

&lt;p&gt;But it is not clear to me how this kind of model should work in terms of the output format. If the outputs are tokens, they could be relresented as embeddings, one-hot or maybe indices/ints extracted from the embeddings? &lt;/p&gt;

&lt;p&gt;Source codes I found doing something similar are either old or not that straightforward for learning. Some of my questions are:&lt;/p&gt;

&lt;p&gt;Can you describe the shape and meaning of the inputs and outputs for such model?&lt;/p&gt;

&lt;p&gt;Is it possible to use an embedded output (or the inverse of an embedding layer to output an integer representing a token)?&lt;/p&gt;

&lt;p&gt;If the output is one-hot, doesn’t it get too heavy since the total number of tokens would be around 100k to 1m (number of possible english words)?&lt;/p&gt;

&lt;p&gt;Are there some tutorials or examples you’d recommend of a tokenizer being trained using keras/tensorflow (hopefully 2.0)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,jbilh6,True,,rodrigonader,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jbilh6/how_do_neural_tokenizers_work/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jbilh6/how_do_neural_tokenizers_work/,22217,1602744574.0,0,,False,,,,,,,,,
662,,tensorflow,"I have seen some charts of the popularity of pytorch going up(maybe surpassing tensorflow in the future)  should I learn pytorch or tensorflow if I want to get a data scientist job / do freelancing ?
Or does it not matter ?",t2_128ob4,False,,0,False,Tensorflow vs Pytorch for job opportunities/freelancing,[],r/tensorflow,False,6,,0,,,False,t3_jarlfg,False,dark,1.0,,public,17,0,{},,,False,[],,False,False,,{},,False,17,,False,self,False,,[],{},,True,,1602669646.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have seen some charts of the popularity of pytorch going up(maybe surpassing tensorflow in the future)  should I learn pytorch or tensorflow if I want to get a data scientist job / do freelancing ?
Or does it not matter ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jarlfg,True,,darvidas,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/jarlfg/tensorflow_vs_pytorch_for_job/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jarlfg/tensorflow_vs_pytorch_for_job/,22217,1602640846.0,0,,False,,,,,,,,,
663,,tensorflow,"I am currently playing around with RNN's using time series generator but I keep getting flat forecast I have adjust and tried everything. If anyone can help please comment because I'm fresh out of ideas.

https://stackoverflow.com/questions/56022318/lstm-in-python-generating-flat-forecasts

The link listed is almost the exact same issue I am having.

Here is a link for the code with data set please feel free to download and play around with:

http://s000.tinyupload.com/index.php?file_id=18130941295831362068",t2_rrcojwq,False,,0,False,LSTM in python generating a flat forrcast,[],r/tensorflow,False,6,,0,,,False,t3_jaoz8w,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,1602672803.0,,[],{},,True,,1602660126.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently playing around with RNN&amp;#39;s using time series generator but I keep getting flat forecast I have adjust and tried everything. If anyone can help please comment because I&amp;#39;m fresh out of ideas.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://stackoverflow.com/questions/56022318/lstm-in-python-generating-flat-forecasts""&gt;https://stackoverflow.com/questions/56022318/lstm-in-python-generating-flat-forecasts&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The link listed is almost the exact same issue I am having.&lt;/p&gt;

&lt;p&gt;Here is a link for the code with data set please feel free to download and play around with:&lt;/p&gt;

&lt;p&gt;&lt;a href=""http://s000.tinyupload.com/index.php?file_id=18130941295831362068""&gt;http://s000.tinyupload.com/index.php?file_id=18130941295831362068&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jaoz8w,True,,Perc_Nowitzki_,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/jaoz8w/lstm_in_python_generating_a_flat_forrcast/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jaoz8w/lstm_in_python_generating_a_flat_forrcast/,22217,1602631326.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
664,,tensorflow,"In tensorflow 2.x version, we don't need session to calculate the graph.

Now I have a tensor x, how could I print the tensor values?

Most of the solutions I found online is about keras, but that's not what I need. 

Thank you!",t2_11cquw,False,,0,False,How to print tensor values in tensorflow 2.x version?,[],r/tensorflow,False,6,,0,,,False,t3_jash61,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1602672949.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In tensorflow 2.x version, we don&amp;#39;t need session to calculate the graph.&lt;/p&gt;

&lt;p&gt;Now I have a tensor x, how could I print the tensor values?&lt;/p&gt;

&lt;p&gt;Most of the solutions I found online is about keras, but that&amp;#39;s not what I need. &lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jash61,True,,Laurence-Lin,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jash61/how_to_print_tensor_values_in_tensorflow_2x/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jash61/how_to_print_tensor_values_in_tensorflow_2x/,22217,1602644149.0,0,,False,,,,,,,,,
665,,tensorflow,,t2_7t6vk108,False,,0,False,Devfest talks about ML with TF and Android 11,[],r/tensorflow,False,6,,0,78.0,,False,t3_jav76s,False,dark,0.6,,public,1,0,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Last year I applied at 1 &lt;a href=""https://twitter.com/hashtag/DevFest?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest&lt;/a&gt; and got rejected and I have made progress, this year I will be speaking at 5 &lt;a href=""https://twitter.com/hashtag/DevFest2020?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest2020&lt;/a&gt; about &lt;a href=""https://twitter.com/TensorFlow?ref_src=twsrc%5Etfw""&gt;@TensorFlow&lt;/a&gt;  , &lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; , and &lt;a href=""https://twitter.com/AndroidDev?ref_src=twsrc%5Etfw""&gt;@AndroidDev&lt;/a&gt; ! Join me at these events&lt;a href=""https://twitter.com/gdg?ref_src=twsrc%5Etfw""&gt;@gdg&lt;/a&gt; &lt;a href=""https://twitter.com/googledevs?ref_src=twsrc%5Etfw""&gt;@googledevs&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleDevsIN?ref_src=twsrc%5Etfw""&gt;@GoogleDevsIN&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleIndia?ref_src=twsrc%5Etfw""&gt;@GoogleIndia&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/AndroidDev?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#AndroidDev&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/ML?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#ML&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/community?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#community&lt;/a&gt; &lt;a href=""https://t.co/eKv7wUYcy1""&gt;pic.twitter.com/eKv7wUYcy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli #DevFest (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1316230949500190720?ref_src=twsrc%5Etfw""&gt;October 14, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'height': 474}",140.0,,False,[],"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/rishit_dagli/status/1316230949500190720', 'author_name': 'Rishit Dagli #DevFest', 'height': 474, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Last year I applied at 1 &lt;a href=""https://twitter.com/hashtag/DevFest?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest&lt;/a&gt; and got rejected and I have made progress, this year I will be speaking at 5 &lt;a href=""https://twitter.com/hashtag/DevFest2020?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest2020&lt;/a&gt; about &lt;a href=""https://twitter.com/TensorFlow?ref_src=twsrc%5Etfw""&gt;@TensorFlow&lt;/a&gt;  , &lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; , and &lt;a href=""https://twitter.com/AndroidDev?ref_src=twsrc%5Etfw""&gt;@AndroidDev&lt;/a&gt; ! Join me at these events&lt;a href=""https://twitter.com/gdg?ref_src=twsrc%5Etfw""&gt;@gdg&lt;/a&gt; &lt;a href=""https://twitter.com/googledevs?ref_src=twsrc%5Etfw""&gt;@googledevs&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleDevsIN?ref_src=twsrc%5Etfw""&gt;@GoogleDevsIN&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleIndia?ref_src=twsrc%5Etfw""&gt;@GoogleIndia&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/AndroidDev?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#AndroidDev&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/ML?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#ML&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/community?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#community&lt;/a&gt; &lt;a href=""https://t.co/eKv7wUYcy1""&gt;pic.twitter.com/eKv7wUYcy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli #DevFest (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1316230949500190720?ref_src=twsrc%5Etfw""&gt;October 14, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/rishit_dagli', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,False,,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Last year I applied at 1 &lt;a href=""https://twitter.com/hashtag/DevFest?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest&lt;/a&gt; and got rejected and I have made progress, this year I will be speaking at 5 &lt;a href=""https://twitter.com/hashtag/DevFest2020?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest2020&lt;/a&gt; about &lt;a href=""https://twitter.com/TensorFlow?ref_src=twsrc%5Etfw""&gt;@TensorFlow&lt;/a&gt;  , &lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; , and &lt;a href=""https://twitter.com/AndroidDev?ref_src=twsrc%5Etfw""&gt;@AndroidDev&lt;/a&gt; ! Join me at these events&lt;a href=""https://twitter.com/gdg?ref_src=twsrc%5Etfw""&gt;@gdg&lt;/a&gt; &lt;a href=""https://twitter.com/googledevs?ref_src=twsrc%5Etfw""&gt;@googledevs&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleDevsIN?ref_src=twsrc%5Etfw""&gt;@GoogleDevsIN&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleIndia?ref_src=twsrc%5Etfw""&gt;@GoogleIndia&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/AndroidDev?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#AndroidDev&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/ML?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#ML&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/community?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#community&lt;/a&gt; &lt;a href=""https://t.co/eKv7wUYcy1""&gt;pic.twitter.com/eKv7wUYcy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli #DevFest (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1316230949500190720?ref_src=twsrc%5Etfw""&gt;October 14, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/jav76s', 'height': 474}",,False,1,,False,https://b.thumbs.redditmedia.com/TZk-tlAk4TVpVDsPTfXmd-aAzwRnvZixIBg56HOt9kA.jpg,False,,[],{},,False,,1602684485.0,text,6,,,text,twitter.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jav76s,True,,Rishit-dagli,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/jav76s/devfest_talks_about_ml_with_tf_and_android_11/,all_ads,False,https://twitter.com/rishit_dagli/status/1316230949500190720?s=20,22217,1602655685.0,0,"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/rishit_dagli/status/1316230949500190720', 'author_name': 'Rishit Dagli #DevFest', 'height': 474, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Last year I applied at 1 &lt;a href=""https://twitter.com/hashtag/DevFest?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest&lt;/a&gt; and got rejected and I have made progress, this year I will be speaking at 5 &lt;a href=""https://twitter.com/hashtag/DevFest2020?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#DevFest2020&lt;/a&gt; about &lt;a href=""https://twitter.com/TensorFlow?ref_src=twsrc%5Etfw""&gt;@TensorFlow&lt;/a&gt;  , &lt;a href=""https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#MachineLearning&lt;/a&gt; , and &lt;a href=""https://twitter.com/AndroidDev?ref_src=twsrc%5Etfw""&gt;@AndroidDev&lt;/a&gt; ! Join me at these events&lt;a href=""https://twitter.com/gdg?ref_src=twsrc%5Etfw""&gt;@gdg&lt;/a&gt; &lt;a href=""https://twitter.com/googledevs?ref_src=twsrc%5Etfw""&gt;@googledevs&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleDevsIN?ref_src=twsrc%5Etfw""&gt;@GoogleDevsIN&lt;/a&gt; &lt;a href=""https://twitter.com/GoogleIndia?ref_src=twsrc%5Etfw""&gt;@GoogleIndia&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/AndroidDev?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#AndroidDev&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/ML?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#ML&lt;/a&gt; &lt;a href=""https://twitter.com/hashtag/community?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#community&lt;/a&gt; &lt;a href=""https://t.co/eKv7wUYcy1""&gt;pic.twitter.com/eKv7wUYcy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rishit Dagli #DevFest (@rishit_dagli) &lt;a href=""https://twitter.com/rishit_dagli/status/1316230949500190720?ref_src=twsrc%5Etfw""&gt;October 14, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/rishit_dagli', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,link,https://twitter.com/rishit_dagli/status/1316230949500190720?s=20,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ElRaK-2FJCEwH1HoQovqMMiiEN-Q6jzRlRDeBuv3mQE.jpg?auto=webp&amp;s=fb21ff23d2a031e345ab6b5882e770a6b7a88ad4', 'width': 140, 'height': 78}, 'resolutions': [{'url': 'https://external-preview.redd.it/ElRaK-2FJCEwH1HoQovqMMiiEN-Q6jzRlRDeBuv3mQE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b90cac93465172954a593763fe6da9bdf7e5221', 'width': 108, 'height': 60}], 'variants': {}, 'id': 'AYQRTKDH4CxoQt3cDm3dqzPg_TJ9RnLS6U1pn6Xmov4'}], 'enabled': False}",,,,,,
666,,tensorflow,"Hi all.
I have been tasked to benchmark virtualized gpu against physical gpus on the servers. I was wondering if anybody has experience with this and could guide me how to do it. For now, I just have couple of sample models and matrix calculation to test, but I am looking for something more professional.",t2_6lquq1dr,False,,0,False,Virtual GPU Test,[],r/tensorflow,False,6,,0,,,False,t3_jamfoi,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1602651870.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all.
I have been tasked to benchmark virtualized gpu against physical gpus on the servers. I was wondering if anybody has experience with this and could guide me how to do it. For now, I just have couple of sample models and matrix calculation to test, but I am looking for something more professional.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,jamfoi,True,,mk1817,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/jamfoi/virtual_gpu_test/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jamfoi/virtual_gpu_test/,22217,1602623070.0,0,,False,,,,,,,,,
667,,tensorflow,"I’m currently pursuing a project where I’d like to retrain a YOLO model with a small dataset of cloud images that I’ve been collecting.  Then convert this model to tf.lite and port to unity or just write a swift app to get it onto the iPhone.  

So far from googling I’ve seen there are pre-trained models in Keras.  
I’m also planning on using labellmg to label the cloud images I’ve been collecting by size and class type. 

I am a beginner and have been taking the deep learning specialization on coursera.  I realize nothing compares to setting out on my own into the wild wild web to figure this out. That being said as I leave the artificial confines of coursera, I can’t help but feel a bit stuck.  Google searches haven’t yielded a tutorial of what I’m looking to do in TF or Keras. 

Any help or pointers would be greatly appreciated!

(I would like to stick to solutions in TF, Keras, and Tf.lite as I do not know C at all to play with dark net)",t2_145xhy,False,,0,False,Transfer Learning a YOLO pre-trained model on a custom dataset,[],r/tensorflow,False,6,,0,,,False,t3_jar9lr,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1602639997.0,,[],{},,True,,1602668419.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m currently pursuing a project where I’d like to retrain a YOLO model with a small dataset of cloud images that I’ve been collecting.  Then convert this model to tf.lite and port to unity or just write a swift app to get it onto the iPhone.  &lt;/p&gt;

&lt;p&gt;So far from googling I’ve seen there are pre-trained models in Keras.&lt;br/&gt;
I’m also planning on using labellmg to label the cloud images I’ve been collecting by size and class type. &lt;/p&gt;

&lt;p&gt;I am a beginner and have been taking the deep learning specialization on coursera.  I realize nothing compares to setting out on my own into the wild wild web to figure this out. That being said as I leave the artificial confines of coursera, I can’t help but feel a bit stuck.  Google searches haven’t yielded a tutorial of what I’m looking to do in TF or Keras. &lt;/p&gt;

&lt;p&gt;Any help or pointers would be greatly appreciated!&lt;/p&gt;

&lt;p&gt;(I would like to stick to solutions in TF, Keras, and Tf.lite as I do not know C at all to play with dark net)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jar9lr,True,,Odin08,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jar9lr/transfer_learning_a_yolo_pretrained_model_on_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jar9lr/transfer_learning_a_yolo_pretrained_model_on_a/,22217,1602639619.0,0,,False,,,,,,,,,
668,,tensorflow,"I have a two class model with a softmax activation in the final layer...

The model, instantiated as a `tf.keras.Model` object, yields outputs in the expected range `[0,1]`:
    
    In [4]: model.predict(img[np.newaxis, ...])
    Out[4]: array([[0.0577133, 0.9422867]], dtype=float32)

The quantized edgetpu model yields outputs in some other range that I can't determine...

I'm trying to convert these scaled outputs back into a range that can be interpreted as a probability distribution using a function like this:

    def unscale(quantized_output, n):
        old_min, old_max = -n, n
        new_min, new_max = 0, 1
        return [((x - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min for x in quantized_output]


After recording min/max values for a while I see these are the extremes `[-1.5623251 1.3998433]` hence hardcoding the `old_min`/ `old_max` values as `-1.6` and `1.6`, but this is just a guess...

How do I determine the true min and max output values of the quantized model?",t2_mwqf3,False,,0,False,How to determine min/max range of edgetpu model's output?,[],r/tensorflow,False,6,,0,,,False,t3_jan7t4,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1602709800.0,,[],{},,True,,1602654250.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a two class model with a softmax activation in the final layer...&lt;/p&gt;

&lt;p&gt;The model, instantiated as a &lt;code&gt;tf.keras.Model&lt;/code&gt; object, yields outputs in the expected range &lt;code&gt;[0,1]&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In [4]: model.predict(img[np.newaxis, ...])
Out[4]: array([[0.0577133, 0.9422867]], dtype=float32)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The quantized edgetpu model yields outputs in some other range that I can&amp;#39;t determine...&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to convert these scaled outputs back into a range that can be interpreted as a probability distribution using a function like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def unscale(quantized_output, n):
    old_min, old_max = -n, n
    new_min, new_max = 0, 1
    return [((x - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min for x in quantized_output]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After recording min/max values for a while I see these are the extremes &lt;code&gt;[-1.5623251 1.3998433]&lt;/code&gt; hence hardcoding the &lt;code&gt;old_min&lt;/code&gt;/ &lt;code&gt;old_max&lt;/code&gt; values as &lt;code&gt;-1.6&lt;/code&gt; and &lt;code&gt;1.6&lt;/code&gt;, but this is just a guess...&lt;/p&gt;

&lt;p&gt;How do I determine the true min and max output values of the quantized model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jan7t4,True,,bit_by_byte,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/jan7t4/how_to_determine_minmax_range_of_edgetpu_models/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jan7t4/how_to_determine_minmax_range_of_edgetpu_models/,22217,1602625450.0,4,,False,,,,,,,,,
669,,tensorflow,"Like, do I place it under the tensorflow package or the Python package or what?",t2_4760f5hy,False,,0,False,What package am I supposed to put the msvcp140_1.dll file?,[],r/tensorflow,False,6,,0,,,False,t3_jaj9yk,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1602642418.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Like, do I place it under the tensorflow package or the Python package or what?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,jaj9yk,True,,ARNisUsername,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/jaj9yk/what_package_am_i_supposed_to_put_the_msvcp140/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/jaj9yk/what_package_am_i_supposed_to_put_the_msvcp140/,22217,1602613618.0,0,,False,,,,,,,,,
670,,tensorflow,I've downloaded the latest version of CUDA 11.1 and I was wondering if Tensorflow supports this version or it requires version 10.1?,t2_2nwqlqha,False,,0,False,Does Tensorflow support CUDA 11.1,[],r/tensorflow,False,6,,0,,,False,t3_j9wzy1,False,dark,0.84,,public,8,0,{},,,False,[],,False,False,,{},,False,8,,False,self,False,,[],{},,True,,1602557626.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve downloaded the latest version of CUDA 11.1 and I was wondering if Tensorflow supports this version or it requires version 10.1?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j9wzy1,True,,amirrezafahimi98,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/j9wzy1/does_tensorflow_support_cuda_111/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9wzy1/does_tensorflow_support_cuda_111/,22217,1602528826.0,0,,False,,,,,,,,,
671,,tensorflow,"Forgive me if this is not the right subreddit.

I'm noobie to tensorflow and AI in general but almost 6 years of software development experience. I want to prepare for the tensorflow exam. What's your experience on preparing, any advice (even tensorflow is not good at this stage) is much appreciated.",t2_54r3x8li,False,,0,False,Anyone passed the tensorflow exam? What's your experience,[],r/tensorflow,False,6,,0,,,False,t3_j9tevr,False,dark,0.86,,public,10,0,{},,,False,[],,False,False,,{},Question,False,10,,False,self,1602536975.0,,[],{},,True,,1602546728.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Forgive me if this is not the right subreddit.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m noobie to tensorflow and AI in general but almost 6 years of software development experience. I want to prepare for the tensorflow exam. What&amp;#39;s your experience on preparing, any advice (even tensorflow is not good at this stage) is much appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j9tevr,True,,Newhabesha,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/j9tevr/anyone_passed_the_tensorflow_exam_whats_your/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9tevr/anyone_passed_the_tensorflow_exam_whats_your/,22217,1602517928.0,0,,False,,,,,,,,,
672,,tensorflow,"**TL;DR:** TF exam broke to where I couldn't even see/work on questions, haven't heard back from support

&amp;#x200B;

So yesterday I started my exam with pycharm set up and ready to go per the guide. After installing packages and setting up the environment, a window popped up saying ""Sign in via the opened browser."" Nothing popped up on the browser, and I was signed in to my google account. I tried signing in and out, closing and reopening both Chrome and Edges, and nothing. I couldn't click anywhere in pycharm other than the cancel button which did nothing for 20 min. I had to kill the process and try again. That got rid of the ""Sign in via..."" window, but when I clicked on the exam button in the top right, it told me time was ticking down. There was no exam in sight, and when I clicked on the ""view instructions"" all the links didn't do anything. I couldn't do anything and the support team (at  [tensorflow-certificate-team@google.com](mailto:tensorflow-certificate-team@google.com)) didn't respond to my emails. 

&amp;#x200B;

&amp;#x200B;

Has anyone heard of this issue? I tried googling it and came up dry. Does anyone have experience with the support team? Will they be understanding whenever they get back to me?",t2_7my6r,False,,0,False,"TF Exam broke, now what? Has customer service been helpful?",[],r/tensorflow,False,6,,0,,,False,t3_j9vtn1,False,dark,0.9,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1602554108.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; TF exam broke to where I couldn&amp;#39;t even see/work on questions, haven&amp;#39;t heard back from support&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;So yesterday I started my exam with pycharm set up and ready to go per the guide. After installing packages and setting up the environment, a window popped up saying &amp;quot;Sign in via the opened browser.&amp;quot; Nothing popped up on the browser, and I was signed in to my google account. I tried signing in and out, closing and reopening both Chrome and Edges, and nothing. I couldn&amp;#39;t click anywhere in pycharm other than the cancel button which did nothing for 20 min. I had to kill the process and try again. That got rid of the &amp;quot;Sign in via...&amp;quot; window, but when I clicked on the exam button in the top right, it told me time was ticking down. There was no exam in sight, and when I clicked on the &amp;quot;view instructions&amp;quot; all the links didn&amp;#39;t do anything. I couldn&amp;#39;t do anything and the support team (at  [&lt;a href=""mailto:tensorflow-certificate-team@google.com""&gt;tensorflow-certificate-team@google.com&lt;/a&gt;](mailto:&lt;a href=""mailto:tensorflow-certificate-team@google.com""&gt;tensorflow-certificate-team@google.com&lt;/a&gt;)) didn&amp;#39;t respond to my emails. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Has anyone heard of this issue? I tried googling it and came up dry. Does anyone have experience with the support team? Will they be understanding whenever they get back to me?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j9vtn1,True,,izath46,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j9vtn1/tf_exam_broke_now_what_has_customer_service_been/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9vtn1/tf_exam_broke_now_what_has_customer_service_been/,22217,1602525308.0,0,,False,,,,,,,,,
673,,tensorflow,"Hello community , I 'm working on MAF , and have some questions about it , I didn't find the documentation  very clear.

My question is about the way of adding Mask Autoregressive Flow to VAE",t2_7l9ti89m,False,,0,False,How already worked with Masked Autoregressive Flow ?,[],r/tensorflow,False,6,,0,,,False,t3_j9yt2m,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,1602539463.0,,[],{},,True,,1602563152.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community , I &amp;#39;m working on MAF , and have some questions about it , I didn&amp;#39;t find the documentation  very clear.&lt;/p&gt;

&lt;p&gt;My question is about the way of adding Mask Autoregressive Flow to VAE&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j9yt2m,True,,rayanaay,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j9yt2m/how_already_worked_with_masked_autoregressive_flow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9yt2m/how_already_worked_with_masked_autoregressive_flow/,22217,1602534352.0,0,,False,,,,,,,,,
674,,tensorflow,"Neural Structured Learning (NSL) is a TensorFlow framework for training neural networks with structured signals. NSL can handle structured input in two ways: 

(i) As an explicit graph (for [Neural Graph Learning](https://arxiv.org/abs/1703.04818))

(ii) As an implicit graph (for [Adversarial Learning](https://arxiv.org/abs/1412.6572))

These techniques only affect the training workflow while the model serving workflow remains unchanged. This occurs due to these techniques being implemented as a form of regularization in the framework. 

Github: [https://github.com/tensorflow/neural-structured-learning](https://github.com/tensorflow/neural-structured-learning) 

Summary: [https://www.marktechpost.com/2020/10/12/neural-structured-learning-nsl-a-tensorflow-framework-to-train-neural-networks-with-structured-signals/](https://www.marktechpost.com/2020/10/12/neural-structured-learning-nsl-a-tensorflow-framework-to-train-neural-networks-with-structured-signals/)

&amp;#x200B;

https://preview.redd.it/hzcf0jtfkos51.png?width=2330&amp;format=png&amp;auto=webp&amp;s=05da1740ec499e6aa8c947ccd6f78c2dfa6c4099",t2_2wsvqwhg,False,,0,False,Neural Structured Learning (NSL): A TensorFlow Framework To Train Neural Networks With Structured Signals,[],r/tensorflow,False,6,,0,56.0,,False,t3_j9spdb,False,dark,0.91,,public,8,0,{},140.0,,False,[],,False,False,,{},Discussion,False,8,,False,https://b.thumbs.redditmedia.com/7N5JDQcObUeGWbY46aF17Cul49IpQbPMb7vnP3QDm8o.jpg,False,,[],{},,True,,1602544508.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Neural Structured Learning (NSL) is a TensorFlow framework for training neural networks with structured signals. NSL can handle structured input in two ways: &lt;/p&gt;

&lt;p&gt;(i) As an explicit graph (for &lt;a href=""https://arxiv.org/abs/1703.04818""&gt;Neural Graph Learning&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;(ii) As an implicit graph (for &lt;a href=""https://arxiv.org/abs/1412.6572""&gt;Adversarial Learning&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;These techniques only affect the training workflow while the model serving workflow remains unchanged. This occurs due to these techniques being implemented as a form of regularization in the framework. &lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/tensorflow/neural-structured-learning""&gt;https://github.com/tensorflow/neural-structured-learning&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/10/12/neural-structured-learning-nsl-a-tensorflow-framework-to-train-neural-networks-with-structured-signals/""&gt;https://www.marktechpost.com/2020/10/12/neural-structured-learning-nsl-a-tensorflow-framework-to-train-neural-networks-with-structured-signals/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/hzcf0jtfkos51.png?width=2330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=05da1740ec499e6aa8c947ccd6f78c2dfa6c4099""&gt;https://preview.redd.it/hzcf0jtfkos51.png?width=2330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=05da1740ec499e6aa8c947ccd6f78c2dfa6c4099&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j9spdb,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j9spdb/neural_structured_learning_nsl_a_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9spdb/neural_structured_learning_nsl_a_tensorflow/,22217,1602515708.0,0,,False,,,,,"{'hzcf0jtfkos51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 43, 'x': 108, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1a28ef0b0d2a67ef14c7505d9a338badb6e2fde8'}, {'y': 86, 'x': 216, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=09472a6725bccdc990cde8aeb244645c9e6cbee6'}, {'y': 128, 'x': 320, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=50319a544d614e394f6918b8c7cd76017ff49cba'}, {'y': 257, 'x': 640, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=54bc9fe031462d7d1f89c4c8f0743816077d683f'}, {'y': 385, 'x': 960, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=21b26c4b0ed70055211ea778b8569aff41049579'}, {'y': 433, 'x': 1080, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=03a0f31f118ffbe788227162381079447b9bdaf8'}], 's': {'y': 936, 'x': 2330, 'u': 'https://preview.redd.it/hzcf0jtfkos51.png?width=2330&amp;format=png&amp;auto=webp&amp;s=05da1740ec499e6aa8c947ccd6f78c2dfa6c4099'}, 'id': 'hzcf0jtfkos51'}}",,,,
675,,tensorflow,,t2_7t6vk108,False,,0,False,"First, alpha release of TensorFlow Java!",[],r/tensorflow,False,6,,0,140.0,,False,t3_j9k4ow,False,dark,0.79,,public,21,0,{},140.0,,False,[],,False,False,,{},,False,21,,False,https://b.thumbs.redditmedia.com/4MT1eeJnkesGnbo7O6XqXRBQC8DQgN8MGze-XN3V-TI.jpg,False,,[],{},,False,,1602505023.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j9k4ow,True,,Rishit-dagli,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j9k4ow/first_alpha_release_of_tensorflow_java/,all_ads,False,https://github.com/tensorflow/java/releases/tag/v0.2.0,22217,1602476223.0,0,,False,link,https://github.com/tensorflow/java/releases/tag/v0.2.0,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
676,,tensorflow,"In my new video, I introduce fundamental frequency-domain audio features, such as Band Energy Ratio, Spectral Centroid, and Spectral Spread. I explain the intuition and the math behind these acoustic features, and mention a few sample applications.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=3-bjAoAxQ9o&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=21](https://www.youtube.com/watch?v=3-bjAoAxQ9o&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=21)",t2_12ahau,False,,0,False,I published a video explaining frequency-domain audio features for machine learning,[],r/tensorflow,False,6,,0,,,False,t3_j9pevj,False,dark,0.87,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1602532059.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new video, I introduce fundamental frequency-domain audio features, such as Band Energy Ratio, Spectral Centroid, and Spectral Spread. I explain the intuition and the math behind these acoustic features, and mention a few sample applications.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=3-bjAoAxQ9o&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=21""&gt;https://www.youtube.com/watch?v=3-bjAoAxQ9o&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=21&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j9pevj,True,,diabulusInMusica,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j9pevj/i_published_a_video_explaining_frequencydomain/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9pevj/i_published_a_video_explaining_frequencydomain/,22217,1602503259.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yrXR3Cgco9tlw-HH4RHAP4lhY_tobHa_fXIVrWqu924.jpg?auto=webp&amp;s=ccd03dd04cd787ed74df59b5986b82d9f91302c1', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/yrXR3Cgco9tlw-HH4RHAP4lhY_tobHa_fXIVrWqu924.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=48b27faae92c789ecf5e65c59b5846741a59794e', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/yrXR3Cgco9tlw-HH4RHAP4lhY_tobHa_fXIVrWqu924.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ec596b575a65b017c0fbebec6ce6ad7a7b45fac', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/yrXR3Cgco9tlw-HH4RHAP4lhY_tobHa_fXIVrWqu924.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=58430198ed4f2651597f819b9253705575808618', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'BYVpur9FnWsVUqIgdyLU7Z6x2kcGKbq1jai1M58OcEw'}], 'enabled': False}",,,,,,
677,,tensorflow,"Last night, I almost hit the ""Start Exam"" button! Then a thought came up in my head: what if they enforce a specific version of TF2.xx??


Given my hardware specs, the latest I can have on my machine is TF2.2 and I read on Reddit [a statement](https://www.reddit.com/r/tensorflow/comments/itsfkx/tensorflow_software_version_for_certification_exam/g5n75pr/) (from the author of the exam @Laurence_Moroney) that TF2.0 is the version to be used in the exam... 


Unfortunately, I can't get TF2.0 to use GPU on my local machine, and the only solution on the internet for my case is to upgrade the TF version!! which is against the reason I downgraded to TF2.0 (or tried to!).

Long story short, now I plan to use the *""free version""* of **Google Colabs**, will it be enough? Does it take a reasonable time to train models during the exam, using Google Colab?
I am concerned that I might get cut off of resources if I use GPU runtime for hours!


Is it safer to pay for the  **Google Colab Pro**, or there is no need to?",t2_gvt73wh,False,,0,False,Can I pass the Tensorflow Developer exam with using just Google Colab? What about the Colab Pro?,[],r/tensorflow,False,6,,0,,,False,t3_j9kxhf,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1602482557.0,,[],{},,True,,1602508659.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Last night, I almost hit the &amp;quot;Start Exam&amp;quot; button! Then a thought came up in my head: what if they enforce a specific version of TF2.xx??&lt;/p&gt;

&lt;p&gt;Given my hardware specs, the latest I can have on my machine is TF2.2 and I read on Reddit &lt;a href=""https://www.reddit.com/r/tensorflow/comments/itsfkx/tensorflow_software_version_for_certification_exam/g5n75pr/""&gt;a statement&lt;/a&gt; (from the author of the exam @Laurence_Moroney) that TF2.0 is the version to be used in the exam... &lt;/p&gt;

&lt;p&gt;Unfortunately, I can&amp;#39;t get TF2.0 to use GPU on my local machine, and the only solution on the internet for my case is to upgrade the TF version!! which is against the reason I downgraded to TF2.0 (or tried to!).&lt;/p&gt;

&lt;p&gt;Long story short, now I plan to use the &lt;em&gt;&amp;quot;free version&amp;quot;&lt;/em&gt; of &lt;strong&gt;Google Colabs&lt;/strong&gt;, will it be enough? Does it take a reasonable time to train models during the exam, using Google Colab?
I am concerned that I might get cut off of resources if I use GPU runtime for hours!&lt;/p&gt;

&lt;p&gt;Is it safer to pay for the  &lt;strong&gt;Google Colab Pro&lt;/strong&gt;, or there is no need to?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j9kxhf,True,,salouri,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/j9kxhf/can_i_pass_the_tensorflow_developer_exam_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9kxhf/can_i_pass_the_tensorflow_developer_exam_with/,22217,1602479859.0,0,,False,,,,,,,,,
678,,tensorflow," 

hello,

I have about 500 networkx graphs and I wanted to perform graph classification on them into 2 classes.

This is how a node looks like.

`{0: {'id': tensor(144), 'residue_name': tensor(8), 'h': tensor([0.0000, 0.0000, 0.0000, 0.0000, 6.0700, 0.1300, 0.1500]), 'coords': tensor([-21.1550, 23.3610, 1.9100]), 'ss': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.]), 'asa': tensor([10752.]), 'rsa': tensor([128.])}`

This is how an edge looks like.

`(0, 2, {'id': 322, 'rel_type': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64), 'norm': tensor(1.)})`

If i try to use stellar graphs, it throws an error that it only accepts numeric features and i am not able to use DGL as none of their examples show to load our own dataset.

How do I use my data with these libraries or are there any other libraries I can use?",t2_2feck1ws,False,,0,False,Graph Classification,[],r/tensorflow,False,6,,0,,,False,t3_j9m3il,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1602514628.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hello,&lt;/p&gt;

&lt;p&gt;I have about 500 networkx graphs and I wanted to perform graph classification on them into 2 classes.&lt;/p&gt;

&lt;p&gt;This is how a node looks like.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;{0: {&amp;#39;id&amp;#39;: tensor(144), &amp;#39;residue_name&amp;#39;: tensor(8), &amp;#39;h&amp;#39;: tensor([0.0000, 0.0000, 0.0000, 0.0000, 6.0700, 0.1300, 0.1500]), &amp;#39;coords&amp;#39;: tensor([-21.1550, 23.3610, 1.9100]), &amp;#39;ss&amp;#39;: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.]), &amp;#39;asa&amp;#39;: tensor([10752.]), &amp;#39;rsa&amp;#39;: tensor([128.])}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is how an edge looks like.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;(0, 2, {&amp;#39;id&amp;#39;: 322, &amp;#39;rel_type&amp;#39;: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64), &amp;#39;norm&amp;#39;: tensor(1.)})&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If i try to use stellar graphs, it throws an error that it only accepts numeric features and i am not able to use DGL as none of their examples show to load our own dataset.&lt;/p&gt;

&lt;p&gt;How do I use my data with these libraries or are there any other libraries I can use?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j9m3il,True,,ybkhan,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j9m3il/graph_classification/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9m3il/graph_classification/,22217,1602485828.0,0,,False,,,,,,,,,
679,,tensorflow,,t2_jo9b4,False,,0,False,Learn the basics of Tensorflow Extended in ~ 45 minutes ( mini video course ),[],r/tensorflow,False,6,,0,105.0,,False,t3_j93kgg,False,dark,1.0,,public,28,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/videoseries?list=PL1v7L5pwiJuNs0pugCNpnH_f_20vBR0SJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tensorflow Extended - Explained: Introduction', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/videoseries?list=PL1v7L5pwiJuNs0pugCNpnH_f_20vBR0SJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Theodoros Ntakouris', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Tu2n94WiMYY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCD7zSKJcfjn9hoLndOUeugg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/videoseries?list=PL1v7L5pwiJuNs0pugCNpnH_f_20vBR0SJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j93kgg', 'height': 338}",,False,28,,False,https://b.thumbs.redditmedia.com/V3ArUgmh7t0qMKLZ9N0h4U4_lvTi4mh24yblOAxGC1c.jpg,False,,[],{},,False,,1602443204.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j93kgg,True,,Zarkopafilis,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j93kgg/learn_the_basics_of_tensorflow_extended_in_45/,all_ads,False,https://www.youtube.com/watch?v=Tu2n94WiMYY&amp;list=PL1v7L5pwiJuNs0pugCNpnH_f_20vBR0SJ,22217,1602414404.0,1,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tensorflow Extended - Explained: Introduction', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/videoseries?list=PL1v7L5pwiJuNs0pugCNpnH_f_20vBR0SJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Theodoros Ntakouris', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Tu2n94WiMYY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCD7zSKJcfjn9hoLndOUeugg'}}",False,rich:video,https://www.youtube.com/watch?v=Tu2n94WiMYY&amp;list=PL1v7L5pwiJuNs0pugCNpnH_f_20vBR0SJ,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Q07003yvCMPDEoHfdfbijlwRLJMGz941jsPIBuxfQf0.jpg?auto=webp&amp;s=7a5908d73e9ccabf6743509a3dea69d1929f88ce', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/Q07003yvCMPDEoHfdfbijlwRLJMGz941jsPIBuxfQf0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=03d65d24a9f9ead29f753213d553b8355909ce5f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/Q07003yvCMPDEoHfdfbijlwRLJMGz941jsPIBuxfQf0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c645512e740b5c68235ee720eb2d0ae788efe016', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/Q07003yvCMPDEoHfdfbijlwRLJMGz941jsPIBuxfQf0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fb747432d567f86cf76ff6746c475552c961bf6f', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'u9_BRB5Al0J-R-NDeulmzFHjim6-7FXMUhtx1iYFr-A'}], 'enabled': False}",,,,,,
680,,tensorflow,"I've read that the ampere series cards need Cuda 11.1 to work, while big projects like stylegan2 need tensorflow 1.14 with cuda 10.0. Does this mean it is not possible to run models like stylegan2 on rtx 30xx cards?",t2_b73fzq8,False,,0,False,Rtx 30xx compatibility tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_j9414d,False,dark,1.0,,public,11,0,{},,,False,[],,False,False,,{},,False,11,,False,self,False,,[],{},,True,,1602445609.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve read that the ampere series cards need Cuda 11.1 to work, while big projects like stylegan2 need tensorflow 1.14 with cuda 10.0. Does this mean it is not possible to run models like stylegan2 on rtx 30xx cards?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j9414d,True,,Stories_in_the_Stars,,17,True,all_ads,False,[],False,,/r/tensorflow/comments/j9414d/rtx_30xx_compatibility_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j9414d/rtx_30xx_compatibility_tensorflow/,22217,1602416809.0,0,,False,,,,,,,,,
681,,tensorflow,I want to get a copy of the convereted model (.tflite file) in my mobile application and save it in another location when user performs a specific task in my mobile app. Is there ay way to do that? I know that .tflite files are not compressed but dont know how to get a copy of that while using the mobile application,t2_16rnekap,False,,0,False,Copy .tflite file to another location while using the mobile application,[],r/tensorflow,False,6,,0,,,False,t3_j922ve,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1602435446.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to get a copy of the convereted model (.tflite file) in my mobile application and save it in another location when user performs a specific task in my mobile app. Is there ay way to do that? I know that .tflite files are not compressed but dont know how to get a copy of that while using the mobile application&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j922ve,True,,The_Aoki_Taki,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/j922ve/copy_tflite_file_to_another_location_while_using/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j922ve/copy_tflite_file_to_another_location_while_using/,22217,1602406646.0,0,,False,,,,,,,,,
682,,tensorflow,"1. I've seen multiple posts where they use the tfds library for loading the dataset . I just want to know if this is mandatory or can i even use keras.datasets (in case the question is related to the dataset) ? 
2. Are there any minimum requirements to meet when training the model  ? (maybe something like : train a model to achieve val\_acc of 99.4% etc)
3. Apparently you dont have to type everything from scratch but rather just fill in some parts of the program during the exam , can I write whatever I want and  change the names of variables to what i want or will that mess with the backend of the plugin ?

I've finished the specialization course on coursera and practiced fairly well apart from course exercises but im still slightly doubtful about it",t2_16kcfa,False,,0,False,I'm about to take the tensorflow dev exam ... I want to know some more details about it which i cant seem to find it on the web,[],r/tensorflow,False,6,,0,,,False,t3_j92ahm,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1602436504.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;ol&gt;
&lt;li&gt;I&amp;#39;ve seen multiple posts where they use the tfds library for loading the dataset . I just want to know if this is mandatory or can i even use keras.datasets (in case the question is related to the dataset) ? &lt;/li&gt;
&lt;li&gt;Are there any minimum requirements to meet when training the model  ? (maybe something like : train a model to achieve val_acc of 99.4% etc)&lt;/li&gt;
&lt;li&gt;Apparently you dont have to type everything from scratch but rather just fill in some parts of the program during the exam , can I write whatever I want and  change the names of variables to what i want or will that mess with the backend of the plugin ?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;#39;ve finished the specialization course on coursera and practiced fairly well apart from course exercises but im still slightly doubtful about it&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j92ahm,True,,emphee12,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/j92ahm/im_about_to_take_the_tensorflow_dev_exam_i_want/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j92ahm/im_about_to_take_the_tensorflow_dev_exam_i_want/,22217,1602407704.0,0,,False,,,,,,,,,
683,,tensorflow,"App: [https://web.lab-ml.com](https://web.lab-ml.com/home)

Github: [https://github.com/lab-ml/app](https://github.com/lab-ml/app)

samples: [https://web.lab-ml.com/runs?labml\_token=samples](https://web.lab-ml.com/runs?labml_token=samples)

&amp;#x200B;

https://preview.redd.it/1zx8lugqrfs51.png?width=2880&amp;format=png&amp;auto=webp&amp;s=3a0ec8018609c247b6d0b03b54d211de7a269def",t2_5xy0sou7,False,,0,False,[P] Monitor Keras model training on mobile phones,[],r/tensorflow,False,6,,0,122.0,,False,t3_j92l5y,False,dark,0.86,,public,5,0,{},140.0,,False,[],,False,False,,{},,False,5,,False,https://b.thumbs.redditmedia.com/DkxXLFEtchprCkKP80kKyFyf7w7RSKNb9_HX0Zj9yzg.jpg,False,,[],{},,True,,1602438010.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;App: &lt;a href=""https://web.lab-ml.com/home""&gt;https://web.lab-ml.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/lab-ml/app""&gt;https://github.com/lab-ml/app&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;samples: &lt;a href=""https://web.lab-ml.com/runs?labml_token=samples""&gt;https://web.lab-ml.com/runs?labml_token=samples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/1zx8lugqrfs51.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3a0ec8018609c247b6d0b03b54d211de7a269def""&gt;https://preview.redd.it/1zx8lugqrfs51.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3a0ec8018609c247b6d0b03b54d211de7a269def&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j92l5y,True,,hnipun,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j92l5y/p_monitor_keras_model_training_on_mobile_phones/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j92l5y/p_monitor_keras_model_training_on_mobile_phones/,22217,1602409210.0,0,,False,,,,,"{'1zx8lugqrfs51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 94, 'x': 108, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7d206a10984d5dec68feca66ec26471dea14dd1'}, {'y': 189, 'x': 216, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d91ebd56efaf69a6ca84f63509d3591a27f64905'}, {'y': 280, 'x': 320, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=20927a8eebc7b32eb7a4248ec638b02224a29a1f'}, {'y': 560, 'x': 640, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9a8de71ece4fe1f4518c544593ac7cb9d21a22e'}, {'y': 841, 'x': 960, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=88737a803ebf7280bfaecbf8caf5d528780e807c'}, {'y': 946, 'x': 1080, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4c41c73e02563ca3f6da151cbeca5fbbc79bc220'}], 's': {'y': 2524, 'x': 2880, 'u': 'https://preview.redd.it/1zx8lugqrfs51.png?width=2880&amp;format=png&amp;auto=webp&amp;s=3a0ec8018609c247b6d0b03b54d211de7a269def'}, 'id': '1zx8lugqrfs51'}}",,,,
684,,tensorflow,"I'm new to TensorFlow and I cannot seem to find how to do this despite extensive searching online. I want to use the TensorFlow model I have built in Java to set some Java variable values, which in this case, is a double. Is there a good way of going about this?

Here is the code snippet:

    try(SavedModelBundle b = SavedModelBundle.load(""/somePath"", ""serve"")) {
        Session s = b.session();
        Tensor&lt;TInt32&gt; x = TInt32.scalarOf(1);
        Tensor&lt;TInt32&gt; y = TInt32.scalarOf(2);
    		
        Tensor&lt;TInt32&gt; result =(Tensor&lt;TInt32&gt;) s.runner().feed(""x"", x).feed(""y"", y).fetch(""ans"").run().get(0);
    
        // I know this won't work but do whatever is needed to convert to a double
        this.ExampleDouble = result;
    }",t2_3f1yyxzm,False,,0,False,How do you cast a Tensor&lt;TInt32&gt; in Java to a double and other native Java variable types?,[],r/tensorflow,False,6,,0,,,False,t3_j8oi3q,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1602379743.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m new to TensorFlow and I cannot seem to find how to do this despite extensive searching online. I want to use the TensorFlow model I have built in Java to set some Java variable values, which in this case, is a double. Is there a good way of going about this?&lt;/p&gt;

&lt;p&gt;Here is the code snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;try(SavedModelBundle b = SavedModelBundle.load(&amp;quot;/somePath&amp;quot;, &amp;quot;serve&amp;quot;)) {
    Session s = b.session();
    Tensor&amp;lt;TInt32&amp;gt; x = TInt32.scalarOf(1);
    Tensor&amp;lt;TInt32&amp;gt; y = TInt32.scalarOf(2);

    Tensor&amp;lt;TInt32&amp;gt; result =(Tensor&amp;lt;TInt32&amp;gt;) s.runner().feed(&amp;quot;x&amp;quot;, x).feed(&amp;quot;y&amp;quot;, y).fetch(&amp;quot;ans&amp;quot;).run().get(0);

    // I know this won&amp;#39;t work but do whatever is needed to convert to a double
    this.ExampleDouble = result;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j8oi3q,True,,_SadSupermarket,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j8oi3q/how_do_you_cast_a_tensortint32_in_java_to_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j8oi3q/how_do_you_cast_a_tensortint32_in_java_to_a/,22217,1602350943.0,0,,False,,,,,,,,,
685,,tensorflow,"Hello community , does anyone already add MAF Layer to an existing model ? I'm struggling into implement a solution based on MAF with TF-2.0 . I have a classic variational auto-encoder (VAE) ,and I want to add to it some MAF Layer . I didn't found the documentation very clear sincerely .

Does anyone know something about it ? It would be of a great help for me. Thanks",t2_7l9ti89m,False,,0,False,Masked Atuoregressive Flow (MAF) TF2.0,[],r/tensorflow,False,6,,0,,,False,t3_j8hjdv,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1602350577.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community , does anyone already add MAF Layer to an existing model ? I&amp;#39;m struggling into implement a solution based on MAF with TF-2.0 . I have a classic variational auto-encoder (VAE) ,and I want to add to it some MAF Layer . I didn&amp;#39;t found the documentation very clear sincerely .&lt;/p&gt;

&lt;p&gt;Does anyone know something about it ? It would be of a great help for me. Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j8hjdv,True,,rayanaay,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j8hjdv/masked_atuoregressive_flow_maf_tf20/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j8hjdv/masked_atuoregressive_flow_maf_tf20/,22217,1602321777.0,0,,False,,,,,,,,,
686,,tensorflow,"[riotu-lab](https://github.com/riotu-lab)/[tf2trt\_with\_onnx](https://github.com/riotu-lab/tf2trt_with_onnx) this Github repo has Jupyter notebook documents how to convert a Tensorflow or Keras model to TenosrRT using ONNX. ONNX is the official way to convert TF/Keras model to TRT. 

This is has been tested successfully on Facenet Keras model   
If anyone has a question please ask!",t2_14pplt,False,,0,False,Jupyter Notebook to Convert TF/Keras model to TenosrRT with ONNX,[],r/tensorflow,False,6,,0,,,False,t3_j8ftoi,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1602341045.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/riotu-lab""&gt;riotu-lab&lt;/a&gt;/&lt;a href=""https://github.com/riotu-lab/tf2trt_with_onnx""&gt;tf2trt_with_onnx&lt;/a&gt; this Github repo has Jupyter notebook documents how to convert a Tensorflow or Keras model to TenosrRT using ONNX. ONNX is the official way to convert TF/Keras model to TRT. &lt;/p&gt;

&lt;p&gt;This is has been tested successfully on Facenet Keras model&lt;br/&gt;
If anyone has a question please ask!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j8ftoi,True,,anasmk96,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j8ftoi/jupyter_notebook_to_convert_tfkeras_model_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j8ftoi/jupyter_notebook_to_convert_tfkeras_model_to/,22217,1602312245.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Cei5f42vR3qLjnILeFCx02hOSj34FECIEcV1Tvc65_g.jpg?auto=webp&amp;s=3e86cc78818414dba6ea4815675eb0a7ff6f0597', 'width': 131, 'height': 131}, 'resolutions': [{'url': 'https://external-preview.redd.it/Cei5f42vR3qLjnILeFCx02hOSj34FECIEcV1Tvc65_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=68cfc13b85f7a215047ef876c5bb1a3f9a6ab2ef', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'qzi4QhMEvGbdUCFM6d0ocA2ZJmJJtFG3bXfWO0TMO4o'}], 'enabled': False}",,,,,,
687,,tensorflow,"Hello,

I have no experience with TensorFlow, but I have lots of python experience. I am trying to look for a target board in my images. All images will look very similar to [this](https://i.imgur.com/GnUke1W.jpeg) , where the target board takes up the majority of the image. We can assume that the camera will always be looking directly at the target board from straight ahead, as shown in the image. The board may however roll/rotate +/- 15 degrees.

I tried to follow [TensorFlow 2.0 Object Detection API Tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) but when I went to train my model I was only ever able to get a bounding box that included a lot of the background image, and had a confidence of, at best, 60%. My training images were all cropped images of the board, like [this](https://i.imgur.com/MsAhpkZ.jpg) , and the associated annotation xml file for that image had the target area of the entire image width/height. My test images looked like the first image I linked in this post.

What am I doing wrong? Why does the model, after roughly 3000 steps, fail to detect the board anymore? I cannot find a sweet spot between 2000 (where it was approximately 60%) and 3000 steps that accurately finds the target board.

Lastly, how do I eventually incorporate object rotation into this? I would ideally like to rotate and crop to my target, such that the + is parallel/perpendicular to the X/Y axis.

Thanks.

&amp;#x200B;

EDIT: Machine specs: i9-9900K, 32GB RAM, NVIDIA RTX 2080 Super

EDIT2: I have roughly 20 actual image of my target board. I used the Python package [Augmentor](https://github.com/mdbloice/Augmentor) to apply a small amount of rotation, flipping, and distortion to the image. All target boards will look exactly the same. They will be a white background with 4 triangles surrounding a plus symbol. I used Augmentor to create 4,000 slightly different target boards.",t2_1n9hv0lc,False,,0,False,How to Train and Find Rotated Object in Image?,[],r/tensorflow,False,6,,0,,,False,t3_j8cx8b,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1602298776.0,,[],{},,True,,1602327308.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I have no experience with TensorFlow, but I have lots of python experience. I am trying to look for a target board in my images. All images will look very similar to &lt;a href=""https://i.imgur.com/GnUke1W.jpeg""&gt;this&lt;/a&gt; , where the target board takes up the majority of the image. We can assume that the camera will always be looking directly at the target board from straight ahead, as shown in the image. The board may however roll/rotate +/- 15 degrees.&lt;/p&gt;

&lt;p&gt;I tried to follow &lt;a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/""&gt;TensorFlow 2.0 Object Detection API Tutorial&lt;/a&gt; but when I went to train my model I was only ever able to get a bounding box that included a lot of the background image, and had a confidence of, at best, 60%. My training images were all cropped images of the board, like &lt;a href=""https://i.imgur.com/MsAhpkZ.jpg""&gt;this&lt;/a&gt; , and the associated annotation xml file for that image had the target area of the entire image width/height. My test images looked like the first image I linked in this post.&lt;/p&gt;

&lt;p&gt;What am I doing wrong? Why does the model, after roughly 3000 steps, fail to detect the board anymore? I cannot find a sweet spot between 2000 (where it was approximately 60%) and 3000 steps that accurately finds the target board.&lt;/p&gt;

&lt;p&gt;Lastly, how do I eventually incorporate object rotation into this? I would ideally like to rotate and crop to my target, such that the + is parallel/perpendicular to the X/Y axis.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;EDIT: Machine specs: i9-9900K, 32GB RAM, NVIDIA RTX 2080 Super&lt;/p&gt;

&lt;p&gt;EDIT2: I have roughly 20 actual image of my target board. I used the Python package &lt;a href=""https://github.com/mdbloice/Augmentor""&gt;Augmentor&lt;/a&gt; to apply a small amount of rotation, flipping, and distortion to the image. All target boards will look exactly the same. They will be a white background with 4 triangles surrounding a plus symbol. I used Augmentor to create 4,000 slightly different target boards.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j8cx8b,True,,hurdur_or_bust,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j8cx8b/how_to_train_and_find_rotated_object_in_image/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j8cx8b/how_to_train_and_find_rotated_object_in_image/,22217,1602298508.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?auto=webp&amp;s=eb6bdb13ba899f65d97777033bb021fc1575540b', 'width': 1927, 'height': 1283}, 'resolutions': [{'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dbc5e693faea47e96f88d8ad5f520213684d57cd', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c5deeceafba885bed0fff5595ce020a6651e3a3', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=333cfe23a34541c2a164e99fc4c45a52f9cf7714', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1441194e18c5ff79debd4f208a34cc966bd6f620', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f9c9f259d4847124dc4f6661e9d6eb11de845b20', 'width': 960, 'height': 639}, {'url': 'https://external-preview.redd.it/x3rpMbGE65uqpbTcpM1HHn_XXMiNHLu1FoRp09Gvvcc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f0576edbe9c79b878b86b5ec8e49e31395240441', 'width': 1080, 'height': 719}], 'variants': {}, 'id': 'pQoPR8wnee5LcZUhTApCZj-4hjf4zfUJr4aexVthYJM'}], 'enabled': False}",,,,,,
688,,tensorflow,Hi guys. I have a RX 5500 XT that I'm trying to run tensorflow on. I have my pc dual booted so I can run ubuntu 2020.04 or Windows 10. Is there any way that I can run tensorflow using my card? I've looked at ROCm but that doesn't support the NAVI chipset.,t2_619e4iu4,False,,0,False,Any way to run tensorflow on RX 5500 XT,[],r/tensorflow,False,6,,0,,,False,t3_j86229,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1602302133.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys. I have a RX 5500 XT that I&amp;#39;m trying to run tensorflow on. I have my pc dual booted so I can run ubuntu 2020.04 or Windows 10. Is there any way that I can run tensorflow using my card? I&amp;#39;ve looked at ROCm but that doesn&amp;#39;t support the NAVI chipset.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j86229,True,,4n0nym0usR3dd1t0r,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j86229/any_way_to_run_tensorflow_on_rx_5500_xt/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j86229/any_way_to_run_tensorflow_on_rx_5500_xt/,22217,1602273333.0,0,,False,,,,,,,,,
689,,tensorflow,"I have an image-classification model that has a pretty good accuracy but I have created a function that crops each image into 5 different images and then takes the most accurate prediction from those. I was wondering if there was an easy way to replace the original prediction with this new prediction in the evaluate function for a keras generator so that I can see the accuracy across my testing batch of around 50,000 different images.",t2_6qhyby1n,False,,0,False,How do I replace original prediction with post-processing prediction in evaluate function?,[],r/tensorflow,False,6,,0,,,False,t3_j85mzt,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1602300774.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an image-classification model that has a pretty good accuracy but I have created a function that crops each image into 5 different images and then takes the most accurate prediction from those. I was wondering if there was an easy way to replace the original prediction with this new prediction in the evaluate function for a keras generator so that I can see the accuracy across my testing batch of around 50,000 different images.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j85mzt,True,,188_888,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j85mzt/how_do_i_replace_original_prediction_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j85mzt/how_do_i_replace_original_prediction_with/,22217,1602271974.0,0,,False,,,,,,,,,
690,,tensorflow,"Hello community. I'm currently implementing a VAE solution . In TensorFlow 2.0 examples , I saw that they used `sigmoid_cross_entropy_with_logits` as the reconstruction loss.

I didn't understand this choice , I would instead use MSE or RMSE errors to reconstruct the loss ,and use the `KL Divergence` for the latent loss.

I want to precise that in my task ,images don't have classes ,they are just a bunch of images that cannot be classified . I can simply say that I have one class.,what loss should I use instead of `sigmoid_cross_entropy_with_logits` does `MSE` would do the job ?",t2_7l9ti89m,False,,0,False,Which losses to use in Variational Autoencoders,[],r/tensorflow,False,6,,0,,,False,t3_j7v4zc,False,dark,0.89,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1602260163.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community. I&amp;#39;m currently implementing a VAE solution . In TensorFlow 2.0 examples , I saw that they used &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; as the reconstruction loss.&lt;/p&gt;

&lt;p&gt;I didn&amp;#39;t understand this choice , I would instead use MSE or RMSE errors to reconstruct the loss ,and use the &lt;code&gt;KL Divergence&lt;/code&gt; for the latent loss.&lt;/p&gt;

&lt;p&gt;I want to precise that in my task ,images don&amp;#39;t have classes ,they are just a bunch of images that cannot be classified . I can simply say that I have one class.,what loss should I use instead of &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; does &lt;code&gt;MSE&lt;/code&gt; would do the job ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j7v4zc,True,,rayanaay,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/j7v4zc/which_losses_to_use_in_variational_autoencoders/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j7v4zc/which_losses_to_use_in_variational_autoencoders/,22217,1602231363.0,0,,False,,,,,,,,,
691,,tensorflow,"I am trying to create an example for seq2seq.beamsearchdecoder

`vocab_size = 10`

`max_time = 16`

`batch_size = 2`

`emb_dim = 20`

`cell_dim = 5`

`attention_dim = cell_dim`

`beam_width = 3`

`hidden_size = 7`

`inputs = tf.random.uniform(`

`[batch_size, max_time, emb_dim],`

`maxval=1., dtype=tf.float32)`

`embedding = tf.random.uniform(`

`[vocab_size, emb_dim], maxval=1., dtype=tf.float32)`

`# make encoder`

`lstm = tf.keras.layers.LSTMCell(hidden_size)`

`lstmW = tf.keras.layers.RNN(lstm, return_sequences=True, return_state=True)`

`whole_encoder_seq_output, final_encoder_state, final_carry_state = lstmW(inputs)`

`tiled_encoder_output = tfa.seq2seq.tile_batch(whole_encoder_seq_output, multiplier=beam_width)`

`tiled_encoder_final_state = tfa.seq2seq.tile_batch(final_encoder_state, multiplier=beam_width)`

`encoder_initial_state = lstmW.get_initial_state(inputs)`

`tiled_encoder_initial_state = tfa.seq2seq.tile_batch(encoder_initial_state, multiplier=beam_width)`

`#make decoder`

`memory = tiled_encoder_final_state`

`attn_cells = tfa.seq2seq.AttentionWrapper(`

`lstm,`

`attention_mechanism=tfa.seq2seq.BahdanauAttention(units=hidden_size, memory=memory, memory_sequence_length=batch_size*beam_width),`

`attention_layer_size=hidden_size,`

`initial_cell_state=tiled_encoder_final_state`

`)`

`decoder_initial_state= attn_cells.get_initial_state(batch_size=batch_size*beam_width, dtype= tf.float32)`

`decoder_initial_state = decoder_initial_state.clone(cell_state=tiled_encoder_output)`

`#make predictions`

`decoder = tfa.seq2seq.BeamSearchDecoder(`

`cell=attn_cells,`     

`beam_width=beam_width,`

`output_layer=tf.keras.layers.Dense(hidden_size, name='output_proj')`

`) #second structure decoder`

`start_tokens = tf.zeros((batch_size,), dtype=tf.int32) decoder.initialize(embedding=embedding, start_tokens= start_tokens ,end_token= 1, initial_state=decoder_initial_state)#first structure decoder_initial_state`

but I am getting the following error

Entire first structure: AttentionWrapperState(cell\_state=., attention=., time=., alignments=., alignment\_history=(), attention\_state=.)

Entire second structure: AttentionWrapperState(cell\_state=\[., .\], attention=., time=., alignments=., alignment\_history=(), attention\_state=.)

the first structure is a sequence while other is not.

&amp;#x200B;

&amp;#x200B;

\\",t2_dgcv2k,False,,0,False,TensorFlow beamsearchdecoder attentionwrapper with clone error,[],r/tensorflow,False,6,,0,,,False,t3_j7tjju,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1602228297.0,,[],{},,True,,1602251313.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to create an example for seq2seq.beamsearchdecoder&lt;/p&gt;

&lt;p&gt;&lt;code&gt;vocab_size = 10&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;max_time = 16&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;batch_size = 2&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;emb_dim = 20&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cell_dim = 5&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;attention_dim = cell_dim&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;beam_width = 3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hidden_size = 7&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;inputs = tf.random.uniform(&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[batch_size, max_time, emb_dim],&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;maxval=1., dtype=tf.float32)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;embedding = tf.random.uniform(&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[vocab_size, emb_dim], maxval=1., dtype=tf.float32)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;# make encoder&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lstm = tf.keras.layers.LSTMCell(hidden_size)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lstmW = tf.keras.layers.RNN(lstm, return_sequences=True, return_state=True)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;whole_encoder_seq_output, final_encoder_state, final_carry_state = lstmW(inputs)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tiled_encoder_output = tfa.seq2seq.tile_batch(whole_encoder_seq_output, multiplier=beam_width)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tiled_encoder_final_state = tfa.seq2seq.tile_batch(final_encoder_state, multiplier=beam_width)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;encoder_initial_state = lstmW.get_initial_state(inputs)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tiled_encoder_initial_state = tfa.seq2seq.tile_batch(encoder_initial_state, multiplier=beam_width)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#make decoder&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;memory = tiled_encoder_final_state&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;attn_cells = tfa.seq2seq.AttentionWrapper(&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lstm,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;attention_mechanism=tfa.seq2seq.BahdanauAttention(units=hidden_size, memory=memory, memory_sequence_length=batch_size*beam_width),&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;attention_layer_size=hidden_size,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;initial_cell_state=tiled_encoder_final_state&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;decoder_initial_state= attn_cells.get_initial_state(batch_size=batch_size*beam_width, dtype= tf.float32)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;decoder_initial_state = decoder_initial_state.clone(cell_state=tiled_encoder_output)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#make predictions&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;decoder = tfa.seq2seq.BeamSearchDecoder(&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cell=attn_cells,&lt;/code&gt;     &lt;/p&gt;

&lt;p&gt;&lt;code&gt;beam_width=beam_width,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;output_layer=tf.keras.layers.Dense(hidden_size, name=&amp;#39;output_proj&amp;#39;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;) #second structure decoder&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;start_tokens = tf.zeros((batch_size,), dtype=tf.int32) decoder.initialize(embedding=embedding, start_tokens= start_tokens ,end_token= 1, initial_state=decoder_initial_state)#first structure decoder_initial_state&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;but I am getting the following error&lt;/p&gt;

&lt;p&gt;Entire first structure: AttentionWrapperState(cell_state=., attention=., time=., alignments=., alignment_history=(), attention_state=.)&lt;/p&gt;

&lt;p&gt;Entire second structure: AttentionWrapperState(cell_state=[., .], attention=., time=., alignments=., alignment_history=(), attention_state=.)&lt;/p&gt;

&lt;p&gt;the first structure is a sequence while other is not.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;\&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j7tjju,True,,ibia-nat,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j7tjju/tensorflow_beamsearchdecoder_attentionwrapper/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j7tjju/tensorflow_beamsearchdecoder_attentionwrapper/,22217,1602222513.0,0,,False,,,,,,,,,
692,,tensorflow,"In my new video, I explain how to extract MFCCs (and 1st and 2nd MFCCs derivatives) from an audio file with Python and Librosa. I also visualise MFCCs for a music piece.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=WJI-17MNpdE&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=20](https://www.youtube.com/watch?v=WJI-17MNpdE&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=20)",t2_12ahau,False,,0,False,I published a tutorial where I extract Mel-Frequency Cepstral Coefficients from audio data with Python,[],r/tensorflow,False,6,,0,,,False,t3_j7b8nc,False,dark,1.0,,public,17,0,{},,,False,[],,False,False,,{},Discussion,False,17,,False,self,False,,[],{},,True,,1602184758.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new video, I explain how to extract MFCCs (and 1st and 2nd MFCCs derivatives) from an audio file with Python and Librosa. I also visualise MFCCs for a music piece.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=WJI-17MNpdE&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=20""&gt;https://www.youtube.com/watch?v=WJI-17MNpdE&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=20&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j7b8nc,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j7b8nc/i_published_a_tutorial_where_i_extract/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j7b8nc/i_published_a_tutorial_where_i_extract/,22217,1602155958.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/GFbSk3MOqBTWJ2oK92mE1Vz4EcrihnjSTgbNmOO6e8E.jpg?auto=webp&amp;s=77748b3f5c15ca733d51db6ffa6a54535f10b5c5', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/GFbSk3MOqBTWJ2oK92mE1Vz4EcrihnjSTgbNmOO6e8E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01e9071d688e71a587fabd7346f06c4512faffbe', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/GFbSk3MOqBTWJ2oK92mE1Vz4EcrihnjSTgbNmOO6e8E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2fc71137c444d25132b49e6cdc65774607135e6', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/GFbSk3MOqBTWJ2oK92mE1Vz4EcrihnjSTgbNmOO6e8E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6243df5e84dbbd9c6fef4491c42ab950ef5e362d', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Sz2VsqbhEOF0c59K35dKU576-kD1cMkB0r1wSlIBHQ0'}], 'enabled': False}",,,,,,
693,,tensorflow,"So i finally after a day or 2 got my first training going on a 3080. Have tensorflow gpu installed in my environment. But now the training just started. And my gpu stays at 0% somtimes goes to 1. Is this normal?

EDIT1: oke after a few minutes the training stops and i get this.

https://imgur.com/a/NafQfqo",t2_dysp7,False,,0,False,Stylegan2 first training 0 gpu utilization,[],r/tensorflow,False,6,,0,,,False,t3_j7bvvp,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,1602160129.0,,[],{},,True,,1602187803.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i finally after a day or 2 got my first training going on a 3080. Have tensorflow gpu installed in my environment. But now the training just started. And my gpu stays at 0% somtimes goes to 1. Is this normal?&lt;/p&gt;

&lt;p&gt;EDIT1: oke after a few minutes the training stops and i get this.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://imgur.com/a/NafQfqo""&gt;https://imgur.com/a/NafQfqo&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j7bvvp,True,,ephemeralkazu,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/j7bvvp/stylegan2_first_training_0_gpu_utilization/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j7bvvp/stylegan2_first_training_0_gpu_utilization/,22217,1602159003.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?auto=webp&amp;s=759dc08f4c99b8607b3ceffad08a00d98048a870', 'width': 1432, 'height': 465}, 'resolutions': [{'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e063492ad8bfd8243bdeb86f1d6c9a01f24bbd4', 'width': 108, 'height': 35}, {'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b230697127c538f8f86271b9d9519e84569a5177', 'width': 216, 'height': 70}, {'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d702857619c6dc51c3b3d998de7ba5d573c74f47', 'width': 320, 'height': 103}, {'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb5b775349e71d50b1be64974cc30621a750e431', 'width': 640, 'height': 207}, {'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e122b4280489d41789542f96b9fa8974b3f6434', 'width': 960, 'height': 311}, {'url': 'https://external-preview.redd.it/QS4pS2myLRA4EvjxVSkGT7zTKMvlICPdSEDAsvTuDZ0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e01f01936475465adfbf45e9b897816b0cb12b58', 'width': 1080, 'height': 350}], 'variants': {}, 'id': '9rzMIJGCdI4bUMGVQUauQXZOJu1LmiG9UdrRa8h8ojQ'}], 'enabled': False}",,,,,,
694,,tensorflow,,t2_5moj37ik,False,,0,False,Supreme Commander: Forged Alliance - All Cinematics (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS,[],r/tensorflow,False,6,,0,105.0,,False,t3_j7d72k,False,dark,0.63,,public,2,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_uQgVFKB4lU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Supreme Commander: Forged Alliance - All Cinematics (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_uQgVFKB4lU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_uQgVFKB4lU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_uQgVFKB4lU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j7d72k', 'height': 338}",,False,2,,False,https://b.thumbs.redditmedia.com/oD1kgdQVkBHuMxM-g1s9Z_lx7tRY9w9ZX34Kw3HJTQw.jpg,False,,[],{},,False,,1602193172.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j7d72k,True,,stepanmetior,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j7d72k/supreme_commander_forged_alliance_all_cinematics/,all_ads,False,https://www.youtube.com/watch?v=_uQgVFKB4lU&amp;feature=youtu.be,22217,1602164372.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Supreme Commander: Forged Alliance - All Cinematics (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_uQgVFKB4lU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_uQgVFKB4lU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=_uQgVFKB4lU&amp;feature=youtu.be,"{'images': [{'source': {'url': 'https://external-preview.redd.it/YJx2noHd6uG83ta-4xRAy9HSKvbuyAmuenracOfGdVQ.jpg?auto=webp&amp;s=cb269d4a9669b1fe3a2251273be5cd080670d6b6', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/YJx2noHd6uG83ta-4xRAy9HSKvbuyAmuenracOfGdVQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=602239eb22c3ee2ba0213cf59cdb443bf7a5e98f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/YJx2noHd6uG83ta-4xRAy9HSKvbuyAmuenracOfGdVQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f5c36ed7959f2a2d06c56afd34fe6f7eee8fa535', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/YJx2noHd6uG83ta-4xRAy9HSKvbuyAmuenracOfGdVQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=38eb51f988525aafa0842b7e97ba2b716ff61465', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'FDyMIWQiFL3Fo1GPT3P8vOF1_WfqrmvNxNX7lNhu7PI'}], 'enabled': False}",,,,,,
695,,tensorflow,"Hi everyone,

last time I checked (3 years ago) rocm was absolutely useless.

Does anyone of you have a proper benchmark between consumer grade nvidia gpus with cuda and amd gpus using rocm?

I would also appreciate reports from rocm users about how they experience rocm.

Best wishes.",t2_10chz3,False,,0,False,CUDA vs rocm,[],r/tensorflow,False,6,,0,,,False,t3_j6zcgw,False,dark,1.0,,public,22,0,{},,,False,[],,False,False,,{},Question,False,22,,False,self,False,,[],{},,True,,1602133291.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;last time I checked (3 years ago) rocm was absolutely useless.&lt;/p&gt;

&lt;p&gt;Does anyone of you have a proper benchmark between consumer grade nvidia gpus with cuda and amd gpus using rocm?&lt;/p&gt;

&lt;p&gt;I would also appreciate reports from rocm users about how they experience rocm.&lt;/p&gt;

&lt;p&gt;Best wishes.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j6zcgw,True,,pag07,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/j6zcgw/cuda_vs_rocm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j6zcgw/cuda_vs_rocm/,22217,1602104491.0,0,,False,,,,,,,,,
696,,tensorflow,"Hello all,

I just got my hands on a brand new RTX 2060 Super to replace my GTX 1060.

I went straight to executing a few ML Tensorflow algorithms I've been working on and the RTX 2060 Super is on average 30% slower than my GTX 1060 !!!

I know there are some architecture changes under the hood ; I don't use mixed precision at all yet (so bye bye Tensor cores for now). 

Could it be because I use tf.float64 ?

Any help or links would be greatly appreciated, I'm not sure where to start.

Best regards,",t2_fxlya1c,False,,0,False,RTX 2060 Super slower than a GTX 1060 !,[],r/tensorflow,False,6,,0,,,False,t3_j6nn2d,False,dark,0.95,,public,16,0,{},,,False,[],,False,False,,{},,False,16,,False,self,False,,[],{},,True,,1602090626.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;I just got my hands on a brand new RTX 2060 Super to replace my GTX 1060.&lt;/p&gt;

&lt;p&gt;I went straight to executing a few ML Tensorflow algorithms I&amp;#39;ve been working on and the RTX 2060 Super is on average 30% slower than my GTX 1060 !!!&lt;/p&gt;

&lt;p&gt;I know there are some architecture changes under the hood ; I don&amp;#39;t use mixed precision at all yet (so bye bye Tensor cores for now). &lt;/p&gt;

&lt;p&gt;Could it be because I use tf.float64 ?&lt;/p&gt;

&lt;p&gt;Any help or links would be greatly appreciated, I&amp;#39;m not sure where to start.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j6nn2d,True,,l1t3o,,16,True,all_ads,False,[],False,,/r/tensorflow/comments/j6nn2d/rtx_2060_super_slower_than_a_gtx_1060/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j6nn2d/rtx_2060_super_slower_than_a_gtx_1060/,22217,1602061826.0,0,,False,,,,,,,,,
697,,tensorflow,"Hi guys,

Anyone has experience on migration of tf1 frozen graph yo tf2 savemodel? Is there a corresponding method to frozen graph in TF2.x?

Our team want to move to TF2.X from TF1.14. 

Save model:
In TF1.14, we apply freeze_ graph approach to generate .pb file.
In TF2.x, in turn we apply tf.saved_model.save to save trained model to savemodel directory.

Load model:
TF1.14, it only take 3.4s to load model
TF2.x, it take 24s

Thanks in advance.",t2_klixk,False,,0,False,[Question] tf.saved_model.load in TF2.x is much slower than tf.import_graph_def in TF1.14,[],r/tensorflow,False,6,,0,,,False,t3_j6njzg,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1602090110.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;Anyone has experience on migration of tf1 frozen graph yo tf2 savemodel? Is there a corresponding method to frozen graph in TF2.x?&lt;/p&gt;

&lt;p&gt;Our team want to move to TF2.X from TF1.14. &lt;/p&gt;

&lt;p&gt;Save model:
In TF1.14, we apply freeze_ graph approach to generate .pb file.
In TF2.x, in turn we apply tf.saved_model.save to save trained model to savemodel directory.&lt;/p&gt;

&lt;p&gt;Load model:
TF1.14, it only take 3.4s to load model
TF2.x, it take 24s&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j6njzg,True,,fov223,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j6njzg/question_tfsaved_modelload_in_tf2x_is_much_slower/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j6njzg/question_tfsaved_modelload_in_tf2x_is_much_slower/,22217,1602061310.0,0,,False,,,,,,,,,
698,,tensorflow,,t2_xt6j8xa,False,,0,False,I wrote a blog on Federated learning. I hope you find it helpful.,[],r/tensorflow,False,6,,0,93.0,,False,t3_j65lw5,False,dark,0.94,,public,15,0,{},140.0,,False,[],,False,False,,{},,False,15,,False,https://b.thumbs.redditmedia.com/wpNTmN1QjihH0LvXfybjVUkqYbr_jahrfpZCaqKI-Xo.jpg,False,,[],{},,False,,1602021864.0,text,6,,,text,medium.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j65lw5,True,,clean_pegasus,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j65lw5/i_wrote_a_blog_on_federated_learning_i_hope_you/,all_ads,False,https://medium.com/@cleanpegasus/understanding-federated-learning-99bc86a0d026,22217,1601993064.0,0,,False,link,https://medium.com/@cleanpegasus/understanding-federated-learning-99bc86a0d026,"{'images': [{'source': {'url': 'https://external-preview.redd.it/hkTVAlcH32EfnY04VbucovUE06G3FN_wmzx1IXUsm5M.jpg?auto=webp&amp;s=c8ada152bba9ba8e886812a70f1bdc4111422564', 'width': 640, 'height': 426}, 'resolutions': [{'url': 'https://external-preview.redd.it/hkTVAlcH32EfnY04VbucovUE06G3FN_wmzx1IXUsm5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=243fa400108d1e6073f2f08129ec790c39015907', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/hkTVAlcH32EfnY04VbucovUE06G3FN_wmzx1IXUsm5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf101991c2f322d3f94ef255dc4f2bbca84149d1', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/hkTVAlcH32EfnY04VbucovUE06G3FN_wmzx1IXUsm5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1314cf84ff88e72da371eb1f31c8cb53c4fc956d', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/hkTVAlcH32EfnY04VbucovUE06G3FN_wmzx1IXUsm5M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab5de7621a6a69b31cfaa1514d50a7790b78c112', 'width': 640, 'height': 426}], 'variants': {}, 'id': 'igy0xnUysDulc4pwj32lCp7RUEIyXSD33pTEXvyR398'}], 'enabled': False}",,,,,,
699,,tensorflow,,t2_47jpmh5m,False,,0,False,Top 10 Machine Learning Courses(Theory and Practical in 2020),[],r/tensorflow,False,6,,0,108.0,,False,t3_j68zsg,False,dark,0.72,,public,3,0,{},140.0,,False,[],,False,False,,{},,False,3,,False,https://b.thumbs.redditmedia.com/T6sU0NY5KJcqLl1x3wL7CepBM-jVQDG9WX8PmoTKJ5g.jpg,False,,[],{},,False,,1602032937.0,text,6,,,text,kdnuggets.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j68zsg,True,,ItisAhmad,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j68zsg/top_10_machine_learning_coursestheory_and/,all_ads,False,https://www.kdnuggets.com/2020/10/10-best-machine-learning-courses-2020.html,22217,1602004137.0,0,,False,link,https://www.kdnuggets.com/2020/10/10-best-machine-learning-courses-2020.html,"{'images': [{'source': {'url': 'https://external-preview.redd.it/K2B7sPYoF0nUWjwRGOYAG6eQxTF8-Gu8rXPOW12fAjU.jpg?auto=webp&amp;s=066820cf4927985dfff14a31f7ae1d8391ad41b6', 'width': 875, 'height': 681}, 'resolutions': [{'url': 'https://external-preview.redd.it/K2B7sPYoF0nUWjwRGOYAG6eQxTF8-Gu8rXPOW12fAjU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c67afbce228f4267be0d74ace5c95baa385bb3ad', 'width': 108, 'height': 84}, {'url': 'https://external-preview.redd.it/K2B7sPYoF0nUWjwRGOYAG6eQxTF8-Gu8rXPOW12fAjU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df9b119d2b49815101c208ce87cd3c97d38655a4', 'width': 216, 'height': 168}, {'url': 'https://external-preview.redd.it/K2B7sPYoF0nUWjwRGOYAG6eQxTF8-Gu8rXPOW12fAjU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=943bc416104552d8d7db83700bfcea296c00a9c8', 'width': 320, 'height': 249}, {'url': 'https://external-preview.redd.it/K2B7sPYoF0nUWjwRGOYAG6eQxTF8-Gu8rXPOW12fAjU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca03f576bd797227f31292432401094948ce6099', 'width': 640, 'height': 498}], 'variants': {}, 'id': 'AeiXsB_oUuQlDDyHM0jm_Zhe6s-Unc4zDsNtEChv9ac'}], 'enabled': False}",,,,,,
700,,tensorflow,"Apologies in advance because I'm not super familiar with tensorflow itself, and just working with a library that makes use of it.

I'm working on a project that involves translating terabytes of English text into its phonetic representation. Luckily there's a fantastic library called [pincelate](https://github.com/aparrish/pincelate), that uses a tensorflow backend to guess pronunciations of words that don't appear in my main pronunciation dictionary.

Pincelate was written for tensorflow 1.15 and keras 2.2.5. I've got it set up with those dependencies in its own conda environment, and my multithreaded script can translate my source text at a speed of \~25-200 lines/second running on my CPU. The single-threaded GPU version is a lot slower because so much in the script is file i/o and text manipulation that isn't in tensorflow, which is why I'm running on CPU.

I thought it'd be worth seeing if there was any improvement to be had by using a more recent tensorflow (and tf.keras, since standalone keras is going away). I modified the import statements and a few model loading calls (pretty much exactly what [this person did in this pull request](https://github.com/aparrish/pincelate/pull/9/files)) but otherwise left the code untouched. 

Performance using tensorflow 2.3.1 and tf.keras has been pretty terrible in comparison, \~1.5-8 lines/second. Basically what I was getting without multiprocessing. But my CPU is still showing near-max usage across all cores, so I don't think it's a multiprocessing problem. It's still loading models trained under the original code, but the tensorflow docs indicate those models should still be compatible. 

I haven't come across any performance complaints related to tf.keras. If anything, I've seen reports of performance improvements. Is there something important I'm missing that needs to be done as I migrate the code?",t2_7ngwzjz,False,,0,False,Performance drop migrating from standalone keras to tf.keras?,[],r/tensorflow,False,6,,0,,,False,t3_j69rsn,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1602035338.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Apologies in advance because I&amp;#39;m not super familiar with tensorflow itself, and just working with a library that makes use of it.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on a project that involves translating terabytes of English text into its phonetic representation. Luckily there&amp;#39;s a fantastic library called &lt;a href=""https://github.com/aparrish/pincelate""&gt;pincelate&lt;/a&gt;, that uses a tensorflow backend to guess pronunciations of words that don&amp;#39;t appear in my main pronunciation dictionary.&lt;/p&gt;

&lt;p&gt;Pincelate was written for tensorflow 1.15 and keras 2.2.5. I&amp;#39;ve got it set up with those dependencies in its own conda environment, and my multithreaded script can translate my source text at a speed of ~25-200 lines/second running on my CPU. The single-threaded GPU version is a lot slower because so much in the script is file i/o and text manipulation that isn&amp;#39;t in tensorflow, which is why I&amp;#39;m running on CPU.&lt;/p&gt;

&lt;p&gt;I thought it&amp;#39;d be worth seeing if there was any improvement to be had by using a more recent tensorflow (and tf.keras, since standalone keras is going away). I modified the import statements and a few model loading calls (pretty much exactly what &lt;a href=""https://github.com/aparrish/pincelate/pull/9/files""&gt;this person did in this pull request&lt;/a&gt;) but otherwise left the code untouched. &lt;/p&gt;

&lt;p&gt;Performance using tensorflow 2.3.1 and tf.keras has been pretty terrible in comparison, ~1.5-8 lines/second. Basically what I was getting without multiprocessing. But my CPU is still showing near-max usage across all cores, so I don&amp;#39;t think it&amp;#39;s a multiprocessing problem. It&amp;#39;s still loading models trained under the original code, but the tensorflow docs indicate those models should still be compatible. &lt;/p&gt;

&lt;p&gt;I haven&amp;#39;t come across any performance complaints related to tf.keras. If anything, I&amp;#39;ve seen reports of performance improvements. Is there something important I&amp;#39;m missing that needs to be done as I migrate the code?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j69rsn,True,,porterhousegames,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j69rsn/performance_drop_migrating_from_standalone_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j69rsn/performance_drop_migrating_from_standalone_keras/,22217,1602006538.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-rEFpAQBcPae9h0kRVpD6evFUU-BhBs2YSNUOnXJrUw.jpg?auto=webp&amp;s=98bc72bf12928b62debe97d6cb3a2365746a9425', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-rEFpAQBcPae9h0kRVpD6evFUU-BhBs2YSNUOnXJrUw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b098bc5505e9709ef076d08c0621fbcc1e890cae', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-rEFpAQBcPae9h0kRVpD6evFUU-BhBs2YSNUOnXJrUw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=88c4eda7213514dcf3a4164687daf7a4c176afaa', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-rEFpAQBcPae9h0kRVpD6evFUU-BhBs2YSNUOnXJrUw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b08a3653abc8cb8408d1fcc12e78bad76db5630', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'ukrJgwrvscZHwBHdsk-mDl4q0ctgm3h4wxbtmm6pnQE'}], 'enabled': False}",,,,,,
701,,tensorflow,,t2_44mbtmjy,False,,0,False,Latest from Microsoft and Samsung researchers: State of the art in Face Attribute Editing with GANs,[],r/tensorflow,False,6,,0,118.0,,False,t3_j6fa65,False,dark,0.33,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/dv5Z0op2niS_v0yw-wcEUjohl1r6PM7HnEOJf-lkGtI.jpg,False,,[],{},,False,,1602052846.0,text,6,,,text,self.LatestInML,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j6fa65,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j6fa65/latest_from_microsoft_and_samsung_researchers/,all_ads,False,/r/LatestInML/comments/j6f9j1/latest_from_microsoft_and_samsung_researchers/,22217,1602024046.0,0,,False,,/r/LatestInML/comments/j6f9j1/latest_from_microsoft_and_samsung_researchers/,,,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2010.01424?fbclid=IwAR1e4xGFFCfh5qA--HlsZmtVirxbcmS8R6pUFs7QVSpOIypadZHni0_i5HQ)\n\nhttps://preview.redd.it/4vt92us9yjr51.jpg?width=980&amp;format=pjpg&amp;auto=webp&amp;s=2bd2ea1ccd14bebf2647e09d1aa5162fc756cd01', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from Microsoft and Samsung researchers: State of the art in Face Attribute Editing with GANs', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 118, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'4vt92us9yjr51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 91, 'x': 108, 'u': 'https://preview.redd.it/4vt92us9yjr51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bea0f828b321b3e2127d778a4d4431024166bc7'}, {'y': 182, 'x': 216, 'u': 'https://preview.redd.it/4vt92us9yjr51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdd7ada6ec7d1871bbd04cfc3e9766ddf45079d2'}, {'y': 269, 'x': 320, 'u': 'https://preview.redd.it/4vt92us9yjr51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b5ab6cfbf481cb1b31eefa2f911fd6e2837c8966'}, {'y': 539, 'x': 640, 'u': 'https://preview.redd.it/4vt92us9yjr51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4160ab89a90d37b4eec9ca21ab0fb820dda6b0fe'}, {'y': 809, 'x': 960, 'u': 'https://preview.redd.it/4vt92us9yjr51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=256e9393c711f1cefa3d0d9ab03d0072f4088d08'}], 's': {'y': 826, 'x': 980, 'u': 'https://preview.redd.it/4vt92us9yjr51.jpg?width=980&amp;format=pjpg&amp;auto=webp&amp;s=2bd2ea1ccd14bebf2647e09d1aa5162fc756cd01'}, 'id': '4vt92us9yjr51'}}, 'name': 't3_j6f9j1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 27, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 27, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/dv5Z0op2niS_v0yw-wcEUjohl1r6PM7HnEOJf-lkGtI.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1602052784.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2010.01424?fbclid=IwAR1e4xGFFCfh5qA--HlsZmtVirxbcmS8R6pUFs7QVSpOIypadZHni0_i5HQ""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/4vt92us9yjr51.jpg?width=980&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2bd2ea1ccd14bebf2647e09d1aa5162fc756cd01""&gt;https://preview.redd.it/4vt92us9yjr51.jpg?width=980&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2bd2ea1ccd14bebf2647e09d1aa5162fc756cd01&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'j6f9j1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/j6f9j1/latest_from_microsoft_and_samsung_researchers/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/j6f9j1/latest_from_microsoft_and_samsung_researchers/', 'subreddit_subscribers': 6676, 'created_utc': 1602023984.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_j6f9j1,
702,,tensorflow,,t2_8cl48,False,,0,False,Install Tensorflow on Windows 10 Working,[],r/tensorflow,False,6,,0,,,False,t3_j60hte,False,dark,0.71,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,default,False,,[],{},,False,,1601996243.0,text,6,,,text,devopslanka.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j60hte,True,,sameera88,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j60hte/install_tensorflow_on_windows_10_working/,all_ads,False,https://devopslanka.com/2020/10/06/install-tensorflow-on-windows-10-working/,22217,1601967443.0,0,,False,,https://devopslanka.com/2020/10/06/install-tensorflow-on-windows-10-working/,,,,,,,
703,,tensorflow,,t2_3ev8u036,False,,0,False,Why you should write Algorithms for Projects that may not require them,[],r/tensorflow,False,6,,0,93.0,,False,t3_j67yl7,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Discussion,False,1,,False,https://b.thumbs.redditmedia.com/YJQh-_lvxNV1PG83d30HsA1gQzmDO73GOdFK7uNmgAs.jpg,False,,[],{},,False,,1602029725.0,text,6,,,text,medium.com,False,,,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j67yl7,True,,jingleshine456,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j67yl7/why_you_should_write_algorithms_for_projects_that/,all_ads,False,https://medium.com/@j_kirchner/using-an-algorithmic-approach-to-project-design-592643b4834e,22217,1602000925.0,0,,False,link,https://medium.com/@j_kirchner/using-an-algorithmic-approach-to-project-design-592643b4834e,"{'images': [{'source': {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?auto=webp&amp;s=16f02fb545d71494bc6d828d85d0310910681341', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e45de1bf23335163b42c1d23501f61c66a8403c', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=218dc12d3117f08ff4ce153a877e7ffdb42e55d7', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=566f94f3b145bb7e0896495199f3343a7c7b084a', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c085438e660360662f5c53f49a517dd3fe42755c', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6f36b549293ed78044c3cc6ab9517aef0605b05', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4773498fdcd2456e4c9ac177f9240e73a49ab597', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'lOKKMfm1df9GxsNA1f2rXGOS8N4eaTFFT-JmVSKhI6Q'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'programming', 'selftext': '', 'author_fullname': 't2_3ev8u036', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Why you should write Algorithms for Projects that may not require them', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/programming', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 93, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_j3x3g9', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.48, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'author_premium': False, 'thumbnail': 'default', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1601682901.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'medium.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://medium.com/@j_kirchner/using-an-algorithmic-approach-to-project-design-592643b4834e', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?auto=webp&amp;s=16f02fb545d71494bc6d828d85d0310910681341', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e45de1bf23335163b42c1d23501f61c66a8403c', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=218dc12d3117f08ff4ce153a877e7ffdb42e55d7', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=566f94f3b145bb7e0896495199f3343a7c7b084a', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c085438e660360662f5c53f49a517dd3fe42755c', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6f36b549293ed78044c3cc6ab9517aef0605b05', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/M69hZjxeLqORZeao5V-XUmWaGlEtpoM0oXW3SBJGbMM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4773498fdcd2456e4c9ac177f9240e73a49ab597', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'lOKKMfm1df9GxsNA1f2rXGOS8N4eaTFFT-JmVSKhI6Q'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2fwo', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'j3x3g9', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'jingleshine456', 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/programming/comments/j3x3g9/why_you_should_write_algorithms_for_projects_that/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://medium.com/@j_kirchner/using-an-algorithmic-approach-to-project-design-592643b4834e', 'subreddit_subscribers': 3253980, 'created_utc': 1601654101.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_j3x3g9,
704,,tensorflow,"I have a keras model that i converted for tfjs and i would like to be able to run it on the user's device for my web app. After the conversion i'm left with a model.json and a shard1of1.bin file. Is it standard procedure to serve the model from the google cloud platform or is it possible for me to include the model in the assets of my app and access it that way instead of having to host it on google cloud or aws? 

I tried to just throw the model onto github and make a request to it there but that resulted in lots of CORS issues (understandably). I'm worried I'm convoluting this... I thought I would be able to include the model in the assets of the app and access it there but that doesn't seem to be the case.",t2_849fflvy,False,,0,False,Tensorflow js- where do i keep/serve my model?,[],r/tensorflow,False,6,,0,,,False,t3_j67fcf,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1602027995.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a keras model that i converted for tfjs and i would like to be able to run it on the user&amp;#39;s device for my web app. After the conversion i&amp;#39;m left with a model.json and a shard1of1.bin file. Is it standard procedure to serve the model from the google cloud platform or is it possible for me to include the model in the assets of my app and access it that way instead of having to host it on google cloud or aws? &lt;/p&gt;

&lt;p&gt;I tried to just throw the model onto github and make a request to it there but that resulted in lots of CORS issues (understandably). I&amp;#39;m worried I&amp;#39;m convoluting this... I thought I would be able to include the model in the assets of the app and access it there but that doesn&amp;#39;t seem to be the case.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j67fcf,True,,campscoobydoo,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j67fcf/tensorflow_js_where_do_i_keepserve_my_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j67fcf/tensorflow_js_where_do_i_keepserve_my_model/,22217,1601999195.0,0,,False,,,,,,,,,
705,,tensorflow,"Hello Tensorflow Community,

&amp;#x200B;

this weekend I started looking into Tensorflow for object detetction. After a day of trial and error I got my code working so far that I can test all the models presented on the [TensorFlow 2 Detection Model Zoo-Page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)

&amp;#x200B;

My PC Specs:

i7 8700k 6 x 4,5GHz

RTX 2070 Super

32GB DDR4 3200MHz RAM

Everything running on a NVME Samsung 960 EVO

&amp;#x200B;

In this example I am running the [EfficientDet D7 1536x1536](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d7_coco17_tpu-32.tar.gz) model with an advertised speed of 325 ms and a COCO mAP of 51.2 and the  [SSD MobileNet V2 FPNLite 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz) with an advertised speed of 39 ms and a COCO mAP of 28.2.

However in my example the model takes way longer (2-3x) for inference.

&amp;#x200B;

Timings corresponding to the code (EfficientDet D7):

Grab took 0.04 seconds

Inference  took 0.92 seconds

Boxes took 0.12 seconds

Frame took 1.09 seconds

&amp;#x200B;

&amp;#x200B;

Timings corresponding to the code (ssd\_mobilenet\_v2 640x640):

Grab took 0.05 seconds

Inference  took 0.12 seconds

Boxes took 0.05 seconds

Frame took 0.22 seconds

&amp;#x200B;

&amp;#x200B;

My full code here (with some debugging leftovers): [https://pastebin.pl/view/5647503b](https://pastebin.pl/view/5647503b)

Screenshot for further info (EfficientDet D7): [https://imgur.com/a/XyydPp9](https://imgur.com/a/XyydPp9)

Screenshot for further info (ssd\_mobilenet\_v2 640x640): [https://imgur.com/a/W7YD2Bv](https://imgur.com/a/W7YD2Bv)

&amp;#x200B;

All code is running inside a conda environment with Python 3.6, Tensorflow 2.3.1, CUDA 10.1 and Cudnn 10.1.

&amp;#x200B;

Now for my questions:

\- Am I doing something horribly wrong?

\- Are the advertised speeds even achievable (with a normal computer)?

\- Sometimes even the draw for the detectionboxes takes \~0.3 seconds (is that normal?)

(visualization\_utils.visualize\_boxes\_and\_labels\_on\_image\_array())

\- Is the inference-time the advertised speed on the model-zoo page?

&amp;#x200B;

I am grateful for any replys

&amp;#x200B;

&amp;#x200B;

Edit:

I updated the detect\_fn to a more TF2 approach:

        @tf.function
        def detect_fn(self, image):
            """"""Detect objects in image.""""""
            start_time = time.time()
            image, shapes = self.detection_model.preprocess(image)
            prediction_dict = self.detection_model.predict(image, shapes)
            detections = self.detection_model.postprocess(prediction_dict, shapes)
            print('Inference took {} seconds'.format(str(time.time() - start_time)[:4]))
            # return detections, prediction_dict, tf.reshape(shapes, [-1])
            return detections

&amp;#x200B;

but that sadly doesn't change the inference speed at all.

&amp;#x200B;

Edit:

EfficientDet D7

Step 0: Inference took 7.95 seconds

Step 1: Inference took 0.96 seconds

Step 2: Inference took 0.96 seconds

Call-Trace: [https://cdn.discordapp.com/attachments/462892567575658497/764139635701055539/efficientdet\_d7\_gpu\_cpu.png](https://cdn.discordapp.com/attachments/462892567575658497/764139635701055539/efficientdet_d7_gpu_cpu.png)

I don't really know if there are any anomalies. Need to do further investigation.

&amp;#x200B;

&amp;#x200B;

Edit: According to some more knowledgeable person there is a corresponding GPU Kernel for the  NonMaxSuppressionV5 Operation which is consuming my CPU Pipeline.

[https://github.com/tensorflow/tensorflow/blob/e8598ce0454c440fca64e4ebc4aeedfa7afd5c97/tensorflow/core/kernels/image/non\_max\_suppression\_op.cu.cc#L580](https://github.com/tensorflow/tensorflow/blob/e8598ce0454c440fca64e4ebc4aeedfa7afd5c97/tensorflow/core/kernels/image/non_max_suppression_op.cu.cc#L580)

I still need to figure out how to implement the GPU version

&amp;#x200B;",t2_mocpu,False,,0,False,Can't achieve advertised Model Zoo TF2 detection speeds,[],r/tensorflow,False,6,,0,,,False,t3_j63ybu,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Slow Inference Speed,False,0,,False,self,1602328628.0,,[],{},,True,,1602015287.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello Tensorflow Community,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;this weekend I started looking into Tensorflow for object detetction. After a day of trial and error I got my code working so far that I can test all the models presented on the &lt;a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md""&gt;TensorFlow 2 Detection Model Zoo-Page&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My PC Specs:&lt;/p&gt;

&lt;p&gt;i7 8700k 6 x 4,5GHz&lt;/p&gt;

&lt;p&gt;RTX 2070 Super&lt;/p&gt;

&lt;p&gt;32GB DDR4 3200MHz RAM&lt;/p&gt;

&lt;p&gt;Everything running on a NVME Samsung 960 EVO&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;In this example I am running the &lt;a href=""http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d7_coco17_tpu-32.tar.gz""&gt;EfficientDet D7 1536x1536&lt;/a&gt; model with an advertised speed of 325 ms and a COCO mAP of 51.2 and the  &lt;a href=""http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz""&gt;SSD MobileNet V2 FPNLite 640x640&lt;/a&gt; with an advertised speed of 39 ms and a COCO mAP of 28.2.&lt;/p&gt;

&lt;p&gt;However in my example the model takes way longer (2-3x) for inference.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Timings corresponding to the code (EfficientDet D7):&lt;/p&gt;

&lt;p&gt;Grab took 0.04 seconds&lt;/p&gt;

&lt;p&gt;Inference  took 0.92 seconds&lt;/p&gt;

&lt;p&gt;Boxes took 0.12 seconds&lt;/p&gt;

&lt;p&gt;Frame took 1.09 seconds&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Timings corresponding to the code (ssd_mobilenet_v2 640x640):&lt;/p&gt;

&lt;p&gt;Grab took 0.05 seconds&lt;/p&gt;

&lt;p&gt;Inference  took 0.12 seconds&lt;/p&gt;

&lt;p&gt;Boxes took 0.05 seconds&lt;/p&gt;

&lt;p&gt;Frame took 0.22 seconds&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My full code here (with some debugging leftovers): &lt;a href=""https://pastebin.pl/view/5647503b""&gt;https://pastebin.pl/view/5647503b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Screenshot for further info (EfficientDet D7): &lt;a href=""https://imgur.com/a/XyydPp9""&gt;https://imgur.com/a/XyydPp9&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Screenshot for further info (ssd_mobilenet_v2 640x640): &lt;a href=""https://imgur.com/a/W7YD2Bv""&gt;https://imgur.com/a/W7YD2Bv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;All code is running inside a conda environment with Python 3.6, Tensorflow 2.3.1, CUDA 10.1 and Cudnn 10.1.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Now for my questions:&lt;/p&gt;

&lt;p&gt;- Am I doing something horribly wrong?&lt;/p&gt;

&lt;p&gt;- Are the advertised speeds even achievable (with a normal computer)?&lt;/p&gt;

&lt;p&gt;- Sometimes even the draw for the detectionboxes takes ~0.3 seconds (is that normal?)&lt;/p&gt;

&lt;p&gt;(visualization_utils.visualize_boxes_and_labels_on_image_array())&lt;/p&gt;

&lt;p&gt;- Is the inference-time the advertised speed on the model-zoo page?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am grateful for any replys&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit:&lt;/p&gt;

&lt;p&gt;I updated the detect_fn to a more TF2 approach:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    @tf.function
    def detect_fn(self, image):
        &amp;quot;&amp;quot;&amp;quot;Detect objects in image.&amp;quot;&amp;quot;&amp;quot;
        start_time = time.time()
        image, shapes = self.detection_model.preprocess(image)
        prediction_dict = self.detection_model.predict(image, shapes)
        detections = self.detection_model.postprocess(prediction_dict, shapes)
        print(&amp;#39;Inference took {} seconds&amp;#39;.format(str(time.time() - start_time)[:4]))
        # return detections, prediction_dict, tf.reshape(shapes, [-1])
        return detections
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;but that sadly doesn&amp;#39;t change the inference speed at all.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit:&lt;/p&gt;

&lt;p&gt;EfficientDet D7&lt;/p&gt;

&lt;p&gt;Step 0: Inference took 7.95 seconds&lt;/p&gt;

&lt;p&gt;Step 1: Inference took 0.96 seconds&lt;/p&gt;

&lt;p&gt;Step 2: Inference took 0.96 seconds&lt;/p&gt;

&lt;p&gt;Call-Trace: &lt;a href=""https://cdn.discordapp.com/attachments/462892567575658497/764139635701055539/efficientdet_d7_gpu_cpu.png""&gt;https://cdn.discordapp.com/attachments/462892567575658497/764139635701055539/efficientdet_d7_gpu_cpu.png&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t really know if there are any anomalies. Need to do further investigation.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit: According to some more knowledgeable person there is a corresponding GPU Kernel for the  NonMaxSuppressionV5 Operation which is consuming my CPU Pipeline.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/tensorflow/tensorflow/blob/e8598ce0454c440fca64e4ebc4aeedfa7afd5c97/tensorflow/core/kernels/image/non_max_suppression_op.cu.cc#L580""&gt;https://github.com/tensorflow/tensorflow/blob/e8598ce0454c440fca64e4ebc4aeedfa7afd5c97/tensorflow/core/kernels/image/non_max_suppression_op.cu.cc#L580&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I still need to figure out how to implement the GPU version&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j63ybu,True,,wNdRkNd,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j63ybu/cant_achieve_advertised_model_zoo_tf2_detection/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j63ybu/cant_achieve_advertised_model_zoo_tf2_detection/,22217,1601986487.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?auto=webp&amp;s=6d8ef0b9f9515009745e50bf7c0500f7916ef046', 'width': 1288, 'height': 1442}, 'resolutions': [{'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=538224279739b98c0656be32bad2b85bb4975956', 'width': 108, 'height': 120}, {'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c398046e220020c86e0b1a66cdc5a3d2fe02bd03', 'width': 216, 'height': 241}, {'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9880b8c62fdcf1a54b5e538f0f11603c93b84146', 'width': 320, 'height': 358}, {'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=71ad42c087f5325061d97e548780b8b44136e0a3', 'width': 640, 'height': 716}, {'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a7364fb7e849882a95d3a4bedb4251d2fb7e4454', 'width': 960, 'height': 1074}, {'url': 'https://external-preview.redd.it/IL9RNvc8LkV_ZWXgd2R6IIUKzoeb2CxKmmZJXWuOLH0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f7b3b9445c0dc390cf3380a28626c30eba4913f', 'width': 1080, 'height': 1209}], 'variants': {}, 'id': 'qF6PAleTayMw5P-i8OlVD89tUaJuJ4W03FyRK7Tzhjg'}], 'enabled': False}",,,,,,
706,,tensorflow,"Hi everyone! I'm working on a project about creating an agent that plays a Mortal Kombat game written in Javascript. My problem is that I want to train a deep learning model in Google Colab (Python + tensorflow) so my first idea is to ""migrate"" the project from JS to Python to train the model in a ""similar"" game environment, but surely there are better solutions, any advice?

Thank You!",t2_69jauppe,False,,0,False,How can I apply reinforcement learning in a Javascript environment?,[],r/tensorflow,False,6,,0,,,False,t3_j5tvqk,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1601967519.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone! I&amp;#39;m working on a project about creating an agent that plays a Mortal Kombat game written in Javascript. My problem is that I want to train a deep learning model in Google Colab (Python + tensorflow) so my first idea is to &amp;quot;migrate&amp;quot; the project from JS to Python to train the model in a &amp;quot;similar&amp;quot; game environment, but surely there are better solutions, any advice?&lt;/p&gt;

&lt;p&gt;Thank You!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j5tvqk,True,,mcarlomagno,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j5tvqk/how_can_i_apply_reinforcement_learning_in_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j5tvqk/how_can_i_apply_reinforcement_learning_in_a/,22217,1601938719.0,0,,False,,,,,,,,,
707,,tensorflow,"Mel-Frequency Cepstral Coefficients have traditionally been used in numerous speech and music processing problems. They are a somewhat elusive audio feature to grasp. In my new video, I introduce the concept of Cepstrum, illustrate its intuition, and discuss how we can extract MFCCs.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

https://www.youtube.com/watch?v=4\_SH2nfbQZ8&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=19",t2_12ahau,False,,0,False,I published a tutorial where I explain Mel-Frequency Cepstral Coefficients (MFCCs) easily,[],r/tensorflow,False,6,,0,,,False,t3_j5h35b,False,dark,0.93,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,self,False,,[],{},,True,,1601923030.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Mel-Frequency Cepstral Coefficients have traditionally been used in numerous speech and music processing problems. They are a somewhat elusive audio feature to grasp. In my new video, I introduce the concept of Cepstrum, illustrate its intuition, and discuss how we can extract MFCCs.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=4%5C_SH2nfbQZ8&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=19""&gt;https://www.youtube.com/watch?v=4\_SH2nfbQZ8&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=19&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j5h35b,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j5h35b/i_published_a_tutorial_where_i_explain/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j5h35b/i_published_a_tutorial_where_i_explain/,22217,1601894230.0,0,,False,,,,,,,,,
708,,tensorflow,"Most end users dont know how or wont follow manual install instructions. If they click it and it doesnt work, or at most click next next... next, they use some other program. I'm not looking for instructions how to in theory deploy tensorflow to desktop. I want to click someone's existing program then copy the parts of that already working deployment by removing their code and adding my own, then unzip it on other computers and it works instantly there too. Linux and Windows.",t2_1vezkas1,False,,0,False,What opensource programs for end user desktop include tensorflow?,[],r/tensorflow,False,6,,0,,,False,t3_j5kw10,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,1601910099.0,,[],{},,True,,1601938708.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Most end users dont know how or wont follow manual install instructions. If they click it and it doesnt work, or at most click next next... next, they use some other program. I&amp;#39;m not looking for instructions how to in theory deploy tensorflow to desktop. I want to click someone&amp;#39;s existing program then copy the parts of that already working deployment by removing their code and adding my own, then unzip it on other computers and it works instantly there too. Linux and Windows.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j5kw10,True,,isananimal,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j5kw10/what_opensource_programs_for_end_user_desktop/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j5kw10/what_opensource_programs_for_end_user_desktop/,22217,1601909908.0,0,,False,,,,,,,,,
709,,tensorflow,,t2_5moj37ik,False,,0,False,Supreme Commander - All Cinematics (Remastered 8K 60FPS),[],r/tensorflow,False,6,,0,105.0,,False,t3_j595yj,False,dark,0.87,,public,11,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yLBHxGhgAho?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Supreme Commander - All Cinematics (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yLBHxGhgAho?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yLBHxGhgAho/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yLBHxGhgAho?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j595yj', 'height': 338}",,False,11,,False,https://b.thumbs.redditmedia.com/U1IpbGfrbrG-7VOj2lUkDw3wt8EiNmdWaLe_WsQyqvg.jpg,False,,[],{},,False,,1601883993.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j595yj,True,,stepanmetior,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j595yj/supreme_commander_all_cinematics_remastered_8k/,all_ads,False,https://www.youtube.com/watch?v=yLBHxGhgAho&amp;feature=youtu.be,22217,1601855193.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Supreme Commander - All Cinematics (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yLBHxGhgAho?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yLBHxGhgAho/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=yLBHxGhgAho&amp;feature=youtu.be,"{'images': [{'source': {'url': 'https://external-preview.redd.it/7Gr9ffYA63zQJbZnAqX3PVVCPl5XiFkhysV573tnC58.jpg?auto=webp&amp;s=25f25499d4d0c5f58b4ba9da87714e8bca85d7c1', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/7Gr9ffYA63zQJbZnAqX3PVVCPl5XiFkhysV573tnC58.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81c86627ca13062f284897cba0abe14bf372caf5', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/7Gr9ffYA63zQJbZnAqX3PVVCPl5XiFkhysV573tnC58.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=269bec2dbcb0db95e9adc085a4def17f06c6e228', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/7Gr9ffYA63zQJbZnAqX3PVVCPl5XiFkhysV573tnC58.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5aad9b68b66ae858bf2131b0e0eb64ff37ba7927', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'wLuFiOKyGU3Nivk3qflPHcX0qClgaRY6WKAfX5xrYoY'}], 'enabled': False}",,,,,,
710,,tensorflow,,t2_3e708,False,,0,False,Build your own Alexa with the ESP32,[],r/tensorflow,False,6,,0,105.0,,False,t3_j4yfe2,False,dark,0.98,,public,28,1,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Build your own Alexa with the ESP32', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/re-dSV_a0tM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j4yfe2', 'height': 338}",,False,28,,True,https://b.thumbs.redditmedia.com/yd9vUPQ2wNvC9fUXY1xPZq97HAx_Pj8wvcmyue9aOXA.jpg,False,,[],{},,False,,1601844616.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4yfe2,True,,iamflimflam1,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j4yfe2/build_your_own_alexa_with_the_esp32/,all_ads,False,https://www.youtube.com/watch?v=re-dSV_a0tM&amp;feature=share,22217,1601815816.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Build your own Alexa with the ESP32', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/re-dSV_a0tM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}}",False,rich:video,https://www.youtube.com/watch?v=re-dSV_a0tM&amp;feature=share,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?auto=webp&amp;s=cea4a48c983f0199274a56d6a8eac3299d348950', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5cbf2a73e362d8f90f3ad15775ce3c8743991d60', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=860d2302d731e3bafaa2bca30275d1f6d192be95', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ae8c4ccea0b44ea07dc974a6d0beb54ee56764a', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'qrT0lsp4-NChl9wLVZfd2NhsKloCE4mnNaFIZagrLlY'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'esp32', 'selftext': '', 'author_fullname': 't2_3e708', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Build your own Alexa with the ESP32', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/esp32', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 105, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_j4yf8l', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 132, 'total_awards_received': 2, 'media_embed': {'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Build your own Alexa with the ESP32', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/re-dSV_a0tM/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}, 'type': 'youtube.com'}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j4yf8l', 'height': 338}, 'link_flair_text': None, 'can_mod_post': False, 'score': 132, 'approved_by': None, 'author_premium': True, 'thumbnail': 'https://b.thumbs.redditmedia.com/yd9vUPQ2wNvC9fUXY1xPZq97HAx_Pj8wvcmyue9aOXA.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'rich:video', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1601844595.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=re-dSV_a0tM&amp;feature=share', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?auto=webp&amp;s=cea4a48c983f0199274a56d6a8eac3299d348950', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5cbf2a73e362d8f90f3ad15775ce3c8743991d60', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=860d2302d731e3bafaa2bca30275d1f6d192be95', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/yAO5Wad_8HM1-dH9qtqHNV__abv1lv5CLyj4bkAtdlc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ae8c4ccea0b44ea07dc974a6d0beb54ee56764a', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'qrT0lsp4-NChl9wLVZfd2NhsKloCE4mnNaFIZagrLlY'}], 'enabled': False}, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'award_74fe5152-7906-4991-9016-bc2d8e261200', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': False, 'awardings_required_to_grant_benefits': None, 'description': ""I don't know what to do with my hands!"", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Excited', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png'}], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3bddg', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'j4yf8l', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'iamflimflam1', 'discussion_type': None, 'num_comments': 24, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/esp32/comments/j4yf8l/build_your_own_alexa_with_the_esp32/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.youtube.com/watch?v=re-dSV_a0tM&amp;feature=share', 'subreddit_subscribers': 34160, 'created_utc': 1601815795.0, 'num_crossposts': 1, 'media': {'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Build your own Alexa with the ESP32', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/re-dSV_a0tM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/re-dSV_a0tM/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}, 'type': 'youtube.com'}, 'is_video': False}]",t3_j4yf8l,
711,,tensorflow,"Hi all,

I made a post last night where I believed I was not using my GPUs at all.  I now think that's not true, but I am still a little confused by what's happening.

I followed [this guide](https://towardsdatascience.com/train-neural-networks-using-amd-gpus-and-keras-37189c453878) and am running the code below.  A few things stand out to me.

1. I'm getting 6ms per step which is slower than I got without trying to use both GPUs, and about 120 times slower than what the guide got with a single RX-480.
2. I can see that the GPUs are being used:

&amp;#x200B;

    ========================ROCm System Management Interface========================
    ================================================================================
    GPU  Temp   AvgPwr  SCLK    MCLK    Fan     Perf  PwrCap  VRAM%  GPU%  
    0    57.0c  27.0W   852Mhz  945Mhz  14.9%   auto  220.0W   95%   51%   
    1    50.0c  23.0W   852Mhz  167Mhz  13.73%  auto  220.0W   99%   54%   
    ================================================================================
    ==============================End of ROCm SMI Log ==============================

&amp;#x200B;

but the output lines `""INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).""` I am not sure what to make of.

&amp;#x200B;

Code and complete output:

    import tensorflow as tf; #2.3.1
    from tensorflow.keras.datasets import mnist
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Dropout
    from tensorflow.keras.optimizers import RMSprop
    from tensorflow.keras.utils import to_categorical
    strategy = tf.distribute.MirroredStrategy()
    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
    
    with strategy.scope():
        batch_size = 128
        num_classes = 10
        epochs = 10
    
        # the data, split between train and test sets
        (x_train, y_train), (x_test, y_test) = mnist.load_data()
        x_train = x_train.reshape(60000, 784)
        x_test = x_test.reshape(10000, 784)
        x_train = x_train.astype('float32')
        x_test = x_test.astype('float32')
        x_train /= 255
        x_test /= 255
        print(x_train.shape[0], 'train samples')
        print(x_test.shape[0], 'test samples')# convert class vectors to binary class matrices
        y_train = to_categorical(y_train, num_classes)
        y_test = to_categorical(y_test, num_classes)
    
        model = Sequential()
        model.add(Dense(512, activation='relu', input_shape=(784,)))
        model.add(Dropout(0.2))
        model.add(Dense(512, activation='relu'))
        model.add(Dropout(0.2))
        model.add(Dense(num_classes, activation='softmax'))
    
        model.summary()

Which yields:

    INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
    Number of devices: 2
    60000 train samples
    10000 test samples
    Model: ""sequential""
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense (Dense)                (None, 512)               401920    
    _________________________________________________________________
    dropout (Dropout)            (None, 512)               0         
    _________________________________________________________________
    dense_1 (Dense)              (None, 512)               262656    
    _________________________________________________________________
    dropout_1 (Dropout)          (None, 512)               0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 10)                5130      
    =================================================================
    Total params: 669,706
    Trainable params: 669,706
    Non-trainable params: 0

And then:

    model.compile(loss='categorical_crossentropy',
                  optimizer=RMSprop(),
                  metrics=['accuracy'])
    history = model.fit(x_train, y_train,
                        batch_size=batch_size,
                        epochs=epochs,
                        verbose=1,
                        validation_data=(x_test, y_test))

which yields:

    Epoch 1/10
    WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.data.Iterator.get_next_as_optional()` instead.
    INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    464/469 [============================&gt;.] - ETA: 0s - accuracy: 0.9248 - loss: 0.2446INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
    469/469 [==============================] - 4s 9ms/step - accuracy: 0.9252 - loss: 0.2433 - val_accuracy: 0.9578 - val_loss: 0.1437
    Epoch 2/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9689 - loss: 0.1028 - val_accuracy: 0.9724 - val_loss: 0.0916
    Epoch 3/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9769 - loss: 0.0768 - val_accuracy: 0.9789 - val_loss: 0.0733
    Epoch 4/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9823 - loss: 0.0611 - val_accuracy: 0.9805 - val_loss: 0.0676
    Epoch 5/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9848 - loss: 0.0517 - val_accuracy: 0.9810 - val_loss: 0.0746
    Epoch 6/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9871 - loss: 0.0437 - val_accuracy: 0.9814 - val_loss: 0.0759
    Epoch 7/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9888 - loss: 0.0381 - val_accuracy: 0.9793 - val_loss: 0.0958
    Epoch 8/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9901 - loss: 0.0344 - val_accuracy: 0.9827 - val_loss: 0.0833
    Epoch 9/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9901 - loss: 0.0316 - val_accuracy: 0.9813 - val_loss: 0.0923
    Epoch 10/10
    469/469 [==============================] - 3s 6ms/step - accuracy: 0.9921 - loss: 0.0275 - val_accuracy: 0.9828 - val_loss: 0.0874

I am completely new to all of this so any help would be enormously appreciated.",t2_4onunrh3,False,,0,False,"Getting very low performance with two GPUs (Ubuntu 20.04.1, Ryzen 1950X, 2 Vegas)",[],r/tensorflow,False,6,,0,,,False,t3_j4zx3d,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1601851048.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I made a post last night where I believed I was not using my GPUs at all.  I now think that&amp;#39;s not true, but I am still a little confused by what&amp;#39;s happening.&lt;/p&gt;

&lt;p&gt;I followed &lt;a href=""https://towardsdatascience.com/train-neural-networks-using-amd-gpus-and-keras-37189c453878""&gt;this guide&lt;/a&gt; and am running the code below.  A few things stand out to me.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I&amp;#39;m getting 6ms per step which is slower than I got without trying to use both GPUs, and about 120 times slower than what the guide got with a single RX-480.&lt;/li&gt;
&lt;li&gt;I can see that the GPUs are being used:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;========================ROCm System Management Interface========================
================================================================================
GPU  Temp   AvgPwr  SCLK    MCLK    Fan     Perf  PwrCap  VRAM%  GPU%  
0    57.0c  27.0W   852Mhz  945Mhz  14.9%   auto  220.0W   95%   51%   
1    50.0c  23.0W   852Mhz  167Mhz  13.73%  auto  220.0W   99%   54%   
================================================================================
==============================End of ROCm SMI Log ==============================
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;but the output lines &lt;code&gt;&amp;quot;INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).&amp;quot;&lt;/code&gt; I am not sure what to make of.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Code and complete output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf; #2.3.1
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.utils import to_categorical
strategy = tf.distribute.MirroredStrategy()
print(&amp;#39;Number of devices: {}&amp;#39;.format(strategy.num_replicas_in_sync))

with strategy.scope():
    batch_size = 128
    num_classes = 10
    epochs = 10

    # the data, split between train and test sets
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(60000, 784)
    x_test = x_test.reshape(10000, 784)
    x_train = x_train.astype(&amp;#39;float32&amp;#39;)
    x_test = x_test.astype(&amp;#39;float32&amp;#39;)
    x_train /= 255
    x_test /= 255
    print(x_train.shape[0], &amp;#39;train samples&amp;#39;)
    print(x_test.shape[0], &amp;#39;test samples&amp;#39;)# convert class vectors to binary class matrices
    y_train = to_categorical(y_train, num_classes)
    y_test = to_categorical(y_test, num_classes)

    model = Sequential()
    model.add(Dense(512, activation=&amp;#39;relu&amp;#39;, input_shape=(784,)))
    model.add(Dropout(0.2))
    model.add(Dense(512, activation=&amp;#39;relu&amp;#39;))
    model.add(Dropout(0.2))
    model.add(Dense(num_classes, activation=&amp;#39;softmax&amp;#39;))

    model.summary()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which yields:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;INFO:tensorflow:Using MirroredStrategy with devices (&amp;#39;/job:localhost/replica:0/task:0/device:GPU:0&amp;#39;, &amp;#39;/job:localhost/replica:0/task:0/device:GPU:1&amp;#39;)
Number of devices: 2
60000 train samples
10000 test samples
Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 512)               401920    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               262656    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
=================================================================
Total params: 669,706
Trainable params: 669,706
Non-trainable params: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;,
              optimizer=RMSprop(),
              metrics=[&amp;#39;accuracy&amp;#39;])
history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(x_test, y_test))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which yields:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Epoch 1/10
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Iterator.get_next_as_optional()` instead.
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
464/469 [============================&amp;gt;.] - ETA: 0s - accuracy: 0.9248 - loss: 0.2446INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&amp;#39;/job:localhost/replica:0/task:0/device:CPU:0&amp;#39;,).
469/469 [==============================] - 4s 9ms/step - accuracy: 0.9252 - loss: 0.2433 - val_accuracy: 0.9578 - val_loss: 0.1437
Epoch 2/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9689 - loss: 0.1028 - val_accuracy: 0.9724 - val_loss: 0.0916
Epoch 3/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9769 - loss: 0.0768 - val_accuracy: 0.9789 - val_loss: 0.0733
Epoch 4/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9823 - loss: 0.0611 - val_accuracy: 0.9805 - val_loss: 0.0676
Epoch 5/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9848 - loss: 0.0517 - val_accuracy: 0.9810 - val_loss: 0.0746
Epoch 6/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9871 - loss: 0.0437 - val_accuracy: 0.9814 - val_loss: 0.0759
Epoch 7/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9888 - loss: 0.0381 - val_accuracy: 0.9793 - val_loss: 0.0958
Epoch 8/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9901 - loss: 0.0344 - val_accuracy: 0.9827 - val_loss: 0.0833
Epoch 9/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9901 - loss: 0.0316 - val_accuracy: 0.9813 - val_loss: 0.0923
Epoch 10/10
469/469 [==============================] - 3s 6ms/step - accuracy: 0.9921 - loss: 0.0275 - val_accuracy: 0.9828 - val_loss: 0.0874
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am completely new to all of this so any help would be enormously appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4zx3d,True,,wentdot,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j4zx3d/getting_very_low_performance_with_two_gpus_ubuntu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j4zx3d/getting_very_low_performance_with_two_gpus_ubuntu/,22217,1601822248.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?auto=webp&amp;s=7517e9c05cc2e1d48def66777378b4bc6ed736b2', 'width': 1200, 'height': 1200}, 'resolutions': [{'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e049cb21435be6d3710b03a3854708ea61bfa6f1', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=050a4b614197b958d587461b95d34c145852a2dd', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f249378f6e6b32fa80e6e74539db37db69437ee6', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c62ee6bac76ce8b83b6a7a506a67a8973e1c577', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e2b9bcfb3289aa8c63da5a7083b4c408469b8839', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87f1a3ab595ecc054f783b0ef8068be438525966', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': 'y-s_XMQm9f5KytPnVS6vGoGJsxspncbL_nlm5p9B36g'}], 'enabled': False}",,,,,,
712,,tensorflow,"I just passed the Tensorflow Developer Certification Exam yesterday, I've heard from others that there might be a hoodie to purchase after you passed the exam, is that true? It would be really swag if there is one.",t2_33jkt2kj,False,,0,False,Tensorflow Developer Certification Hoodie,[],r/tensorflow,False,6,,0,,,False,t3_j4rfs0,False,dark,1.0,,public,13,0,{},,,False,[],,False,False,,{},,False,13,,False,self,False,,[],{},,True,,1601806910.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just passed the Tensorflow Developer Certification Exam yesterday, I&amp;#39;ve heard from others that there might be a hoodie to purchase after you passed the exam, is that true? It would be really swag if there is one.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4rfs0,True,,ghnreigns,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j4rfs0/tensorflow_developer_certification_hoodie/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j4rfs0/tensorflow_developer_certification_hoodie/,22217,1601778110.0,0,,False,,,,,,,,,
713,,tensorflow,"EDIT: I now believe the issue is a little different than I wrote here.  I made a newer post [here.](https://www.reddit.com/r/tensorflow/comments/j4zx3d/getting_very_low_performance_with_two_gpus_ubuntu/)

&amp;#x200B;

Hi all,

I installed everything this afternoon and I thought I'd figured it out, but I am having an issue where I can see that only my cpu is being used by tensorflow.  For reference, I followed this guide:

[https://towardsdatascience.com/train-neural-networks-using-amd-gpus-and-keras-37189c453878](https://towardsdatascience.com/train-neural-networks-using-amd-gpus-and-keras-37189c453878)

When I run jupyter notebooks I see this, but I can watch my CPU usage go up when I run the example code given in the tutorial and also see that the time per step is abysmal compared to what it ought to be (3ms / step).  Any tips would be appreciated!

    Kernel started: dc0e3dd4-cb8b-4966-808c-275109d7d828, name: python3
    2020-10-04 00:55:54.504572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libamdhip64.so
    2020-10-04 00:55:54.590711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: 
    pciBusID: 0000:0c:00.0 name: Vega 10 XTX [Radeon Vega Frontier Edition]     ROCm AMD GPU ISA: gfx900
    coreClock: 1.6GHz coreCount: 64 deviceMemorySize: 15.98GiB deviceMemoryBandwidth: 450.61GiB/s
    2020-10-04 00:55:54.590778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 1 with properties: 
    pciBusID: 0000:43:00.0 name: Vega 10 XT [Radeon RX Vega 64]     ROCm AMD GPU ISA: gfx900
    coreClock: 1.63GHz coreCount: 64 deviceMemorySize: 7.98GiB deviceMemoryBandwidth: 450.61GiB/s
    2020-10-04 00:55:54.594086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocblas.so
    2020-10-04 00:55:54.595564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libMIOpen.so
    2020-10-04 00:55:54.602565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocfft.so
    2020-10-04 00:55:54.602838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocrand.so
    2020-10-04 00:55:54.603009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
    2020-10-04 00:55:54.609553: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3399600000 Hz
    2020-10-04 00:55:54.610598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58e1970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
    2020-10-04 00:55:54.610622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
    2020-10-04 00:55:54.613108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x594d650 initialized for platform ROCM (this does not guarantee that XLA will be used). Devices:
    2020-10-04 00:55:54.613127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Vega 10 XTX [Radeon Vega Frontier Edition], AMDGPU ISA version: gfx900
    2020-10-04 00:55:54.613137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Vega 10 XT [Radeon RX Vega 64], AMDGPU ISA version: gfx900
    2020-10-04 00:55:55.259440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: 
    pciBusID: 0000:0c:00.0 name: Vega 10 XTX [Radeon Vega Frontier Edition]     ROCm AMD GPU ISA: gfx900
    coreClock: 1.6GHz coreCount: 64 deviceMemorySize: 15.98GiB deviceMemoryBandwidth: 450.61GiB/s
    2020-10-04 00:55:55.259541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 1 with properties: 
    pciBusID: 0000:43:00.0 name: Vega 10 XT [Radeon RX Vega 64]     ROCm AMD GPU ISA: gfx900
    coreClock: 1.63GHz coreCount: 64 deviceMemorySize: 7.98GiB deviceMemoryBandwidth: 450.61GiB/s
    2020-10-04 00:55:55.259583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocblas.so
    2020-10-04 00:55:55.259604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libMIOpen.so
    2020-10-04 00:55:55.259627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocfft.so
    2020-10-04 00:55:55.259650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocrand.so
    2020-10-04 00:55:55.259940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
    2020-10-04 00:55:55.259972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
    2020-10-04 00:55:55.259983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
    2020-10-04 00:55:55.259991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
    2020-10-04 00:55:55.259998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
    2020-10-04 00:55:55.260233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15385 MB memory) -&gt; physical GPU (device: 0, name: Vega 10 XTX [Radeon Vega Frontier Edition], pci bus id: 0000:0c:00.0)
    2020-10-04 00:55:55.265708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7685 MB memory) -&gt; physical GPU (device: 1, name: Vega 10 XT [Radeon RX Vega 64], pci bus id: 0000:43:00.0)
    2020-10-04 00:55:59.028748: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:506] ROCm Fusion is enabled.",t2_4onunrh3,False,,0,False,"Using Tensorflow/ROCM with Ryzen Threadripper 1950X and two Vegas, Ubuntu 20.04.1 - only CPU is being used, despite visible GPUs",[],r/tensorflow,False,6,,0,,,False,t3_j4qfet,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},,False,8,,False,self,1601822588.0,,[],{},,True,,1601802456.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;EDIT: I now believe the issue is a little different than I wrote here.  I made a newer post &lt;a href=""https://www.reddit.com/r/tensorflow/comments/j4zx3d/getting_very_low_performance_with_two_gpus_ubuntu/""&gt;here.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I installed everything this afternoon and I thought I&amp;#39;d figured it out, but I am having an issue where I can see that only my cpu is being used by tensorflow.  For reference, I followed this guide:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://towardsdatascience.com/train-neural-networks-using-amd-gpus-and-keras-37189c453878""&gt;https://towardsdatascience.com/train-neural-networks-using-amd-gpus-and-keras-37189c453878&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When I run jupyter notebooks I see this, but I can watch my CPU usage go up when I run the example code given in the tutorial and also see that the time per step is abysmal compared to what it ought to be (3ms / step).  Any tips would be appreciated!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Kernel started: dc0e3dd4-cb8b-4966-808c-275109d7d828, name: python3
2020-10-04 00:55:54.504572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libamdhip64.so
2020-10-04 00:55:54.590711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: Vega 10 XTX [Radeon Vega Frontier Edition]     ROCm AMD GPU ISA: gfx900
coreClock: 1.6GHz coreCount: 64 deviceMemorySize: 15.98GiB deviceMemoryBandwidth: 450.61GiB/s
2020-10-04 00:55:54.590778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 1 with properties: 
pciBusID: 0000:43:00.0 name: Vega 10 XT [Radeon RX Vega 64]     ROCm AMD GPU ISA: gfx900
coreClock: 1.63GHz coreCount: 64 deviceMemorySize: 7.98GiB deviceMemoryBandwidth: 450.61GiB/s
2020-10-04 00:55:54.594086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocblas.so
2020-10-04 00:55:54.595564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libMIOpen.so
2020-10-04 00:55:54.602565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocfft.so
2020-10-04 00:55:54.602838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocrand.so
2020-10-04 00:55:54.603009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-10-04 00:55:54.609553: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3399600000 Hz
2020-10-04 00:55:54.610598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58e1970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-04 00:55:54.610622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-04 00:55:54.613108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x594d650 initialized for platform ROCM (this does not guarantee that XLA will be used). Devices:
2020-10-04 00:55:54.613127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Vega 10 XTX [Radeon Vega Frontier Edition], AMDGPU ISA version: gfx900
2020-10-04 00:55:54.613137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Vega 10 XT [Radeon RX Vega 64], AMDGPU ISA version: gfx900
2020-10-04 00:55:55.259440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: Vega 10 XTX [Radeon Vega Frontier Edition]     ROCm AMD GPU ISA: gfx900
coreClock: 1.6GHz coreCount: 64 deviceMemorySize: 15.98GiB deviceMemoryBandwidth: 450.61GiB/s
2020-10-04 00:55:55.259541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 1 with properties: 
pciBusID: 0000:43:00.0 name: Vega 10 XT [Radeon RX Vega 64]     ROCm AMD GPU ISA: gfx900
coreClock: 1.63GHz coreCount: 64 deviceMemorySize: 7.98GiB deviceMemoryBandwidth: 450.61GiB/s
2020-10-04 00:55:55.259583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocblas.so
2020-10-04 00:55:55.259604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libMIOpen.so
2020-10-04 00:55:55.259627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocfft.so
2020-10-04 00:55:55.259650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library librocrand.so
2020-10-04 00:55:55.259940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-10-04 00:55:55.259972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-04 00:55:55.259983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
2020-10-04 00:55:55.259991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
2020-10-04 00:55:55.259998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
2020-10-04 00:55:55.260233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15385 MB memory) -&amp;gt; physical GPU (device: 0, name: Vega 10 XTX [Radeon Vega Frontier Edition], pci bus id: 0000:0c:00.0)
2020-10-04 00:55:55.265708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7685 MB memory) -&amp;gt; physical GPU (device: 1, name: Vega 10 XT [Radeon RX Vega 64], pci bus id: 0000:43:00.0)
2020-10-04 00:55:59.028748: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:506] ROCm Fusion is enabled.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4qfet,True,,wentdot,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j4qfet/using_tensorflowrocm_with_ryzen_threadripper/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j4qfet/using_tensorflowrocm_with_ryzen_threadripper/,22217,1601773656.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?auto=webp&amp;s=7517e9c05cc2e1d48def66777378b4bc6ed736b2', 'width': 1200, 'height': 1200}, 'resolutions': [{'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e049cb21435be6d3710b03a3854708ea61bfa6f1', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=050a4b614197b958d587461b95d34c145852a2dd', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f249378f6e6b32fa80e6e74539db37db69437ee6', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c62ee6bac76ce8b83b6a7a506a67a8973e1c577', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e2b9bcfb3289aa8c63da5a7083b4c408469b8839', 'width': 960, 'height': 960}, {'url': 'https://external-preview.redd.it/yDMtjhY6oY22wdkZvQJVWgF8l3lhnXvknTRMfwYI20I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87f1a3ab595ecc054f783b0ef8068be438525966', 'width': 1080, 'height': 1080}], 'variants': {}, 'id': 'y-s_XMQm9f5KytPnVS6vGoGJsxspncbL_nlm5p9B36g'}], 'enabled': False}",,,,,,
714,,tensorflow,,t2_44mbtmjy,False,,0,False,"Latest from USC researchers: Given a single neutral scan, researchers generate a complete set of dynamic face model assets, including personalized blendshapes and physically-based dynamic facial skin textures of the input individual!",[],r/tensorflow,False,6,,0,57.0,,False,t3_j4ow4k,False,dark,1.0,,public,6,0,{},140.0,,False,[],,False,False,,{},,False,6,,False,https://b.thumbs.redditmedia.com/JHy2vjKukU-QBhXKMcYR0ilwFs5rMAd3r05F2nACvrs.jpg,False,,[],{},,False,,1601796062.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4ow4k,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j4ow4k/latest_from_usc_researchers_given_a_single/,all_ads,False,/r/LatestInML/comments/j4ov82/latest_from_usc_researchers_given_a_single/,22217,1601767262.0,0,,False,link,/r/LatestInML/comments/j4ov82/latest_from_usc_researchers_given_a_single/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?auto=webp&amp;s=e7804f63cc4fe6fa74953a8cd639cbd0a99ae66b', 'width': 1416, 'height': 560}, 'resolutions': [{'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2cfc05051cfdf58ad5e7535e33f1dec6d3376b8a', 'width': 108, 'height': 42}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3782a935836b933c81d338b24c7b9135ad42155', 'width': 216, 'height': 85}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8acaf13db31258f7a6cbc071230e383ad8c0178c', 'width': 320, 'height': 126}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0bd96f22422da27e6f16d4ec763dc3d9a57375f8', 'width': 640, 'height': 253}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ba05363fc63ca621fde524a46ecb5ed7b7a5fdd2', 'width': 960, 'height': 379}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=047e6ae1f35e0201696d6fc9b6ba4e46286249dc', 'width': 1080, 'height': 427}], 'variants': {}, 'id': 'fIC6MV79UrjbkKAupqmUulZM8sI8ATbNy3zGwXzZXuk'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and expert/code/API request: [click here](https://www.catalyzex.com/paper/arxiv:2010.00560)\n\nhttps://preview.redd.it/cdl5h39mqyq51.jpg?width=1906&amp;format=pjpg&amp;auto=webp&amp;s=a85ce1c1150abd3bef95236ea3f1b74682c87d9c', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from USC researchers: Given a single neutral scan, researchers generate a complete set of dynamic face model assets, including personalized blendshapes and physically-based dynamic facial skin textures of the input individual!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 57, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'cdl5h39mqyq51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 44, 'x': 108, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4559f52c05b66ae24e4c9410911a51d765a02ef7'}, {'y': 88, 'x': 216, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf64c80c29fd0461ce3a88db4c5df22a3af4188d'}, {'y': 130, 'x': 320, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=689cad57ad863d3c0db038748d1c50c332825ce1'}, {'y': 261, 'x': 640, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6862fa25ab45bf3107857e46fcf7e30d8c8e09d4'}, {'y': 392, 'x': 960, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a0f1aae5fe1770f75bfa67606e412a4e73eda0d4'}, {'y': 441, 'x': 1080, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c8320df62ef0aab032c1b28ebfa803731b55f617'}], 's': {'y': 780, 'x': 1906, 'u': 'https://preview.redd.it/cdl5h39mqyq51.jpg?width=1906&amp;format=pjpg&amp;auto=webp&amp;s=a85ce1c1150abd3bef95236ea3f1b74682c87d9c'}, 'id': 'cdl5h39mqyq51'}}, 'name': 't3_j4ov82', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 22, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 22, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/JHy2vjKukU-QBhXKMcYR0ilwFs5rMAd3r05F2nACvrs.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1601795962.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and expert/code/API request: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2010.00560""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/cdl5h39mqyq51.jpg?width=1906&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a85ce1c1150abd3bef95236ea3f1b74682c87d9c""&gt;https://preview.redd.it/cdl5h39mqyq51.jpg?width=1906&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a85ce1c1150abd3bef95236ea3f1b74682c87d9c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?auto=webp&amp;s=e7804f63cc4fe6fa74953a8cd639cbd0a99ae66b', 'width': 1416, 'height': 560}, 'resolutions': [{'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2cfc05051cfdf58ad5e7535e33f1dec6d3376b8a', 'width': 108, 'height': 42}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3782a935836b933c81d338b24c7b9135ad42155', 'width': 216, 'height': 85}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8acaf13db31258f7a6cbc071230e383ad8c0178c', 'width': 320, 'height': 126}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0bd96f22422da27e6f16d4ec763dc3d9a57375f8', 'width': 640, 'height': 253}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ba05363fc63ca621fde524a46ecb5ed7b7a5fdd2', 'width': 960, 'height': 379}, {'url': 'https://external-preview.redd.it/g3DkrbKGB6YEuOu1q5xzu__4ww4tx1sSP1JbfRcCT_Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=047e6ae1f35e0201696d6fc9b6ba4e46286249dc', 'width': 1080, 'height': 427}], 'variants': {}, 'id': 'fIC6MV79UrjbkKAupqmUulZM8sI8ATbNy3zGwXzZXuk'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'j4ov82', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/j4ov82/latest_from_usc_researchers_given_a_single/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/j4ov82/latest_from_usc_researchers_given_a_single/', 'subreddit_subscribers': 6676, 'created_utc': 1601767162.0, 'num_crossposts': 12, 'media': None, 'is_video': False}]",t3_j4ov82,
715,,tensorflow," 

Hello. I am a art student. And in my profession I use a lot of new technology. 3d printing, But also unity and VR. But now I want to learn how to make a specific GAN. The GAN I would like to make. Is a smaller version of thispersondoesnotexist site but now with faces i present to the GAN.Im wondering if there is already a pretty basic premade version of that one. Or a guide on how to make one yourself. I know my way around code. atleast I can read it to a certain degree. Im not an expert. I cant write code out of the top of my head. But following a guide is not that hard for me.

Is there somebody who can send me a direction.

I would also like to make a gan that takes for example all Rembrandt Paintings. And then creates something new out of it. The end result doesnt need to be perfect.

I have a high end pc with a 3080 btw.",t2_dysp7,False,,0,False,Art student. and ex-IT student want to use a GAN,[],r/tensorflow,False,6,,0,,,False,t3_j4m83g,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1601785984.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello. I am a art student. And in my profession I use a lot of new technology. 3d printing, But also unity and VR. But now I want to learn how to make a specific GAN. The GAN I would like to make. Is a smaller version of thispersondoesnotexist site but now with faces i present to the GAN.Im wondering if there is already a pretty basic premade version of that one. Or a guide on how to make one yourself. I know my way around code. atleast I can read it to a certain degree. Im not an expert. I cant write code out of the top of my head. But following a guide is not that hard for me.&lt;/p&gt;

&lt;p&gt;Is there somebody who can send me a direction.&lt;/p&gt;

&lt;p&gt;I would also like to make a gan that takes for example all Rembrandt Paintings. And then creates something new out of it. The end result doesnt need to be perfect.&lt;/p&gt;

&lt;p&gt;I have a high end pc with a 3080 btw.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j4m83g,True,,ephemeralkazu,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/j4m83g/art_student_and_exit_student_want_to_use_a_gan/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j4m83g/art_student_and_exit_student_want_to_use_a_gan/,22217,1601757184.0,0,,False,,,,,,,,,
716,,tensorflow,"Does anyone know how to make an object detector form scratch? Preferably it trains from images with boundary boxes. Can you pls explain to me how it works, im quite new to tensorflow.",t2_6378kyom,False,,0,False,Quick question,[],r/tensorflow,False,6,,0,,,False,t3_j4o9fq,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1601793561.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone know how to make an object detector form scratch? Preferably it trains from images with boundary boxes. Can you pls explain to me how it works, im quite new to tensorflow.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4o9fq,True,,Fun-Programmer4564,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j4o9fq/quick_question/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j4o9fq/quick_question/,22217,1601764761.0,0,,False,,,,,,,,,
717,,tensorflow,Is it possible to have an AMD card as the main driver for your system and have a Nvidia card in the spare pcie slot just for tensorflow? (Windows 10),t2_5z0kf,False,,0,False,Installing a AMD and Nvidia gpu into same machine.,[],r/tensorflow,False,6,,0,,,False,t3_j4f9c0,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1601761539.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to have an AMD card as the main driver for your system and have a Nvidia card in the spare pcie slot just for tensorflow? (Windows 10)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j4f9c0,True,,CammyBear,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/j4f9c0/installing_a_amd_and_nvidia_gpu_into_same_machine/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j4f9c0/installing_a_amd_and_nvidia_gpu_into_same_machine/,22217,1601732739.0,0,,False,,,,,,,,,
718,,tensorflow,,t2_xy0vran,False,,0,False,Learn to build Image classification API with TensorFlow. https://youtu.be/23R2eI95S30,[],r/tensorflow,False,6,,0,78.0,,False,t3_j42uwf,False,dark,0.88,,public,25,0,{},140.0,,False,[],"{'reddit_video': {'fallback_url': 'https://v.redd.it/tp2hbrwuvqq51/DASH_720.mp4?source=fallback', 'height': 720, 'width': 1280, 'scrubber_media_url': 'https://v.redd.it/tp2hbrwuvqq51/DASH_96.mp4', 'dash_url': 'https://v.redd.it/tp2hbrwuvqq51/DASHPlaylist.mpd?a=1618044818%2CYTE4MWZmNGY0YzYzN2QzOGU2OWNlYmQ3YjcyNjU1ZjQ0M2M3Yzg2MDE3ZGViOWQyYWQ0Njk2ZTU3ODdkNmY4OQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 66, 'hls_url': 'https://v.redd.it/tp2hbrwuvqq51/HLSPlaylist.m3u8?a=1618044818%2CMzQ1ODY2ZTE0OGQ3MDIyZjlkZDE1YmNiMjM4OTFlNzc1NDI1YjBkODYwZmFlOTUyOWVjZTJhZTgxYTc5MGFlZQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,25,,False,https://b.thumbs.redditmedia.com/_g1SlX_BPdjhAxrlZPCmNe08UjhDWex33lQGt-xX0jI.jpg,False,,[],{},,False,,1601701021.0,text,6,,,text,v.redd.it,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j42uwf,True,,aniketmaurya,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j42uwf/learn_to_build_image_classification_api_with/,all_ads,False,https://v.redd.it/tp2hbrwuvqq51,22217,1601672221.0,0,"{'reddit_video': {'fallback_url': 'https://v.redd.it/tp2hbrwuvqq51/DASH_720.mp4?source=fallback', 'height': 720, 'width': 1280, 'scrubber_media_url': 'https://v.redd.it/tp2hbrwuvqq51/DASH_96.mp4', 'dash_url': 'https://v.redd.it/tp2hbrwuvqq51/DASHPlaylist.mpd?a=1618044818%2CYTE4MWZmNGY0YzYzN2QzOGU2OWNlYmQ3YjcyNjU1ZjQ0M2M3Yzg2MDE3ZGViOWQyYWQ0Njk2ZTU3ODdkNmY4OQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 66, 'hls_url': 'https://v.redd.it/tp2hbrwuvqq51/HLSPlaylist.m3u8?a=1618044818%2CMzQ1ODY2ZTE0OGQ3MDIyZjlkZDE1YmNiMjM4OTFlNzc1NDI1YjBkODYwZmFlOTUyOWVjZTJhZTgxYTc5MGFlZQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,hosted:video,https://v.redd.it/tp2hbrwuvqq51,"{'images': [{'source': {'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?format=pjpg&amp;auto=webp&amp;s=ceaf01d1f6edf99512a3d5b06dc2f86cc9abbfea', 'width': 1280, 'height': 720}, 'resolutions': [{'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0e5bcba0bcd8e677b724e5535a751db65acec6b4', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ef5b31118b0b40ca1f710d3a31c3515779b36f34', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=36e6ce2d060ff24dcf951a8ce6ddcc558394fd5b', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=77e7821397985810b6e35713b81ca6d6f0ef64d1', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7abb7081bc2fce1574e96911598036f0b506aa82', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/alIjSkEIJyNiU2BXQvvc90_7jvACNbpL7jhNw0ic7Zk.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=30e7c5ae7743ab3ddb3b488734bb472ae85a1323', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '0mpR5WvaDErcPhMYIQ5DT2sRdWI8VH3fV5fDxg7K4rs'}], 'enabled': False}",,,,,,
719,,tensorflow,"[https://github.com/iglaweb/TFProfiler](https://github.com/iglaweb/TFProfiler)  


TFProfiler is an app to profile TensorFlow Lite model and measure its performance using FPS, model initialization time, model inference time, memory consumption, etc right on device. You can tweak model runs with different delegates (CPU, GPU, NNAPI, HEXAGON), XNNPACK option, number of threads, etc.",t2_1069v9,False,,0,False,TFProfiler to profile your .tflite model with one click,[],r/tensorflow,False,6,,0,,,False,t3_j42nsd,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1601700370.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/iglaweb/TFProfiler""&gt;https://github.com/iglaweb/TFProfiler&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;TFProfiler is an app to profile TensorFlow Lite model and measure its performance using FPS, model initialization time, model inference time, memory consumption, etc right on device. You can tweak model runs with different delegates (CPU, GPU, NNAPI, HEXAGON), XNNPACK option, number of threads, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j42nsd,True,,iglaweb,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j42nsd/tfprofiler_to_profile_your_tflite_model_with_one/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j42nsd/tfprofiler_to_profile_your_tflite_model_with_one/,22217,1601671570.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?auto=webp&amp;s=ba307190d13a736ff335252fcde9eefd17e6be50', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0545416e5deb894f81e90ce1dcd93acc700fe40b', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff7b4175bf1b9ff3e1f69cc6b148ab6dc344dc11', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/jCOjGa94wLZ2UHAtMECCdh9TewtPXZ2vAZhdpHOUep4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=680dfa26f6493040dbf0d755e595d774ae161e70', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'ksYP-l3VbTqB9qMbGb6zbd9Mw6rCYwSnQsJUCYcBuU0'}], 'enabled': False}",,,,,,
720,,tensorflow,,t2_v7nu2,False,,0,False,"John Snow Labs Spark-NLP 2.6.2: New SentenceDetectorDL, improved BioBERT models, new Models Hub, and other improvements!",[],r/tensorflow,False,6,,0,70.0,,False,t3_j3uabw,False,dark,0.9,,public,7,0,{},140.0,,False,[],,False,False,,{},,False,7,,False,https://b.thumbs.redditmedia.com/JK4pUeYrFZpDOS_c9MNcuFIwOMWE_t_d5UHFiRoVJpU.jpg,False,,[],{},,False,,1601673508.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j3uabw,True,,dark-night-rises,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j3uabw/john_snow_labs_sparknlp_262_new/,all_ads,False,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.2,22217,1601644708.0,0,,False,link,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.2,"{'images': [{'source': {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?auto=webp&amp;s=26d4e2ccac57601a99f4cf45d17f0e00f92fead8', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d55caafe011d4551ac15197e82b07dc37606c085', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e16ade26c248b8f9dfe83d12e5a437af7764697', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6301bc373904ebf9e06640d72df79738f466d080', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c3eadd9c1d9a2e41e1b423431c1666469d533309', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d59956f28b0a75b5571510adebb6a47c3dff02e2', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cd7fba8bfcb78eb50ebaa2190e9d66a954f7bf8', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'jMsd8PwIcNruRH9ONi-X0NcTUSJ4CHYE0cb1s8qw_TI'}], 'enabled': False}",,,,,,
721,,tensorflow,,t2_ibs89,False,,0,False,Optimize runtime memory,[],r/tensorflow,False,6,,0,46.0,,False,t3_j40nv3,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/R-Zfx8NIM6qYSCh1J4JffdAXlLiRxDxDhWgLPqOzqrg.jpg,False,,[],{},,False,,1601693998.0,text,6,,,text,blog.tensorflow.org,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j40nv3,True,,nbortolotti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j40nv3/optimize_runtime_memory/,all_ads,False,https://blog.tensorflow.org/2020/10/optimizing-tensorflow-lite-runtime.html,22217,1601665198.0,0,,False,link,https://blog.tensorflow.org/2020/10/optimizing-tensorflow-lite-runtime.html,"{'images': [{'source': {'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?auto=webp&amp;s=fadca660d4dad21f5be0468f9378ecdcf344f65f', 'width': 1200, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38031b1f7c42b687c52b60adf7eb8b29b7f87641', 'width': 108, 'height': 36}, {'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c771747cf0381e5e5723bb6fe2c96444e378d4b', 'width': 216, 'height': 72}, {'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f7748f41b393d546f506aa0079a0d53482513a', 'width': 320, 'height': 106}, {'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=75ff9d076cf7720437cc3d40031be38304f4a20a', 'width': 640, 'height': 213}, {'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=19ff1c675d339fa7cecf304dd9b30e8d9e15940b', 'width': 960, 'height': 320}, {'url': 'https://external-preview.redd.it/xmQD4WK52xnPpfu8hJRXPAtL5fQpJUhc-UQllqZWeOA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ca534c2afd12fce5cca8b5cce672d5dc8c3c61f1', 'width': 1080, 'height': 360}], 'variants': {}, 'id': 'NASC7MuLbRTMymY78Ou1Z1jNvn5Z-9TQIlf3NW00hPI'}], 'enabled': False}",,,,,,
722,,tensorflow,"Hello, student here, I am in a class this semester which requires tensorflow and a GPU to use it (no problem)

However, after receiving the first TF assignment, the class is requiring us to use tf 1.10.

This does not seem to be compatible with CUDA10 and by extension I cannot use it with my RTX 2060.

I can get 1.15 working just fine.

Is there a guide anywhere to get this up and running?

(This 1.10 requirement is throwing the entire class into chaos for seemingly everyone)",t2_rejz1,False,,0,False,(beginner) Using old TF version with RTX/CUDA10,[],r/tensorflow,False,6,,0,,,False,t3_j3mwyk,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1601636514.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, student here, I am in a class this semester which requires tensorflow and a GPU to use it (no problem)&lt;/p&gt;

&lt;p&gt;However, after receiving the first TF assignment, the class is requiring us to use tf 1.10.&lt;/p&gt;

&lt;p&gt;This does not seem to be compatible with CUDA10 and by extension I cannot use it with my RTX 2060.&lt;/p&gt;

&lt;p&gt;I can get 1.15 working just fine.&lt;/p&gt;

&lt;p&gt;Is there a guide anywhere to get this up and running?&lt;/p&gt;

&lt;p&gt;(This 1.10 requirement is throwing the entire class into chaos for seemingly everyone)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j3mwyk,True,,SloppyCandy,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j3mwyk/beginner_using_old_tf_version_with_rtxcuda10/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j3mwyk/beginner_using_old_tf_version_with_rtxcuda10/,22217,1601607714.0,0,,False,,,,,,,,,
723,,tensorflow,"I've just upgraded to a 3090 FE from my old 1080 Ti, and installed the new drivers, etc. But now anything I run with tensorflow seems to output garbage data. Has anyone had anything like this happen to them before?

For example, just running inference on a pretrained stylegan2 model outputs random noisy images (oddly the first image it generates seems to be mostly ok). Examples: [https://imgur.com/a/tiqZVld](https://imgur.com/a/tiqZVld)

If I try to train any model the losses/weights end up going to NaN almost instantly (using FP32, not FP16). For stylegan2 it crashes when training due to NaN matrix values.

My first thought was some kind of hardware error, but video games/passmark seem to run fine. So I'm a bit stumped. Maybe it's an issue with conflicting cuda versions or something? I've tried a few different models with different tensorflow versions. Also reinstalled drivers/tried the studio driver version with no luck.

Thanks in advance if anyone can help me out.

EDIT: I think I got it to work. Steps below:

1. Create a python 3.8 conda environment and install tf-nightly-gpu via pip (thanks /u/kevso311)
2. Install cuda 11.0 and cuDNN 8.0.2
3. Install cuda 11.1
4. Replace ptxas.exe in the v11.0 bin directory with the v11.1 version (the 11.0 version was causing errors for me)
5. Make sure your path/cuda path point to cuda 11.0 (not 11.1)

I'm getting an issue now where some models just hang on the start of training. But the data corruption and NaN values seems to be fixed.",t2_j77lt,False,,0,False,Garbage data/NaN with tensorflow on RTX 3090 (windows),[],r/tensorflow,False,6,,0,,,False,t3_j3268v,False,dark,1.0,,public,27,0,{},,,False,[],,False,False,,{},Question,False,27,,False,self,1601629728.0,,[],{},,True,,1601557063.0,text,6,,,text,self.tensorflow,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve just upgraded to a 3090 FE from my old 1080 Ti, and installed the new drivers, etc. But now anything I run with tensorflow seems to output garbage data. Has anyone had anything like this happen to them before?&lt;/p&gt;

&lt;p&gt;For example, just running inference on a pretrained stylegan2 model outputs random noisy images (oddly the first image it generates seems to be mostly ok). Examples: &lt;a href=""https://imgur.com/a/tiqZVld""&gt;https://imgur.com/a/tiqZVld&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If I try to train any model the losses/weights end up going to NaN almost instantly (using FP32, not FP16). For stylegan2 it crashes when training due to NaN matrix values.&lt;/p&gt;

&lt;p&gt;My first thought was some kind of hardware error, but video games/passmark seem to run fine. So I&amp;#39;m a bit stumped. Maybe it&amp;#39;s an issue with conflicting cuda versions or something? I&amp;#39;ve tried a few different models with different tensorflow versions. Also reinstalled drivers/tried the studio driver version with no luck.&lt;/p&gt;

&lt;p&gt;Thanks in advance if anyone can help me out.&lt;/p&gt;

&lt;p&gt;EDIT: I think I got it to work. Steps below:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a python 3.8 conda environment and install tf-nightly-gpu via pip (thanks &lt;a href=""/u/kevso311""&gt;/u/kevso311&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Install cuda 11.0 and cuDNN 8.0.2&lt;/li&gt;
&lt;li&gt;Install cuda 11.1&lt;/li&gt;
&lt;li&gt;Replace ptxas.exe in the v11.0 bin directory with the v11.1 version (the 11.0 version was causing errors for me)&lt;/li&gt;
&lt;li&gt;Make sure your path/cuda path point to cuda 11.0 (not 11.1)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;#39;m getting an issue now where some models just hang on the start of training. But the data corruption and NaN values seems to be fixed.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j3268v,True,,I_Am_Meowing_Cows,,19,True,all_ads,False,[],False,,/r/tensorflow/comments/j3268v/garbage_datanan_with_tensorflow_on_rtx_3090/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j3268v/garbage_datanan_with_tensorflow_on_rtx_3090/,22217,1601528263.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?auto=webp&amp;s=89a1a5bc1936c0dce5ae79fcbedc5d420f61ab46', 'width': 1458, 'height': 1773}, 'resolutions': [{'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abf76bdabd86d2c4fa002f68e51347820b2f83b9', 'width': 108, 'height': 131}, {'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7453a426b123310ee45d9a60b5d06e3045d9bbfc', 'width': 216, 'height': 262}, {'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc7ccd9b1bfd28967598b433c4a7a53647320ded', 'width': 320, 'height': 389}, {'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c4099dcd374c8b9b041adb325ef27238c6b7209', 'width': 640, 'height': 778}, {'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=227ba95dbad7dc9c95ab031ce38fe82d392df139', 'width': 960, 'height': 1167}, {'url': 'https://external-preview.redd.it/7r28mSC8o8X67GK6HSjoeJwyeXrtTiUOI3buVhAJno4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c5877be88e639c11f8580373fd08d5ca47a6c587', 'width': 1080, 'height': 1313}], 'variants': {}, 'id': 'UAw9R-ihySsJTfCCI7S1MscD56srl6iRWfRuo7FLvZA'}], 'enabled': False}",,,,,,
724,,tensorflow,,t2_5moj37ik,False,,0,False,F.E.A.R. 3 - Trailer (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS,[],r/tensorflow,False,6,,0,105.0,,False,t3_j3b5es,False,dark,0.67,,public,1,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/Bm9tBMCaKpk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'F.E.A.R. 3 - Trailer (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/Bm9tBMCaKpk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Bm9tBMCaKpk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/Bm9tBMCaKpk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j3b5es', 'height': 338}",,False,1,,False,https://b.thumbs.redditmedia.com/3oR_MqON0O7gl9HcsGEBodeQAzeFbGV6fIoco5rhlYM.jpg,False,,[],{},,False,,1601596185.0,text,6,,,text,youtube.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j3b5es,True,,stepanmetior,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j3b5es/fear_3_trailer_remastered_8k_60fps_resolution/,all_ads,False,https://www.youtube.com/watch?v=Bm9tBMCaKpk,22217,1601567385.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'F.E.A.R. 3 - Trailer (Remastered 8K 60FPS)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/Bm9tBMCaKpk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Bm9tBMCaKpk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=Bm9tBMCaKpk,"{'images': [{'source': {'url': 'https://external-preview.redd.it/AzYyceXAeAabv0WQ0E_7xPpmb5gIb-00i-hTd4E6VSM.jpg?auto=webp&amp;s=a77c50c4de7e027b9042ec2490c293a8c0af945f', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/AzYyceXAeAabv0WQ0E_7xPpmb5gIb-00i-hTd4E6VSM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7956f71897238ab44b59ad9552c667e0ac67f0d0', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/AzYyceXAeAabv0WQ0E_7xPpmb5gIb-00i-hTd4E6VSM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=197e311feedc8fd3e9c85bb5f22ef86eb35219bb', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/AzYyceXAeAabv0WQ0E_7xPpmb5gIb-00i-hTd4E6VSM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=619f2f91403d521b35a59c5be8e4f590424df7c1', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'n5urOtNwhEzTSWw0k7Pj7YjE26qfyH6B2DMWUhjU_ks'}], 'enabled': False}",,,,,,
725,,tensorflow,,t2_3v9pkzti,False,,0,False,Creating Calculators in Mediapipe — Beyond The Documentation,[],r/tensorflow,False,6,,0,,,False,t3_j32fo3,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Mediapipe,False,6,,False,default,False,,[],{},,False,,1601558241.0,text,6,,,text,medium.com,False,,,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j32fo3,True,,_Ari___,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j32fo3/creating_calculators_in_mediapipe_beyond_the/,all_ads,False,https://medium.com/@arianalavi1/creating-calculators-in-mediapipe-beyond-the-documentation-83e1883b91a?source=friends_link&amp;sk=0428794f27a1e7d62cdd0726fdc5eb62,22217,1601529441.0,0,,False,,https://medium.com/@arianalavi1/creating-calculators-in-mediapipe-beyond-the-documentation-83e1883b91a?source=friends_link&amp;sk=0428794f27a1e7d62cdd0726fdc5eb62,,,,,,,
726,,tensorflow,"I have created a conda environment in Linux and installed pip install tensorflowjs in it. When i tried to import tensorflowjs as tfjs, I got AttributeError: module 'tensorflow\_hub.tf\_v1' has no attribute 'estimator'. I have attached Pictures of the code and error. Please help me in resolving it.

https://preview.redd.it/jff05wjjghq51.png?width=1533&amp;format=png&amp;auto=webp&amp;s=5a08d3a35d8bb508d1e7f3122e00e1a6491417fc

https://preview.redd.it/z9hf60kjghq51.png?width=1533&amp;format=png&amp;auto=webp&amp;s=8fc4d75ab639ba1cba8f117ea342762b7211348b",t2_11g6pzng,False,,0,False,Tensorflow JS import error and compatibility issue.,[],r/tensorflow,False,6,,0,79.0,,False,t3_j38b7j,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://a.thumbs.redditmedia.com/E91FTmN98Qpg5LoVZ7fC5ZQrH_2xtBJSjoD7-wyzt-8.jpg,False,,[],{},,True,,1601586793.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have created a conda environment in Linux and installed pip install tensorflowjs in it. When i tried to import tensorflowjs as tfjs, I got AttributeError: module &amp;#39;tensorflow_hub.tf_v1&amp;#39; has no attribute &amp;#39;estimator&amp;#39;. I have attached Pictures of the code and error. Please help me in resolving it.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/jff05wjjghq51.png?width=1533&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a08d3a35d8bb508d1e7f3122e00e1a6491417fc""&gt;https://preview.redd.it/jff05wjjghq51.png?width=1533&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a08d3a35d8bb508d1e7f3122e00e1a6491417fc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/z9hf60kjghq51.png?width=1533&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8fc4d75ab639ba1cba8f117ea342762b7211348b""&gt;https://preview.redd.it/z9hf60kjghq51.png?width=1533&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8fc4d75ab639ba1cba8f117ea342762b7211348b&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j38b7j,True,,thiyagumessi,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j38b7j/tensorflow_js_import_error_and_compatibility_issue/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j38b7j/tensorflow_js_import_error_and_compatibility_issue/,22217,1601557993.0,0,,False,,,,,"{'z9hf60kjghq51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 61, 'x': 108, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c1d99bb26da6654eac9464df4a30463c20c2dcf'}, {'y': 123, 'x': 216, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a914bbbf887f753a264c23e9d7dbd4ae9453bfa'}, {'y': 182, 'x': 320, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef563aea2976c91b17d90ea2742478aa835b106e'}, {'y': 364, 'x': 640, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9615d376c4a61c01a2fdfd3b0b871442a388441d'}, {'y': 546, 'x': 960, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f9bbcadeee34aecf01b9f482202283b4f053094'}, {'y': 615, 'x': 1080, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba60c3636f0e364b1b32421cfb1cf11422943f41'}], 's': {'y': 873, 'x': 1533, 'u': 'https://preview.redd.it/z9hf60kjghq51.png?width=1533&amp;format=png&amp;auto=webp&amp;s=8fc4d75ab639ba1cba8f117ea342762b7211348b'}, 'id': 'z9hf60kjghq51'}, 'jff05wjjghq51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 61, 'x': 108, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=24dd297339dd500ca3d4ed5373a071e5d8006d9c'}, {'y': 123, 'x': 216, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=57a04e3c2ec8cbc07040f12f73bc018767f5ff65'}, {'y': 182, 'x': 320, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fed969c4b7abd2f5631230b06a23487f5b1c314'}, {'y': 364, 'x': 640, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4f9dce126417530f58a7214489a31ee2fddcbff'}, {'y': 546, 'x': 960, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=789cd5b46e8073993c04624e1c182e3c7f79096d'}, {'y': 615, 'x': 1080, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5c51428ecf3ca8b179dff557666257a1d8037431'}], 's': {'y': 873, 'x': 1533, 'u': 'https://preview.redd.it/jff05wjjghq51.png?width=1533&amp;format=png&amp;auto=webp&amp;s=5a08d3a35d8bb508d1e7f3122e00e1a6491417fc'}, 'id': 'jff05wjjghq51'}}",,,,
727,,tensorflow,"I am beginner in tensorflow.

To learn about lstm I have a simple array  1,2,3,4,5 and job of lstm is  to predict 6

&amp;#x200B;

 

`model = tf.keras.Sequential()`  
`model.add(layers.LSTM(1,input_shape=(5,1)))`  
`model.add(layers.Dense(1))`  
`x=np.array([1,2,3,4,5])`  
`print(x.reshape((1,1,5)))`  
`x=tf.Variable(np.array(x.reshape((1,5,1))))`  
`y=tf.Variable(np.array([6]))`  
`model.compile()`  
`model.fit(x,y)`

&amp;#x200B;

I get  `ValueError: Failed to find data adapter that can handle input:`",t2_7f71agho,False,,0,False,How to use LSTM,[],r/tensorflow,False,6,,0,,,False,t3_j37yt6,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,1601567121.0,,[],{},,True,,1601585506.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am beginner in tensorflow.&lt;/p&gt;

&lt;p&gt;To learn about lstm I have a simple array  1,2,3,4,5 and job of lstm is  to predict 6&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;model = tf.keras.Sequential()&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.add(layers.LSTM(1,input_shape=(5,1)))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.add(layers.Dense(1))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x=np.array([1,2,3,4,5])&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;print(x.reshape((1,1,5)))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;x=tf.Variable(np.array(x.reshape((1,5,1))))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;y=tf.Variable(np.array([6]))&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.compile()&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;model.fit(x,y)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I get  &lt;code&gt;ValueError: Failed to find data adapter that can handle input:&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j37yt6,True,,DrAsgardian,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j37yt6/how_to_use_lstm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j37yt6/how_to_use_lstm/,22217,1601556706.0,0,,False,,,,,,,,,
728,,tensorflow,"I am self-studying Berkeley CS285 (Deep Reinforcement Learning) and I want to work on the homework assignments. The official exercises of the 2019 version of the course are written in TF1 and there is an unofficial, modified version of these exercises written in PyTorch. Also, it seems that in the 2020 version of the course, that is currently running, they transitioned to PyTorch officially. However, currently only 3/5 exercises are available.

I have been using PyTorch for a while now, but did not really get my hands on TF. In light of the release of TF2, I was wondering whether it is still worth learning TF1, through working on the official exercises. I also thought that there might be a lot of legacy code written in TF1, especially in the field of Deep RL, and thus it might be beneficial to know it, at least to some extent.

What are your thoughts? Is TF1 still worth learning for these purposes?",t2_seonf98,False,,0,False,Is it still worth learning Tensorflow 1 for Deep RL in 2020?,[],r/tensorflow,False,6,,0,,,False,t3_j34rt7,False,dark,0.99,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1601570253.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am self-studying Berkeley CS285 (Deep Reinforcement Learning) and I want to work on the homework assignments. The official exercises of the 2019 version of the course are written in TF1 and there is an unofficial, modified version of these exercises written in PyTorch. Also, it seems that in the 2020 version of the course, that is currently running, they transitioned to PyTorch officially. However, currently only 3/5 exercises are available.&lt;/p&gt;

&lt;p&gt;I have been using PyTorch for a while now, but did not really get my hands on TF. In light of the release of TF2, I was wondering whether it is still worth learning TF1, through working on the official exercises. I also thought that there might be a lot of legacy code written in TF1, especially in the field of Deep RL, and thus it might be beneficial to know it, at least to some extent.&lt;/p&gt;

&lt;p&gt;What are your thoughts? Is TF1 still worth learning for these purposes?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j34rt7,True,,roee97,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j34rt7/is_it_still_worth_learning_tensorflow_1_for_deep/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j34rt7/is_it_still_worth_learning_tensorflow_1_for_deep/,22217,1601541453.0,0,,False,,,,,,,,,
729,,tensorflow,,t2_44mbtmjy,False,,0,False,Propagate the style from a few selected keyframes to the rest of the sequence!,[],r/tensorflow,False,6,,0,47.0,,False,t3_j31upr,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},,False,3,,False,https://b.thumbs.redditmedia.com/PAbkIR1KQwKA2mMzkR2kJnf_mEalkdrHGfPdXdvSENc.jpg,False,,[],{},,False,,1601555554.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j31upr,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j31upr/propagate_the_style_from_a_few_selected_keyframes/,all_ads,False,/r/LatestInML/comments/j31ppz/propagate_the_style_from_a_few_selected_keyframes/,22217,1601526754.0,0,,False,link,/r/LatestInML/comments/j31ppz/propagate_the_style_from_a_few_selected_keyframes/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?auto=webp&amp;s=a1901fe5d002f3795486f202f76033c9fa770d49', 'width': 1414, 'height': 482}, 'resolutions': [{'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1aae6966d035e1ce69b62de5a0338365ad1d3f68', 'width': 108, 'height': 36}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ce8b7500eb54c767d5daf1338f845c63068b2909', 'width': 216, 'height': 73}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d968b41b08b87ffc9aa88729faf35fe478f0d0f', 'width': 320, 'height': 109}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b515b34d98ffc21224a7984e87376dabe96e210', 'width': 640, 'height': 218}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=75a57604e58af2ccb25f18b8007f126c33e27ceb', 'width': 960, 'height': 327}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7ef95d09ff935038d2dbb8ad3e83bc9ed5e09722', 'width': 1080, 'height': 368}], 'variants': {}, 'id': 'KEnKpXFf_MD3D5ZvBjPeLVTjjENXzaW_Yblhd1RQ0rM'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2004.14489)\n\nhttps://reddit.com/link/j31ppz/video/yad0ut0yteq51/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Propagate the style from a few selected keyframes to the rest of the sequence!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 47, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'yad0ut0yteq51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/j31ppz/asset/yad0ut0yteq51/DASHPlaylist.mpd?a=1618044824%2CMzgzNzM5OTY2NzgxZjBjMWQwYjJlMzUwZDMxMGRmMTFlZjkzOTZkZDIyM2JjNTRkNmI0M2EzMDAxZjhmMDM0ZA%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/j31ppz/asset/yad0ut0yteq51/HLSPlaylist.m3u8?a=1618044824%2CYjJjNmMzOTNhZTc4N2NkMWM1NTlhZDM0ZTNhNjZhMjc4NDEzODBiNjU1ZDc2OWJlOWE2ZWExMTUzMzExZDBiZQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'yad0ut0yteq51', 'isGif': False}}, 'name': 't3_j31ppz', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 21, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/PAbkIR1KQwKA2mMzkR2kJnf_mEalkdrHGfPdXdvSENc.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1601554945.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2004.14489""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/j31ppz/video/yad0ut0yteq51/player""&gt;https://reddit.com/link/j31ppz/video/yad0ut0yteq51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?auto=webp&amp;s=a1901fe5d002f3795486f202f76033c9fa770d49', 'width': 1414, 'height': 482}, 'resolutions': [{'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1aae6966d035e1ce69b62de5a0338365ad1d3f68', 'width': 108, 'height': 36}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ce8b7500eb54c767d5daf1338f845c63068b2909', 'width': 216, 'height': 73}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d968b41b08b87ffc9aa88729faf35fe478f0d0f', 'width': 320, 'height': 109}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b515b34d98ffc21224a7984e87376dabe96e210', 'width': 640, 'height': 218}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=75a57604e58af2ccb25f18b8007f126c33e27ceb', 'width': 960, 'height': 327}, {'url': 'https://external-preview.redd.it/dZGIVnHHzZR2OOut7VFLB8BvhJIsY0Y5XLYkBQKKSbM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7ef95d09ff935038d2dbb8ad3e83bc9ed5e09722', 'width': 1080, 'height': 368}], 'variants': {}, 'id': 'KEnKpXFf_MD3D5ZvBjPeLVTjjENXzaW_Yblhd1RQ0rM'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'j31ppz', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/j31ppz/propagate_the_style_from_a_few_selected_keyframes/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/j31ppz/propagate_the_style_from_a_few_selected_keyframes/', 'subreddit_subscribers': 6676, 'created_utc': 1601526145.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_j31ppz,
730,,tensorflow,,t2_5moj37ik,False,,0,False,Prototype 2 - Trailer (Remastered 8K) Resolution increased using neural networks to 8K,[],r/tensorflow,False,6,,0,105.0,,False,t3_j2m5gy,False,dark,0.86,,public,14,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ItPlddRTKHQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Prototype 2 - Trailer (Remastered 8K)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ItPlddRTKHQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ItPlddRTKHQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ItPlddRTKHQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j2m5gy', 'height': 338}",,False,14,,False,https://a.thumbs.redditmedia.com/YQYWX5PdUolXJ7y2WuFcVydRfiin33fbfdao3mDLvX8.jpg,False,,[],{},,False,,1601501480.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j2m5gy,True,,stepanmetior,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j2m5gy/prototype_2_trailer_remastered_8k_resolution/,all_ads,False,https://www.youtube.com/watch?v=ItPlddRTKHQ,22217,1601472680.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Prototype 2 - Trailer (Remastered 8K)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/ItPlddRTKHQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ItPlddRTKHQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=ItPlddRTKHQ,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rCT_OJFY0gqh33hXd18IkJ-odJIOtK__DcNF2iaGwaA.jpg?auto=webp&amp;s=aa8ebe448ddc419bae1a92b65341694e358a3412', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/rCT_OJFY0gqh33hXd18IkJ-odJIOtK__DcNF2iaGwaA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d55b1179d23e7ef2eaac0f73b981fa381a0e3a65', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/rCT_OJFY0gqh33hXd18IkJ-odJIOtK__DcNF2iaGwaA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=34a8c86802b05fec6c70886b495b53808bd76750', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/rCT_OJFY0gqh33hXd18IkJ-odJIOtK__DcNF2iaGwaA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d19c7143ac6247ad1c0921c6045ea8cee559292', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'nGl4DsoIv4HU4S62e2zrDUczQCSWbqxOmlBdZKYtOx4'}], 'enabled': False}",,,,,,
731,,tensorflow,"To help myself better understand TF 2.X I did a short tutorial building up and training a model from ""scratch"" starting with auto-diff and then adding the abstractions that come with Keras. Posting this in hopes that it will help someone else, as an alternative to the more abstract ""getting started"" MNIST tutorials.

[https://github.com/rbitr/blog/blob/master/tutorial.md](https://github.com/rbitr/blog/blob/master/tutorial.md)",t2_3p5zdojr,False,,0,False,"Yet another tensorflow tutorial - from ""scratch""",[],r/tensorflow,False,6,,0,,,False,t3_j2od43,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1601508804.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;To help myself better understand TF 2.X I did a short tutorial building up and training a model from &amp;quot;scratch&amp;quot; starting with auto-diff and then adding the abstractions that come with Keras. Posting this in hopes that it will help someone else, as an alternative to the more abstract &amp;quot;getting started&amp;quot; MNIST tutorials.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/rbitr/blog/blob/master/tutorial.md""&gt;https://github.com/rbitr/blog/blob/master/tutorial.md&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j2od43,True,,Dependent-Material41,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j2od43/yet_another_tensorflow_tutorial_from_scratch/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j2od43/yet_another_tensorflow_tutorial_from_scratch/,22217,1601480004.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/6LwWMxdoRz-xWSy0mebUW_2sOOE5HzYarjWXRMW-Dc0.jpg?auto=webp&amp;s=bc911f8409815df1bcf9834293a6c6d7ae786db7', 'width': 420, 'height': 420}, 'resolutions': [{'url': 'https://external-preview.redd.it/6LwWMxdoRz-xWSy0mebUW_2sOOE5HzYarjWXRMW-Dc0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cc91e8db0c65c31ef3d76f21faa196cf58f4c35', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/6LwWMxdoRz-xWSy0mebUW_2sOOE5HzYarjWXRMW-Dc0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac092a882ec5d4085e53665c73c6fdfe3c3e87a1', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/6LwWMxdoRz-xWSy0mebUW_2sOOE5HzYarjWXRMW-Dc0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=555214d7f2f1dd3ea1a388572c6f5a81d967f23f', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'wixDwOsMYyDw0lcvYbX-ltiFeNFUBK0Ks_ZnGncha10'}], 'enabled': False}",,,,,,
732,,tensorflow,"‘Recommendation’ is something you come across every day on almost every online platform, from the morning news stories to the late-night online TV shows. The personalized suggestions “Guess you like” or “You might like” are given using AI-powered technology, predicting a user’s general behavior and preferences. But technology is developing day by day and enhancing its productivity. Thus, Google, being one of the leading companies in recommender system research, development, and deployment, has recently introduced TensorFlow Recommenders (TFRS), a new open-sourced TensorFlow package.

Github: https://github.com/tensorflow/recommenders

Summary: https://www.marktechpost.com/2020/09/29/google-open-sources-tensorflow-recommenders-tfrs-helping-users-find-what-they-love/",t2_2wsvqwhg,False,,0,False,Google Open-Sources TensorFlow Recommenders (TFRS): Helping Users Find What They Love,[],r/tensorflow,False,6,,0,,,False,t3_j2fdoc,False,dark,0.87,,public,19,0,{},,,False,[],,False,False,,{},Discussion,False,19,,False,self,False,,[],{},,True,,1601468843.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;‘Recommendation’ is something you come across every day on almost every online platform, from the morning news stories to the late-night online TV shows. The personalized suggestions “Guess you like” or “You might like” are given using AI-powered technology, predicting a user’s general behavior and preferences. But technology is developing day by day and enhancing its productivity. Thus, Google, being one of the leading companies in recommender system research, development, and deployment, has recently introduced TensorFlow Recommenders (TFRS), a new open-sourced TensorFlow package.&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/tensorflow/recommenders""&gt;https://github.com/tensorflow/recommenders&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/09/29/google-open-sources-tensorflow-recommenders-tfrs-helping-users-find-what-they-love/""&gt;https://www.marktechpost.com/2020/09/29/google-open-sources-tensorflow-recommenders-tfrs-helping-users-find-what-they-love/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j2fdoc,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j2fdoc/google_opensources_tensorflow_recommenders_tfrs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j2fdoc/google_opensources_tensorflow_recommenders_tfrs/,22217,1601440043.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&amp;s=1be8201f880a5c366de54369c2aa4e955104cb29', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23fe2a26654b9dfa089db56c75d95e53c52a3457', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29b34709e638685879704cd228981f63426094b2', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3162b174042591b97c5d8b2638f7c941c0d62d02', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'uaXe31fUPreb1XtDwvG0ohRrbxl7E_8E7dCysGu2y-Q'}], 'enabled': False}",,,,,,
733,,tensorflow,"I'm hoping to learn more about a particular warning I'm seeing when running a Python API locally that queries ML models. Disclaimer: I'm not a Python programmer or a data scientist. ;) I'm involved with team management now but my background is in .NET. Our data scientist has built this API but I want to validate what I'm hearing from this person with the broader community as we're running into some memory management issues (roughly 2.5MB of memory is consumed on every API call and is never released/garbage collected, resulting in application crashes when max system memory is reached).

**UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape.**  **This may consume a large amount of memory.**

This is the warning we're receiving on running the Python API locally. It appears to be caused by the bottom two lines of code:

    from tensorflow.python.keras.models import load_model
    from deepctr.layers import custom_objects
    
    params['model_cr']  = load_model('deepfm_cr.h5',custom_objects)
    params['model_wr']  = load_model('deepfm_wr.h5',custom_objects)

These are the only lines that leverage the imported Tensorflow module and removing them eliminates the warning. Is this a warning that we should be paying attention to or can it safely be ignored as I've seen in some other posts on StackOverflow?

Our data scientist is indicating that this warning (and the 2.5MB per call that is never released) is the result of a ""known memory leak in either Tensorflow or DeepFM"" and that in order to fix it, we'd need to patch one of those modules but from what I've seen that doesn't appear to be documented anywhere and I haven't seen any references to that in the research I've done on my own. I'm finding it hard to believe that Tensorflow or DeepFM would have such glaring issues, especially in our use case which is extremely lightweight compared to much more complex use cases.

Thanks for any light you might be able to shed on this!",t2_119pnm,False,,0,False,UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape.,[],r/tensorflow,False,6,,0,,,False,t3_j2pbrc,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1601483269.0,,[],{},,True,,1601511784.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m hoping to learn more about a particular warning I&amp;#39;m seeing when running a Python API locally that queries ML models. Disclaimer: I&amp;#39;m not a Python programmer or a data scientist. ;) I&amp;#39;m involved with team management now but my background is in .NET. Our data scientist has built this API but I want to validate what I&amp;#39;m hearing from this person with the broader community as we&amp;#39;re running into some memory management issues (roughly 2.5MB of memory is consumed on every API call and is never released/garbage collected, resulting in application crashes when max system memory is reached).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape.&lt;/strong&gt;  &lt;strong&gt;This may consume a large amount of memory.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is the warning we&amp;#39;re receiving on running the Python API locally. It appears to be caused by the bottom two lines of code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tensorflow.python.keras.models import load_model
from deepctr.layers import custom_objects

params[&amp;#39;model_cr&amp;#39;]  = load_model(&amp;#39;deepfm_cr.h5&amp;#39;,custom_objects)
params[&amp;#39;model_wr&amp;#39;]  = load_model(&amp;#39;deepfm_wr.h5&amp;#39;,custom_objects)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are the only lines that leverage the imported Tensorflow module and removing them eliminates the warning. Is this a warning that we should be paying attention to or can it safely be ignored as I&amp;#39;ve seen in some other posts on StackOverflow?&lt;/p&gt;

&lt;p&gt;Our data scientist is indicating that this warning (and the 2.5MB per call that is never released) is the result of a &amp;quot;known memory leak in either Tensorflow or DeepFM&amp;quot; and that in order to fix it, we&amp;#39;d need to patch one of those modules but from what I&amp;#39;ve seen that doesn&amp;#39;t appear to be documented anywhere and I haven&amp;#39;t seen any references to that in the research I&amp;#39;ve done on my own. I&amp;#39;m finding it hard to believe that Tensorflow or DeepFM would have such glaring issues, especially in our use case which is extremely lightweight compared to much more complex use cases.&lt;/p&gt;

&lt;p&gt;Thanks for any light you might be able to shed on this!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j2pbrc,True,,twindiesel77,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j2pbrc/userwarning_converting_sparse_indexedslices_to_a/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j2pbrc/userwarning_converting_sparse_indexedslices_to_a/,22217,1601482984.0,0,,False,,,,,,,,,
734,,tensorflow," I am implementing a simple SGD, and the tensor is used to calculate a custom loss function.",t2_2nvdpdl,False,,0,False,Is there a way to create a tensor in tensorflow such that some elements are constants and some are variables?,[],r/tensorflow,False,6,,0,,,False,t3_j2gn4k,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1601474638.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am implementing a simple SGD, and the tensor is used to calculate a custom loss function.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j2gn4k,True,,curtlytalks,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j2gn4k/is_there_a_way_to_create_a_tensor_in_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j2gn4k/is_there_a_way_to_create_a_tensor_in_tensorflow/,22217,1601445838.0,0,,False,,,,,,,,,
735,,tensorflow,"The code:

import tensorflow as tf   
import os   
loaded\_model = tf.keras.models.load\_model('C:/Users/USER/Desktop/project-tst#1/my\_project\_model')  
\#Running the Model  
import numpy as np  
from tensorflow import keras  
from tensorflow.keras.preprocessing import image

\# predicting images

path = os.path.join('c:/', 'Users', 'USER', 'Downloads')

img = image.load\_img(path, target\_size=(300, 300))

x = image.img\_to\_array(img)

x = np.expand\_dims(x, axis=0)

images = np.vstack(\[x\])

classes = loaded\_model.predict(images, batch\_size=10)

print(classes\[0\])

if classes\[0\]&gt;0.5:

print(""It is a fox"")

else:

print(""It is a cat"")

&amp;#x200B;

and here are the errors:

&amp;#x200B;

Traceback (most recent call last):

File ""c:/Users/USER/Desktop/obj-classification/obj-class.py"", line 19, in &lt;module&gt;

img = image.load\_img(path, target\_size=(300, 300))

File ""C:\\Users\\USER\\Anaconda2\\envs\\py3-TF2.0\\lib\\site-packages\\keras\_preprocessing\\image\\[utils.py](https://utils.py/)"", line 110, in load\_img

img = pil\_image.open(path)

File ""C:\\Users\\USER\\Anaconda2\\envs\\py3-TF2.0\\lib\\site-packages\\PIL\\[Image.py](https://image.py/)"", line 2878, in open

fp = [builtins.open](https://builtins.open/)(filename, ""rb"")

PermissionError: \[Errno 13\] Permission denied: 'c:/Users\\\\USER\\\\Downloads'

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

Thank you",t2_4rlddyx5,False,,0,False,what is the solution to this problem( PermissionError: [Errno 13] Permission denied)?,[],r/tensorflow,False,6,,0,,,False,t3_j2j3xz,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1601487781.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The code:&lt;/p&gt;

&lt;p&gt;import tensorflow as tf&lt;br/&gt;
import os&lt;br/&gt;
loaded_model = tf.keras.models.load_model(&amp;#39;C:/Users/USER/Desktop/project-tst#1/my_project_model&amp;#39;)&lt;br/&gt;
#Running the Model&lt;br/&gt;
import numpy as np&lt;br/&gt;
from tensorflow import keras&lt;br/&gt;
from tensorflow.keras.preprocessing import image&lt;/p&gt;

&lt;p&gt;# predicting images&lt;/p&gt;

&lt;p&gt;path = os.path.join(&amp;#39;c:/&amp;#39;, &amp;#39;Users&amp;#39;, &amp;#39;USER&amp;#39;, &amp;#39;Downloads&amp;#39;)&lt;/p&gt;

&lt;p&gt;img = image.load_img(path, target_size=(300, 300))&lt;/p&gt;

&lt;p&gt;x = image.img_to_array(img)&lt;/p&gt;

&lt;p&gt;x = np.expand_dims(x, axis=0)&lt;/p&gt;

&lt;p&gt;images = np.vstack([x])&lt;/p&gt;

&lt;p&gt;classes = loaded_model.predict(images, batch_size=10)&lt;/p&gt;

&lt;p&gt;print(classes[0])&lt;/p&gt;

&lt;p&gt;if classes[0]&amp;gt;0.5:&lt;/p&gt;

&lt;p&gt;print(&amp;quot;It is a fox&amp;quot;)&lt;/p&gt;

&lt;p&gt;else:&lt;/p&gt;

&lt;p&gt;print(&amp;quot;It is a cat&amp;quot;)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;and here are the errors:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Traceback (most recent call last):&lt;/p&gt;

&lt;p&gt;File &amp;quot;c:/Users/USER/Desktop/obj-classification/obj-class.py&amp;quot;, line 19, in &amp;lt;module&amp;gt;&lt;/p&gt;

&lt;p&gt;img = image.load_img(path, target_size=(300, 300))&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\USER\Anaconda2\envs\py3-TF2.0\lib\site-packages\keras_preprocessing\image\&lt;a href=""https://utils.py/""&gt;utils.py&lt;/a&gt;&amp;quot;, line 110, in load_img&lt;/p&gt;

&lt;p&gt;img = pil_image.open(path)&lt;/p&gt;

&lt;p&gt;File &amp;quot;C:\Users\USER\Anaconda2\envs\py3-TF2.0\lib\site-packages\PIL\&lt;a href=""https://image.py/""&gt;Image.py&lt;/a&gt;&amp;quot;, line 2878, in open&lt;/p&gt;

&lt;p&gt;fp = &lt;a href=""https://builtins.open/""&gt;builtins.open&lt;/a&gt;(filename, &amp;quot;rb&amp;quot;)&lt;/p&gt;

&lt;p&gt;PermissionError: [Errno 13] Permission denied: &amp;#39;c:/Users\\USER\\Downloads&amp;#39;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j2j3xz,True,,Randy-Brandy,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j2j3xz/what_is_the_solution_to_this_problem/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j2j3xz/what_is_the_solution_to_this_problem/,22217,1601458981.0,0,,False,,,,,,,,,
736,,tensorflow,"I attempted to write the Tensorflow Developer certificate Exam last week. So how the exam works is you have to pay for the exam and start the exam environment on the Trueability portal and then start the exam inside pycharm using the Tensorflow Exam plugin.   

I had done this before and it worked fine on the previous attempt but on this attempt i couldnt start the exam because the plugin gave a message saying "" We dont have your exam ready right now. Please try again later."" I contacted the support at Trueability and they said everything was fine on their end and it is a problem that has to be resolved by the Tensorflow certification team.   
It is not a problem with pycharm as i was using the latest version and had already given an attempt on that version before. I basically couldnt start the exam and the exam environment timed out on the Trueability portal. Even now if i click on the exam plugin it still gives me the same message about the exam not being ready 


Now I emailed them multiple times at their support email at tensorflow-certificate-team@google.com but i have not received a response for over a week now. I dont know how to proceed with getting my issue fixed and was wondering if anyone here could help get in touch with the team behind the certification exam.",t2_hut8x,False,,0,False,Bug with starting the Tensorflow Developer Certificate Exam.,[],r/tensorflow,False,6,,0,,,False,t3_j2i582,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1601482337.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I attempted to write the Tensorflow Developer certificate Exam last week. So how the exam works is you have to pay for the exam and start the exam environment on the Trueability portal and then start the exam inside pycharm using the Tensorflow Exam plugin.   &lt;/p&gt;

&lt;p&gt;I had done this before and it worked fine on the previous attempt but on this attempt i couldnt start the exam because the plugin gave a message saying &amp;quot; We dont have your exam ready right now. Please try again later.&amp;quot; I contacted the support at Trueability and they said everything was fine on their end and it is a problem that has to be resolved by the Tensorflow certification team.&lt;br/&gt;
It is not a problem with pycharm as i was using the latest version and had already given an attempt on that version before. I basically couldnt start the exam and the exam environment timed out on the Trueability portal. Even now if i click on the exam plugin it still gives me the same message about the exam not being ready &lt;/p&gt;

&lt;p&gt;Now I emailed them multiple times at their support email at &lt;a href=""mailto:tensorflow-certificate-team@google.com""&gt;tensorflow-certificate-team@google.com&lt;/a&gt; but i have not received a response for over a week now. I dont know how to proceed with getting my issue fixed and was wondering if anyone here could help get in touch with the team behind the certification exam.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j2i582,True,,Paradox_D,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j2i582/bug_with_starting_the_tensorflow_developer/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j2i582/bug_with_starting_the_tensorflow_developer/,22217,1601453537.0,0,,False,,,,,,,,,
737,,tensorflow,,t2_4k0jtvab,False,,0,False,How to Run DeepSORT Object Tracking with YOLOv4 and TensorFlow in Google Colab,[],r/tensorflow,False,6,,0,105.0,,False,t3_j1yg2z,False,dark,0.96,,public,21,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_zrNUzDS8Zc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'YOLOv4 in the CLOUD: Build Object Tracking Using DeepSORT in Google Colab (FREE GPU)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_zrNUzDS8Zc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_zrNUzDS8Zc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCrydcKaojc44XnuXrfhlV8Q'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_zrNUzDS8Zc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j1yg2z', 'height': 338}",,False,21,,False,https://a.thumbs.redditmedia.com/nyy4D2BSqAON3sOTaX1fbyRKtkXCvvdFh0pw71P5tp8.jpg,False,,[],{},,False,,1601412118.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j1yg2z,True,,The-AI-Guy,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j1yg2z/how_to_run_deepsort_object_tracking_with_yolov4/,all_ads,False,https://www.youtube.com/watch?v=_zrNUzDS8Zc,22217,1601383318.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'YOLOv4 in the CLOUD: Build Object Tracking Using DeepSORT in Google Colab (FREE GPU)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/_zrNUzDS8Zc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_zrNUzDS8Zc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCrydcKaojc44XnuXrfhlV8Q'}}",False,rich:video,https://www.youtube.com/watch?v=_zrNUzDS8Zc,"{'images': [{'source': {'url': 'https://external-preview.redd.it/imNQBey5SsO7_4U2P8ij9A37x4nX9sGJQovWfXKyF0o.jpg?auto=webp&amp;s=d87c05b4c32e3be33b00ae1cdcbdb1201082b98e', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/imNQBey5SsO7_4U2P8ij9A37x4nX9sGJQovWfXKyF0o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41e75213b20cfb846cd1e08469875172ec86b072', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/imNQBey5SsO7_4U2P8ij9A37x4nX9sGJQovWfXKyF0o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=50959fcc4500b4b17db20318de6f0f9fc290149a', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/imNQBey5SsO7_4U2P8ij9A37x4nX9sGJQovWfXKyF0o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7d7ab3f05d71b2703a666dc810c6820339ea9f4', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Q7KQjwc1-TxbLbVcWhadwlCM2LjbiA6LSfPispaJGEo'}], 'enabled': False}",,,,,,
738,,tensorflow,,t2_15pbcg,False,,0,False,Benchmarking tensorflow on NVIDIA GeForce RTX 3090,[],r/tensorflow,False,6,,0,93.0,,False,t3_j20utn,False,dark,0.78,,public,5,0,{},140.0,,False,[],,False,False,,{},Discussion,False,5,,False,https://b.thumbs.redditmedia.com/rSOQE9r7tte9-SaQY1iP1M0T39HEXyUUoiIvAG3qxMc.jpg,False,,[],{},,False,,1601420385.0,text,6,,,text,evolution.ai,False,,,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j20utn,True,,mag_pl,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j20utn/benchmarking_tensorflow_on_nvidia_geforce_rtx_3090/,all_ads,False,https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090,22217,1601391585.0,0,,False,link,https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090,"{'images': [{'source': {'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?auto=webp&amp;s=e01072a8895255c501b1f838d4047465641640b3', 'width': 2048, 'height': 1365}, 'resolutions': [{'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=74aa8615ed46f3a073e851e149aa8a17018cc203', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d246d6e58528092dc9df502347b93721300cf4a4', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=29f390e90a9eca86eabed33aaee4a28ecba29a54', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=503284e81e4566d8a78d7b7e94d87acd647bacd0', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36fc8239980cecb2081c61afe6e22af21ee0f30b', 'width': 960, 'height': 639}, {'url': 'https://external-preview.redd.it/YSf-2WjK1wqGrXX2LrZyfXDzEt63Ii4fwodw_UV1Apk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5fac10c7f028ef49679ac31ba1d9638ce5219df', 'width': 1080, 'height': 719}], 'variants': {}, 'id': 'Ej7QPP62NDAe0gqyRspSp4CqauXSnEWrN7zXTvA9UwM'}], 'enabled': False}",,,,,,
739,,tensorflow,"Hello, I had previously asked a question regarding the use of tensorflow and neural network architectures on tabular data. Tabular data meaning, structured excel or csv type format with columns and rows with numbers in each column. No images, no text, just simply data that I could be using for scikit-learn classifiers and regressors. I have a tabular dataset with 449,371 rows, and previously I had done a project with 316,800 rows, which ended up being horrific. My loss was “NAN” and my accuracy would stay at 0.25, ive sent pictures of this issue a few weeks ago, and I was told that maybe my problem was that the data wasn’t “deep enough” for deep learning. Is this true? I mean I have a 450k rows of data, is this truly not deep enough? Does sklearn solve this issue better than tensorflow?",t2_5w4i5kd1,False,,0,False,Neural Networks on Tabular data,[],r/tensorflow,False,6,,0,,,False,t3_j21ocl,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1601422900.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I had previously asked a question regarding the use of tensorflow and neural network architectures on tabular data. Tabular data meaning, structured excel or csv type format with columns and rows with numbers in each column. No images, no text, just simply data that I could be using for scikit-learn classifiers and regressors. I have a tabular dataset with 449,371 rows, and previously I had done a project with 316,800 rows, which ended up being horrific. My loss was “NAN” and my accuracy would stay at 0.25, ive sent pictures of this issue a few weeks ago, and I was told that maybe my problem was that the data wasn’t “deep enough” for deep learning. Is this true? I mean I have a 450k rows of data, is this truly not deep enough? Does sklearn solve this issue better than tensorflow?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j21ocl,True,,veeeerain,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j21ocl/neural_networks_on_tabular_data/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j21ocl/neural_networks_on_tabular_data/,22217,1601394100.0,0,,False,,,,,,,,,
740,,tensorflow,"Hi

I'm trying to run the predict method using the saved model, so that the nn doesn't repeat training, 

but it's not working and the training is getting repeated every time I run the code.

I'm still new to TensorFlow, so any explanation would be helpful. 

Thanks

Here is the code:

 

import os   
\# Accessing the directory of our training cat pictures  
train\_cat\_dir = os.path.join(""c:/"", 'Users', 'USER', 'Desktop', 'fox-or-cat', 'cats')  
\# Accessing the directory of our training fox pictures  
train\_fox\_dir = os.path.join(""c:/"", ""Users"", ""USER"", ""Desktop"", ""fox-or-cat"", 'foxes')  
\# Accessing the directory of our validation cat pictures  
validation\_cat\_dir = os.path.join(""c:/"", ""Users"", ""USER"", ""Desktop"", ""validation-fox-or-cat"", 'cats')  
\# Accessing the directory of our validation fox pictures  
validation\_fox\_dir = os.path.join('c:/', 'Users', ""USER"", ""Desktop"", ""validation-fox-or-cat"", 'foxes')  
import tensorflow as tf   
model = tf.keras.models.Sequential(\[   
 \# Note the input shape is the desired size of the image 300x300 with 3 bytes color  
 \# This is the first convolution  
tf.keras.layers.Conv2D(16, (3,3), activation='relu', input\_shape=(300, 300, 3)),  
tf.keras.layers.MaxPooling2D(2, 2),  
 \# The second convolution  
tf.keras.layers.Conv2D(32, (3,3), activation='relu'),  
tf.keras.layers.MaxPooling2D(2,2),  
 \# The third convolution  
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),  
tf.keras.layers.MaxPooling2D(2,2),  
 \# The fourth convolution  
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),  
tf.keras.layers.MaxPooling2D(2,2),  
 \# The fifth convolution  
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),  
tf.keras.layers.MaxPooling2D(2,2),  
 \# Flatten the results to feed into a DNN  
tf.keras.layers.Flatten(),  
 \# 512 neuron hidden layer  
tf.keras.layers.Dense(512, activation='relu'),  
 \# Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('foxes')  
tf.keras.layers.Dense(1, activation='sigmoid')  
\])

&amp;#x200B;

model.summary()  
from tensorflow.keras.optimizers import RMSprop  
model.compile(loss='binary\_crossentropy',  
optimizer=RMSprop(lr=0.001),  
metrics=\['accuracy'\])  
from tensorflow.keras.preprocessing.image import ImageDataGenerator  
\# All images will be rescaled by 1./255  
train\_datagen = ImageDataGenerator(rescale=1/255)  
validation\_datagen = ImageDataGenerator(rescale=1/255)  
training\_image\_dir = os.path.join('c:/', 'Users', 'USER', 'Desktop', 'fox-or-cat')  
validation\_image\_dir = os.path.join('c:/', 'Users', 'USER', 'Desktop', 'validation-fox-or-cat')

&amp;#x200B;

\# Flow training images in batches of 128 using train\_datagen generator  
train\_generator = train\_datagen.flow\_from\_directory(  
training\_image\_dir, # This is the source directory for training images  
target\_size=(300, 300),  # All images will be resized to 150x150  
batch\_size=128,  
 \# Since we use binary\_crossentropy loss, we need binary labels  
class\_mode='binary')  
\# Flow training images in batches of 128 using train\_datagen generator  
validation\_generator = validation\_datagen.flow\_from\_directory(  
validation\_image\_dir,  # This is the source directory for training images  
target\_size=(300, 300),  # All images will be resized to 150x150  
batch\_size=32,  
 \# Since we use binary\_crossentropy loss, we need binary labels  
class\_mode='binary')

&amp;#x200B;

\### Training  
history = model.fit(  
train\_generator,  
steps\_per\_epoch=7,    
epochs=50,  
verbose=1,  
validation\_data = validation\_generator,  
validation\_steps=7)

 

model.save('my\_project\_model') 

loaded\_model = tf.keras.models.load\_model('my\_project\_model')  


 \#Running the Model  
import numpy as np  
from keras.preprocessing import image  
   
\# predicting images  
path = os.path.join(""c:/"", 'Users', 'USER', 'Downloads')   
img = image.load\_img(path, target\_size=(300, 300))  
x = image.img\_to\_array(img)  
x = np.expand\_dims(x, axis=0)  
images = np.vstack(\[x\])  
classes = loaded\_model.predict(images, batch\_size=10)  
print(classes\[0\])  
if classes\[0\]&gt;0.5:  
 print(""It is a fox"")  
else:  
 print(""It is a cat"")",t2_4rlddyx5,False,,0,False,How to predict images using a saved model?,[],r/tensorflow,False,6,,0,,,False,t3_j1zhh9,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1601415930.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to run the predict method using the saved model, so that the nn doesn&amp;#39;t repeat training, &lt;/p&gt;

&lt;p&gt;but it&amp;#39;s not working and the training is getting repeated every time I run the code.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m still new to TensorFlow, so any explanation would be helpful. &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;Here is the code:&lt;/p&gt;

&lt;p&gt;import os&lt;br/&gt;
# Accessing the directory of our training cat pictures&lt;br/&gt;
train_cat_dir = os.path.join(&amp;quot;c:/&amp;quot;, &amp;#39;Users&amp;#39;, &amp;#39;USER&amp;#39;, &amp;#39;Desktop&amp;#39;, &amp;#39;fox-or-cat&amp;#39;, &amp;#39;cats&amp;#39;)&lt;br/&gt;
# Accessing the directory of our training fox pictures&lt;br/&gt;
train_fox_dir = os.path.join(&amp;quot;c:/&amp;quot;, &amp;quot;Users&amp;quot;, &amp;quot;USER&amp;quot;, &amp;quot;Desktop&amp;quot;, &amp;quot;fox-or-cat&amp;quot;, &amp;#39;foxes&amp;#39;)&lt;br/&gt;
# Accessing the directory of our validation cat pictures&lt;br/&gt;
validation_cat_dir = os.path.join(&amp;quot;c:/&amp;quot;, &amp;quot;Users&amp;quot;, &amp;quot;USER&amp;quot;, &amp;quot;Desktop&amp;quot;, &amp;quot;validation-fox-or-cat&amp;quot;, &amp;#39;cats&amp;#39;)&lt;br/&gt;
# Accessing the directory of our validation fox pictures&lt;br/&gt;
validation_fox_dir = os.path.join(&amp;#39;c:/&amp;#39;, &amp;#39;Users&amp;#39;, &amp;quot;USER&amp;quot;, &amp;quot;Desktop&amp;quot;, &amp;quot;validation-fox-or-cat&amp;quot;, &amp;#39;foxes&amp;#39;)&lt;br/&gt;
import tensorflow as tf&lt;br/&gt;
model = tf.keras.models.Sequential([&lt;br/&gt;
 # Note the input shape is the desired size of the image 300x300 with 3 bytes color&lt;br/&gt;
 # This is the first convolution&lt;br/&gt;
tf.keras.layers.Conv2D(16, (3,3), activation=&amp;#39;relu&amp;#39;, input_shape=(300, 300, 3)),&lt;br/&gt;
tf.keras.layers.MaxPooling2D(2, 2),&lt;br/&gt;
 # The second convolution&lt;br/&gt;
tf.keras.layers.Conv2D(32, (3,3), activation=&amp;#39;relu&amp;#39;),&lt;br/&gt;
tf.keras.layers.MaxPooling2D(2,2),&lt;br/&gt;
 # The third convolution&lt;br/&gt;
tf.keras.layers.Conv2D(64, (3,3), activation=&amp;#39;relu&amp;#39;),&lt;br/&gt;
tf.keras.layers.MaxPooling2D(2,2),&lt;br/&gt;
 # The fourth convolution&lt;br/&gt;
tf.keras.layers.Conv2D(64, (3,3), activation=&amp;#39;relu&amp;#39;),&lt;br/&gt;
tf.keras.layers.MaxPooling2D(2,2),&lt;br/&gt;
 # The fifth convolution&lt;br/&gt;
tf.keras.layers.Conv2D(64, (3,3), activation=&amp;#39;relu&amp;#39;),&lt;br/&gt;
tf.keras.layers.MaxPooling2D(2,2),&lt;br/&gt;
 # Flatten the results to feed into a DNN&lt;br/&gt;
tf.keras.layers.Flatten(),&lt;br/&gt;
 # 512 neuron hidden layer&lt;br/&gt;
tf.keras.layers.Dense(512, activation=&amp;#39;relu&amp;#39;),&lt;br/&gt;
 # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (&amp;#39;cats&amp;#39;) and 1 for the other (&amp;#39;foxes&amp;#39;)&lt;br/&gt;
tf.keras.layers.Dense(1, activation=&amp;#39;sigmoid&amp;#39;)&lt;br/&gt;
])&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;model.summary()&lt;br/&gt;
from tensorflow.keras.optimizers import RMSprop&lt;br/&gt;
model.compile(loss=&amp;#39;binary_crossentropy&amp;#39;,&lt;br/&gt;
optimizer=RMSprop(lr=0.001),&lt;br/&gt;
metrics=[&amp;#39;accuracy&amp;#39;])&lt;br/&gt;
from tensorflow.keras.preprocessing.image import ImageDataGenerator&lt;br/&gt;
# All images will be rescaled by 1./255&lt;br/&gt;
train_datagen = ImageDataGenerator(rescale=1/255)&lt;br/&gt;
validation_datagen = ImageDataGenerator(rescale=1/255)&lt;br/&gt;
training_image_dir = os.path.join(&amp;#39;c:/&amp;#39;, &amp;#39;Users&amp;#39;, &amp;#39;USER&amp;#39;, &amp;#39;Desktop&amp;#39;, &amp;#39;fox-or-cat&amp;#39;)&lt;br/&gt;
validation_image_dir = os.path.join(&amp;#39;c:/&amp;#39;, &amp;#39;Users&amp;#39;, &amp;#39;USER&amp;#39;, &amp;#39;Desktop&amp;#39;, &amp;#39;validation-fox-or-cat&amp;#39;)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Flow training images in batches of 128 using train_datagen generator&lt;br/&gt;
train_generator = train_datagen.flow_from_directory(&lt;br/&gt;
training_image_dir, # This is the source directory for training images&lt;br/&gt;
target_size=(300, 300),  # All images will be resized to 150x150&lt;br/&gt;
batch_size=128,&lt;br/&gt;
 # Since we use binary_crossentropy loss, we need binary labels&lt;br/&gt;
class_mode=&amp;#39;binary&amp;#39;)&lt;br/&gt;
# Flow training images in batches of 128 using train_datagen generator&lt;br/&gt;
validation_generator = validation_datagen.flow_from_directory(&lt;br/&gt;
validation_image_dir,  # This is the source directory for training images&lt;br/&gt;
target_size=(300, 300),  # All images will be resized to 150x150&lt;br/&gt;
batch_size=32,&lt;br/&gt;
 # Since we use binary_crossentropy loss, we need binary labels&lt;br/&gt;
class_mode=&amp;#39;binary&amp;#39;)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;### Training&lt;br/&gt;
history = model.fit(&lt;br/&gt;
train_generator,&lt;br/&gt;
steps_per_epoch=7,&lt;br/&gt;
epochs=50,&lt;br/&gt;
verbose=1,&lt;br/&gt;
validation_data = validation_generator,&lt;br/&gt;
validation_steps=7)&lt;/p&gt;

&lt;p&gt;model.save(&amp;#39;my_project_model&amp;#39;) &lt;/p&gt;

&lt;p&gt;loaded_model = tf.keras.models.load_model(&amp;#39;my_project_model&amp;#39;)  &lt;/p&gt;

&lt;p&gt;#Running the Model&lt;br/&gt;
import numpy as np&lt;br/&gt;
from keras.preprocessing import image  &lt;/p&gt;

&lt;p&gt;# predicting images&lt;br/&gt;
path = os.path.join(&amp;quot;c:/&amp;quot;, &amp;#39;Users&amp;#39;, &amp;#39;USER&amp;#39;, &amp;#39;Downloads&amp;#39;)&lt;br/&gt;
img = image.load_img(path, target_size=(300, 300))&lt;br/&gt;
x = image.img_to_array(img)&lt;br/&gt;
x = np.expand_dims(x, axis=0)&lt;br/&gt;
images = np.vstack([x])&lt;br/&gt;
classes = loaded_model.predict(images, batch_size=10)&lt;br/&gt;
print(classes[0])&lt;br/&gt;
if classes[0]&amp;gt;0.5:&lt;br/&gt;
 print(&amp;quot;It is a fox&amp;quot;)&lt;br/&gt;
else:&lt;br/&gt;
 print(&amp;quot;It is a cat&amp;quot;)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j1zhh9,True,,Randy-Brandy,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/j1zhh9/how_to_predict_images_using_a_saved_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1zhh9/how_to_predict_images_using_a_saved_model/,22217,1601387130.0,0,,False,,,,,,,,,
741,,tensorflow,"Found the named entity recognition services from Google and Azure way too expensive and wonder if and how I could do it myself. I'm a TS dev but don't have neither tensorflow nor Python skills. is the tensorflow js an opton, does it have a good ecosystem?",t2_2x0723cu,False,,0,False,What's the easiest way to setup some NER API?,[],r/tensorflow,False,6,,0,,,False,t3_j1sjpz,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,1601354742.0,,[],{},,True,,1601383276.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Found the named entity recognition services from Google and Azure way too expensive and wonder if and how I could do it myself. I&amp;#39;m a TS dev but don&amp;#39;t have neither tensorflow nor Python skills. is the tensorflow js an opton, does it have a good ecosystem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j1sjpz,True,,desmap,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j1sjpz/whats_the_easiest_way_to_setup_some_ner_api/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1sjpz/whats_the_easiest_way_to_setup_some_ner_api/,22217,1601354476.0,0,,False,,,,,,,,,
742,,tensorflow,"Hey there,

I am kinda new to tensorflow, just started using it for a new project using rnn for text understanding, and I was wondering why everybody is using it with linux, and whether I should switch.

Now I know the dev environment is kinda biased for linux, but honestly I've always used Windows for most my stuff, and never had much problem with it. I am not here asking for an endorsement of linux for development, just wondering if there are any particularities or features of tf that I'd only get on linux, compared to windows.",t2_65oxu,False,,0,False,Why is everybody using tf on Linux?,[],r/tensorflow,False,6,,0,,,False,t3_j1id4b,False,dark,0.78,,public,10,0,{},,,False,[],,False,False,,{},Question,False,10,,False,self,False,,[],{},,True,,1601348427.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;I am kinda new to tensorflow, just started using it for a new project using rnn for text understanding, and I was wondering why everybody is using it with linux, and whether I should switch.&lt;/p&gt;

&lt;p&gt;Now I know the dev environment is kinda biased for linux, but honestly I&amp;#39;ve always used Windows for most my stuff, and never had much problem with it. I am not here asking for an endorsement of linux for development, just wondering if there are any particularities or features of tf that I&amp;#39;d only get on linux, compared to windows.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j1id4b,True,,Althis,,16,True,all_ads,False,[],False,,/r/tensorflow/comments/j1id4b/why_is_everybody_using_tf_on_linux/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1id4b/why_is_everybody_using_tf_on_linux/,22217,1601319627.0,0,,False,,,,,,,,,
743,,tensorflow,"Hey guys! So I have this assignment to train a very simple neural network. Our dataset has 6 features that are fed into the network and we are required to train it and then predict one output number. The professor gave us the code and basically told us to learn by ourselves lol. So my doubt is, in the following code, in which the layers for the neural network are defined, does the first dense layer defined (the one with 50 neurons) corresponds to the input layer, or is it the first hidden layer?

Thanks in advance!

    def get_compiled_model():
    model = tf.keras.Sequential([      tf.keras.layers.Dense(50, activation='relu', input_shape=(6,)),     tf.keras.layers.Dense(30, activation='relu'),     tf.keras.layers.Dense(30, activation='relu'),     tf.keras.layers.Dense(1, activation='linear'),   
    ])

 ",t2_6a4swe20,False,,0,False,How many layers does my NN have?,[],r/tensorflow,False,6,,0,,,False,t3_j1rnaa,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1601379518.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys! So I have this assignment to train a very simple neural network. Our dataset has 6 features that are fed into the network and we are required to train it and then predict one output number. The professor gave us the code and basically told us to learn by ourselves lol. So my doubt is, in the following code, in which the layers for the neural network are defined, does the first dense layer defined (the one with 50 neurons) corresponds to the input layer, or is it the first hidden layer?&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_compiled_model():
model = tf.keras.Sequential([      tf.keras.layers.Dense(50, activation=&amp;#39;relu&amp;#39;, input_shape=(6,)),     tf.keras.layers.Dense(30, activation=&amp;#39;relu&amp;#39;),     tf.keras.layers.Dense(30, activation=&amp;#39;relu&amp;#39;),     tf.keras.layers.Dense(1, activation=&amp;#39;linear&amp;#39;),   
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt; &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j1rnaa,True,,estejim17,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/j1rnaa/how_many_layers_does_my_nn_have/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1rnaa/how_many_layers_does_my_nn_have/,22217,1601350718.0,0,,False,,,,,,,,,
744,,tensorflow,"Hello! I just created a model and I am loading location data out of a CSV. I then put all of the location data into one list, with each index being another list of a pair of X and Y cords.  Finally, I made it into a NumPy array with np.asarray, and printing it out looks like how I want it, 2 columns (x, y), and many rows down.

&amp;#x200B;

\[\[0.03284732 0.71823503\]

 \[0.         0.80737603\]

 \[0.53450931 0.6075211 \]

 \[0.56680244 0.89441298\]

...

 \[0.75476707 0.57551977\]

 \[0.96351955 0.16136675\]\]

&amp;#x200B;

When I train the model, instead of going through the different data points, it just says 1/1. I set the Epoch to be high because it's the only way it actually trains. For example:

&amp;#x200B;

Epoch 992/1500

1/1 \[==============================\] - 0s 182us/step - loss: 0.3187 - accuracy: 0.8333

&amp;#x200B;

If there's anyone who knows how to fix this please let me know. This is my first real model not following a tutorial.",t2_7egje811,False,,0,False,Tensorflow training total tasks stays at 1/1... instead of going through the data,[],r/tensorflow,False,6,,0,,,False,t3_j1pkgv,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1601371849.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I just created a model and I am loading location data out of a CSV. I then put all of the location data into one list, with each index being another list of a pair of X and Y cords.  Finally, I made it into a NumPy array with np.asarray, and printing it out looks like how I want it, 2 columns (x, y), and many rows down.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;[[0.03284732 0.71823503]&lt;/p&gt;

&lt;p&gt;[0.         0.80737603]&lt;/p&gt;

&lt;p&gt;[0.53450931 0.6075211 ]&lt;/p&gt;

&lt;p&gt;[0.56680244 0.89441298]&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;[0.75476707 0.57551977]&lt;/p&gt;

&lt;p&gt;[0.96351955 0.16136675]]&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;When I train the model, instead of going through the different data points, it just says 1/1. I set the Epoch to be high because it&amp;#39;s the only way it actually trains. For example:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Epoch 992/1500&lt;/p&gt;

&lt;p&gt;1/1 [==============================] - 0s 182us/step - loss: 0.3187 - accuracy: 0.8333&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;If there&amp;#39;s anyone who knows how to fix this please let me know. This is my first real model not following a tutorial.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j1pkgv,True,,Pixels_128,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j1pkgv/tensorflow_training_total_tasks_stays_at_11/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1pkgv/tensorflow_training_total_tasks_stays_at_11/,22217,1601343049.0,0,,False,,,,,,,,,
745,,tensorflow,https://medium.com/@cleanpegasus/getting-started-with-tensorflow-serving-b03c130bdb5c,t2_xt6j8xa,False,,0,False,I wrote a blog on getting started with tensorflow serving. Please let me know if it's any good.,[],r/tensorflow,False,6,,0,,,False,t3_j19qx8,False,dark,0.92,,public,11,0,{},,,False,[],,False,False,,{},,False,11,,False,self,False,,[],{},,True,,1601318727.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://medium.com/@cleanpegasus/getting-started-with-tensorflow-serving-b03c130bdb5c""&gt;https://medium.com/@cleanpegasus/getting-started-with-tensorflow-serving-b03c130bdb5c&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j19qx8,True,,clean_pegasus,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j19qx8/i_wrote_a_blog_on_getting_started_with_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j19qx8/i_wrote_a_blog_on_getting_started_with_tensorflow/,22217,1601289927.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/blMzWsTtDJfEzPTU3GhJV3wkhzOmB7qI3uGpfnaW9SA.jpg?auto=webp&amp;s=bc2da3059bc2a89bce23092b188ef5b93963ae11', 'width': 1000, 'height': 562}, 'resolutions': [{'url': 'https://external-preview.redd.it/blMzWsTtDJfEzPTU3GhJV3wkhzOmB7qI3uGpfnaW9SA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f474ec3406914740cdacb1d60e0b04c10ff04ea', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/blMzWsTtDJfEzPTU3GhJV3wkhzOmB7qI3uGpfnaW9SA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5aa2be0adb2f5722c9003f4c74f649fdb97c87d', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/blMzWsTtDJfEzPTU3GhJV3wkhzOmB7qI3uGpfnaW9SA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1313601d9fb774b2f15c4b14172bb9d57c990ac5', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/blMzWsTtDJfEzPTU3GhJV3wkhzOmB7qI3uGpfnaW9SA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=347df94d825f1f15aadbf95aa465534452bcbc88', 'width': 640, 'height': 359}, {'url': 'https://external-preview.redd.it/blMzWsTtDJfEzPTU3GhJV3wkhzOmB7qI3uGpfnaW9SA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d0af2b43ffb42a555bd49f4bbfbfbe80664cf94b', 'width': 960, 'height': 539}], 'variants': {}, 'id': '7AJXen_Vf-MTeBgcQw2bSnjSvTQSmcwueGFQitQxLSA'}], 'enabled': False}",,,,,,
746,,tensorflow,,t2_89vuvmuk,False,,0,False,#Excellent,[],r/tensorflow,False,6,,0,105.0,,False,t3_j1rfmr,False,dark,0.25,,public,0,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/AgjbzHR8AnA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tinder Gold Free for Android &amp; iOS ❤️\u200d🔥 How to get Tined Gold for Free ❤️\u200d🔥 Lifetime Free', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/AgjbzHR8AnA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Emel Eberi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/AgjbzHR8AnA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCaK31LPnadiNBqSKuRcLAmA'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/AgjbzHR8AnA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j1rfmr', 'height': 338}",,False,0,,False,https://b.thumbs.redditmedia.com/3h_u3pr3uHNgOQsQJBLPa5rune0I2cAUfHu6DFuX8hk.jpg,False,,[],{},,False,,1601378711.0,text,6,,,text,youtu.be,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j1rfmr,True,,Pritish123m,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/j1rfmr/excellent/,all_ads,False,https://youtu.be/AgjbzHR8AnA,22217,1601349911.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Tinder Gold Free for Android &amp; iOS ❤️\u200d🔥 How to get Tined Gold for Free ❤️\u200d🔥 Lifetime Free', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/AgjbzHR8AnA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Emel Eberi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/AgjbzHR8AnA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCaK31LPnadiNBqSKuRcLAmA'}}",False,rich:video,https://youtu.be/AgjbzHR8AnA,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-UN1Eus63PW3oGg1nLBtSU9AOnUEN7gRIK-tXyx7SGA.jpg?auto=webp&amp;s=4c84037769c8de20d326c2331981cacdba03b892', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/-UN1Eus63PW3oGg1nLBtSU9AOnUEN7gRIK-tXyx7SGA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2455e88c65b97815fa2321805d9a8067373fd19', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/-UN1Eus63PW3oGg1nLBtSU9AOnUEN7gRIK-tXyx7SGA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f263fc37fe92ba9969fcb78d746eca6e28124e4b', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/-UN1Eus63PW3oGg1nLBtSU9AOnUEN7gRIK-tXyx7SGA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=afbff2b2b70f9b72ec273fb396575f23c3caa265', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'tf-OnW8PWyYf4nveeJ-HI46kASv53jdbpJPctOqHkac'}], 'enabled': False}",,,,,,
747,,tensorflow,"I submitted my exam on september 12. Notified that I passed the exam after 2 seconds and got my certificate 3 days later but I'm still not in the TensorFlow Developer Network (which is the most important part I guess). 

They said ""You are now eligible to be listed among fellow TensorFlow developers in the TensorFlow Certificate Network. \[...\] **you will be added to our directory within 2 weeks of your submission.""** but still nothing.

Also the directory seems stuck on august, the most recent developer was certified on august 31. It seems very unlikely that nobody passed the exam in september.

Any idea on what's going on?",t2_4650dvvr,False,,0,False,TensorFlow Developer Directory stuck on august 31?,[],r/tensorflow,False,6,,0,,,False,t3_j18f1v,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1601311348.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I submitted my exam on september 12. Notified that I passed the exam after 2 seconds and got my certificate 3 days later but I&amp;#39;m still not in the TensorFlow Developer Network (which is the most important part I guess). &lt;/p&gt;

&lt;p&gt;They said &amp;quot;You are now eligible to be listed among fellow TensorFlow developers in the TensorFlow Certificate Network. [...] &lt;strong&gt;you will be added to our directory within 2 weeks of your submission.&amp;quot;&lt;/strong&gt; but still nothing.&lt;/p&gt;

&lt;p&gt;Also the directory seems stuck on august, the most recent developer was certified on august 31. It seems very unlikely that nobody passed the exam in september.&lt;/p&gt;

&lt;p&gt;Any idea on what&amp;#39;s going on?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j18f1v,True,,Bodhis4ttva,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j18f1v/tensorflow_developer_directory_stuck_on_august_31/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j18f1v/tensorflow_developer_directory_stuck_on_august_31/,22217,1601282548.0,0,,False,,,,,,,,,
748,,tensorflow,"Hello,

What is the best distro to be installed for TensorFlow GPU with NVIDIA GeForce 1050 Ti ?",t2_f8wf5,False,,0,False,What is the best distro for tensorflow GPU,[],r/tensorflow,False,6,,0,,,False,t3_j1fmox,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1601340422.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;What is the best distro to be installed for TensorFlow GPU with NVIDIA GeForce 1050 Ti ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j1fmox,True,,wbadry,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j1fmox/what_is_the_best_distro_for_tensorflow_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1fmox/what_is_the_best_distro_for_tensorflow_gpu/,22217,1601311622.0,0,,False,,,,,,,,,
749,,tensorflow,"I'm attempting to create a a self driving car AI using TensorFlow. The car itself is really simple its just a rectangle on a 2D track, it 'sees' its environment with 8 distances from centre of the car to the track these 8 distances are spread out 45 degrees between them. The information I plan on giving the network are these 8 distances, the speed of the car and the acceleration/deceleration rate. I was originally thinking of using a simple deep neural network, what do other people think to this idea? Thank you for any suggestions or improvements!",t2_4gc23p0w,False,,0,False,What would the best neural network type to use for a self driving car?,[],r/tensorflow,False,6,,0,,,False,t3_j1eqir,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Question,False,0,,False,self,False,,[],{},,True,,1601337648.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m attempting to create a a self driving car AI using TensorFlow. The car itself is really simple its just a rectangle on a 2D track, it &amp;#39;sees&amp;#39; its environment with 8 distances from centre of the car to the track these 8 distances are spread out 45 degrees between them. The information I plan on giving the network are these 8 distances, the speed of the car and the acceleration/deceleration rate. I was originally thinking of using a simple deep neural network, what do other people think to this idea? Thank you for any suggestions or improvements!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j1eqir,True,,F1nn1711,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j1eqir/what_would_the_best_neural_network_type_to_use/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1eqir/what_would_the_best_neural_network_type_to_use/,22217,1601308848.0,0,,False,,,,,,,,,
750,,tensorflow,"I'm using my own generator for training and I want to do the shuffling and selecting of validation data from my main dataset without having to parse it into a separate validation set on disk. 

Does the fit method recognize some format as being data for validation? Do I just give it two tuples and it will take the second tuple as validation data?",t2_5wuzf,False,,0,False,What do I need to yield for a validation split in my own generator?,[],r/tensorflow,False,6,,0,,,False,t3_j1aejp,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1601321984.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m using my own generator for training and I want to do the shuffling and selecting of validation data from my main dataset without having to parse it into a separate validation set on disk. &lt;/p&gt;

&lt;p&gt;Does the fit method recognize some format as being data for validation? Do I just give it two tuples and it will take the second tuple as validation data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j1aejp,True,,thejeran,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/j1aejp/what_do_i_need_to_yield_for_a_validation_split_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j1aejp/what_do_i_need_to_yield_for_a_validation_split_in/,22217,1601293184.0,0,,False,,,,,,,,,
751,,tensorflow,[https://analyticsindiamag.com/tensorflow-tfrs-recommenders-package/](https://analyticsindiamag.com/tensorflow-tfrs-recommenders-package/),t2_40d0zt4s,False,,0,False,Tensorflow Releases New Package For Recommendation Systems: TFRS,[],r/tensorflow,False,6,,0,,,False,t3_j18d1j,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Discussion,False,3,,False,self,False,,[],{},,True,,1601311021.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://analyticsindiamag.com/tensorflow-tfrs-recommenders-package/""&gt;https://analyticsindiamag.com/tensorflow-tfrs-recommenders-package/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j18d1j,True,,analyticsindiam,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j18d1j/tensorflow_releases_new_package_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j18d1j/tensorflow_releases_new_package_for/,22217,1601282221.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?auto=webp&amp;s=54af32bfef4d260837406156a2c20b425281d11b', 'width': 1280, 'height': 720}, 'resolutions': [{'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e7ca18e75608ab8b25df2a37720a9c6706578681', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a7dd82584466eb5ccde48eacdc9dc3420e87033', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e82b63f3b649dca655a1adbc337cf22cabc507fc', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1cff97797b7a0b3e894c50f44cf9781cf11b6065', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=305d5b158042f8bae3ab1c325ce927f715a97372', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/-LO16wJz99TGjIn3wd6DQUYWpIG1dAGGbOyZuAmp6Xc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f6854dc1df54642f77695c0fe837808f7e1f75e', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'FOavXLiAfvsbaNeDIUzbVrqkROSMMvd2F6QCxo1WklI'}], 'enabled': False}",,,,,,
752,,tensorflow,"Hi there,

I'm new to RL, and am looking at creating custom environments for two agents playing against each other in a game I made with tf-agents. I'm aware tf-agents doesn't seem to handle multi-agent environments out of the box (and I'm using windows so RLlib isn't an easy option). I've read a few tutorials about custom environments, and am doing my best to hash something workable together.

The game I'm trying to train agents on needs the moves of both players, which are essentially coordinates of the pieces they control, and then calculates the final position following those moves. The reason I'm using twisted is to handle this sort of asynchronous issue- the \_step() method can't just send a move to the game and return the result, as the result is only returned if the game has both sets of moves- my thought was with server-client stuff, the \_step() method can just send the moves, and the client can wait to receive the result.

In the below code you can see a custom environment, which connects to a server on localhost (which is running in the script which runs the game). The \_step(action) method would send the action to the game, which, once both players moves have been collected, calculates the result and returns a result and observation spec through the connection. Ideally the dataReceived() method unpacks the result, and ticks on the time\_step. 

Here a move will consists of a 6x2 array with values between 0 and 1 (which represent destination coordinates for the relevant players in the game as a proportion of the screen's pixels). self.\_state and the observation spec is a 13x4 array, which again represents the position of players as a proportion of the screen pixels, plus some other info.

Here's example of the basic environment I'm aiming for, the two custom environments will be the same save for the reward values based on the observation:

     class TrainClient(Protocol):
    
        def __init__(self):
            self.moves = []
    
        def connectionMade(self):
            pass
    
        def dataReceived(self, data):
    
            response = pickle.loads(data)
            
            if response[0] == ActionState.CHANGE_POSSESSION:
                return time_step.termination(response[1], 10)
    
            elif response[0] == ActionState.DOWN_INCREASE:
                return time_step.transition(response[1], reward=0.05, discount=1.0)
    
            elif response[0] == ActionState.TOUCHDOWN:
                return time_step.termination(response[1], -10)
    
            elif response[0] == ActionState.VALID_MOVE:
                return time_step.transition(response[1:], reward=0, discount=0)
    
    
    class TrainClientFactory(ClientFactory):
        def startedConnecting(self, connector):
            print('Started to connect.')
    
        def buildProtocol(self, addr):
            print('Connected.')
            return TrainClient()
    
        def clientConnectionLost(self, connector, reason):
            print('Lost connection.  Reason:', reason)
    
        def clientConnectionFailed(self, connector, reason):
            print('Connection failed. Reason:', reason)
    
    
    class ActionState(Enum):
        VALID_MOVE = 1
        ILLEGAL_MOVE = 2
        CHANGE_POSSESSION = 3
        DOWN_INCREASE = 4
        TOUCHDOWN = 5
        GAME_COMPLETE = 6
    
    
    class CrossEnv(PyEnvironment):
    
        def __init__(self, connection):
            self._action_spec = array_spec.BoundedArraySpec((6, 2), np.float, minimum=0, maximum=1, name='moves')
            self._observation_spec = array_spec.BoundedArraySpec((13, 4), np.float, minimum=0, maximum=1, name='field')
            self._state = [[0.9, 0.18759375, 0., 0.],
                           [0.125, 0.18759375, 0., 0.],
                           [0.5835, 0.18759375, 0., 0.],
                           [0.4165, 0.18759375, 0., 0.],
                           [0.5, 0.18759375, 0., 0.],
                           [0.9, 0.0939375, 0., 0.],
                           [0.125, 0.0939375, 0., 0.],
                           [0.5835, 0.0939375, 0., 0.],
                           [0.4165, 0.0939375, 0., 0.],
                           [0.5, 0.04696875, 1., 0.],
                           [0.5215, 0.04696875, 0., 0.],
                           [1., 0., 0., 0.],
                           [0., 0., 0., 0.]]
            self._episode_ended = False
            self.connection = connection
    
        def action_spec(self):
            return self._action_spec
    
        def observation_spec(self):
            return self._observation_spec
    
        def _reset(self):
            self._state = [[0.9, 0.18759375, 0., 0.],
                           [0.125, 0.18759375, 0., 0.],
                           [0.5835, 0.18759375, 0., 0.],
                           [0.4165, 0.18759375, 0., 0.],
                           [0.5, 0.18759375, 0., 0.],
                           [0.9, 0.0939375, 0., 0.],
                           [0.125, 0.0939375, 0., 0.],
                           [0.5835, 0.0939375, 0., 0.],
                           [0.4165, 0.0939375, 0., 0.],
                           [0.5, 0.04696875, 1., 0.],
                           [0.5215, 0.04696875, 0., 0.],
                           [1., 0., 0., 0.],
                           [0., 0., 0., 0.]]
    
            self._episode_ended = False
            return time_step.restart(np.array(self._state))
    
        def _step(self, action):
    
            if self._episode_ended:
                return self.reset()
            list1 = ['cross']
            list1.append(action)
            moves = pickle.dumps(list1)
            print(f'action: {list1}')
            self.connection.transport.write(moves)
    
    
    connection = reactor.connectTCP('localhost', 8001, TrainClientFactory())
    cross_footballEnvironment = CrossEnv(connection)
    
    reactor.run()

Trying to validate the environment with

    utils.validate_py_environment(cross_footballEnvironment, episodes=5)

currently returns an attribute error on the time\_step:

`if time_step.is_last():`

`AttributeError: 'NoneType' object has no attribute 'is_last'`

Strangely the same code ran last night without error. I can't find the error online anywhere, but I assume it's is something to do with the time\_step transitions/terminations being in the twisted protocol method rather than the \_step method?

Would be interested if anyone has any thoughts on that error, but also if the more experienced out there have general thoughts about whether this approach could/should work? Or if it's a bad idea and there are better alternatives? 

Any thoughts appreciated!",t2_2h944crl,False,,0,False,"tf-agents: to replicate multi-agent environments, could an approach with two custom environments simultaneously interacting with game engine via twisted clients work? (Plus an AttributeError in utils.validate_pyenvironment(), time_step is None type)",[],r/tensorflow,False,6,,0,,,False,t3_j19sae,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1601318931.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m new to RL, and am looking at creating custom environments for two agents playing against each other in a game I made with tf-agents. I&amp;#39;m aware tf-agents doesn&amp;#39;t seem to handle multi-agent environments out of the box (and I&amp;#39;m using windows so RLlib isn&amp;#39;t an easy option). I&amp;#39;ve read a few tutorials about custom environments, and am doing my best to hash something workable together.&lt;/p&gt;

&lt;p&gt;The game I&amp;#39;m trying to train agents on needs the moves of both players, which are essentially coordinates of the pieces they control, and then calculates the final position following those moves. The reason I&amp;#39;m using twisted is to handle this sort of asynchronous issue- the _step() method can&amp;#39;t just send a move to the game and return the result, as the result is only returned if the game has both sets of moves- my thought was with server-client stuff, the _step() method can just send the moves, and the client can wait to receive the result.&lt;/p&gt;

&lt;p&gt;In the below code you can see a custom environment, which connects to a server on localhost (which is running in the script which runs the game). The _step(action) method would send the action to the game, which, once both players moves have been collected, calculates the result and returns a result and observation spec through the connection. Ideally the dataReceived() method unpacks the result, and ticks on the time_step. &lt;/p&gt;

&lt;p&gt;Here a move will consists of a 6x2 array with values between 0 and 1 (which represent destination coordinates for the relevant players in the game as a proportion of the screen&amp;#39;s pixels). self._state and the observation spec is a 13x4 array, which again represents the position of players as a proportion of the screen pixels, plus some other info.&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s example of the basic environment I&amp;#39;m aiming for, the two custom environments will be the same save for the reward values based on the observation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; class TrainClient(Protocol):

    def __init__(self):
        self.moves = []

    def connectionMade(self):
        pass

    def dataReceived(self, data):

        response = pickle.loads(data)

        if response[0] == ActionState.CHANGE_POSSESSION:
            return time_step.termination(response[1], 10)

        elif response[0] == ActionState.DOWN_INCREASE:
            return time_step.transition(response[1], reward=0.05, discount=1.0)

        elif response[0] == ActionState.TOUCHDOWN:
            return time_step.termination(response[1], -10)

        elif response[0] == ActionState.VALID_MOVE:
            return time_step.transition(response[1:], reward=0, discount=0)


class TrainClientFactory(ClientFactory):
    def startedConnecting(self, connector):
        print(&amp;#39;Started to connect.&amp;#39;)

    def buildProtocol(self, addr):
        print(&amp;#39;Connected.&amp;#39;)
        return TrainClient()

    def clientConnectionLost(self, connector, reason):
        print(&amp;#39;Lost connection.  Reason:&amp;#39;, reason)

    def clientConnectionFailed(self, connector, reason):
        print(&amp;#39;Connection failed. Reason:&amp;#39;, reason)


class ActionState(Enum):
    VALID_MOVE = 1
    ILLEGAL_MOVE = 2
    CHANGE_POSSESSION = 3
    DOWN_INCREASE = 4
    TOUCHDOWN = 5
    GAME_COMPLETE = 6


class CrossEnv(PyEnvironment):

    def __init__(self, connection):
        self._action_spec = array_spec.BoundedArraySpec((6, 2), np.float, minimum=0, maximum=1, name=&amp;#39;moves&amp;#39;)
        self._observation_spec = array_spec.BoundedArraySpec((13, 4), np.float, minimum=0, maximum=1, name=&amp;#39;field&amp;#39;)
        self._state = [[0.9, 0.18759375, 0., 0.],
                       [0.125, 0.18759375, 0., 0.],
                       [0.5835, 0.18759375, 0., 0.],
                       [0.4165, 0.18759375, 0., 0.],
                       [0.5, 0.18759375, 0., 0.],
                       [0.9, 0.0939375, 0., 0.],
                       [0.125, 0.0939375, 0., 0.],
                       [0.5835, 0.0939375, 0., 0.],
                       [0.4165, 0.0939375, 0., 0.],
                       [0.5, 0.04696875, 1., 0.],
                       [0.5215, 0.04696875, 0., 0.],
                       [1., 0., 0., 0.],
                       [0., 0., 0., 0.]]
        self._episode_ended = False
        self.connection = connection

    def action_spec(self):
        return self._action_spec

    def observation_spec(self):
        return self._observation_spec

    def _reset(self):
        self._state = [[0.9, 0.18759375, 0., 0.],
                       [0.125, 0.18759375, 0., 0.],
                       [0.5835, 0.18759375, 0., 0.],
                       [0.4165, 0.18759375, 0., 0.],
                       [0.5, 0.18759375, 0., 0.],
                       [0.9, 0.0939375, 0., 0.],
                       [0.125, 0.0939375, 0., 0.],
                       [0.5835, 0.0939375, 0., 0.],
                       [0.4165, 0.0939375, 0., 0.],
                       [0.5, 0.04696875, 1., 0.],
                       [0.5215, 0.04696875, 0., 0.],
                       [1., 0., 0., 0.],
                       [0., 0., 0., 0.]]

        self._episode_ended = False
        return time_step.restart(np.array(self._state))

    def _step(self, action):

        if self._episode_ended:
            return self.reset()
        list1 = [&amp;#39;cross&amp;#39;]
        list1.append(action)
        moves = pickle.dumps(list1)
        print(f&amp;#39;action: {list1}&amp;#39;)
        self.connection.transport.write(moves)


connection = reactor.connectTCP(&amp;#39;localhost&amp;#39;, 8001, TrainClientFactory())
cross_footballEnvironment = CrossEnv(connection)

reactor.run()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Trying to validate the environment with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;utils.validate_py_environment(cross_footballEnvironment, episodes=5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;currently returns an attribute error on the time_step:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;if time_step.is_last():&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AttributeError: &amp;#39;NoneType&amp;#39; object has no attribute &amp;#39;is_last&amp;#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Strangely the same code ran last night without error. I can&amp;#39;t find the error online anywhere, but I assume it&amp;#39;s is something to do with the time_step transitions/terminations being in the twisted protocol method rather than the _step method?&lt;/p&gt;

&lt;p&gt;Would be interested if anyone has any thoughts on that error, but also if the more experienced out there have general thoughts about whether this approach could/should work? Or if it&amp;#39;s a bad idea and there are better alternatives? &lt;/p&gt;

&lt;p&gt;Any thoughts appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j19sae,True,,drjjm,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j19sae/tfagents_to_replicate_multiagent_environments/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j19sae/tfagents_to_replicate_multiagent_environments/,22217,1601290131.0,0,,False,,,,,,,,,
753,,tensorflow,"I've just started with DeepFaceLab / Machine Learning and was using a 1660 Super but sold it in anticipation of the RTX 3070 but apparently TensorFlow doesn't yet work with Nvidia's Ampere architecture. 

Is it correct to assume TensorFlow will be updated sooner rather than later?

I'm trying to decide if I should just get a 2070 Super instead.",t2_6hpt2nl1,False,,0,False,Does Tensorflow work with RTX 3000 series?,[],r/tensorflow,False,6,,0,,,False,t3_j0s938,False,dark,0.94,,public,12,0,{},,,False,[],,False,False,,{},Question,False,12,,False,self,False,,[],{},,True,,1601246656.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve just started with DeepFaceLab / Machine Learning and was using a 1660 Super but sold it in anticipation of the RTX 3070 but apparently TensorFlow doesn&amp;#39;t yet work with Nvidia&amp;#39;s Ampere architecture. &lt;/p&gt;

&lt;p&gt;Is it correct to assume TensorFlow will be updated sooner rather than later?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to decide if I should just get a 2070 Super instead.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j0s938,True,,PsillyPseudonym,,18,True,all_ads,False,[],False,,/r/tensorflow/comments/j0s938/does_tensorflow_work_with_rtx_3000_series/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j0s938/does_tensorflow_work_with_rtx_3000_series/,22217,1601217856.0,0,,False,,,,,,,,,
754,,tensorflow,,t2_1p75i2n6,False,,0,False,"Hi #Devs, I registered to attend India's largest developer conclave - ""DevFest India"". There are some amazing sessions by expert speakers and you can join me now! Register at: https://devfestindia.com/ #DevFestIndia #DevFest @DevFestIndia",[],r/tensorflow,False,6,,0,70.0,,False,t3_j18a7z,False,dark,0.25,,public,0,0,{},140.0,,False,[],,True,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/p5FRO9TW1G_weCvHeEo7InOHqHFGNV9jkjWYN8KgNVY.jpg,False,,[],{},,False,,1601310578.0,text,6,,,text,i.redd.it,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j18a7z,True,,JackRyu,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j18a7z/hi_devs_i_registered_to_attend_indias_largest/,all_ads,False,https://i.redd.it/ojoef29wmup51.jpg,22217,1601281778.0,0,,False,image,https://i.redd.it/ojoef29wmup51.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?auto=webp&amp;s=854f14970b1e05eb14a31287372363644c1f7c06', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc44c8390a70ba1f7f7053822b358855c70c7da0', 'width': 108, 'height': 54}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be4c840296fbde52abbeaad902f671c9152300b0', 'width': 216, 'height': 108}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8c6b442ce407cc9b2859044fddcd58a648b75c5', 'width': 320, 'height': 160}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2bb356e4260f3c93ff5869d23848d3de91db0b06', 'width': 640, 'height': 320}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a1eefd859466fe37541b377a27eaf729e0ea475', 'width': 960, 'height': 480}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94931ec69ccda696d3558654ba8c28ae5bb7801c', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'fwE1qLKHt91rPJMFAW0dzGkLYo3RyC2IeJg31g1Xifo'}], 'enabled': True}",,,,"[{'approved_at_utc': None, 'subreddit': 'TECHKBMB', 'selftext': '', 'author_fullname': 't2_1p75i2n6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Hi #Devs, I registered to attend India\'s largest developer conclave - ""DevFest India"". There are some amazing sessions by expert speakers and you can join me now! Register at: https://devfestindia.com/ #DevFestIndia #DevFest @DevFestIndia', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/TECHKBMB', 'hidden': False, 'pwls': None, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 70, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_j189bs', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'NEWS', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/p5FRO9TW1G_weCvHeEo7InOHqHFGNV9jkjWYN8KgNVY.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'image', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1601310432.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/ojoef29wmup51.jpg', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?auto=webp&amp;s=854f14970b1e05eb14a31287372363644c1f7c06', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc44c8390a70ba1f7f7053822b358855c70c7da0', 'width': 108, 'height': 54}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be4c840296fbde52abbeaad902f671c9152300b0', 'width': 216, 'height': 108}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8c6b442ce407cc9b2859044fddcd58a648b75c5', 'width': 320, 'height': 160}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2bb356e4260f3c93ff5869d23848d3de91db0b06', 'width': 640, 'height': 320}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a1eefd859466fe37541b377a27eaf729e0ea475', 'width': 960, 'height': 480}, {'url': 'https://preview.redd.it/ojoef29wmup51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94931ec69ccda696d3558654ba8c28ae5bb7801c', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'fwE1qLKHt91rPJMFAW0dzGkLYo3RyC2IeJg31g1Xifo'}], 'enabled': True}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'e8557896-f26f-11ea-b7fb-0eb0f8c3a0c5', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2x5lnq', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ffd635', 'id': 'j189bs', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'JackRyu', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/TECHKBMB/comments/j189bs/hi_devs_i_registered_to_attend_indias_largest/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/ojoef29wmup51.jpg', 'subreddit_subscribers': 3, 'created_utc': 1601281632.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_j189bs,
755,,tensorflow,,t2_70ba9e8c,False,,0,False,Fine-Tuning DistilBert for Multi-Class Text Classification using transformers and TensorFlow,[],r/tensorflow,False,6,,0,,,False,t3_j0o8ug,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,default,False,,[],{},,False,,1601227508.0,text,6,,,text,sunnyville.ai,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j0o8ug,True,,sunnyville04,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j0o8ug/finetuning_distilbert_for_multiclass_text/,all_ads,False,https://www.sunnyville.ai/fine-tuning-distilbert-multi-class-text-classification-using-transformers-and-tensorflow/,22217,1601198708.0,0,,False,,https://www.sunnyville.ai/fine-tuning-distilbert-multi-class-text-classification-using-transformers-and-tensorflow/,,,,,,,
756,,tensorflow,,t2_683tvs22,False,,0,False,Editing MrBeast with StyleGAN2,[],r/tensorflow,False,6,,0,105.0,,False,t3_j0rfa6,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nmQbL0Ho4Nw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Editing Jimmy's Face with AI (StyleGAN2)"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nmQbL0Ho4Nw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/nmQbL0Ho4Nw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nmQbL0Ho4Nw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/j0rfa6', 'height': 338}",,False,2,,False,https://a.thumbs.redditmedia.com/-7ww_MMEtyVcPcmwv-Xf2r0guXjDzBexyAUI3iw_H64.jpg,False,,[],{},,False,,1601243472.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j0rfa6,True,,N2AI,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j0rfa6/editing_mrbeast_with_stylegan2/,all_ads,False,https://youtu.be/nmQbL0Ho4Nw,22217,1601214672.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Editing Jimmy's Face with AI (StyleGAN2)"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nmQbL0Ho4Nw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/nmQbL0Ho4Nw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,rich:video,https://youtu.be/nmQbL0Ho4Nw,"{'images': [{'source': {'url': 'https://external-preview.redd.it/gFQe02VarAoAum8BUFgdECeMT_tDXmPioHcecEOSnyk.jpg?auto=webp&amp;s=ac439df53fe1753d69cd7d256c2c26b48051d8d0', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/gFQe02VarAoAum8BUFgdECeMT_tDXmPioHcecEOSnyk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25d8b0c2da0c729a1e04dd7365986770f510e4b3', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/gFQe02VarAoAum8BUFgdECeMT_tDXmPioHcecEOSnyk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3eaac78146e9ab2f6cd31888a15c890ce441e15', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/gFQe02VarAoAum8BUFgdECeMT_tDXmPioHcecEOSnyk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=223669fc0de32e451e16a0064d191d75fd5f1632', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'sV2yXFSayJ0q-W2Qa-AhOr9CY0vFwm-73BmWrMMXYIU'}], 'enabled': False}",,,,,,
757,,tensorflow,"So I built a CNN image classifier yesterday, and I did it in google colab. I initially did it without a validation set, and I was getting decent accuracy on my training set of a 0.887 and loss of 0.2, but i wanted to go back through and add a validation set to check for overfitting as my model was training. So essentially I went back added a validation set and retrained, model during each epoch showed little signs of overfitting, as I the training accuracy and validation accuracy were within 0.1-0.2 and loss was close to each other as well. No drastic differences, however colab distrupted the training process and the runtime stopped, so my model stopped training last night at 50/100 epochs. No worries I thought, I’ll retrain it this morning so it had longer time to run. So now this was my 2nd time retraining the model with a validation set but this time there’s a huge discrepancy between my loss and accuracy between validation and training set. I don’t know if this is because I’ve fed the same model now twice, and now it’s overfitting it because I had fed it data on 50/100 epochs yesterday, but now I don’t know what’s wrong. Can a model overfit just from retraining it a couple times? I really have no control fo this as my runtime always disconnects when I’m not watching the colab. And hence I have to retrain it. Any advice? Does overfitting get caused by this?",t2_5w4i5kd1,False,,0,False,Overfitting when restarting colab?,[],r/tensorflow,False,6,,0,,,False,t3_j0ubhc,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1601254026.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I built a CNN image classifier yesterday, and I did it in google colab. I initially did it without a validation set, and I was getting decent accuracy on my training set of a 0.887 and loss of 0.2, but i wanted to go back through and add a validation set to check for overfitting as my model was training. So essentially I went back added a validation set and retrained, model during each epoch showed little signs of overfitting, as I the training accuracy and validation accuracy were within 0.1-0.2 and loss was close to each other as well. No drastic differences, however colab distrupted the training process and the runtime stopped, so my model stopped training last night at 50/100 epochs. No worries I thought, I’ll retrain it this morning so it had longer time to run. So now this was my 2nd time retraining the model with a validation set but this time there’s a huge discrepancy between my loss and accuracy between validation and training set. I don’t know if this is because I’ve fed the same model now twice, and now it’s overfitting it because I had fed it data on 50/100 epochs yesterday, but now I don’t know what’s wrong. Can a model overfit just from retraining it a couple times? I really have no control fo this as my runtime always disconnects when I’m not watching the colab. And hence I have to retrain it. Any advice? Does overfitting get caused by this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j0ubhc,True,,veeeerain,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/j0ubhc/overfitting_when_restarting_colab/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j0ubhc/overfitting_when_restarting_colab/,22217,1601225226.0,0,,False,,,,,,,,,
758,,tensorflow,"Hi everyone! I'm happy to announce that I writed my first post in towards data science community, my post is about a virtual steering wheel using posenet, if you find it interesting, let me some feedback.

Thank you!

[https://towardsdatascience.com/virtual-steering-wheel-with-javascript-and-posenet-12439712a68](https://towardsdatascience.com/virtual-steering-wheel-with-javascript-and-posenet-12439712a68)",t2_69jauppe,False,,0,False,My First Mediom post on Towards Data Science using Tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_j0q2fx,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,self,False,,[],{},,True,,1601237423.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone! I&amp;#39;m happy to announce that I writed my first post in towards data science community, my post is about a virtual steering wheel using posenet, if you find it interesting, let me some feedback.&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://towardsdatascience.com/virtual-steering-wheel-with-javascript-and-posenet-12439712a68""&gt;https://towardsdatascience.com/virtual-steering-wheel-with-javascript-and-posenet-12439712a68&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,j0q2fx,True,,mcarlomagno,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/j0q2fx/my_first_mediom_post_on_towards_data_science/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j0q2fx/my_first_mediom_post_on_towards_data_science/,22217,1601208623.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/eICL4FtRMaqvbbYWYpY3VG0rR0R1mZBjqgTRr1vsmac.jpg?auto=webp&amp;s=f7f4ef2ba6ba8fc6f3d5a11dec9ebb2a4bece919', 'width': 600, 'height': 326}, 'resolutions': [{'url': 'https://external-preview.redd.it/eICL4FtRMaqvbbYWYpY3VG0rR0R1mZBjqgTRr1vsmac.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ea1c7f87b8c096c8e5ed3abbb7231302ff573ab', 'width': 108, 'height': 58}, {'url': 'https://external-preview.redd.it/eICL4FtRMaqvbbYWYpY3VG0rR0R1mZBjqgTRr1vsmac.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4f5d344af3ce93a89f90da08fd168fe399eee23', 'width': 216, 'height': 117}, {'url': 'https://external-preview.redd.it/eICL4FtRMaqvbbYWYpY3VG0rR0R1mZBjqgTRr1vsmac.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46bdad4c513c1757aef5bdfae06f2aec7ca320e6', 'width': 320, 'height': 173}], 'variants': {}, 'id': 'r-trK3ZgQyrd3iquCjrjsP2k8URE4gn_eEOgm5sYmJ8'}], 'enabled': False}",,,,,,
759,,tensorflow,"I recently got a new machine and it has a GPU that can run TensorFlow on it (RTX 2070). So natrually I decided to upgrade to the tensorflow-gpu version and start using that instead. I followed this tutorial: [**https://www.youtube.com/watch?v=zTGrt1oyul4**](https://www.youtube.com/watch?v=zTGrt1oyul4)**,** and the installation was successful. But the problem now is that after I uninstalled the original TensorFlow version, keras refuse to start and claims that the TensorFlow version has to be 2.2 or later, while I have tensorflow 2.3. Any Ideas on how to fix this? I tried reinstalling keras and now not even keras will import.",t2_2ro3hv1w,False,,0,False,Eras and TensorFlow does not work anymore after attempting to install TensorFlow GPU,[],r/tensorflow,False,6,,0,,,False,t3_j0jn31,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1601204844.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently got a new machine and it has a GPU that can run TensorFlow on it (RTX 2070). So natrually I decided to upgrade to the tensorflow-gpu version and start using that instead. I followed this tutorial: &lt;a href=""https://www.youtube.com/watch?v=zTGrt1oyul4""&gt;&lt;strong&gt;https://www.youtube.com/watch?v=zTGrt1oyul4&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; and the installation was successful. But the problem now is that after I uninstalled the original TensorFlow version, keras refuse to start and claims that the TensorFlow version has to be 2.2 or later, while I have tensorflow 2.3. Any Ideas on how to fix this? I tried reinstalling keras and now not even keras will import.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j0jn31,True,,The747IsDead,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j0jn31/eras_and_tensorflow_does_not_work_anymore_after/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j0jn31/eras_and_tensorflow_does_not_work_anymore_after/,22217,1601176044.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/DMpwmwftu4R9znWrkf0TNDBER9oQLfvbwObkOnOXCic.jpg?auto=webp&amp;s=83524ed4a24905a1c6ae1b85b474f19ab94c13e8', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/DMpwmwftu4R9znWrkf0TNDBER9oQLfvbwObkOnOXCic.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e7989e727d497dbdbb1c116d21852224b0a5989f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/DMpwmwftu4R9znWrkf0TNDBER9oQLfvbwObkOnOXCic.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d75fcc46c16fca41473616022dfdb8f22eb973b9', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/DMpwmwftu4R9znWrkf0TNDBER9oQLfvbwObkOnOXCic.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2705ef249c19d66ed9cbda1eeb79e8cb56437210', 'width': 320, 'height': 240}], 'variants': {}, 'id': '5CGN-xS3zgDO1bHZV9zn4xZr3r0z4gP1NCamBKUpK6s'}], 'enabled': False}",,,,,,
760,,tensorflow,"Let's say the dataset consists of 1200 images, how many images should in each the training  &amp; validation sets be?",t2_4rlddyx5,False,,0,False,How to divide a dataset into training &amp; validation sets?,[],r/tensorflow,False,6,,0,,,False,t3_j03epy,False,dark,0.82,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1601143010.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Let&amp;#39;s say the dataset consists of 1200 images, how many images should in each the training  &amp;amp; validation sets be?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j03epy,True,,Randy-Brandy,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/j03epy/how_to_divide_a_dataset_into_training_validation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j03epy/how_to_divide_a_dataset_into_training_validation/,22217,1601114210.0,0,,False,,,,,,,,,
761,,tensorflow, I was running a GitHub code and the github doesnt have a proper read me file. When I trained the model I have ckpt-13000.index and ckpt-13000.data-00000-of-00001 file. I have worked with .h5 and .pb files but I am bemused with these type of files. Can anyone guide me that how can I load the model with the help of these files? The code is in Tensoflow 2.0,t2_492gevj0,False,,0,False,How to load a model with ckpt files?,[],r/tensorflow,False,6,,0,,,False,t3_j01iwa,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1601133315.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was running a GitHub code and the github doesnt have a proper read me file. When I trained the model I have ckpt-13000.index and ckpt-13000.data-00000-of-00001 file. I have worked with .h5 and .pb files but I am bemused with these type of files. Can anyone guide me that how can I load the model with the help of these files? The code is in Tensoflow 2.0&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,j01iwa,True,,ambuje12,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/j01iwa/how_to_load_a_model_with_ckpt_files/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j01iwa/how_to_load_a_model_with_ckpt_files/,22217,1601104515.0,0,,False,,,,,,,,,
762,,tensorflow,"Let's say the dataset consists of 1200 images, how many images should in each of the training &amp; validation set be?

Thanks",t2_4rlddyx5,False,,0,False,How to divide a dataset into training and validation sets?,[],r/tensorflow,False,6,,0,,,False,t3_j03djb,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1601142825.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Let&amp;#39;s say the dataset consists of 1200 images, how many images should in each of the training &amp;amp; validation set be?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,j03djb,True,,Randy-Brandy,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/j03djb/how_to_divide_a_dataset_into_training_and/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/j03djb/how_to_divide_a_dataset_into_training_and/,22217,1601114025.0,0,,False,,,,,,,,,
763,,tensorflow,,t2_jo9b4,False,,0,False,Advanced Tensorflow Data Input Pipelines: Handling Time Series,[],r/tensorflow,False,6,,0,70.0,,False,t3_izln3c,False,dark,0.91,,public,8,0,{},140.0,,False,[],,False,False,,{},,False,8,,False,https://a.thumbs.redditmedia.com/0XIjdfsTKXQg3GuWZ4H-rXeKFJ19Njq8a7h6UPkzg_8.jpg,False,,[],{},,False,,1601076847.0,text,6,,,text,medium.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,izln3c,True,,Zarkopafilis,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/izln3c/advanced_tensorflow_data_input_pipelines_handling/,all_ads,False,https://medium.com/@zarkopafilis/advanced-tensorflow-data-input-pipelines-handling-time-series-e990717d0089?sk=b406e1f70299730e709d741a2443ed14,22217,1601048047.0,0,,False,link,https://medium.com/@zarkopafilis/advanced-tensorflow-data-input-pipelines-handling-time-series-e990717d0089?sk=b406e1f70299730e709d741a2443ed14,"{'images': [{'source': {'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?auto=webp&amp;s=97e718a52e288ea5dd675063a763a7caa4be8d42', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73360bc0a29f7522dd500345ef7de13c58af3f44', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bac2b4b03e379b6512d7e6607b937a2fd08eca6f', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07b5230b42d22af8f4c83fff6661b41c40a89626', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=27ea06c0a6eafaf55c56c17ea33904f2d3536864', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6e1c26e71bd3c8aeb18024f3700e70d6cd64f925', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/q1YMoDMI6wms7Y696zI7s7FMvGNQvTrN-m-AH_OdfHs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7cdf14fc7f0a352e8d8abcf4af88998e514be6c8', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'GNRqcMu853-TReckw9LHnA2Q7N56GyJisSkHMI04Ics'}], 'enabled': False}",,,,,,
764,,tensorflow,I want the esp32 cam to detect an object. When it detects the object i want it to turn on an led. How can I use tensorflow for this?,t2_7m4o7t7l,False,,0,False,How to use tensorflow with esp32 cam,[],r/tensorflow,False,6,,0,,,False,t3_izty5t,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1601103003.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want the esp32 cam to detect an object. When it detects the object i want it to turn on an led. How can I use tensorflow for this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,izty5t,True,,SnooBeans1504,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/izty5t/how_to_use_tensorflow_with_esp32_cam/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/izty5t/how_to_use_tensorflow_with_esp32_cam/,22217,1601074203.0,0,,False,,,,,,,,,
765,,tensorflow,,t2_5w4i5kd1,False,,0,False,Issue with image data generator when compiling with model.,[],r/tensorflow,False,6,,0,51.0,,False,t3_izdw8j,False,dark,0.91,,public,8,0,{},140.0,,False,[],,True,False,,{},Question,False,8,,False,https://b.thumbs.redditmedia.com/hhfcjEFwAKbkOWMKB3_3EUhJXvMMZxVZT2cMqmFIKAk.jpg,False,,[],{},,False,,1601040981.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,izdw8j,True,,veeeerain,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/izdw8j/issue_with_image_data_generator_when_compiling/,all_ads,False,https://i.redd.it/bnputoood8p51.jpg,22217,1601012181.0,0,,False,image,https://i.redd.it/bnputoood8p51.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/bnputoood8p51.jpg?auto=webp&amp;s=e3ae6d97e98579f1654a3030215c0c39b6002522', 'width': 1656, 'height': 611}, 'resolutions': [{'url': 'https://preview.redd.it/bnputoood8p51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25aa2b18eb782890ad722b56dd64b1cc56a9d653', 'width': 108, 'height': 39}, {'url': 'https://preview.redd.it/bnputoood8p51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=735eb33c7ca1cd58e8ea064d1cb00eceda68a750', 'width': 216, 'height': 79}, {'url': 'https://preview.redd.it/bnputoood8p51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65493dd1f6539049e4cda58d07c4303d445ac173', 'width': 320, 'height': 118}, {'url': 'https://preview.redd.it/bnputoood8p51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=101b106b9613a76556006e13c5d9ccb194893307', 'width': 640, 'height': 236}, {'url': 'https://preview.redd.it/bnputoood8p51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1f80263abe20ee1b11a6a8a8df20a65f4412e5a', 'width': 960, 'height': 354}, {'url': 'https://preview.redd.it/bnputoood8p51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=52f6f74e94624be5c86ab1c6c54e2e9066549faa', 'width': 1080, 'height': 398}], 'variants': {}, 'id': 'M0ksMZ0H7G8InywxWRBL1k2iBRhnwHZYoCEUZ3mdj1U'}], 'enabled': True}",,,,,,
766,,tensorflow,"I've exhausted Google, trying a number of the instructions there - but I have not yet had any success. Can this community point me to a decent  beginners tutorial on installing TF or TFlite on Ubuntu running in a VM?

If it helps, my goal is to process still images for person detection. These still images are taken by a Raspberry Pi running [Motion](https://github.com/Motion-Project/motion), and saved. Motion produces a lot of false positives, so I want to process the images for people to reduce useless notifications. I did get this method working on the Pi, but it was overheating etc - so I would like to (I think?) run TF on a WIN10 I5 machine that I am already running VirtualBox on for other projects. Thanks!",t2_cw46x,False,,0,False,Looking for tutorial on installing TF or TFlite on Ubuntu running in a VM,[],r/tensorflow,False,6,,0,,,False,t3_iz5ovz,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1601009903.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve exhausted Google, trying a number of the instructions there - but I have not yet had any success. Can this community point me to a decent  beginners tutorial on installing TF or TFlite on Ubuntu running in a VM?&lt;/p&gt;

&lt;p&gt;If it helps, my goal is to process still images for person detection. These still images are taken by a Raspberry Pi running &lt;a href=""https://github.com/Motion-Project/motion""&gt;Motion&lt;/a&gt;, and saved. Motion produces a lot of false positives, so I want to process the images for people to reduce useless notifications. I did get this method working on the Pi, but it was overheating etc - so I would like to (I think?) run TF on a WIN10 I5 machine that I am already running VirtualBox on for other projects. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iz5ovz,True,,Tie_Good_Flies,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/iz5ovz/looking_for_tutorial_on_installing_tf_or_tflite/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iz5ovz/looking_for_tutorial_on_installing_tf_or_tflite/,22217,1600981103.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/fFDzY_kPe4hKGjul4fX3MEYGYRkKr3AeuzCiu3wdLaQ.jpg?auto=webp&amp;s=19512f846dff8fd03d2be122174f63e4fbfe5abf', 'width': 43, 'height': 43}, 'resolutions': [], 'variants': {}, 'id': 'NsMOrkvKdqxReb65W8Cw_tZqn_UK8JgWRG802tkGIgA'}], 'enabled': False}",,,,,,
767,,tensorflow,,t2_3e708,False,,0,False,TensorFlow Lite With Platform.io and the ESP32,[],r/tensorflow,False,6,,0,105.0,,False,t3_iyw977,False,dark,1.0,,public,19,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'TensorFlow Lite With Platform.io and the ESP32', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kZdIO82059E/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iyw977', 'height': 338}",,False,19,,True,https://a.thumbs.redditmedia.com/Z-WLSpA_LFA0Kfw0lwACmKbGFRgyTQtXcmPqVgIKh-8.jpg,False,,[],{},,False,,1600979088.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iyw977,True,,iamflimflam1,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iyw977/tensorflow_lite_with_platformio_and_the_esp32/,all_ads,False,https://www.youtube.com/watch?v=kZdIO82059E&amp;feature=share,22217,1600950288.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'TensorFlow Lite With Platform.io and the ESP32', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kZdIO82059E/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}}",False,rich:video,https://www.youtube.com/watch?v=kZdIO82059E&amp;feature=share,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?auto=webp&amp;s=b0dab86b631780008e074c1161ed8114178ce407', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ad26fdaed3842b6395e7f38aabe40462225abf4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d935c31e37b895ebc2bfc93970def060f21a66ba', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66f551b77b2c6c7cf1512ec21ee2108e0c022357', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'EdMhoo8p5Dsj3w4vQtgCvTpsotwsc9nYjhm5ugu-2f4'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'esp32', 'selftext': '', 'author_fullname': 't2_3e708', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'TensorFlow Lite With Platform.io and the ESP32', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/esp32', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 105, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_iyuwl1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.98, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 102, 'total_awards_received': 1, 'media_embed': {'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'TensorFlow Lite With Platform.io and the ESP32', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kZdIO82059E/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iyuwl1', 'height': 338}, 'link_flair_text': None, 'can_mod_post': False, 'score': 102, 'approved_by': None, 'author_premium': True, 'thumbnail': 'https://a.thumbs.redditmedia.com/Z-WLSpA_LFA0Kfw0lwACmKbGFRgyTQtXcmPqVgIKh-8.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'rich:video', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1600973106.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': True, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=kZdIO82059E&amp;feature=share', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?auto=webp&amp;s=b0dab86b631780008e074c1161ed8114178ce407', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ad26fdaed3842b6395e7f38aabe40462225abf4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d935c31e37b895ebc2bfc93970def060f21a66ba', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/Ypv2iWK9rwmWlnerevHV_vdL9icJ_iufUL7pVYlF6gM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66f551b77b2c6c7cf1512ec21ee2108e0c022357', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'EdMhoo8p5Dsj3w4vQtgCvTpsotwsc9nYjhm5ugu-2f4'}], 'enabled': False}, 'all_awardings': [{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'award_74fe5152-7906-4991-9016-bc2d8e261200', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': False, 'awardings_required_to_grant_benefits': None, 'description': ""I don't know what to do with my hands!"", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Excited', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png'}], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3bddg', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iyuwl1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'iamflimflam1', 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/esp32/comments/iyuwl1/tensorflow_lite_with_platformio_and_the_esp32/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.youtube.com/watch?v=kZdIO82059E&amp;feature=share', 'subreddit_subscribers': 34160, 'created_utc': 1600944306.0, 'num_crossposts': 1, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'TensorFlow Lite With Platform.io and the ESP32', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/kZdIO82059E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'atomic14', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kZdIO82059E/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/bbstchris'}}, 'is_video': False}]",t3_iyuwl1,
768,,tensorflow,"Hi people. I have done the following to try and master Tensorflow. 
Tensorflow specialization in coursera
Tensorflow documents
Hands on with scikit learn, keras and tensorflow
Deep learning with MIT

But still, I am not comfortable with it. Each time I see a model defined differently, I get confused. And the fact that I can't personally ask doubts to anyone immediately does me no good. A lot of doubts pop up in my brain but all I could find in the internet is just the code and not what's under the hood. A lot of you people must be really good at TensorFlow. Can someone tell ne the right way to learn? If you don't believe there is any 'right' way in doing a task, please share the way you did it.
Thanks guys. Hope I find my solution here",t2_831npz15,False,,0,False,How to learn Tensorflow?,[],r/tensorflow,False,6,,0,,,False,t3_iyrmg7,False,dark,0.86,,public,10,0,{},,,False,[],,False,False,,{},Question,False,10,,False,self,False,,[],{},,True,,1600955892.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi people. I have done the following to try and master Tensorflow. 
Tensorflow specialization in coursera
Tensorflow documents
Hands on with scikit learn, keras and tensorflow
Deep learning with MIT&lt;/p&gt;

&lt;p&gt;But still, I am not comfortable with it. Each time I see a model defined differently, I get confused. And the fact that I can&amp;#39;t personally ask doubts to anyone immediately does me no good. A lot of doubts pop up in my brain but all I could find in the internet is just the code and not what&amp;#39;s under the hood. A lot of you people must be really good at TensorFlow. Can someone tell ne the right way to learn? If you don&amp;#39;t believe there is any &amp;#39;right&amp;#39; way in doing a task, please share the way you did it.
Thanks guys. Hope I find my solution here&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iyrmg7,True,,Gokulnath7,,11,True,all_ads,False,[],False,,/r/tensorflow/comments/iyrmg7/how_to_learn_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iyrmg7/how_to_learn_tensorflow/,22217,1600927092.0,0,,False,,,,,,,,,
769,,tensorflow,"    ds_train.cardinality()
    &lt;tf.Tensor: shape=(), dtype=int64, numpy=2016&gt;
    for i in range(5):
        aug = ds_train.map(augment_data)
        ds_train.concatenate(aug)
    ds_train.cardinality()
    &lt;tf.Tensor: shape=(), dtype=int64, numpy=2016&gt;
    

I don't understand why the dataset is not getting bigger",t2_5cb22no,False,,0,False,How can I add to a dataset from another dataset?,[],r/tensorflow,False,6,,0,,,False,t3_iz1mj0,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1600997281.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;ds_train.cardinality()
&amp;lt;tf.Tensor: shape=(), dtype=int64, numpy=2016&amp;gt;
for i in range(5):
    aug = ds_train.map(augment_data)
    ds_train.concatenate(aug)
ds_train.cardinality()
&amp;lt;tf.Tensor: shape=(), dtype=int64, numpy=2016&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I don&amp;#39;t understand why the dataset is not getting bigger&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iz1mj0,True,,insanelylogical,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iz1mj0/how_can_i_add_to_a_dataset_from_another_dataset/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iz1mj0/how_can_i_add_to_a_dataset_from_another_dataset/,22217,1600968481.0,0,,False,,,,,,,,,
770,,tensorflow,,t2_44mbtmjy,False,,0,False,State of the art in 3D dense face alignment!,[],r/tensorflow,False,6,,0,46.0,,False,t3_iyoc8i,False,dark,0.76,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/rEp1M_fhEu4amg6H0CkLLlgNlhcR64U8UxadJOPhsGQ.jpg,False,,[],{},,False,,1600942729.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iyoc8i,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iyoc8i/state_of_the_art_in_3d_dense_face_alignment/,all_ads,False,/r/LatestInML/comments/ixybzg/state_of_the_art_in_3d_dense_face_alignment/,22217,1600913929.0,0,,False,link,/r/LatestInML/comments/ixybzg/state_of_the_art_in_3d_dense_face_alignment/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?auto=webp&amp;s=d04fd36af2c66cf3e408f79e531814ebb4825cf2', 'width': 768, 'height': 254}, 'resolutions': [{'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63107c7359497967be1f5cbf1feed8772f6560ab', 'width': 108, 'height': 35}, {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cd94befba07eb8ccf6466da2e10e42bface4540', 'width': 216, 'height': 71}, {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=963d9efaf73080017fe62cd864897994316f915c', 'width': 320, 'height': 105}, {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ac1fa38c4759f4f6cec243142eeeee0c705b12a', 'width': 640, 'height': 211}], 'variants': {}, 'id': 'Cb5rxQ8BthbQdR7i0UqCX6FZLYHQ9Cu07HBiEPgLuS8'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert request: [click here](https://catalyzex.com/paper/arxiv:2009.09960)\n\nhttps://reddit.com/link/ixybzg/video/hnh2wy0u4so51/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in 3D dense face alignment!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 46, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'hnh2wy0u4so51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/ixybzg/asset/hnh2wy0u4so51/DASHPlaylist.mpd?a=1618044834%2CNWIyZmI2Yjg3ZWNiMTg4MDU2ODE3NGNjOTEwOTFiMjYwNWNlYzkzNjBkZDVmZGQ5NDA0NTEwOTY4MWJlNTMzNw%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 359, 'hlsUrl': 'https://v.redd.it/link/ixybzg/asset/hnh2wy0u4so51/HLSPlaylist.m3u8?a=1618044834%2CYzRkNmQ4ZWQ0MjliNTQ3MWNiY2I3OGQwNGVmMmY1MTUzMGY3ZmRhOTRiNDEwNTQxNWZmYWM0MGJlODlhN2E3Zg%3D%3D&amp;v=1&amp;f=sd', 'id': 'hnh2wy0u4so51', 'isGif': False}}, 'name': 't3_ixybzg', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 7, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/rEp1M_fhEu4amg6H0CkLLlgNlhcR64U8UxadJOPhsGQ.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1600844330.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert request: &lt;a href=""https://catalyzex.com/paper/arxiv:2009.09960""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/ixybzg/video/hnh2wy0u4so51/player""&gt;https://reddit.com/link/ixybzg/video/hnh2wy0u4so51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?auto=webp&amp;s=d04fd36af2c66cf3e408f79e531814ebb4825cf2', 'width': 768, 'height': 254}, 'resolutions': [{'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63107c7359497967be1f5cbf1feed8772f6560ab', 'width': 108, 'height': 35}, {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cd94befba07eb8ccf6466da2e10e42bface4540', 'width': 216, 'height': 71}, {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=963d9efaf73080017fe62cd864897994316f915c', 'width': 320, 'height': 105}, {'url': 'https://external-preview.redd.it/AS8sqhcn5M5-gmgHlScpPf34cbTAkK0vZJ91peKVSp8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ac1fa38c4759f4f6cec243142eeeee0c705b12a', 'width': 640, 'height': 211}], 'variants': {}, 'id': 'Cb5rxQ8BthbQdR7i0UqCX6FZLYHQ9Cu07HBiEPgLuS8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ixybzg', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/ixybzg/state_of_the_art_in_3d_dense_face_alignment/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/ixybzg/state_of_the_art_in_3d_dense_face_alignment/', 'subreddit_subscribers': 6676, 'created_utc': 1600815530.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_ixybzg,
771,,tensorflow,"I've been trying to replicate some results I read in a paper, but it depends on a large batch size of 256 and my GPU can only handle about 32. I created a training loop which gets the gradients over the 32-batch sample, stores them, then after 8 steps (32\*8 = 256) I average the gradients over each layer, and then call on the optimizer to update weights with the 8\*32-averaged gradient list. The model is training fine and starting to match the results from the paper, but this feels like it's too easy to be right.",t2_7ur3x,False,,0,False,[Question] Is there anything necessarily wrong with averaging gradients over batches to simulate a larger batch size?,[],r/tensorflow,False,6,,0,,,False,t3_iylh1m,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1600931278.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been trying to replicate some results I read in a paper, but it depends on a large batch size of 256 and my GPU can only handle about 32. I created a training loop which gets the gradients over the 32-batch sample, stores them, then after 8 steps (32*8 = 256) I average the gradients over each layer, and then call on the optimizer to update weights with the 8*32-averaged gradient list. The model is training fine and starting to match the results from the paper, but this feels like it&amp;#39;s too easy to be right.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iylh1m,True,,spauldeagle,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/iylh1m/question_is_there_anything_necessarily_wrong_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iylh1m/question_is_there_anything_necessarily_wrong_with/,22217,1600902478.0,0,,False,,,,,,,,,
772,,tensorflow,"It seems Tensorflow 2 has been recieved well overall. I have personally enjoyed the convenience of eager execution and the added flexibility in tf.keras API in my recent experiments.

But I'm curious about the opinion of long-time Tensorflow users. Do you still prefer/like Tensorflow 1.1x over the new API? And if yes, what are the reasons?",t2_3cghwury,False,,0,False,Tensorflow 1.1x vs Tensorflow 2.x,[],r/tensorflow,False,6,,0,,,False,t3_iy9sol,False,dark,0.87,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,self,False,,[],{},,True,,1600895445.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It seems Tensorflow 2 has been recieved well overall. I have personally enjoyed the convenience of eager execution and the added flexibility in tf.keras API in my recent experiments.&lt;/p&gt;

&lt;p&gt;But I&amp;#39;m curious about the opinion of long-time Tensorflow users. Do you still prefer/like Tensorflow 1.1x over the new API? And if yes, what are the reasons?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iy9sol,True,,ThatCook2,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/iy9sol/tensorflow_11x_vs_tensorflow_2x/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iy9sol/tensorflow_11x_vs_tensorflow_2x/,22217,1600866645.0,0,,False,,,,,,,,,
773,,tensorflow,,t2_6wt510of,False,,0,False,interpolating between stylegan2 generated billionaires,[],r/tensorflow,False,6,,0,105.0,,False,t3_iy6drm,False,dark,0.9,,public,21,0,"{'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/wADYCIiJfgY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'height': 344}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'From 67$ Billion to 180$ Billion | Top 10 Billionaires StyleGAN2 Interpolation', 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/wADYCIiJfgY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wADYCIiJfgY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/wADYCIiJfgY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iy6drm', 'height': 344}",,False,21,,False,https://b.thumbs.redditmedia.com/QtL1uEdSjNGg6SweuppgxKvpzIvgWcDywKfo-JefCXU.jpg,False,,[],{},,False,,1600879075.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iy6drm,True,,Snoo_72253,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/iy6drm/interpolating_between_stylegan2_generated/,all_ads,False,https://youtu.be/wADYCIiJfgY,22217,1600850275.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'From 67$ Billion to 180$ Billion | Top 10 Billionaires StyleGAN2 Interpolation', 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/wADYCIiJfgY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wADYCIiJfgY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,rich:video,https://youtu.be/wADYCIiJfgY,"{'images': [{'source': {'url': 'https://external-preview.redd.it/sPAa81J-vFwab2a31yrLN49ITb_dDzXmBuITw40cMA4.jpg?auto=webp&amp;s=07f42e9934cf7bb0592eea3656ca49d0e6b9ceb0', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/sPAa81J-vFwab2a31yrLN49ITb_dDzXmBuITw40cMA4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=481d1c9dc7e6548431161efe087c9c4ecf044cb4', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/sPAa81J-vFwab2a31yrLN49ITb_dDzXmBuITw40cMA4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc56e7ee6113ace6d7bd2541c2bd9311e2931329', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/sPAa81J-vFwab2a31yrLN49ITb_dDzXmBuITw40cMA4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f39b0a6e42be64db37d6218b5e1f010fc83487c', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'JjJqB6RU0EsD4Yw8vmsa5FF3BxN3qP39IKJVfYzxXvA'}], 'enabled': False}",,,,,,
774,,tensorflow," 

I am trying to replicate AlexNet model on ImageNet (for learning purposes). The dataset is 1.2 million ImageNet dataset with 50K validation. This is my code :

model function:

&amp;#x200B;

https://preview.redd.it/bi1armh2kxo51.jpg?width=1172&amp;format=pjpg&amp;auto=webp&amp;s=241370dd82723a18951c2a328d649d0cc81a553f

 training function: 

&amp;#x200B;

https://preview.redd.it/6d2o6595kxo51.jpg?width=1406&amp;format=pjpg&amp;auto=webp&amp;s=75a6455d1ab11a2d646ba4dd0d8749db3d0cf2ed

 However, when I start to train this model (8 GPUs, Batch size=32\*nGPU) I get flat loss and accuracy: 

&amp;#x200B;

https://preview.redd.it/3wv57f38kxo51.jpg?width=978&amp;format=pjpg&amp;auto=webp&amp;s=64167df852aa303f0fcfc41cdb637f26daf254e6

 Any idea what's the problem causing flat loss? 

# Code can be found [here](https://github.com/anejad/Convolutional-Neural-Network-Champions/blob/master/AlexNet/AlexNet_Tensorflow_Full.py)",t2_1vryl742,False,,0,False,"Training AlexNet like structure on entire ImageNet in Tensorflow 2.0, Problem with flat loss",[],r/tensorflow,False,6,,0,101.0,,False,t3_iyeejw,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},Question,False,3,,False,https://b.thumbs.redditmedia.com/osDfwwUwS75NciduO3tlyzsmQqpQKUmpngdskWzuItE.jpg,False,,[],{},,True,,1600910090.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to replicate AlexNet model on ImageNet (for learning purposes). The dataset is 1.2 million ImageNet dataset with 50K validation. This is my code :&lt;/p&gt;

&lt;p&gt;model function:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/bi1armh2kxo51.jpg?width=1172&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=241370dd82723a18951c2a328d649d0cc81a553f""&gt;https://preview.redd.it/bi1armh2kxo51.jpg?width=1172&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=241370dd82723a18951c2a328d649d0cc81a553f&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;training function: &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/6d2o6595kxo51.jpg?width=1406&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=75a6455d1ab11a2d646ba4dd0d8749db3d0cf2ed""&gt;https://preview.redd.it/6d2o6595kxo51.jpg?width=1406&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=75a6455d1ab11a2d646ba4dd0d8749db3d0cf2ed&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, when I start to train this model (8 GPUs, Batch size=32*nGPU) I get flat loss and accuracy: &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3wv57f38kxo51.jpg?width=978&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=64167df852aa303f0fcfc41cdb637f26daf254e6""&gt;https://preview.redd.it/3wv57f38kxo51.jpg?width=978&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=64167df852aa303f0fcfc41cdb637f26daf254e6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any idea what&amp;#39;s the problem causing flat loss? &lt;/p&gt;

&lt;h1&gt;Code can be found &lt;a href=""https://github.com/anejad/Convolutional-Neural-Network-Champions/blob/master/AlexNet/AlexNet_Tensorflow_Full.py""&gt;here&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iyeejw,True,,dr_amir7,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iyeejw/training_alexnet_like_structure_on_entire/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iyeejw/training_alexnet_like_structure_on_entire/,22217,1600881290.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/KOFn-R0HLicI-DChrcpRAXXZ6iBWs9ivnxsTDY5sbpM.jpg?auto=webp&amp;s=20795e749e1e08051b6b978b3dd404a9d6d867c7', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/KOFn-R0HLicI-DChrcpRAXXZ6iBWs9ivnxsTDY5sbpM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=90eb1fc81c77b48e3d6853c62a30e44a8a5fd06c', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/KOFn-R0HLicI-DChrcpRAXXZ6iBWs9ivnxsTDY5sbpM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9dbf6619edc2b204925c93fc398ebe321bd19f7f', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/KOFn-R0HLicI-DChrcpRAXXZ6iBWs9ivnxsTDY5sbpM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=703d30a22d76c7eb6996b9388de3b62e0776ba91', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'qEreAd92ZpNMvUEI_D0if55mZIXrgm_uYM-GBPQcX4I'}], 'enabled': False}",,"{'6d2o6595kxo51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 43, 'x': 108, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5f277e3fa4889df4b8e40417f65bcd257c0a988'}, {'y': 87, 'x': 216, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=32d4171ec5e017a5c6de483b3a534680ec50c928'}, {'y': 130, 'x': 320, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7206720e848cd93a83a4a573f89383ea7a93ca67'}, {'y': 260, 'x': 640, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ea2fb68469ecfee35e9bb213619eaab4cf55363'}, {'y': 390, 'x': 960, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c22d37ba7cdfebdb48764e53ae3ade0d005b7d8e'}, {'y': 439, 'x': 1080, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b164adb8ea6cb1aeb3a539ca566bb52d5d66e756'}], 's': {'y': 572, 'x': 1406, 'u': 'https://preview.redd.it/6d2o6595kxo51.jpg?width=1406&amp;format=pjpg&amp;auto=webp&amp;s=75a6455d1ab11a2d646ba4dd0d8749db3d0cf2ed'}, 'id': '6d2o6595kxo51'}, '3wv57f38kxo51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 63, 'x': 108, 'u': 'https://preview.redd.it/3wv57f38kxo51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b731e1aca4c5ffd57341b050aa27f94c0558c0a'}, {'y': 126, 'x': 216, 'u': 'https://preview.redd.it/3wv57f38kxo51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=33413b517ae9366ede5a28a1a7f87db3a4b7dbff'}, {'y': 187, 'x': 320, 'u': 'https://preview.redd.it/3wv57f38kxo51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65db99f3a427f6bd319e27b5e662e2898db969b5'}, {'y': 375, 'x': 640, 'u': 'https://preview.redd.it/3wv57f38kxo51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=870e901af5e8277e74ec536152bc981fae0907da'}, {'y': 563, 'x': 960, 'u': 'https://preview.redd.it/3wv57f38kxo51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9560d43beea7e1407595a60956d4b25b7c34f0b7'}], 's': {'y': 574, 'x': 978, 'u': 'https://preview.redd.it/3wv57f38kxo51.jpg?width=978&amp;format=pjpg&amp;auto=webp&amp;s=64167df852aa303f0fcfc41cdb637f26daf254e6'}, 'id': '3wv57f38kxo51'}, 'bi1armh2kxo51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 78, 'x': 108, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91e89eb53cf86b455d0767ffece1009bda478e1b'}, {'y': 156, 'x': 216, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a0b179550d8b6c7dadcede4f8ff4fa678c72dd1'}, {'y': 231, 'x': 320, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c104baa820f69f7da1d9e9da628fb114d6856443'}, {'y': 462, 'x': 640, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a3e9bd5c4fb256ecb5e0e5ef42f1ef40a5a5d234'}, {'y': 693, 'x': 960, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ba5482e337a829e52f055e9b28314abc58295299'}, {'y': 780, 'x': 1080, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=987657b1002eea3c8cf3a1516c48e401f93ed01d'}], 's': {'y': 847, 'x': 1172, 'u': 'https://preview.redd.it/bi1armh2kxo51.jpg?width=1172&amp;format=pjpg&amp;auto=webp&amp;s=241370dd82723a18951c2a328d649d0cc81a553f'}, 'id': 'bi1armh2kxo51'}}",,,,
775,,tensorflow,"Hi! I recently finished this project, I hope you find it interesting :)

[https://github.com/MCarlomagno/TwitterToxicityDetector](https://github.com/MCarlomagno/TwitterToxicityDetector)",t2_69jauppe,False,,0,False,Twitter toxicity detector using Tensorflow.js,[],r/tensorflow,False,6,,0,,,False,t3_iyfhq8,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1600913300.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I recently finished this project, I hope you find it interesting :)&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/MCarlomagno/TwitterToxicityDetector""&gt;https://github.com/MCarlomagno/TwitterToxicityDetector&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iyfhq8,True,,mcarlomagno,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/iyfhq8/twitter_toxicity_detector_using_tensorflowjs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iyfhq8/twitter_toxicity_detector_using_tensorflowjs/,22217,1600884500.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?auto=webp&amp;s=6256ff620c6fb101b7873db88ab376b6ba194169', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=702583fd158633e1f7ec356fbd8ff56b2685d45d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c32897a04197e7af5d980517276726cc74a57627', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e707e2256ce66e9ac79a51d5428eb14d113a1be5', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'Z1gRMO0wRANYfQrWwYZ8J3yxPMT0tdz4nDFAczHpJOs'}], 'enabled': False}",,,,,,
776,,tensorflow,,t2_jo9b4,False,,0,False,Physically playing Google's T-Rex Offline Game with a PoseNet,[],r/tensorflow,False,6,,0,105.0,,False,t3_iy7mpo,False,dark,1.0,,public,3,0,"{'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/gWQd4n0hGFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'height': 344}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Physically playing Google's T-Rex Offline Game with a PoseNet"", 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/gWQd4n0hGFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Theodoros Ntakouris', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/gWQd4n0hGFw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCD7zSKJcfjn9hoLndOUeugg'}}",False,False,,"{'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/gWQd4n0hGFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iy7mpo', 'height': 344}",,False,3,,False,https://b.thumbs.redditmedia.com/qe_kNYUSaYYgYqyoFdTqrFeprESxz2YT0Z8JZqsgZ7I.jpg,False,,[],{},,False,,1600885916.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iy7mpo,True,,Zarkopafilis,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/iy7mpo/physically_playing_googles_trex_offline_game_with/,all_ads,False,https://www.youtube.com/watch?v=gWQd4n0hGFw&amp;feature=share,22217,1600857116.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Physically playing Google's T-Rex Offline Game with a PoseNet"", 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/gWQd4n0hGFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Theodoros Ntakouris', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/gWQd4n0hGFw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCD7zSKJcfjn9hoLndOUeugg'}}",False,rich:video,https://www.youtube.com/watch?v=gWQd4n0hGFw&amp;feature=share,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ibODAedOS7r1sOWow8IFgNTqT7oU-YWtgUd16gKJx6Q.jpg?auto=webp&amp;s=6286ecd54a3e55eb429a3d669a3a0199a41230f6', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/ibODAedOS7r1sOWow8IFgNTqT7oU-YWtgUd16gKJx6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4eb4d80489175ca13b96ff6b4164d5ca9a60e6b', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/ibODAedOS7r1sOWow8IFgNTqT7oU-YWtgUd16gKJx6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=90685685e3131df5793743367156088a3ee0040d', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/ibODAedOS7r1sOWow8IFgNTqT7oU-YWtgUd16gKJx6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b7612772ec137a4996fce402cdba1473561e1674', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'WxsCiWErGdXL1_fdWAW-DXA9d0TPmSrtg9_oEU9KkdY'}], 'enabled': False}",,,,,,
777,,tensorflow,"I have a trained a classic CNN(pre-trained mobile net) for image classification. I want to now use this model from c++. From my understanding, I need to create a library of the model, that can accept the input and return its outputs. I have the model saved in format .pb  
 (SavedModel).

I have already tried, [CppFlow](https://github.com/serizba/cppflow), where the error shows that it can't read my model. I assume it's due to incompatibility with TF 2.0.

I have also got the command line interface of [SavedModel](https://www.tensorflow.org/guide/saved_model#details_of_the_savedmodel_command_line_interface) working, but I don't know how to use it in my cpp application. I'm not sure how connect the tensorflow C Api with my program and model.

I want to know how I can build a library of my model and use this library such that it can make predictions on the fly. Any guidance will be helpful. Please let me know if any additional information is required.

&amp;#x200B;

PS: I don't think connecting python with c++ is a feasible solution because I'll be performing classification many times on a single frame of a video. This will drastically slow down my program.",t2_6pfjhk3x,False,,0,False,Use keras model from c++,[],r/tensorflow,False,6,,0,,,False,t3_ixu5c3,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1600830932.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a trained a classic CNN(pre-trained mobile net) for image classification. I want to now use this model from c++. From my understanding, I need to create a library of the model, that can accept the input and return its outputs. I have the model saved in format .pb&lt;br/&gt;
 (SavedModel).&lt;/p&gt;

&lt;p&gt;I have already tried, &lt;a href=""https://github.com/serizba/cppflow""&gt;CppFlow&lt;/a&gt;, where the error shows that it can&amp;#39;t read my model. I assume it&amp;#39;s due to incompatibility with TF 2.0.&lt;/p&gt;

&lt;p&gt;I have also got the command line interface of &lt;a href=""https://www.tensorflow.org/guide/saved_model#details_of_the_savedmodel_command_line_interface""&gt;SavedModel&lt;/a&gt; working, but I don&amp;#39;t know how to use it in my cpp application. I&amp;#39;m not sure how connect the tensorflow C Api with my program and model.&lt;/p&gt;

&lt;p&gt;I want to know how I can build a library of my model and use this library such that it can make predictions on the fly. Any guidance will be helpful. Please let me know if any additional information is required.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;PS: I don&amp;#39;t think connecting python with c++ is a feasible solution because I&amp;#39;ll be performing classification many times on a single frame of a video. This will drastically slow down my program.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ixu5c3,True,,weiderthanyou,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ixu5c3/use_keras_model_from_c/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixu5c3/use_keras_model_from_c/,22217,1600802132.0,2,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/vSc1YZctgR6sWzt-ifGfKh71AoDjw3IbZk3Su-rUwW0.jpg?auto=webp&amp;s=7b1f59b912216a292e150fbffbc9c92fb78bf350', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/vSc1YZctgR6sWzt-ifGfKh71AoDjw3IbZk3Su-rUwW0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=05d0d39e453321af67c906c1b2fcd8bb567f5bda', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/vSc1YZctgR6sWzt-ifGfKh71AoDjw3IbZk3Su-rUwW0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa6ae53ea1f4d694bcd94778644b033eba8427dd', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/vSc1YZctgR6sWzt-ifGfKh71AoDjw3IbZk3Su-rUwW0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=991c1302d70a3385d140169c43edce94c434a8b5', 'width': 320, 'height': 320}], 'variants': {}, 'id': '_JSMxtV39e-x0gvJSgC5JopEpuejYYr8hfq4nnSullU'}], 'enabled': False}",,,,,,
778,,tensorflow,So I'm implementing a CycleGAN in tensorflow and I'm wondering why pytorch preforms better by miles? Also is it worth switching to pytorch for these reasons?,t2_5m5rpe85,False,,0,False,Why does pytorch preform better?,[],r/tensorflow,False,6,,0,,,False,t3_iy0312,False,dark,0.55,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1600850688.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;m implementing a CycleGAN in tensorflow and I&amp;#39;m wondering why pytorch preforms better by miles? Also is it worth switching to pytorch for these reasons?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iy0312,True,,boiboi3333,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/iy0312/why_does_pytorch_preform_better/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iy0312/why_does_pytorch_preform_better/,22217,1600821888.0,0,,False,,,,,,,,,
779,,tensorflow,"Hi! I recently uploaded this github repo, please let me some feedback. I hope you'll find it useful :)

[https://github.com/MCarlomagno/CarDrivingResNet](https://github.com/MCarlomagno/CarDrivingResNet)",t2_69jauppe,False,,0,False,Neural Network Car Driving Game using Tensorflow.js,[],r/tensorflow,False,6,,0,,,False,t3_ixmv16,False,dark,0.92,,public,10,0,{},,,False,[],,False,False,,{},,False,10,,False,self,False,,[],{},,True,,1600808278.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I recently uploaded this github repo, please let me some feedback. I hope you&amp;#39;ll find it useful :)&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/MCarlomagno/CarDrivingResNet""&gt;https://github.com/MCarlomagno/CarDrivingResNet&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ixmv16,True,,mcarlomagno,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ixmv16/neural_network_car_driving_game_using_tensorflowjs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixmv16/neural_network_car_driving_game_using_tensorflowjs/,22217,1600779478.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?auto=webp&amp;s=6256ff620c6fb101b7873db88ab376b6ba194169', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=702583fd158633e1f7ec356fbd8ff56b2685d45d', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c32897a04197e7af5d980517276726cc74a57627', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/2zPS8ZrkznNXZWPTUg1P1Qw0losId_nkB5P-N8U-hRc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e707e2256ce66e9ac79a51d5428eb14d113a1be5', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'Z1gRMO0wRANYfQrWwYZ8J3yxPMT0tdz4nDFAczHpJOs'}], 'enabled': False}",,,,,,
780,,tensorflow,"I want to train a model with a tfx/kubeflow pipeline, the idea is when the model itself is being trained the cluster will auto scale to train the model faster and cheaper. 
Is there any examples of people doing this? 
Is it even possible?",t2_iov3r,False,,0,False,Has anyone managed to make a tfx pipeline for kubeflow where the trainer objects autoscales,[],r/tensorflow,False,6,,0,,,False,t3_ixn4me,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1600809216.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to train a model with a tfx/kubeflow pipeline, the idea is when the model itself is being trained the cluster will auto scale to train the model faster and cheaper. 
Is there any examples of people doing this? 
Is it even possible?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ixn4me,True,,Ashrek1999,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ixn4me/has_anyone_managed_to_make_a_tfx_pipeline_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixn4me/has_anyone_managed_to_make_a_tfx_pipeline_for/,22217,1600780416.0,0,,False,,,,,,,,,
781,,tensorflow,"Hey everyone, I’m currently a sophomore at my college pursuing an undergraduate degree. I’m a statistics Major double minoring in computer science and economics, when originally I was a data analytics major. I decided to switch because I wanted a deeper understanding of statistics and a more solid foundation so I can further understand algorithms in depth when I intent to study/practice deep learning. Do any of you feel that having a deeper understanding of statistics helped you in anyway when you were learning deep learning or implementing tensorflow models? Thanks.",t2_5w4i5kd1,False,,0,False,Statistics knowledge helps master deep learning?,[],r/tensorflow,False,6,,0,,,False,t3_ixpuh1,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1600818069.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone, I’m currently a sophomore at my college pursuing an undergraduate degree. I’m a statistics Major double minoring in computer science and economics, when originally I was a data analytics major. I decided to switch because I wanted a deeper understanding of statistics and a more solid foundation so I can further understand algorithms in depth when I intent to study/practice deep learning. Do any of you feel that having a deeper understanding of statistics helped you in anyway when you were learning deep learning or implementing tensorflow models? Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ixpuh1,True,,veeeerain,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ixpuh1/statistics_knowledge_helps_master_deep_learning/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixpuh1/statistics_knowledge_helps_master_deep_learning/,22217,1600789269.0,0,,False,,,,,,,,,
782,,tensorflow,"Hello everyone, I have trained `ResNet50` model on my data. I want to get the output of a custom layer while making the prediction. I tried using the below code to get the output of a custom layer, it gives data in a tensor format, but I need the data in a `NumPy array` format. I tried to convert the tensor to NumPy array but getting errors

Can anyone share some thoughts, any advice will be very helpful

    from keras.models import load_model
    import tensorflow as tf
    import numpy as np
    
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    tf.Session(config=config)
    
    model = load_model(model_path) # load trained model
    
    data = load_data(data_path) # load data for predictions
    result = model.predict(data)
    print(type(result_dev))
    #&lt;class 'numpy.ndarray'&gt; 
    
    result = model.get_layer('avg_pool').output
    print(type(result))
    #&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;

Things I tried

**Option 1**

    result = result.numpy()

&gt;AttributeError: 'Tensor' object has no attribute 'numpy'

**Option 2**

    result = result.eval(session=tf.compat.v1.Session()) 

&gt;2020-09-22 11:21:59.522138: I tensorflow/stream\_executor/cuda/cuda\_gpu\_executor.cc:983\] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero  
&gt;  
&gt;2020-09-22 11:21:59.522343: I tensorflow/core/common\_runtime/gpu/gpu\_device.cc:1618\] Found device 0 with properties: 

Dependency Installed:

    tensorflow-gpu==1.15.0",t2_1as413t4,False,,0,False,How to convert Tensor into NumPy array,[],r/tensorflow,False,6,,0,,,False,t3_ixifkq,False,dark,1.0,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,self,False,,[],{},,True,,1600786316.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, I have trained &lt;code&gt;ResNet50&lt;/code&gt; model on my data. I want to get the output of a custom layer while making the prediction. I tried using the below code to get the output of a custom layer, it gives data in a tensor format, but I need the data in a &lt;code&gt;NumPy array&lt;/code&gt; format. I tried to convert the tensor to NumPy array but getting errors&lt;/p&gt;

&lt;p&gt;Can anyone share some thoughts, any advice will be very helpful&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from keras.models import load_model
import tensorflow as tf
import numpy as np

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
tf.Session(config=config)

model = load_model(model_path) # load trained model

data = load_data(data_path) # load data for predictions
result = model.predict(data)
print(type(result_dev))
#&amp;lt;class &amp;#39;numpy.ndarray&amp;#39;&amp;gt; 

result = model.get_layer(&amp;#39;avg_pool&amp;#39;).output
print(type(result))
#&amp;lt;class &amp;#39;tensorflow.python.framework.ops.Tensor&amp;#39;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Things I tried&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Option 1&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;result = result.numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;AttributeError: &amp;#39;Tensor&amp;#39; object has no attribute &amp;#39;numpy&amp;#39;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Option 2&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;result = result.eval(session=tf.compat.v1.Session()) 
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;2020-09-22 11:21:59.522138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero  &lt;/p&gt;

&lt;p&gt;2020-09-22 11:21:59.522343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Dependency Installed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow-gpu==1.15.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,ixifkq,True,,arush1836,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/ixifkq/how_to_convert_tensor_into_numpy_array/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixifkq/how_to_convert_tensor_into_numpy_array/,22217,1600757516.0,0,,False,,,,,,,,,
783,,tensorflow,,t2_74seeqo6,False,,0,False,Formulating Loss as a Unit Test,[],r/tensorflow,False,6,,0,90.0,,False,t3_ixpr5f,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/wezVGcrPdrlzwJ7WZZJssYYkokEHttYJSYAOlQEIODY.jpg,False,,[],{},,False,,1600817781.0,text,6,,,text,towardsdatascience.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ixpr5f,True,,spenceowen,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ixpr5f/formulating_loss_as_a_unit_test/,all_ads,False,https://towardsdatascience.com/formulating-loss-as-a-unit-test-fbda2c7909bd,22217,1600788981.0,1,,False,link,https://towardsdatascience.com/formulating-loss-as-a-unit-test-fbda2c7909bd,"{'images': [{'source': {'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?auto=webp&amp;s=9fad104fadf768042c5e5704006e6f6f5120509e', 'width': 1200, 'height': 778}, 'resolutions': [{'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6a97c95129f72381362dec2969e4e9a99eae282', 'width': 108, 'height': 70}, {'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b6c1118ca4b32bf2fc839e77b37e05abfba2b72', 'width': 216, 'height': 140}, {'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2aabc1137c3c1589017fd53fb6e67306cb9a49a9', 'width': 320, 'height': 207}, {'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef9c18fa35a9a2a8c7e3663611674965e9fe7db7', 'width': 640, 'height': 414}, {'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=53f80fe17a3d7ca648b077a8b9c757f399674c47', 'width': 960, 'height': 622}, {'url': 'https://external-preview.redd.it/EVaLAURZzfUm_ke1WlG62AVSik_7Psv-P7P6ZoQ4GHk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8307c1d49da55a08907f0b43a76a18b2701c9846', 'width': 1080, 'height': 700}], 'variants': {}, 'id': 'nq0CY8C8AUtlkGUnZ42rJiBNlGS9v960XU5AMLZr4Wk'}], 'enabled': False}",,,,,,
784,,tensorflow,"Hi, I attempted clustering the famous Iris data set with a custom TF layer. However, the clustering fails with the centers being pretty much on top of each other or completely away from the data. Since I have relatively little experience with Tensorflow, I'm not sure which is to blame, my implementation or the method itself. I know it is certainly not anyone else's job to find out which it is and why, but I'm truly stuck. I would appreciate any pointers if you have some time to spare!

The method is based on cluster hardening ([Theano source](https://github.com/ElieAljalbout/Clustering-with-Deep-learning), also contains research article), meaning that each update the network should enforce stricter cluster assignments and update cluster centers towards better values. A PCA-reduced (2D) representation in which the data still has clear clusters is used as an input to the clustering model. But as described above, this doesn't work. Here's the data and cluster movements.

&amp;#x200B;

[Data and cluster centers each epoch](https://preview.redd.it/rzksklk91oo51.png?width=500&amp;format=png&amp;auto=webp&amp;s=2656f1bcd23633c5e156b8751f983a2774e45ecd)

Here's my implementation. Bear with me, the code is a bit lengthy, because I wanted to leave lots of comments and a good visualisation of the results. The model definition itself with TF logic is quite short. In addition to TF 2, it requires `numpy`, `matplotlib` and `sklearn`. So, first the model definition.

    import numpy as np
    import tensorflow as tf
    
    from tensorflow import keras as k
    from tensorflow.keras.optimizers import Adam
    
    from matplotlib import pyplot as plt
    from matplotlib.colors import Normalize
    from sklearn.datasets import load_iris
    from sklearn.decomposition import PCA
    
    class ClusterHardening(k.layers.Layer):
        def __init__(self, n_clusters: int, **kwargs):
            super().__init__(**kwargs)
            self.n_clusters = n_clusters
            self.centers = None
    
        def build(self, input_shape):
            self.centers = self.add_weight(
                'centers',
                [self.n_clusters, int(input_shape[-1])],
                initializer='random_normal',
                trainable=True,
            )
    
        def call(self, inputs, training=False, mask=None):
            """"""
            Optimise for stricter cluster assignments.
    
            Tensor shapes:
            inputs: (n_inputs, 1, latent)
            center: (1, n_center, latent)
            dist:   (n_inputs, n_center)
            q, p:   (n_inputs, n_center)
            loss:   (1,)
            """"""
            inputs = tf.expand_dims(inputs, axis=-2)
            centers = tf.expand_dims(self.centers, axis=-3)
            dist = tf.norm(inputs - centers, axis=-1)
            q_ij = self.student_q(dist)
            p_ij = self.target_p(q_ij)
            kl = self.kullback_leibler(p_ij, q_ij)
            self.add_loss(tf.reduce_sum(kl))
    
            return q_ij
    
        @tf.function
        def student_q(self, dist):
            """"""
            Membership degree.
    
            Q: (n_inputs, n_center) / (n_inputs, 1)
            """"""
            # t-distribution with nu = 1, can be reduced by the common factor in division
            q_ij_num = (1 + dist ** 2) ** -1
    
            # Q normalised summing clusters for each point
            # -&gt; total membership of each data point = 1
            return q_ij_num / tf.reduce_sum(q_ij_num, axis=-1, keepdims=True)
    
        @staticmethod
        @tf.function
        def target_p(q_ij):
            """"""
            Target membership distribution.
    
            P: (n_inputs, n_center) / (1, n_center) / (n_input, 1)
            """"""
            # Squared: values close to zero reduce further
            # Normalised summing original data points for each cluster
            # -&gt; Forces some points to belong to a cluster anyway
            p_ij_num = q_ij ** 2 / tf.reduce_sum(q_ij, axis=0, keepdims=True)
    
            # P normalised summing clusters for each point
            # -&gt; total membership of each data point = 1
            return p_ij_num / tf.reduce_sum(p_ij_num, axis=-1, keepdims=True)
    
        @staticmethod
        @tf.function
        def kullback_leibler(p, q):
            """"""Difference between distributions.""""""
            return p * tf.math.log(p / q)
    
    
    class Clustering(k.Model):
        def __init__(self, n_clusters: int, **kwargs):
            super().__init__(**kwargs)
            self.cluster = ClusterHardening(n_clusters)
    
        def call(self, inputs, training=False, mask=None):
            return self.cluster(inputs)

Then training and visualisation.

    lr = 1e-2
    n_epochs = 100
    latent_dim = 2
    n_clusters = 3
    
    x, y = load_iris(return_X_y=True)
    x = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))
    x = PCA(n_components=latent_dim).fit_transform(x)
    
    adam = Adam(lr)
    model = Clustering(n_clusters)
    model.compile(adam)
    
    h = {'loss': []}
    centers = np.zeros((n_epochs, n_clusters, latent_dim))
    for epoch in range(n_epochs):
        print(f'epoch {epoch} / {n_epochs}')
        h_ = model.fit(x, None, batch_size=x.shape[1], epochs=1, verbose=0).history
        h['loss'].extend(h_['loss'])
        centers[epoch] = model.cluster.centers.numpy()
    
    groups = model.predict(x)
    groups = np.argmax(groups, axis=1)
    
    plt.figure(figsize=(5, 3))
    norm = Normalize(0, 10)
    plt.scatter(x[:, 0], x[:, 1], s=1, c=groups, cmap='tab10', norm=norm)
    plt.scatter(centers[0, :, 0], centers[0, :, 1], s=20, c='k', marker='o')
    plt.scatter(centers[-1, :, 0], centers[-1, :, 1], s=20, c='k', marker='x')
    for c in range(n_clusters):
        plt.plot(centers[:, c, 0], centers[:, c, 1])
    plt.tight_layout()
    
    plt.figure(figsize=(4, 3))
    for v in h.values():
        plt.plot(range(n_epochs), v)
    plt.legend(h.keys())
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.tight_layout()
    
    plt.show()",t2_5lymqxik,False,,0,False,Clustering of simple data leads to degenerate results,[],r/tensorflow,False,6,,0,84.0,,False,t3_ixjtqj,False,dark,1.0,,public,5,0,{},140.0,,False,[],,False,False,,{},Question,False,5,,False,https://b.thumbs.redditmedia.com/8uF_DoyPaP8RJTaJCdH0wl2qnkmljJV3ocWe6LFguKY.jpg,1600765883.0,,[],{},,True,,1600794156.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I attempted clustering the famous Iris data set with a custom TF layer. However, the clustering fails with the centers being pretty much on top of each other or completely away from the data. Since I have relatively little experience with Tensorflow, I&amp;#39;m not sure which is to blame, my implementation or the method itself. I know it is certainly not anyone else&amp;#39;s job to find out which it is and why, but I&amp;#39;m truly stuck. I would appreciate any pointers if you have some time to spare!&lt;/p&gt;

&lt;p&gt;The method is based on cluster hardening (&lt;a href=""https://github.com/ElieAljalbout/Clustering-with-Deep-learning""&gt;Theano source&lt;/a&gt;, also contains research article), meaning that each update the network should enforce stricter cluster assignments and update cluster centers towards better values. A PCA-reduced (2D) representation in which the data still has clear clusters is used as an input to the clustering model. But as described above, this doesn&amp;#39;t work. Here&amp;#39;s the data and cluster movements.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/rzksklk91oo51.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2656f1bcd23633c5e156b8751f983a2774e45ecd""&gt;Data and cluster centers each epoch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here&amp;#39;s my implementation. Bear with me, the code is a bit lengthy, because I wanted to leave lots of comments and a good visualisation of the results. The model definition itself with TF logic is quite short. In addition to TF 2, it requires &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt; and &lt;code&gt;sklearn&lt;/code&gt;. So, first the model definition.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
import tensorflow as tf

from tensorflow import keras as k
from tensorflow.keras.optimizers import Adam

from matplotlib import pyplot as plt
from matplotlib.colors import Normalize
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA

class ClusterHardening(k.layers.Layer):
    def __init__(self, n_clusters: int, **kwargs):
        super().__init__(**kwargs)
        self.n_clusters = n_clusters
        self.centers = None

    def build(self, input_shape):
        self.centers = self.add_weight(
            &amp;#39;centers&amp;#39;,
            [self.n_clusters, int(input_shape[-1])],
            initializer=&amp;#39;random_normal&amp;#39;,
            trainable=True,
        )

    def call(self, inputs, training=False, mask=None):
        &amp;quot;&amp;quot;&amp;quot;
        Optimise for stricter cluster assignments.

        Tensor shapes:
        inputs: (n_inputs, 1, latent)
        center: (1, n_center, latent)
        dist:   (n_inputs, n_center)
        q, p:   (n_inputs, n_center)
        loss:   (1,)
        &amp;quot;&amp;quot;&amp;quot;
        inputs = tf.expand_dims(inputs, axis=-2)
        centers = tf.expand_dims(self.centers, axis=-3)
        dist = tf.norm(inputs - centers, axis=-1)
        q_ij = self.student_q(dist)
        p_ij = self.target_p(q_ij)
        kl = self.kullback_leibler(p_ij, q_ij)
        self.add_loss(tf.reduce_sum(kl))

        return q_ij

    @tf.function
    def student_q(self, dist):
        &amp;quot;&amp;quot;&amp;quot;
        Membership degree.

        Q: (n_inputs, n_center) / (n_inputs, 1)
        &amp;quot;&amp;quot;&amp;quot;
        # t-distribution with nu = 1, can be reduced by the common factor in division
        q_ij_num = (1 + dist ** 2) ** -1

        # Q normalised summing clusters for each point
        # -&amp;gt; total membership of each data point = 1
        return q_ij_num / tf.reduce_sum(q_ij_num, axis=-1, keepdims=True)

    @staticmethod
    @tf.function
    def target_p(q_ij):
        &amp;quot;&amp;quot;&amp;quot;
        Target membership distribution.

        P: (n_inputs, n_center) / (1, n_center) / (n_input, 1)
        &amp;quot;&amp;quot;&amp;quot;
        # Squared: values close to zero reduce further
        # Normalised summing original data points for each cluster
        # -&amp;gt; Forces some points to belong to a cluster anyway
        p_ij_num = q_ij ** 2 / tf.reduce_sum(q_ij, axis=0, keepdims=True)

        # P normalised summing clusters for each point
        # -&amp;gt; total membership of each data point = 1
        return p_ij_num / tf.reduce_sum(p_ij_num, axis=-1, keepdims=True)

    @staticmethod
    @tf.function
    def kullback_leibler(p, q):
        &amp;quot;&amp;quot;&amp;quot;Difference between distributions.&amp;quot;&amp;quot;&amp;quot;
        return p * tf.math.log(p / q)


class Clustering(k.Model):
    def __init__(self, n_clusters: int, **kwargs):
        super().__init__(**kwargs)
        self.cluster = ClusterHardening(n_clusters)

    def call(self, inputs, training=False, mask=None):
        return self.cluster(inputs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then training and visualisation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lr = 1e-2
n_epochs = 100
latent_dim = 2
n_clusters = 3

x, y = load_iris(return_X_y=True)
x = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))
x = PCA(n_components=latent_dim).fit_transform(x)

adam = Adam(lr)
model = Clustering(n_clusters)
model.compile(adam)

h = {&amp;#39;loss&amp;#39;: []}
centers = np.zeros((n_epochs, n_clusters, latent_dim))
for epoch in range(n_epochs):
    print(f&amp;#39;epoch {epoch} / {n_epochs}&amp;#39;)
    h_ = model.fit(x, None, batch_size=x.shape[1], epochs=1, verbose=0).history
    h[&amp;#39;loss&amp;#39;].extend(h_[&amp;#39;loss&amp;#39;])
    centers[epoch] = model.cluster.centers.numpy()

groups = model.predict(x)
groups = np.argmax(groups, axis=1)

plt.figure(figsize=(5, 3))
norm = Normalize(0, 10)
plt.scatter(x[:, 0], x[:, 1], s=1, c=groups, cmap=&amp;#39;tab10&amp;#39;, norm=norm)
plt.scatter(centers[0, :, 0], centers[0, :, 1], s=20, c=&amp;#39;k&amp;#39;, marker=&amp;#39;o&amp;#39;)
plt.scatter(centers[-1, :, 0], centers[-1, :, 1], s=20, c=&amp;#39;k&amp;#39;, marker=&amp;#39;x&amp;#39;)
for c in range(n_clusters):
    plt.plot(centers[:, c, 0], centers[:, c, 1])
plt.tight_layout()

plt.figure(figsize=(4, 3))
for v in h.values():
    plt.plot(range(n_epochs), v)
plt.legend(h.keys())
plt.xlabel(&amp;#39;epoch&amp;#39;)
plt.ylabel(&amp;#39;loss&amp;#39;)
plt.tight_layout()

plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ixjtqj,True,,felix-hilden,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ixjtqj/clustering_of_simple_data_leads_to_degenerate/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixjtqj/clustering_of_simple_data_leads_to_degenerate/,22217,1600765356.0,0,,False,,,,,"{'rzksklk91oo51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 64, 'x': 108, 'u': 'https://preview.redd.it/rzksklk91oo51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a84a0b8e0bf7580d4371f852cb86bab7cd34fee5'}, {'y': 129, 'x': 216, 'u': 'https://preview.redd.it/rzksklk91oo51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=03c8b5d0016dbd54df977d9b2efa05bd68f6b9a6'}, {'y': 192, 'x': 320, 'u': 'https://preview.redd.it/rzksklk91oo51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3fead2268a9d5e34206f943558b58d9df741082'}], 's': {'y': 300, 'x': 500, 'u': 'https://preview.redd.it/rzksklk91oo51.png?width=500&amp;format=png&amp;auto=webp&amp;s=2656f1bcd23633c5e156b8751f983a2774e45ecd'}, 'id': 'rzksklk91oo51'}}",,,,
785,,tensorflow,,t2_1jyhaoq,False,,0,False,Push keras logs to smartphone for monitoring,[],r/tensorflow,False,6,,0,70.0,,False,t3_ixgm51,False,dark,1.0,,public,7,0,{},140.0,,False,[],,False,False,,{},,False,7,,False,https://b.thumbs.redditmedia.com/tlBchM60vEHKyZl6tFGFK2n9aQEe8C_XuNqdVzB6ryY.jpg,False,,[],{},,False,,1600777644.0,text,6,,,text,github.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ixgm51,True,,mlvpj,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/ixgm51/push_keras_logs_to_smartphone_for_monitoring/,all_ads,False,https://github.com/lab-ml/labml,22217,1600748844.0,0,,False,link,https://github.com/lab-ml/labml,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?auto=webp&amp;s=a636d4b7d6a8fb759cdd14a621f273122e4a0ec2', 'width': 4000, 'height': 2000}, 'resolutions': [{'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8153802b90f936592b35cab133c1972e17d87c1', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e49a726bb52004c0074f8bdf0dac715731247356', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a0047664c67ee46169907530015f048b3bb6b45f', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d3382ebb8680dd06eca9f9ec88bde355f7464e0e', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f918109570b8673ad41b5d53ac77a78e34acd68d', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/Wyk2ZaFFadSlp1tc7k5arE_nmZKMnftTCT36vL5y218.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28dae149d5cd0544c764c196db02f27df1656437', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'Yf_TQTLAaWX4-QGo4UivNwAS_DvsJz9xuNZ8OX3OfyM'}], 'enabled': False}",,,,,,
786,,tensorflow,"Hey guys, after realizing my teachers don’t give a shit about teaching anymore since we are remote, I decided to learn machine learning, more specifically deep learning. Last few days I have been reading up on neural networks and tensorflow, and I was wondering what you guys think the best way is to get started with tesnorflow? In other words, what is most basic beginner project to do, to understand the fundamentals? Thanks",t2_7xhziyzc,False,,0,False,Getting started with tensorflow,[],r/tensorflow,False,6,,0,,,False,t3_ixccfh,False,dark,0.7,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1600761154.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, after realizing my teachers don’t give a shit about teaching anymore since we are remote, I decided to learn machine learning, more specifically deep learning. Last few days I have been reading up on neural networks and tensorflow, and I was wondering what you guys think the best way is to get started with tesnorflow? In other words, what is most basic beginner project to do, to understand the fundamentals? Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ixccfh,True,,ArmenianPrince_,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/ixccfh/getting_started_with_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ixccfh/getting_started_with_tensorflow/,22217,1600732354.0,0,,False,,,,,,,,,
787,,tensorflow,"I want to convert a model from tensorflow object detection api to a keras model. Is there any way to do it?

I have provided some details regarding this issue in the below link.

[Coverting object detection api model to keras model](https://stackoverflow.com/questions/63990388/is-there-any-way-to-convert-a-model-from-tensorflow-object-detection-api-into-a)


Any suggestions on how to do this are really welcome.",t2_13m8lq,False,,0,False,Object detection api model to tf.keras model,[],r/tensorflow,False,6,,0,,,False,t3_ix4wox,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1600737980.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to convert a model from tensorflow object detection api to a keras model. Is there any way to do it?&lt;/p&gt;

&lt;p&gt;I have provided some details regarding this issue in the below link.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://stackoverflow.com/questions/63990388/is-there-any-way-to-convert-a-model-from-tensorflow-object-detection-api-into-a""&gt;Coverting object detection api model to keras model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any suggestions on how to do this are really welcome.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ix4wox,True,,harish7397,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ix4wox/object_detection_api_model_to_tfkeras_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ix4wox/object_detection_api_model_to_tfkeras_model/,22217,1600709180.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799', 'width': 316, 'height': 316}, 'resolutions': [{'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0'}], 'enabled': False}",,,,,,
788,,tensorflow,"I am trying to implement the technique described in the MSG-GAN paper:

https://arxiv.org/pdf/1903.06048.pdf

But I am having difficulty understanding some things, for example, how are the connections made from the generator to the discriminator? These are Conv2D connections literally? (in that case, how would I insert the real images to train the discriminator?) Or does the discriminator have multiple outputs (one prediction for each resolution and the generator has to optimize the average loss of the resolutions)?",t2_6aqt5xxb,False,,0,False,Help with the MSG-GAN paper,[],r/tensorflow,False,6,,0,,,False,t3_ix9hew,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1600751519.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to implement the technique described in the MSG-GAN paper:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://arxiv.org/pdf/1903.06048.pdf""&gt;https://arxiv.org/pdf/1903.06048.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But I am having difficulty understanding some things, for example, how are the connections made from the generator to the discriminator? These are Conv2D connections literally? (in that case, how would I insert the real images to train the discriminator?) Or does the discriminator have multiple outputs (one prediction for each resolution and the generator has to optimize the average loss of the resolutions)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ix9hew,True,,Digital_Secrets,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ix9hew/help_with_the_msggan_paper/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ix9hew/help_with_the_msggan_paper/,22217,1600722719.0,0,,False,,,,,,,,,
789,,tensorflow,"Hey, so since on deep q learning, we train the model from memory array one batch at a time during one action cycle, it seems like the GPU isn't really used at all. My analysis on this issue might not be accurate, but

Any advice on efficiently using GPU for Deep Q Learning would be welcome!",t2_7o3vzwku,False,,0,False,Need advice on deep Q learning w/ utilizing GPU!,[],r/tensorflow,False,6,,0,,,False,t3_iwzx05,False,dark,0.86,,public,9,0,{},,,False,[],,False,False,,{},,False,9,,False,self,False,,[],{},,True,,1600721912.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, so since on deep q learning, we train the model from memory array one batch at a time during one action cycle, it seems like the GPU isn&amp;#39;t really used at all. My analysis on this issue might not be accurate, but&lt;/p&gt;

&lt;p&gt;Any advice on efficiently using GPU for Deep Q Learning would be welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iwzx05,True,,cod_n_tiger,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iwzx05/need_advice_on_deep_q_learning_w_utilizing_gpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iwzx05/need_advice_on_deep_q_learning_w_utilizing_gpu/,22217,1600693112.0,0,,False,,,,,,,,,
790,,tensorflow,,t2_ibs89,False,,0,False,Why TensorFlow?,[],r/tensorflow,False,6,,0,105.0,,False,t3_ix1ed3,False,dark,0.4,,public,0,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yjprpOoH5c8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Why TensorFlow?', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yjprpOoH5c8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': 'TensorFlow', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yjprpOoH5c8/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yjprpOoH5c8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ix1ed3', 'height': 338}",,False,0,,False,https://a.thumbs.redditmedia.com/I8VtW-QZbMWqwwPSE-9gC2apoKTN1fTbNRI8VgxGEK0.jpg,False,,[],{},,False,,1600727072.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ix1ed3,True,,nbortolotti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ix1ed3/why_tensorflow/,all_ads,False,https://www.youtube.com/watch?v=yjprpOoH5c8&amp;feature=share,22217,1600698272.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Why TensorFlow?', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/yjprpOoH5c8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': 'TensorFlow', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yjprpOoH5c8/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ'}, 'type': 'youtube.com'}",False,rich:video,https://www.youtube.com/watch?v=yjprpOoH5c8&amp;feature=share,"{'images': [{'source': {'url': 'https://external-preview.redd.it/iUeKS6nevtrE74DV2cR5T5L5Pq45nkLd40UuIEI9wso.jpg?auto=webp&amp;s=3e73709bd90e804cfca22d0fbeb1e39f27833dfe', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/iUeKS6nevtrE74DV2cR5T5L5Pq45nkLd40UuIEI9wso.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d1860d62dd6c387cc1b3da136b6f10368b3fcb1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/iUeKS6nevtrE74DV2cR5T5L5Pq45nkLd40UuIEI9wso.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f64e5bb79f71fd35cc13cb4196fa9a2e80a72910', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/iUeKS6nevtrE74DV2cR5T5L5Pq45nkLd40UuIEI9wso.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=701efee0ffdda3357a1af272f18cd4d54f1dd4ae', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'cqpujKp4Zxz-seLYXeGDxSWsT8jlyaGt4tT2POjxqU4'}], 'enabled': False}",,,,,,
791,,tensorflow,title,t2_3cm19jh2,False,,0,False,Does GTX 1660S work for tensorflow-gpu?,[],r/tensorflow,False,6,,0,,,False,t3_iwxmyz,False,dark,0.63,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1600711909.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;title&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iwxmyz,True,,whenindan,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/iwxmyz/does_gtx_1660s_work_for_tensorflowgpu/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iwxmyz/does_gtx_1660s_work_for_tensorflowgpu/,22217,1600683109.0,0,,False,,,,,,,,,
792,,tensorflow,"I have a 4d tensor output for an object detector that outputs per-pixel, per class box predictions, i.e. Shape H x W x C x 6, where the innermost 6 wide dimension is box parameters for that class. Now, when computing loss, I want to update only the predictions from the ground truth class. To do this, I'd like to have a tensor with shape H x W whose elements are the ground truth class index. This tensor is then used to extract the relevant class only from the input, outputting a tensor with H x W x 6. I know this should be possible using gather or gather\_nd but I can't get the parameters right to get the desired output. Plus I'm confused about the purpose of the batch\_dims parameter for gather\_nd, that may be relevant though to solving this. Any suggestions on how I can properly use these or some other tf function to achieve this result?

&amp;#x200B;

For a single element example, here's an example input/output I'm looking for:

`Prediction tensor: [[[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]]]] # 1 height X 1 width X 2 classes # 6 values/class`

`Ground truth class tensor: [[1]] # 1, 1 has class 1`

`Output:  [[[7, 8, 9, 10, 11, 12]]]`",t2_1hg7w5iv,False,,0,False,How to best use tf.gather/gather_nd to collect along inner dimension,[],r/tensorflow,False,6,,0,,,False,t3_iwscxi,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1600686442.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a 4d tensor output for an object detector that outputs per-pixel, per class box predictions, i.e. Shape H x W x C x 6, where the innermost 6 wide dimension is box parameters for that class. Now, when computing loss, I want to update only the predictions from the ground truth class. To do this, I&amp;#39;d like to have a tensor with shape H x W whose elements are the ground truth class index. This tensor is then used to extract the relevant class only from the input, outputting a tensor with H x W x 6. I know this should be possible using gather or gather_nd but I can&amp;#39;t get the parameters right to get the desired output. Plus I&amp;#39;m confused about the purpose of the batch_dims parameter for gather_nd, that may be relevant though to solving this. Any suggestions on how I can properly use these or some other tf function to achieve this result?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;For a single element example, here&amp;#39;s an example input/output I&amp;#39;m looking for:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Prediction tensor: [[[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]]]] # 1 height X 1 width X 2 classes # 6 values/class&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Ground truth class tensor: [[1]] # 1, 1 has class 1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Output:  [[[7, 8, 9, 10, 11, 12]]]&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iwscxi,True,,atyshka,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/iwscxi/how_to_best_use_tfgathergather_nd_to_collect/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iwscxi/how_to_best_use_tfgathergather_nd_to_collect/,22217,1600657642.0,0,,False,,,,,,,,,
793,,tensorflow,Is there a comprehensive list of all the data augmentation options available in the object setection api?,t2_2p1tbwl7,False,,0,False,TF 2.0 object detection API data augmentation options,[],r/tensorflow,False,6,,0,,,False,t3_iwr39o,False,dark,0.76,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1600681424.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there a comprehensive list of all the data augmentation options available in the object setection api?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iwr39o,True,,EbryJoss,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/iwr39o/tf_20_object_detection_api_data_augmentation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iwr39o/tf_20_object_detection_api_data_augmentation/,22217,1600652624.0,0,,False,,,,,,,,,
794,,tensorflow,"Hello everyone, I have trained [ResNet50](https://keras.io/api/applications/resnet/) model on my data (having 5 classes). I want to get output of custom layer while making prediction

I am using below code for making predictions, It gives me last layer output as expected, but I want the output of other layers

    from keras.models import load_model
    
    model = load_model(model_path)
    result = model.predict(data) # data variable is of size 1000
    print(result.shape)
    #(1000, 5)

What changes I have to make in the code to get custom layer output, any suggestion would be very helpful",t2_1as413t4,False,,0,False,How to get output of custom layer while making prediction,[],r/tensorflow,False,6,,0,,,False,t3_iweqv0,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,self,False,,[],{},,True,,1600640671.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, I have trained &lt;a href=""https://keras.io/api/applications/resnet/""&gt;ResNet50&lt;/a&gt; model on my data (having 5 classes). I want to get output of custom layer while making prediction&lt;/p&gt;

&lt;p&gt;I am using below code for making predictions, It gives me last layer output as expected, but I want the output of other layers&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from keras.models import load_model

model = load_model(model_path)
result = model.predict(data) # data variable is of size 1000
print(result.shape)
#(1000, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What changes I have to make in the code to get custom layer output, any suggestion would be very helpful&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iweqv0,True,,arush1836,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/iweqv0/how_to_get_output_of_custom_layer_while_making/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iweqv0/how_to_get_output_of_custom_layer_while_making/,22217,1600611871.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&amp;s=0c3f0b8af92c3a962f569a389e9673597e12f8ec', 'width': 774, 'height': 269}, 'resolutions': [{'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9985b1dc92701ea8c38c4bb72a28d50198fb54ab', 'width': 108, 'height': 37}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a7452ccf0826692f35ac78457de9275d52f5935', 'width': 216, 'height': 75}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ae2ffe955b207d1da9c058b01c62aff9e80110d7', 'width': 320, 'height': 111}, {'url': 'https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff31c7e26d2e15f6faa6e4bedc2a41dfe0eab9ab', 'width': 640, 'height': 222}], 'variants': {}, 'id': 'qsh7aKFxRPo6CaMu10A7nekvx_ez8hkySyb6h9YVvHI'}], 'enabled': False}",,,,,,
795,,tensorflow,,t2_6wt510of,False,,0,False,interpolating between stylegan generated presidents,[],r/tensorflow,False,6,,0,105.0,,False,t3_iwekoy,False,dark,0.67,,public,3,0,"{'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'height': 344}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates American Presidents (Washington to Trump via StyleGAN2)', 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/XDR2JV0j4hs/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iwekoy', 'height': 344}",,False,3,,False,https://b.thumbs.redditmedia.com/zIi7BnyY_1t8MMPDainUu8eun9QW8RUFJskcoHYcQPI.jpg,False,,[],{},,False,,1600640055.0,text,6,,,text,youtu.be,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iwekoy,True,,Snoo_72253,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/iwekoy/interpolating_between_stylegan_generated/,all_ads,False,https://youtu.be/XDR2JV0j4hs,22217,1600611255.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates American Presidents (Washington to Trump via StyleGAN2)', 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/XDR2JV0j4hs/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,rich:video,https://youtu.be/XDR2JV0j4hs,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?auto=webp&amp;s=5fa51c5098cf2a1d2dcd32adf1cb13f5a114761a', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5de164d6fde2a69bf3cd6bec7b40593576fa0734', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f623d5fa004daa81451a9ec0dbbc97b2ee6f513', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8aae96f885da985af845933f524c5ff22ae2ae21', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'ehuWKHQQngIdPkV-P7NQoi_ce_Dq1B8zVyBiFndwTK0'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'MediaSynthesis', 'selftext': '', 'author_fullname': 't2_683tvs22', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'interpolating between stylegan generated presidents', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MediaSynthesis', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 105, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_iwe8pa', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 50, 'total_awards_received': 1, 'media_embed': {'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'height': 344}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates American Presidents (Washington to Trump via StyleGAN2)', 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/XDR2JV0j4hs/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 459, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iwe8pa', 'height': 344}, 'link_flair_text': 'Video Synthesis', 'can_mod_post': False, 'score': 50, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/zIi7BnyY_1t8MMPDainUu8eun9QW8RUFJskcoHYcQPI.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'rich:video', 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1600638842.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtu.be', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtu.be/XDR2JV0j4hs', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?auto=webp&amp;s=5fa51c5098cf2a1d2dcd32adf1cb13f5a114761a', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5de164d6fde2a69bf3cd6bec7b40593576fa0734', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f623d5fa004daa81451a9ec0dbbc97b2ee6f513', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/-ypxtnd7B0K-oFp4yG58YDxpnPFMcLwDZMi6N1YyATg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8aae96f885da985af845933f524c5ff22ae2ae21', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'ehuWKHQQngIdPkV-P7NQoi_ce_Dq1B8zVyBiFndwTK0'}], 'enabled': False}, 'all_awardings': [{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'award_74fe5152-7906-4991-9016-bc2d8e261200', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': False, 'awardings_required_to_grant_benefits': None, 'description': ""I don't know what to do with my hands!"", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Excited', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '18395ff6-31ff-11e9-95aa-0edbbd6b1386', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_f2bje', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iwe8pa', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'N2AI', 'discussion_type': None, 'num_comments': 17, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MediaSynthesis/comments/iwe8pa/interpolating_between_stylegan_generated/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://youtu.be/XDR2JV0j4hs', 'subreddit_subscribers': 22032, 'created_utc': 1600610042.0, 'num_crossposts': 1, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates American Presidents (Washington to Trump via StyleGAN2)', 'type': 'video', 'thumbnail_width': 480, 'height': 344, 'width': 459, 'html': '&lt;iframe width=""459"" height=""344"" src=""https://www.youtube.com/embed/XDR2JV0j4hs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/XDR2JV0j4hs/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}, 'is_video': False}]",t3_iwe8pa,
796,,tensorflow,"Hello,

I am trying to do a machine learning task and in my current dataset I have featurized protein sequences, so for every protein I have 27 features which are float arrays of different length. So, I have a numpy array of shape (556,1) and for every sample it have 27 features so (27,1) and each feature has variable length and the same feature might have a different shape for different samples. Trying to use this data with sklearn gives the following error ValueError: setting an array element with a sequence  
and using it with keras gives the following error ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)  
. If i try to convert it with input = input.astype(np.float32),  
i get the same error ValueError: setting an array element with a sequence.

Any idea how to fix this or how to I get this data working? I thought about padding each feature to equal length but some features are too big about 10k length so Im skeptical about doing that. Any help would be appreciated.",t2_2feck1ws,False,,0,False,Failed to convert a NumPy array to a Tensor,[],r/tensorflow,False,6,,0,,,False,t3_iw9wjy,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},Question,False,6,,False,self,False,,[],{},,True,,1600618441.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I am trying to do a machine learning task and in my current dataset I have featurized protein sequences, so for every protein I have 27 features which are float arrays of different length. So, I have a numpy array of shape (556,1) and for every sample it have 27 features so (27,1) and each feature has variable length and the same feature might have a different shape for different samples. Trying to use this data with sklearn gives the following error ValueError: setting an array element with a sequence&lt;br/&gt;
and using it with keras gives the following error ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)&lt;br/&gt;
. If i try to convert it with input = input.astype(np.float32),&lt;br/&gt;
i get the same error ValueError: setting an array element with a sequence.&lt;/p&gt;

&lt;p&gt;Any idea how to fix this or how to I get this data working? I thought about padding each feature to equal length but some features are too big about 10k length so Im skeptical about doing that. Any help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iw9wjy,True,,ybkhan,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/iw9wjy/failed_to_convert_a_numpy_array_to_a_tensor/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iw9wjy/failed_to_convert_a_numpy_array_to_a_tensor/,22217,1600589641.0,0,,False,,,,,,,,,
797,,tensorflow,,t2_63ay634e,False,,0,False,"ICYMI: A new browser extension for finding code for ML research papers on the internet (on Google, Arxiv, Scholar, Twitter, Github)",[],r/tensorflow,False,6,,0,140.0,,False,t3_ivz4mq,False,dark,0.91,,public,8,0,{},140.0,,False,[],,False,False,,{},,False,8,,False,https://b.thumbs.redditmedia.com/GkF9zjZNnjH1Zqtjmw3jmxuy2IPnXcnIlmShYOx4YLU.jpg,False,,[],{},,False,,1600572644.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ivz4mq,True,,cv2020br,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ivz4mq/icymi_a_new_browser_extension_for_finding_code/,all_ads,False,/r/LatestInML/comments/ivyqat/a_new_browser_extension_for_finding_code_for_ml/,22217,1600543844.0,0,,False,link,/r/LatestInML/comments/ivyqat/a_new_browser_extension_for_finding_code_for_ml/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?auto=webp&amp;s=b2ec1cfa2b9e720731d4dc172cbef8096fb37c3a', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5435b4b2d94d9df9309e4d5ceb4bc021b52783', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'TIQjNUpyCsCWmTM49ZEEAiVQDWg07G_PjT8zXCX4wSE'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'ICYMI: A New browser extension that finds code implementations for machine learning papers anywhere on the web (Google, Arxiv, Twitter, Scholar, and other sites)!\n\n[link to chrome extension](https://chrome.google.com/webstore/detail/mlai-code-implementation/aikkeehnlfpamidigaffhfmgbkdeheil)  \nor  \n[link to firefox extension](https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/)\n\nhttps://preview.redd.it/kyvp5fh5l5o51.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=1155e81c4ec11447bd5fb37dedebed35e0afc902', 'author_fullname': 't2_63ay634e', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'A new browser extension for finding code for ML research papers on the internet (on Google, Arxiv, Scholar, Twitter, Github)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'kyvp5fh5l5o51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 135, 'x': 108, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e90f2437ec633614dd436753a0394287c84b486'}, {'y': 270, 'x': 216, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e51347d47fd494890176eefb790edf5a4812a43'}, {'y': 400, 'x': 320, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2100caef681ce7eda4784cc52d1dfcd4be075b1'}, {'y': 800, 'x': 640, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=50e85a74ecf8b64bca87197ba5d619a08908ead2'}, {'y': 1200, 'x': 960, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bdc420c293c48a594ad2247cd4579322e6f41214'}, {'y': 1350, 'x': 1080, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f088383ae7ce766c8f2378b2ba6acf76e9099d3'}], 's': {'y': 1350, 'x': 1080, 'u': 'https://preview.redd.it/kyvp5fh5l5o51.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=1155e81c4ec11447bd5fb37dedebed35e0afc902'}, 'id': 'kyvp5fh5l5o51'}}, 'name': 't3_ivyqat', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 43, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 43, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/GkF9zjZNnjH1Zqtjmw3jmxuy2IPnXcnIlmShYOx4YLU.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1600571335.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;ICYMI: A New browser extension that finds code implementations for machine learning papers anywhere on the web (Google, Arxiv, Twitter, Scholar, and other sites)!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://chrome.google.com/webstore/detail/mlai-code-implementation/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;link to chrome extension&lt;/a&gt;&lt;br/&gt;\nor&lt;br/&gt;\n&lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/""&gt;link to firefox extension&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/kyvp5fh5l5o51.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1155e81c4ec11447bd5fb37dedebed35e0afc902""&gt;https://preview.redd.it/kyvp5fh5l5o51.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1155e81c4ec11447bd5fb37dedebed35e0afc902&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?auto=webp&amp;s=b2ec1cfa2b9e720731d4dc172cbef8096fb37c3a', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5435b4b2d94d9df9309e4d5ceb4bc021b52783', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'TIQjNUpyCsCWmTM49ZEEAiVQDWg07G_PjT8zXCX4wSE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ivyqat', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cv2020br', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/ivyqat/a_new_browser_extension_for_finding_code_for_ml/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/ivyqat/a_new_browser_extension_for_finding_code_for_ml/', 'subreddit_subscribers': 6676, 'created_utc': 1600542535.0, 'num_crossposts': 19, 'media': None, 'is_video': False}]",t3_ivyqat,
798,,tensorflow,,t2_5moj37ik,False,,0,False,Transformers: Fall of Cybertron - (Resolution increased using neural networks to 8K),[],r/tensorflow,False,6,,0,105.0,,False,t3_ivklwl,False,dark,1.0,,public,17,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/VVfsAK4icsQ?start=5&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Transformers: Fall of Cybertron - Trailer №3 (Remastered 8K)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/VVfsAK4icsQ?start=5&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VVfsAK4icsQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/VVfsAK4icsQ?start=5&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ivklwl', 'height': 338}",,False,17,,False,https://b.thumbs.redditmedia.com/zM0nh2LKrf_Rb2PDRLj3RJ8HidLYpSkOZQTJYWUtlFo.jpg,False,,[],{},,False,,1600513667.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ivklwl,True,,stepanmetior,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ivklwl/transformers_fall_of_cybertron_resolution/,all_ads,False,https://www.youtube.com/watch?v=VVfsAK4icsQ&amp;t=5s,22217,1600484867.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Transformers: Fall of Cybertron - Trailer №3 (Remastered 8K)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/VVfsAK4icsQ?start=5&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VVfsAK4icsQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}}",False,rich:video,https://www.youtube.com/watch?v=VVfsAK4icsQ&amp;t=5s,"{'images': [{'source': {'url': 'https://external-preview.redd.it/jbbWOxrKTwhKGo0b9wkQNtF0lyl9Dcqq7A4g7DtjKiw.jpg?auto=webp&amp;s=46798364b931d19dfcec0bbc95411182f46c5a9a', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/jbbWOxrKTwhKGo0b9wkQNtF0lyl9Dcqq7A4g7DtjKiw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c36b8bc973c12b62a47393a7b81ff4bbe574589', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/jbbWOxrKTwhKGo0b9wkQNtF0lyl9Dcqq7A4g7DtjKiw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed661c2928783d836d18da8bdb9ab434eb4a0ae1', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/jbbWOxrKTwhKGo0b9wkQNtF0lyl9Dcqq7A4g7DtjKiw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d09a89a1f02bd55cbd586479342d10c7fc37958', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'gMcddG4j-1gifXBUIDGAOZ6rz32mIw1akQPktSzOzEI'}], 'enabled': False}",,,,,,
799,,tensorflow,,t2_vrv17,False,,0,False,What can I do with such a dataset? Can I use it to predict sales? Any Ideas?,[],r/tensorflow,False,6,,0,140.0,,False,t3_ivve4y,False,dark,0.5,,public,0,0,{},140.0,,False,[],,True,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/n3dw_E3usG-q8a3O7ZYLIJeyEOxmikFJ3sffmG4_H_w.jpg,False,,[],{},,False,,1600560692.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ivve4y,True,,a7madx7,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/ivve4y/what_can_i_do_with_such_a_dataset_can_i_use_it_to/,all_ads,False,https://i.redd.it/u66rmqzhp4o51.png,22217,1600531892.0,0,,False,image,https://i.redd.it/u66rmqzhp4o51.png,"{'images': [{'source': {'url': 'https://preview.redd.it/u66rmqzhp4o51.png?auto=webp&amp;s=80ea414141581398298d233c3fe16639c5582297', 'width': 552, 'height': 566}, 'resolutions': [{'url': 'https://preview.redd.it/u66rmqzhp4o51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e0041bb1675a46133a21a6a2b8520e5f31f152e4', 'width': 108, 'height': 110}, {'url': 'https://preview.redd.it/u66rmqzhp4o51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8da58429baf0d3ac14ca848d385a396e861496eb', 'width': 216, 'height': 221}, {'url': 'https://preview.redd.it/u66rmqzhp4o51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7793aea43681e1f13f714c12633992da6ce6594', 'width': 320, 'height': 328}], 'variants': {}, 'id': 'OR--gAMn4Gxdc9aLAjYUrTHfapYLZI0WYWwgZZlOKj8'}], 'enabled': True}",,,,,,
800,,tensorflow,,t2_5w4i5kd1,False,,0,False,"First model went horrible: Same person as before, with more info on my project",[],r/tensorflow,False,6,,0,60.0,,False,t3_ivln9o,False,dark,1.0,,public,4,0,{},140.0,,False,[],,False,False,,{},Question,False,4,,False,https://b.thumbs.redditmedia.com/Ed_J8vjLWkzF_CsT4zwG5C_ohdeIK8wNphrNXXuK27Y.jpg,False,,[],{},,False,,1600517995.0,text,6,,,text,reddit.com,False,,,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ivln9o,True,,veeeerain,,11,True,all_ads,False,[],False,,/r/tensorflow/comments/ivln9o/first_model_went_horrible_same_person_as_before/,all_ads,False,https://www.reddit.com/gallery/ivln9o,22217,1600489195.0,0,,False,,https://www.reddit.com/gallery/ivln9o,,True,"{'ad5vcutk61o51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 46, 'x': 108, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=34749b59d8a5baedd6677a9b55d97135f90ea2cd'}, {'y': 93, 'x': 216, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f15ebe23eab98837fdb4e69d614abe8999b35a5'}, {'y': 138, 'x': 320, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d91c0e84045bca0cf5e19f87b98629beaa192dd3'}, {'y': 277, 'x': 640, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a6e4b5437ea8fecf66e82350659b1ea2a168071'}, {'y': 415, 'x': 960, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6b95243f4597501884458f7631f83bebfc1dbfe2'}, {'y': 467, 'x': 1080, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=279398bd1fe7d900b5be26670dff66ffd4364fe1'}], 's': {'y': 1227, 'x': 2833, 'u': 'https://preview.redd.it/ad5vcutk61o51.jpg?width=2833&amp;format=pjpg&amp;auto=webp&amp;s=bfd9f5561a699a9e44f4a6cb592074e1ba4c0089'}, 'id': 'ad5vcutk61o51'}, '3drd3ttk61o51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 54, 'x': 108, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=decadcfcd6b1593771d0a04c2ca3949b10f80948'}, {'y': 108, 'x': 216, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=67c8dd933f91c822d6266dc3e82a40b5e8b991ec'}, {'y': 161, 'x': 320, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=215f1a60f504868babfa3bc35227eeb0a6fe0a38'}, {'y': 322, 'x': 640, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a55a2d0bd3aa6594fced0df1f572a2facf4d477c'}, {'y': 483, 'x': 960, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c41d10c767137b8af1edfb1e24f9a46c234edc3b'}, {'y': 543, 'x': 1080, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bd4727a89a634e69152d405ca3f947c60a0f61cd'}], 's': {'y': 1450, 'x': 2880, 'u': 'https://preview.redd.it/3drd3ttk61o51.jpg?width=2880&amp;format=pjpg&amp;auto=webp&amp;s=4cb8f093b62c39b158163bebfb0b320418369e66'}, 'id': '3drd3ttk61o51'}}","{'items': [{'caption': 'Here’s my dataset that I fed into the model', 'media_id': 'ad5vcutk61o51', 'id': 5719566}, {'caption': 'Here’s my error and no loss and horrid accuracy.', 'media_id': '3drd3ttk61o51', 'id': 5719567}]}",,,
801,,tensorflow,"Hey, 

I was wondering what's the best practice/method to upload Trained models. Suppose, I trained a few custom models or even finetuned a YOLO/InceptionResnet/other models for a specific purpose. I now want to upload these models so that others might use it, if they ever find a need for it. How should I do it?  
Till now, I have been using \`[git lfs](https://git-lfs.github.com/)\` to upload models &gt; 100MB, since normal \`git commit\` and \`git clone\` wouldn't upload files &gt;100MB. However, I recently trained a model on my custom dataset, and its \~280MB. I think it is a bad practice to upload large models using \`git lfs\`, just because \`git lfs\` allows it. 

Is uploading it to my GDrive and then sharing it through a link, a more appropriate solution (but then again, if in the future, I need to move the uploaded model, the link won't work anymore unless I go back and replace the old link with the new one)?   


Any tips or advices would be greatly appreciated.",t2_143jl934,False,,0,False,Uploading Trained Models,[],r/tensorflow,False,6,,0,,,False,t3_ivanii,False,dark,1.0,,public,11,0,{},,,False,[],,False,False,,{},Discussion,False,11,,False,self,False,,[],{},,True,,1600479371.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, &lt;/p&gt;

&lt;p&gt;I was wondering what&amp;#39;s the best practice/method to upload Trained models. Suppose, I trained a few custom models or even finetuned a YOLO/InceptionResnet/other models for a specific purpose. I now want to upload these models so that others might use it, if they ever find a need for it. How should I do it?&lt;br/&gt;
Till now, I have been using `&lt;a href=""https://git-lfs.github.com/""&gt;git lfs&lt;/a&gt;` to upload models &amp;gt; 100MB, since normal `git commit` and `git clone` wouldn&amp;#39;t upload files &amp;gt;100MB. However, I recently trained a model on my custom dataset, and its ~280MB. I think it is a bad practice to upload large models using `git lfs`, just because `git lfs` allows it. &lt;/p&gt;

&lt;p&gt;Is uploading it to my GDrive and then sharing it through a link, a more appropriate solution (but then again, if in the future, I need to move the uploaded model, the link won&amp;#39;t work anymore unless I go back and replace the old link with the new one)?   &lt;/p&gt;

&lt;p&gt;Any tips or advices would be greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,ivanii,True,,cHotagAbbar99,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ivanii/uploading_trained_models/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ivanii/uploading_trained_models/,22217,1600450571.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?auto=webp&amp;s=4670f4808608051f218b19bd18fbe9c6e0cec2f9', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d576c2ab9942375dc93d2c5a7e7bc28175074ab6', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a40ec75c18a2f8c0a8b25764881d81225a4a580c', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66b6a8f61f5ab8ffae78c2fe9e700987a7ce2e29', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a57c1987194d3c168f7773432e09d23b93d73209', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=733efd441327ee17a3cc6351d4c7859dbf91eedf', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/keekeYU-3qr2Ue3p-dp-Io-k_y-xihHlu61MAkhOpDc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b8c400ed9b0866ec36d71ee4a92c2ca35e5676b', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'OxLg2uPeu9dNeX8R7ShJ9fLtWFodpbYS8naZSZBqohE'}], 'enabled': False}",,,,,,
802,,tensorflow,"Hello everyone,   
I'm new to Tenserflow and after installing it (CPU version) it was a bit slow with my Ryzen 5 3600 CPU. I read on internet that it exist a GPU version of tensorflow. How ever I didn't find anything concerning the installation on Fedora (32) with an AMD GPU (Navi architecture, 5700 XT) even the ROCm project does not seems to support Navi cards.  Also, I'm actualy running with the open-source free driver for my GPU, not the ""pro"" version, is it enough or do I need to upgrade?

&amp;#x200B;

Thanks for your help!",t2_291b2b4c,False,,0,False,Configure tensorflow with AMD Gpu on Fedora,[],r/tensorflow,False,6,,0,,,False,t3_ivez7l,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1600493225.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;
I&amp;#39;m new to Tenserflow and after installing it (CPU version) it was a bit slow with my Ryzen 5 3600 CPU. I read on internet that it exist a GPU version of tensorflow. How ever I didn&amp;#39;t find anything concerning the installation on Fedora (32) with an AMD GPU (Navi architecture, 5700 XT) even the ROCm project does not seems to support Navi cards.  Also, I&amp;#39;m actualy running with the open-source free driver for my GPU, not the &amp;quot;pro&amp;quot; version, is it enough or do I need to upgrade?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for your help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ivez7l,True,,Azumi-San,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ivez7l/configure_tensorflow_with_amd_gpu_on_fedora/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ivez7l/configure_tensorflow_with_amd_gpu_on_fedora/,22217,1600464425.0,0,,False,,,,,,,,,
803,,tensorflow,"In partnership with OpenCV, SuperAnnotate launched an all free-to-use desktop app. This is the fastest annotation software ever built. It closes the gap between free and commercial annotation tools providing CV Engineers with all the functionalities designed to increase the speed, the accuracy and the efficiency of their annotation projects.

I'm sharing an article all about the software and the behind-the-scenes of why [SuperAnnotate Desktop](https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools) was created.",t2_40op27sm,False,,0,False,SuperAnnotate Desktop: A better alternative to free annotation tools,[],r/tensorflow,False,6,,0,,,False,t3_iv2wrr,False,dark,0.86,,public,11,0,{},,,False,[],,False,False,,{},,False,11,,False,self,False,,[],{},,True,,1600450103.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In partnership with OpenCV, SuperAnnotate launched an all free-to-use desktop app. This is the fastest annotation software ever built. It closes the gap between free and commercial annotation tools providing CV Engineers with all the functionalities designed to increase the speed, the accuracy and the efficiency of their annotation projects.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m sharing an article all about the software and the behind-the-scenes of why &lt;a href=""https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools""&gt;SuperAnnotate Desktop&lt;/a&gt; was created.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iv2wrr,True,,burgerswithbacon818,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/iv2wrr/superannotate_desktop_a_better_alternative_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iv2wrr/superannotate_desktop_a_better_alternative_to/,22217,1600421303.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?auto=webp&amp;s=05a40dde4793c57f79e9fef1df1ca804e6e76deb', 'width': 1200, 'height': 628}, 'resolutions': [{'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f6d552a6b9d5962897aac1511a614d30d4af80dd', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=acf7ffc246d1ad549c80a482186f57031f9d185f', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a9e313142f9ff81b1578746c01e1ea6329bc9696', 'width': 320, 'height': 167}, {'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8b6b74f799f1ab959195b9d1dd4e6454983f6302', 'width': 640, 'height': 334}, {'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b5e1f195cdb867ec7fb5941181307c2cac0395bf', 'width': 960, 'height': 502}, {'url': 'https://external-preview.redd.it/rcZzQ4MYZSCng2yCWGu9pOUqvl6lN9zcD1RQjCvKSfw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=46a2146eec29ca079f5cbaced967b9e9e71fe591', 'width': 1080, 'height': 565}], 'variants': {}, 'id': 'b8Ga88eDPJbVvw7zY24mlewh50jCNwWazMuyHhRQuSo'}], 'enabled': False}",,,,,,
804,,tensorflow,,t2_44mbtmjy,False,,0,False,Retiming and duplicating people in video (using neural rendering)!,[],r/tensorflow,False,6,,0,57.0,,False,t3_iuyv25,False,dark,1.0,,public,7,0,{},140.0,,False,[],,False,False,,{},,False,7,,False,https://b.thumbs.redditmedia.com/lBiLI7qpyr-YBxCwiIC-pq3MFfWRBeMldJ0U7R1GvdA.jpg,False,,[],{},,False,,1600429736.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iuyv25,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iuyv25/retiming_and_duplicating_people_in_video_using/,all_ads,False,/r/LatestInML/comments/iuymg2/retiming_and_duplicating_people_in_video_using/,22217,1600400936.0,0,,False,link,/r/LatestInML/comments/iuymg2/retiming_and_duplicating_people_in_video_using/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?auto=webp&amp;s=89d0b3b0a371f93b0d42dddf16e66ee1cf905c12', 'width': 1412, 'height': 578}, 'resolutions': [{'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44ab01afbaff1a592b17fb636bbfb91bdd22188e', 'width': 108, 'height': 44}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7301389cd5e3068441fd4a10be10c1b56506dbc', 'width': 216, 'height': 88}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15c998a4ec53c1c6ad514bc35f539ddf4f5d6ead', 'width': 320, 'height': 130}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22803eda6be407920eb55283fd7414ac21783012', 'width': 640, 'height': 261}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61c1a9ade782e2118c222a0580e8e150d15fced5', 'width': 960, 'height': 392}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28f41374dc04746bdb372204431c28e586b41f1a', 'width': 1080, 'height': 442}], 'variants': {}, 'id': 'MIVqFHr7nrkqun5cwJ50ea8EDiZHa6Mnkd8cwbFxkdY'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2009.07833)\n\n&amp;#x200B;\n\nhttps://reddit.com/link/iuymg2/video/sb6o61yxstn51/player', 'author_fullname': 't2_63ay634e', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Retiming and duplicating people in video (using neural rendering)!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 57, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'sb6o61yxstn51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/iuymg2/asset/sb6o61yxstn51/DASHPlaylist.mpd?a=1618044841%2CNzM0MjcwZGMxYzlhYmZlMmE5MzU3YjQ3OGFkYjFhZmE2Mzk2ZTQzYWZhOGNhY2FlOTExZGM2MDgxZmIxZWZkNA%3D%3D&amp;v=1&amp;f=sd', 'x': 630, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/iuymg2/asset/sb6o61yxstn51/HLSPlaylist.m3u8?a=1618044841%2CNmU1NWI0NjM2ZDYyY2EwMTUyMjNiOWI0NjNmODkzMGYxNGZjNjI1NWFjMzBiY2Q2YTk4ZWExNDA0NTNhZTQ2MQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'sb6o61yxstn51', 'isGif': False}}, 'name': 't3_iuymg2', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 39, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 39, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/lBiLI7qpyr-YBxCwiIC-pq3MFfWRBeMldJ0U7R1GvdA.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1600428712.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2009.07833""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/iuymg2/video/sb6o61yxstn51/player""&gt;https://reddit.com/link/iuymg2/video/sb6o61yxstn51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?auto=webp&amp;s=89d0b3b0a371f93b0d42dddf16e66ee1cf905c12', 'width': 1412, 'height': 578}, 'resolutions': [{'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44ab01afbaff1a592b17fb636bbfb91bdd22188e', 'width': 108, 'height': 44}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7301389cd5e3068441fd4a10be10c1b56506dbc', 'width': 216, 'height': 88}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15c998a4ec53c1c6ad514bc35f539ddf4f5d6ead', 'width': 320, 'height': 130}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22803eda6be407920eb55283fd7414ac21783012', 'width': 640, 'height': 261}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61c1a9ade782e2118c222a0580e8e150d15fced5', 'width': 960, 'height': 392}, {'url': 'https://external-preview.redd.it/nw2vuhKYtQZOavWnIdKw59MWQY67PfY2BxPwhPO2N8E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28f41374dc04746bdb372204431c28e586b41f1a', 'width': 1080, 'height': 442}], 'variants': {}, 'id': 'MIVqFHr7nrkqun5cwJ50ea8EDiZHa6Mnkd8cwbFxkdY'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iuymg2', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cv2020br', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/iuymg2/retiming_and_duplicating_people_in_video_using/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/iuymg2/retiming_and_duplicating_people_in_video_using/', 'subreddit_subscribers': 6676, 'created_utc': 1600399912.0, 'num_crossposts': 15, 'media': None, 'is_video': False}]",t3_iuymg2,
805,,tensorflow,,t2_63ay634e,False,,0,False,"Find code implementations for ML/AI research papers directly on Google, Arxiv, Scholar, Twitter, Github, and more!!",[],r/tensorflow,False,6,,0,140.0,,False,t3_iuwrc7,False,dark,0.83,,public,4,0,{},140.0,,False,[],,False,False,,{},,False,4,,False,https://a.thumbs.redditmedia.com/F-rRKh6_4S55KHTEzTJDG7llud9CCf63I6BsMWR3oH8.jpg,False,,[],{},,False,,1600421318.0,text,6,,,text,self.LatestInML,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iuwrc7,True,,cv2020br,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iuwrc7/find_code_implementations_for_mlai_research/,all_ads,False,/r/LatestInML/comments/iuwpon/find_code_implementations_for_mlai_research/,22217,1600392518.0,0,,False,link,/r/LatestInML/comments/iuwpon/find_code_implementations_for_mlai_research/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?auto=webp&amp;s=b2ec1cfa2b9e720731d4dc172cbef8096fb37c3a', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5435b4b2d94d9df9309e4d5ceb4bc021b52783', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'TIQjNUpyCsCWmTM49ZEEAiVQDWg07G_PjT8zXCX4wSE'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'Browser extension that finds code implementations for machine learning papers anywhere on the web (Google, Arxiv, Twitter, Scholar, and other sites)!\n\n[link to chrome extension](https://chrome.google.com/webstore/detail/mlai-code-implementation/aikkeehnlfpamidigaffhfmgbkdeheil)  \nor  \n[link to firefox extension](https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/mlh1xqxe6tn51.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=65f49d0771fd8847b09c7495a272cdc25af7ca1b', 'author_fullname': 't2_63ay634e', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Find code implementations for ML/AI research papers directly on Google, Arxiv, Scholar, Twitter, Github, and more!!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'mlh1xqxe6tn51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 135, 'x': 108, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=326af424fb84e8e0ee3086d60bde20497ae0656d'}, {'y': 270, 'x': 216, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c43ef5273ab0a0ee3378a7b803e3f119ae7aad1c'}, {'y': 400, 'x': 320, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=701d78b4361432bd77ac99309f04d319e2a4e4db'}, {'y': 800, 'x': 640, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4f09b6743d9129ebe501dfc4d168f55441b658b1'}, {'y': 1200, 'x': 960, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bccdd35af12091d2664d457bb4f1a6542089c21'}, {'y': 1350, 'x': 1080, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9da0a5729e79ad434b619a98945ca7fff70659c7'}], 's': {'y': 1350, 'x': 1080, 'u': 'https://preview.redd.it/mlh1xqxe6tn51.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=65f49d0771fd8847b09c7495a272cdc25af7ca1b'}, 'id': 'mlh1xqxe6tn51'}}, 'name': 't3_iuwpon', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 15, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 15, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/F-rRKh6_4S55KHTEzTJDG7llud9CCf63I6BsMWR3oH8.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1600421124.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Browser extension that finds code implementations for machine learning papers anywhere on the web (Google, Arxiv, Twitter, Scholar, and other sites)!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://chrome.google.com/webstore/detail/mlai-code-implementation/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;link to chrome extension&lt;/a&gt;&lt;br/&gt;\nor&lt;br/&gt;\n&lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/""&gt;link to firefox extension&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/mlh1xqxe6tn51.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=65f49d0771fd8847b09c7495a272cdc25af7ca1b""&gt;https://preview.redd.it/mlh1xqxe6tn51.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=65f49d0771fd8847b09c7495a272cdc25af7ca1b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?auto=webp&amp;s=b2ec1cfa2b9e720731d4dc172cbef8096fb37c3a', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/IxRliQNcpXlsEmjVCgBan5GuWfN25RXCua0vjZmtOP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5435b4b2d94d9df9309e4d5ceb4bc021b52783', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'TIQjNUpyCsCWmTM49ZEEAiVQDWg07G_PjT8zXCX4wSE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iuwpon', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cv2020br', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/iuwpon/find_code_implementations_for_mlai_research/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/iuwpon/find_code_implementations_for_mlai_research/', 'subreddit_subscribers': 6676, 'created_utc': 1600392324.0, 'num_crossposts': 20, 'media': None, 'is_video': False}]",t3_iuwpon,
806,,tensorflow,"Hi!

I'm 14 year old noob, so please bear with me here. I recently upgraded to an RTX 2080S from an AMD GPU, so I want to use Tensorflow now. I installed CUDA 11 and CUDNN 8, but I'm not being able to use my GPU with tensorflow - I've attached a screenshot of the error. I'm on Ubuntu 18.04. Any help is appreciated! I'm willing to provide more info if needed.

EDIT: Apologies for the title - I realize it might be a bit misleading.

UPDATE: It works! I had to downgrade and use CUDA 10.1 and CUDNN 7.6.5 - I guess Tensorflow support isn't great with 11 and 8. Here is the article that saved me: [https://medium.com/@stephengregory\_69986/installing-cuda-10-1-on-ubuntu-20-04-e562a5e724a0](https://medium.com/@stephengregory_69986/installing-cuda-10-1-on-ubuntu-20-04-e562a5e724a0)

And here is the comment that also saved me: [https://medium.com/@mattphillipsphd/hey-this-was-fantastic-fd7c98944b6f](https://medium.com/@mattphillipsphd/hey-this-was-fantastic-fd7c98944b6f)

Yay!

https://preview.redd.it/5nijmsrcxsn51.png?width=737&amp;format=png&amp;auto=webp&amp;s=455f942b1ae3d831b5ee7094071d858662fdb22b",t2_kau8d0d,False,,0,False,Tensorflow Not Seeing GPU (CUDA 11 and CUDNN 8),[],r/tensorflow,False,6,,0,87.0,,False,t3_iuvxyx,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},Question,False,3,,False,https://b.thumbs.redditmedia.com/SX-HV5duCpLet84Fw8ntR02RL44V8Ze5u75ehX596Sw.jpg,1600403903.0,,[],{},,True,,1600418080.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m 14 year old noob, so please bear with me here. I recently upgraded to an RTX 2080S from an AMD GPU, so I want to use Tensorflow now. I installed CUDA 11 and CUDNN 8, but I&amp;#39;m not being able to use my GPU with tensorflow - I&amp;#39;ve attached a screenshot of the error. I&amp;#39;m on Ubuntu 18.04. Any help is appreciated! I&amp;#39;m willing to provide more info if needed.&lt;/p&gt;

&lt;p&gt;EDIT: Apologies for the title - I realize it might be a bit misleading.&lt;/p&gt;

&lt;p&gt;UPDATE: It works! I had to downgrade and use CUDA 10.1 and CUDNN 7.6.5 - I guess Tensorflow support isn&amp;#39;t great with 11 and 8. Here is the article that saved me: &lt;a href=""https://medium.com/@stephengregory_69986/installing-cuda-10-1-on-ubuntu-20-04-e562a5e724a0""&gt;https://medium.com/@stephengregory_69986/installing-cuda-10-1-on-ubuntu-20-04-e562a5e724a0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And here is the comment that also saved me: &lt;a href=""https://medium.com/@mattphillipsphd/hey-this-was-fantastic-fd7c98944b6f""&gt;https://medium.com/@mattphillipsphd/hey-this-was-fantastic-fd7c98944b6f&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yay!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/5nijmsrcxsn51.png?width=737&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=455f942b1ae3d831b5ee7094071d858662fdb22b""&gt;https://preview.redd.it/5nijmsrcxsn51.png?width=737&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=455f942b1ae3d831b5ee7094071d858662fdb22b&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iuvxyx,True,,zarif101,,19,True,all_ads,False,[],False,,/r/tensorflow/comments/iuvxyx/tensorflow_not_seeing_gpu_cuda_11_and_cudnn_8/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iuvxyx/tensorflow_not_seeing_gpu_cuda_11_and_cudnn_8/,22217,1600389280.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/J8G7m6bL9omYa8KmFNEum2787rcfrbH5YkJbvH3EezI.jpg?auto=webp&amp;s=7b7949ee424875ff45d32aab6e6b84338aa1a903', 'width': 728, 'height': 455}, 'resolutions': [{'url': 'https://external-preview.redd.it/J8G7m6bL9omYa8KmFNEum2787rcfrbH5YkJbvH3EezI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b29aa11c78c1f0de0a69d1c4629bb3479ad54e7', 'width': 108, 'height': 67}, {'url': 'https://external-preview.redd.it/J8G7m6bL9omYa8KmFNEum2787rcfrbH5YkJbvH3EezI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=53dc5dccc0767e945c2e3b492957652114cbad91', 'width': 216, 'height': 135}, {'url': 'https://external-preview.redd.it/J8G7m6bL9omYa8KmFNEum2787rcfrbH5YkJbvH3EezI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef9e3a378af8829fccfd44ca0d3a4d3d3eb34bd9', 'width': 320, 'height': 200}, {'url': 'https://external-preview.redd.it/J8G7m6bL9omYa8KmFNEum2787rcfrbH5YkJbvH3EezI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=40fdd45f96a9731bd98828f75f59ebd636da170e', 'width': 640, 'height': 400}], 'variants': {}, 'id': 'Znl-frPS_QCILCDt0Cojx6K7BP34qhgVtoCcen5XPy0'}], 'enabled': False}",,"{'5nijmsrcxsn51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 24, 'x': 108, 'u': 'https://preview.redd.it/5nijmsrcxsn51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f929c987506cff19e1c67c2d492c5cd81fc6b52c'}, {'y': 49, 'x': 216, 'u': 'https://preview.redd.it/5nijmsrcxsn51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3cfde961cda42646795d3ef349b029c3398da2dc'}, {'y': 73, 'x': 320, 'u': 'https://preview.redd.it/5nijmsrcxsn51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b35a4a04b291ea16be66849e454a47040c3507d'}, {'y': 147, 'x': 640, 'u': 'https://preview.redd.it/5nijmsrcxsn51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=416f074cb7267fff559f23576976f430d6605a5b'}], 's': {'y': 170, 'x': 737, 'u': 'https://preview.redd.it/5nijmsrcxsn51.png?width=737&amp;format=png&amp;auto=webp&amp;s=455f942b1ae3d831b5ee7094071d858662fdb22b'}, 'id': '5nijmsrcxsn51'}}",,,,
807,,tensorflow,"In my new video, I explain how to extract Mel spectrograms from an audio file with Python and Librosa. I also visualise Mel filter banks.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=TdnVE5m3o\_0&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=18](https://www.youtube.com/watch?v=TdnVE5m3o_0&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=18)",t2_12ahau,False,,0,False,I published a tutorial where I extract Mel spectrograms from audio data with Python,[],r/tensorflow,False,6,,0,,,False,t3_iulacf,False,dark,0.84,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,self,False,,[],{},,True,,1600384040.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new video, I explain how to extract Mel spectrograms from an audio file with Python and Librosa. I also visualise Mel filter banks.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=TdnVE5m3o_0&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=18""&gt;https://www.youtube.com/watch?v=TdnVE5m3o_0&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=18&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iulacf,True,,diabulusInMusica,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/iulacf/i_published_a_tutorial_where_i_extract_mel/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iulacf/i_published_a_tutorial_where_i_extract_mel/,22217,1600355240.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/bEMFL0p8702x6-fA3N9k61RrhXHuTWZKbkt2ATdhuP4.jpg?auto=webp&amp;s=9ad53b4208dae9b36365fad29323b0d9277927ee', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/bEMFL0p8702x6-fA3N9k61RrhXHuTWZKbkt2ATdhuP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7a64cf3ee9f39a9d49f3ca688bca2bd03e4d712', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/bEMFL0p8702x6-fA3N9k61RrhXHuTWZKbkt2ATdhuP4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38d7b5105d16caa89c72be269fa83a5c194102f9', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/bEMFL0p8702x6-fA3N9k61RrhXHuTWZKbkt2ATdhuP4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd8968d7a8762e22c0a1cd35feff6b1688e4c442', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'hmKBZL3KmcJA49cqyQgTQBlDE0_S5HLUKPQhBfxXOHE'}], 'enabled': False}",,,,,,
808,,tensorflow,"I wonder if I can make the generator more complex to allow for more detail and variation, but use a less complex discriminator. Every trick to stabilize GANs seems to be to cripple the discriminator in some way, and I wonder if this is an appropriate way to address that?

I have been using very similar architecture for these so far, as in:

Current generator:

    def make_generator_model():
        model = tf.keras.Sequential()     model.add(layers.Dense(32*32*128, use_bias=False, input_shape=(100,)))     model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Reshape((32, 32, 128)))
        model.add(layers.Conv2DTranspose(64, (4,4), strides=(1, 1), padding='same', use_bias=False))     
        model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Conv2DTranspose(32, (5,5), strides=(2, 2), padding='same', use_bias=False))
        model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Conv2DTranspose(3, (5,5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    return model

Current discriminator

    def make_discriminator_model():
        model = tf.keras.Sequential()     model.add(layers.Conv2D(32, (4,4), strides=(2, 2), padding='same',                                      input_shape=[128,128,3]))         model.add(layers.LeakyReLU())    
        model.add(layers.Dropout(0.3))
        
        model.add(layers.Conv2D(64, (5,5), strides=(2, 2), padding='same'))     model.add(layers.LeakyReLU())     
        model.add(layers.Dropout(0.3))
        
        model.add(layers.Conv2D(128, (5,5), strides=(1, 1), padding='same'))     model.add(layers.LeakyReLU())     
        model.add(layers.Dropout(0.3))
        
        model.add(layers.Flatten())     
        model.add(layers.Dense(1))
    return model

Idea for more complex generator

    def make_generator_model():
        model = tf.keras.Sequential()     model.add(layers.Dense(8*8*512, use_bias=False, input_shape=(100,)))     model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Reshape((8, 8, 512)))
        model.add(layers.Conv2DTranspose(256, (4,4), strides=(2, 2), padding='same', use_bias=False))     
        model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Conv2DTranspose(128, (5,5), strides=(2, 2), padding='same', use_bias=False))     
        model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Conv2DTranspose(64, (5,5), strides=(2, 2), padding='same', use_bias=False))     
        model.add(layers.BatchNormalization())     
        model.add(layers.LeakyReLU())
        model.add(layers.Conv2DTranspose(3, (5,5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    return model

&amp;#x200B;",t2_5jsg7vd6,False,,0,False,"for GAN training, is it important that the Generator and Discriminator have the same/similar architecture?",[],r/tensorflow,False,6,,0,,,False,t3_iupf66,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1600368200.0,,[],{},,True,,1600396351.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wonder if I can make the generator more complex to allow for more detail and variation, but use a less complex discriminator. Every trick to stabilize GANs seems to be to cripple the discriminator in some way, and I wonder if this is an appropriate way to address that?&lt;/p&gt;

&lt;p&gt;I have been using very similar architecture for these so far, as in:&lt;/p&gt;

&lt;p&gt;Current generator:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def make_generator_model():
    model = tf.keras.Sequential()     model.add(layers.Dense(32*32*128, use_bias=False, input_shape=(100,)))     model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Reshape((32, 32, 128)))
    model.add(layers.Conv2DTranspose(64, (4,4), strides=(1, 1), padding=&amp;#39;same&amp;#39;, use_bias=False))     
    model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Conv2DTranspose(32, (5,5), strides=(2, 2), padding=&amp;#39;same&amp;#39;, use_bias=False))
    model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Conv2DTranspose(3, (5,5), strides=(2, 2), padding=&amp;#39;same&amp;#39;, use_bias=False, activation=&amp;#39;tanh&amp;#39;))
return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Current discriminator&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def make_discriminator_model():
    model = tf.keras.Sequential()     model.add(layers.Conv2D(32, (4,4), strides=(2, 2), padding=&amp;#39;same&amp;#39;,                                      input_shape=[128,128,3]))         model.add(layers.LeakyReLU())    
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Conv2D(64, (5,5), strides=(2, 2), padding=&amp;#39;same&amp;#39;))     model.add(layers.LeakyReLU())     
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Conv2D(128, (5,5), strides=(1, 1), padding=&amp;#39;same&amp;#39;))     model.add(layers.LeakyReLU())     
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Flatten())     
    model.add(layers.Dense(1))
return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Idea for more complex generator&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def make_generator_model():
    model = tf.keras.Sequential()     model.add(layers.Dense(8*8*512, use_bias=False, input_shape=(100,)))     model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Reshape((8, 8, 512)))
    model.add(layers.Conv2DTranspose(256, (4,4), strides=(2, 2), padding=&amp;#39;same&amp;#39;, use_bias=False))     
    model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Conv2DTranspose(128, (5,5), strides=(2, 2), padding=&amp;#39;same&amp;#39;, use_bias=False))     
    model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Conv2DTranspose(64, (5,5), strides=(2, 2), padding=&amp;#39;same&amp;#39;, use_bias=False))     
    model.add(layers.BatchNormalization())     
    model.add(layers.LeakyReLU())
    model.add(layers.Conv2DTranspose(3, (5,5), strides=(2, 2), padding=&amp;#39;same&amp;#39;, use_bias=False, activation=&amp;#39;tanh&amp;#39;))
return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iupf66,True,,diditforthevideocard,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/iupf66/for_gan_training_is_it_important_that_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iupf66/for_gan_training_is_it_important_that_the/,22217,1600367551.0,0,,False,,,,,,,,,
809,,tensorflow,"TensorFlow [open-sources an end-to-end solution](https://www.tensorflow.org/lite/models/recommendation/overview) for on-device recommendation tasks to provide personalized and high-quality recommendations with minimal delay while preserving users’ privacy. Developers build on-device models using TFlite’s solution to achieve the above. When it comes to real-world applications, such as music, videos, merchandise, apps, news, etc., high-quality personalized recommendations are needed.

Summary: https://www.marktechpost.com/2020/09/16/tensorflow-open-sources-an-end-to-end-solution-for-tflite-on-device-recommendation/

Github: https://github.com/tensorflow/examples/tree/master/lite/examples/recommendation/ml",t2_2wsvqwhg,False,,0,False,TensorFlow Open Sources An End-To-End Solution For TFLite On-Device Recommendation,[],r/tensorflow,False,6,,0,,,False,t3_iua2ap,False,dark,1.0,,public,12,0,{},,,False,[],,False,False,,{},Discussion,False,12,,False,self,False,,[],{},,True,,1600337047.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TensorFlow &lt;a href=""https://www.tensorflow.org/lite/models/recommendation/overview""&gt;open-sources an end-to-end solution&lt;/a&gt; for on-device recommendation tasks to provide personalized and high-quality recommendations with minimal delay while preserving users’ privacy. Developers build on-device models using TFlite’s solution to achieve the above. When it comes to real-world applications, such as music, videos, merchandise, apps, news, etc., high-quality personalized recommendations are needed.&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2020/09/16/tensorflow-open-sources-an-end-to-end-solution-for-tflite-on-device-recommendation/""&gt;https://www.marktechpost.com/2020/09/16/tensorflow-open-sources-an-end-to-end-solution-for-tflite-on-device-recommendation/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/tensorflow/examples/tree/master/lite/examples/recommendation/ml""&gt;https://github.com/tensorflow/examples/tree/master/lite/examples/recommendation/ml&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iua2ap,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iua2ap/tensorflow_open_sources_an_endtoend_solution_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iua2ap/tensorflow_open_sources_an_endtoend_solution_for/,22217,1600308247.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?auto=webp&amp;s=2572596fe2183c02bb87888fad10698003d1766c', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f38f154b31bbc61f967552a73eae2d908d46ae03', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=800ed1265a325e2ebbd4bac73e5a0a9f87375fc4', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef1d21237970b3962ea11427b5fb4a133b573f95', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd75fe122929cebeb28f32cabc416c0d34746e81', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e61b7e8ded8e04296fb02cef535a2339569b52b', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/r-mKvCKB_c_IdjcLpB5HStqHERMqcUaOinTgUChhxZo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fce2149c6d3aad062f85426dd46ad50c64a82b2e', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'X-wKcTKmnQRaY7Q0VF7Fv5E2VV8HI6yDgaH8MhXzwMA'}], 'enabled': False}",,,,,,
810,,tensorflow,"Ambianic.ai has posted a $500 TensorFlow bounty at:

[https://www.bountysource.com/issues/92825863-people-fall-detection](https://www.bountysource.com/issues/92825863-people-fall-detection)

More bounties will be posted in the future.

Thanks",t2_84etego5,False,,0,False,"TensorFlow Bounty, $500",[],r/tensorflow,False,6,,0,,,False,t3_iuc7gc,False,dark,0.67,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1600345132.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Ambianic.ai has posted a $500 TensorFlow bounty at:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.bountysource.com/issues/92825863-people-fall-detection""&gt;https://www.bountysource.com/issues/92825863-people-fall-detection&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More bounties will be posted in the future.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iuc7gc,True,,Ambianic,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iuc7gc/tensorflow_bounty_500/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iuc7gc/tensorflow_bounty_500/,22217,1600316332.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/wGzJCwNQFOtPyVf9CVLQ4EtWiPiQOXoorzjaAzJQmBc.jpg?auto=webp&amp;s=5d41c83ca7c9d231624471e32c196c06ed982e01', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/wGzJCwNQFOtPyVf9CVLQ4EtWiPiQOXoorzjaAzJQmBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5bda27c135aaeea53c621b46378ad753c2319f2', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/wGzJCwNQFOtPyVf9CVLQ4EtWiPiQOXoorzjaAzJQmBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2974fdcba5f4b9c555e2b62aae29f7142bc1db0d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/wGzJCwNQFOtPyVf9CVLQ4EtWiPiQOXoorzjaAzJQmBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f5d4b037388729bb594bf1f90d13bd6eaa0e90f9', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'o55WCri_RsvCxedhWRBj-cwy2FmNkZTA7Jy1bgZ48_c'}], 'enabled': False}",,,,,,
811,,tensorflow,,t2_4k0jtvab,False,,0,False,Crop and Save YOLOv4 Object Detections with TensorFlow and Python,[],r/tensorflow,False,6,,0,105.0,,False,t3_ituuek,False,dark,0.89,,public,31,1,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P7r0hIP2GQ4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Crop and Save YOLOv4 Object Detections | Custom YOLOv4 Functions with TensorFlow', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P7r0hIP2GQ4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/P7r0hIP2GQ4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCrydcKaojc44XnuXrfhlV8Q'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P7r0hIP2GQ4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ituuek', 'height': 338}",,False,31,,False,https://b.thumbs.redditmedia.com/_BruKYPmKTOiOF0LwfjrqLK2rY7-hEbAPwJQnsDlo9w.jpg,False,,[],{},,False,,1600289538.0,text,6,,,text,youtube.com,False,,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ituuek,True,,The-AI-Guy,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ituuek/crop_and_save_yolov4_object_detections_with/,all_ads,False,https://www.youtube.com/watch?v=P7r0hIP2GQ4,22217,1600260738.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Crop and Save YOLOv4 Object Detections | Custom YOLOv4 Functions with TensorFlow', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P7r0hIP2GQ4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/P7r0hIP2GQ4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCrydcKaojc44XnuXrfhlV8Q'}}",False,rich:video,https://www.youtube.com/watch?v=P7r0hIP2GQ4,"{'images': [{'source': {'url': 'https://external-preview.redd.it/qbehKu_BKI_CmmlbvX3sMOj9saGnYcnFQFtnhTylzUw.jpg?auto=webp&amp;s=bee91ca505ac76c43fe91cc38576f21594f34632', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/qbehKu_BKI_CmmlbvX3sMOj9saGnYcnFQFtnhTylzUw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e3de4e570484eca57a78b670614d718954dfa1f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/qbehKu_BKI_CmmlbvX3sMOj9saGnYcnFQFtnhTylzUw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1ae7ab75d74d6b91f4edf134d6e9dd4626aa3c3', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/qbehKu_BKI_CmmlbvX3sMOj9saGnYcnFQFtnhTylzUw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f3bdacb4361d653c66027e46f0417b862b5b90d', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'jAv6I64if0xZbnpl_avIeg9jod8PBig6UKjinG3JtbE'}], 'enabled': False}",,,,,,
812,,tensorflow,"I want to use mixed precision in Ubuntu 16 which I read requires tensorflow 2.0+

I had tensorflow 1.4. I then attempted to install the latest version with `pip3 installl tensorflow` and `pip3 install tensorflow-gpu`. 

Even though `pip3 show tensorflow` and `pip3 list | grep tensorflow` both show version 2.3, when I go to Python in the terminal then try

    import tensorflow as tf
    print(tf.__version__)

it shows 1.4.0

Thus when I try `from tensorflow.keras.mixed_precision import experimental as mixed_precision`, it says `importerror: no module named tensorflow.keras`

anyone can help?",t2_tpult,False,,0,False,Why tensorflow versions installed in Ubuntu don't match?,[],r/tensorflow,False,6,,0,,,False,t3_iu9fc7,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1600334694.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to use mixed precision in Ubuntu 16 which I read requires tensorflow 2.0+&lt;/p&gt;

&lt;p&gt;I had tensorflow 1.4. I then attempted to install the latest version with &lt;code&gt;pip3 installl tensorflow&lt;/code&gt; and &lt;code&gt;pip3 install tensorflow-gpu&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;Even though &lt;code&gt;pip3 show tensorflow&lt;/code&gt; and &lt;code&gt;pip3 list | grep tensorflow&lt;/code&gt; both show version 2.3, when I go to Python in the terminal then try&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf
print(tf.__version__)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it shows 1.4.0&lt;/p&gt;

&lt;p&gt;Thus when I try &lt;code&gt;from tensorflow.keras.mixed_precision import experimental as mixed_precision&lt;/code&gt;, it says &lt;code&gt;importerror: no module named tensorflow.keras&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;anyone can help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iu9fc7,True,,74throwaway,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/iu9fc7/why_tensorflow_versions_installed_in_ubuntu_dont/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iu9fc7/why_tensorflow_versions_installed_in_ubuntu_dont/,22217,1600305894.0,4,,False,,,,,,,,,
813,,tensorflow,"Hello,  
I'm planning to take Tensorflow Certification Exam by end of this month. 

I have a question regarding the version of TensorFlow, As per the Candidate Handbook, it says "" TensorFlow 2.x "" but I heard when we install the exam plugin it will auto-install Tensorflow 2.0 which is a pretty old version.

Does anyone update the version to 2.3 and attempted the exam?  Faced any issues with the v2.3?

The reason I'm asking this Is to configure my system with cuDNN and Cuda libs.

https://preview.redd.it/itkwyp9qdhn51.png?width=1349&amp;format=png&amp;auto=webp&amp;s=f3ddbb1fe71852e2bb06c56de851fa5123a68043",t2_58rxwd2e,False,,0,False,Tensorflow software version for certification exam,[],r/tensorflow,False,6,,0,31.0,,False,t3_itsfkx,False,dark,1.0,,public,11,0,{},140.0,,False,[],,False,False,,{},Question,False,11,,False,https://a.thumbs.redditmedia.com/NhhePh-1JKAuLqkimaq7cIPMz46MJl4B1B-FYArRYB4.jpg,False,,[],{},,True,,1600278280.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;br/&gt;
I&amp;#39;m planning to take Tensorflow Certification Exam by end of this month. &lt;/p&gt;

&lt;p&gt;I have a question regarding the version of TensorFlow, As per the Candidate Handbook, it says &amp;quot; TensorFlow 2.x &amp;quot; but I heard when we install the exam plugin it will auto-install Tensorflow 2.0 which is a pretty old version.&lt;/p&gt;

&lt;p&gt;Does anyone update the version to 2.3 and attempted the exam?  Faced any issues with the v2.3?&lt;/p&gt;

&lt;p&gt;The reason I&amp;#39;m asking this Is to configure my system with cuDNN and Cuda libs.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/itkwyp9qdhn51.png?width=1349&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f3ddbb1fe71852e2bb06c56de851fa5123a68043""&gt;https://preview.redd.it/itkwyp9qdhn51.png?width=1349&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f3ddbb1fe71852e2bb06c56de851fa5123a68043&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,itsfkx,True,,gilf0yl,,13,True,all_ads,False,[],False,,/r/tensorflow/comments/itsfkx/tensorflow_software_version_for_certification_exam/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/itsfkx/tensorflow_software_version_for_certification_exam/,22217,1600249480.0,0,,False,,,,,"{'itkwyp9qdhn51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 24, 'x': 108, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c850a6caca37af9e5b894b81be81c21f4cb64f7e'}, {'y': 49, 'x': 216, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=769dd63825a54ddf84526a1ddba674cedf6e0ecc'}, {'y': 72, 'x': 320, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f30d3e853c9c8eb3fb1f1fd7917d22486d508a5c'}, {'y': 145, 'x': 640, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e6ed58535b70c189ece94317643bc0fd190da42'}, {'y': 218, 'x': 960, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0c521f73aee14c3d36bfdb12bc812a2fe1ca3987'}, {'y': 245, 'x': 1080, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=abb28ad2b8298cefcf5d46de631ea36709d6ccf6'}], 's': {'y': 307, 'x': 1349, 'u': 'https://preview.redd.it/itkwyp9qdhn51.png?width=1349&amp;format=png&amp;auto=webp&amp;s=f3ddbb1fe71852e2bb06c56de851fa5123a68043'}, 'id': 'itkwyp9qdhn51'}}",,,,
814,,tensorflow,Does anybody know a quick and efficient way to download a teachable machine model to a raspberry pi that can work WITHOUT internet connection? I’ve looked at plenty of YouTube’s but haven’t found one that works the way I want it to.,t2_25n6izp7,False,,0,False,Teachable machine,[],r/tensorflow,False,6,,0,,,False,t3_iu5x6h,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1600322711.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anybody know a quick and efficient way to download a teachable machine model to a raspberry pi that can work WITHOUT internet connection? I’ve looked at plenty of YouTube’s but haven’t found one that works the way I want it to.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iu5x6h,True,,lillcouch,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/iu5x6h/teachable_machine/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iu5x6h/teachable_machine/,22217,1600293911.0,0,,False,,,,,,,,,
815,,tensorflow,,t2_44mbtmjy,False,,0,False,State of the art in Crop/Weed Segmentation!,[],r/tensorflow,False,6,,0,140.0,,False,t3_iu1iiv,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/PIGppBateaEwkyIUuvA6EwSeua_oJHuHKOce-9aZp_U.jpg,False,,[],{},,False,,1600310032.0,text,6,,,text,self.LatestInML,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iu1iiv,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iu1iiv/state_of_the_art_in_cropweed_segmentation/,all_ads,False,/r/LatestInML/comments/iu1i18/state_of_the_art_in_cropweed_segmentation/,22217,1600281232.0,0,,False,link,/r/LatestInML/comments/iu1i18/state_of_the_art_in_cropweed_segmentation/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?auto=webp&amp;s=19d0de9fe1ce26c99a7400e12650559dd988d65f', 'width': 672, 'height': 884}, 'resolutions': [{'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9d01b6bba9e1406e8df9b2f339cc6d6f9504555', 'width': 108, 'height': 142}, {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3244402a20b43dd6134a1d6ef7cdfdeb7254926', 'width': 216, 'height': 284}, {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b91e2c1755e175f8083e42c623a4a6298c7c4534', 'width': 320, 'height': 420}, {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c279471085aae1bcf95eef06de7bd87eb6ee9c3d', 'width': 640, 'height': 841}], 'variants': {}, 'id': 'grsfcLgqGBVpPx6QX7BoaXBavST0zZIUEYCs-B6Pank'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/expert/API requests: [click here](https://www.catalyzex.com/paper/arxiv:2009.05750)\n\nhttps://preview.redd.it/c52zonkoxjn51.png?width=782&amp;format=png&amp;auto=webp&amp;s=6126a8d41e776292b2a70a47de4a278b76a940c0', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in Crop/Weed Segmentation!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'c52zonkoxjn51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 144, 'x': 108, 'u': 'https://preview.redd.it/c52zonkoxjn51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=24a9e9ba37d54591a8e6a5565265d4a323e7a1ab'}, {'y': 288, 'x': 216, 'u': 'https://preview.redd.it/c52zonkoxjn51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20cb9bb539e06d210fda7a06ec663b48e444ba25'}, {'y': 427, 'x': 320, 'u': 'https://preview.redd.it/c52zonkoxjn51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=acaafc64fefc4f91ba4a35851ce78adc4ec4102f'}, {'y': 854, 'x': 640, 'u': 'https://preview.redd.it/c52zonkoxjn51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=07ff82f5159c1e49884b8592a7ce9061d06a7e32'}], 's': {'y': 1044, 'x': 782, 'u': 'https://preview.redd.it/c52zonkoxjn51.png?width=782&amp;format=png&amp;auto=webp&amp;s=6126a8d41e776292b2a70a47de4a278b76a940c0'}, 'id': 'c52zonkoxjn51'}}, 'name': 't3_iu1i18', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 11, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 11, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/PIGppBateaEwkyIUuvA6EwSeua_oJHuHKOce-9aZp_U.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1600309993.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/expert/API requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2009.05750""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/c52zonkoxjn51.png?width=782&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6126a8d41e776292b2a70a47de4a278b76a940c0""&gt;https://preview.redd.it/c52zonkoxjn51.png?width=782&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6126a8d41e776292b2a70a47de4a278b76a940c0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?auto=webp&amp;s=19d0de9fe1ce26c99a7400e12650559dd988d65f', 'width': 672, 'height': 884}, 'resolutions': [{'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9d01b6bba9e1406e8df9b2f339cc6d6f9504555', 'width': 108, 'height': 142}, {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3244402a20b43dd6134a1d6ef7cdfdeb7254926', 'width': 216, 'height': 284}, {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b91e2c1755e175f8083e42c623a4a6298c7c4534', 'width': 320, 'height': 420}, {'url': 'https://external-preview.redd.it/LTdzTQJgUi1kZ0DmyY-TCOSrWoVOiB9TEZwBn_4Ghs0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c279471085aae1bcf95eef06de7bd87eb6ee9c3d', 'width': 640, 'height': 841}], 'variants': {}, 'id': 'grsfcLgqGBVpPx6QX7BoaXBavST0zZIUEYCs-B6Pank'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iu1i18', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/iu1i18/state_of_the_art_in_cropweed_segmentation/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/iu1i18/state_of_the_art_in_cropweed_segmentation/', 'subreddit_subscribers': 6676, 'created_utc': 1600281193.0, 'num_crossposts': 12, 'media': None, 'is_video': False}]",t3_iu1i18,
816,,tensorflow,"ML colleagues, according to ZipRecruiter Machine Learning Engineers earn $130,530 per year. Learn advanced machine learning techniques and algorithms -- including how to package and deploy your models to a production environment. Gain practical experience using Amazon SageMaker to deploy trained models to a web application, evaluate the performance of your models, A/B test models and update the models as you gather more data..Suggested prerequisites are intermediate knowledge of Python and Machine Learning algorithms. The four skill-based training modules (each with a unique training project) include: 1) Software  Engineering Fundamentals (Project: Build a Python Package), 2) Machine  Learning in Production with Amazon SageMaker (Project: Deploy a Sentiment Analysis Model), 3) Machine Learning Case Studies (Project: Plagiarism Detector), and 4) Machine Learning Capstone (Project: Select a machine learning challenge and propose a possible solution). 

Enroll today at: https://fxo.co/9glo 

Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)",t2_36ixj,False,,0,False,Machine Learning Engineer Training ($130k+ average salary),[],r/tensorflow,False,6,,0,,,False,t3_iu6jos,False,dark,0.27,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,self,False,,[],{},,True,,1600324714.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;ML colleagues, according to ZipRecruiter Machine Learning Engineers earn $130,530 per year. Learn advanced machine learning techniques and algorithms -- including how to package and deploy your models to a production environment. Gain practical experience using Amazon SageMaker to deploy trained models to a web application, evaluate the performance of your models, A/B test models and update the models as you gather more data..Suggested prerequisites are intermediate knowledge of Python and Machine Learning algorithms. The four skill-based training modules (each with a unique training project) include: 1) Software  Engineering Fundamentals (Project: Build a Python Package), 2) Machine  Learning in Production with Amazon SageMaker (Project: Deploy a Sentiment Analysis Model), 3) Machine Learning Case Studies (Project: Plagiarism Detector), and 4) Machine Learning Capstone (Project: Select a machine learning challenge and propose a possible solution). &lt;/p&gt;

&lt;p&gt;Enroll today at: &lt;a href=""https://fxo.co/9glo""&gt;https://fxo.co/9glo&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iu6jos,True,,lwilson747,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iu6jos/machine_learning_engineer_training_130k_average/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iu6jos/machine_learning_engineer_training_130k_average/,22217,1600295914.0,0,,False,,,,,,,,,
817,,tensorflow,"Greetings!

Can someone help me understand the intuition behind not using BIAS in DCGAN(s) such as here

[https://www.tensorflow.org/tutorials/generative/dcgan](https://www.tensorflow.org/tutorials/generative/dcgan)

[https://pytorch.org/tutorials/beginner/dcgan\_faces\_tutorial.html](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)

?",t2_4ecq42y4,False,,0,False,Role of BIAS in DCGANS: why is it set to FALSE in some cases,[],r/tensorflow,False,6,,0,,,False,t3_itlfzx,False,dark,0.91,,public,8,0,{},,,False,[],,False,False,,{},,False,8,,False,self,False,,[],{},,True,,1600246154.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Greetings!&lt;/p&gt;

&lt;p&gt;Can someone help me understand the intuition behind not using BIAS in DCGAN(s) such as here&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.tensorflow.org/tutorials/generative/dcgan""&gt;https://www.tensorflow.org/tutorials/generative/dcgan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html""&gt;https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,itlfzx,True,,ncuxomun,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/itlfzx/role_of_bias_in_dcgans_why_is_it_set_to_false_in/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/itlfzx/role_of_bias_in_dcgans_why_is_it_set_to_false_in/,22217,1600217354.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
818,,tensorflow,,t2_11vb76,False,,0,False,Used TensorFlow to Decrease Ambiguity in Texting,[],r/tensorflow,False,6,,0,78.0,,False,t3_itogpa,False,dark,1.0,,public,5,0,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Have you ever got a text from someone and wondered what they meant by it? &lt;br&gt;&lt;br&gt;Are you fed up with ambiguity in texts and people throwing around random emoji 😂🥰🧐and punctuation💯⁉️🆘? &lt;br&gt;&lt;br&gt;Thanks to ML, we can now track your face while texting and know what emotion you&amp;#39;re showing! &lt;a href=""https://t.co/Kd7W5v7Tpt""&gt;pic.twitter.com/Kd7W5v7Tpt&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bram Adams (@_bramses) &lt;a href=""https://twitter.com/_bramses/status/1306046333325893633?ref_src=twsrc%5Etfw""&gt;September 16, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'height': 492}",140.0,,False,[],"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/_bramses/status/1306046333325893633', 'author_name': 'Bram Adams', 'height': 492, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Have you ever got a text from someone and wondered what they meant by it? &lt;br&gt;&lt;br&gt;Are you fed up with ambiguity in texts and people throwing around random emoji 😂🥰🧐and punctuation💯⁉️🆘? &lt;br&gt;&lt;br&gt;Thanks to ML, we can now track your face while texting and know what emotion you&amp;#39;re showing! &lt;a href=""https://t.co/Kd7W5v7Tpt""&gt;pic.twitter.com/Kd7W5v7Tpt&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bram Adams (@_bramses) &lt;a href=""https://twitter.com/_bramses/status/1306046333325893633?ref_src=twsrc%5Etfw""&gt;September 16, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/_bramses', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,False,,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Have you ever got a text from someone and wondered what they meant by it? &lt;br&gt;&lt;br&gt;Are you fed up with ambiguity in texts and people throwing around random emoji 😂🥰🧐and punctuation💯⁉️🆘? &lt;br&gt;&lt;br&gt;Thanks to ML, we can now track your face while texting and know what emotion you&amp;#39;re showing! &lt;a href=""https://t.co/Kd7W5v7Tpt""&gt;pic.twitter.com/Kd7W5v7Tpt&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bram Adams (@_bramses) &lt;a href=""https://twitter.com/_bramses/status/1306046333325893633?ref_src=twsrc%5Etfw""&gt;September 16, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/itogpa', 'height': 492}",Discussion,False,5,,False,https://b.thumbs.redditmedia.com/m5VY7mheZAXiMcaGeIDeiVYxS-boX8iKSCmrKyiFXnQ.jpg,False,,[],{},,False,,1600257922.0,text,6,,,text,twitter.com,False,,,,,,False,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,itogpa,True,,DrKickflip,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/itogpa/used_tensorflow_to_decrease_ambiguity_in_texting/,all_ads,False,https://twitter.com/_bramses/status/1306046333325893633?s=20,22217,1600229122.0,0,"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/_bramses/status/1306046333325893633', 'author_name': 'Bram Adams', 'height': 492, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Have you ever got a text from someone and wondered what they meant by it? &lt;br&gt;&lt;br&gt;Are you fed up with ambiguity in texts and people throwing around random emoji 😂🥰🧐and punctuation💯⁉️🆘? &lt;br&gt;&lt;br&gt;Thanks to ML, we can now track your face while texting and know what emotion you&amp;#39;re showing! &lt;a href=""https://t.co/Kd7W5v7Tpt""&gt;pic.twitter.com/Kd7W5v7Tpt&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bram Adams (@_bramses) &lt;a href=""https://twitter.com/_bramses/status/1306046333325893633?ref_src=twsrc%5Etfw""&gt;September 16, 2020&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/_bramses', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,link,https://twitter.com/_bramses/status/1306046333325893633?s=20,"{'images': [{'source': {'url': 'https://external-preview.redd.it/IErGwuHU4vyyJvWmowVv5nKdbjDqTyoRIkhwZqmLAwU.jpg?auto=webp&amp;s=8677e0b7f3bb4d1e149abbb356c7e659345847f2', 'width': 140, 'height': 78}, 'resolutions': [{'url': 'https://external-preview.redd.it/IErGwuHU4vyyJvWmowVv5nKdbjDqTyoRIkhwZqmLAwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=debef59558aa7e857ae52ec0db645053c472cf69', 'width': 108, 'height': 60}], 'variants': {}, 'id': '_BKWVHTdetVjSorzBRKGiKf6T5DYhrj69Cra_xurU6A'}], 'enabled': False}",,,,,,
819,,tensorflow,,t2_1cjispl7,False,,0,False,Why might my val. accuracy and loss be so variable? ~500 val. samples,[],r/tensorflow,False,6,,0,140.0,,False,t3_itiske,False,dark,0.78,,public,5,0,{},140.0,,False,[],,True,False,,{},,False,5,,False,https://a.thumbs.redditmedia.com/1dhTPsF_669jI5p4SdIoaPD65q0SFTYtZp287HbUe00.jpg,False,,[],{},,False,,1600236360.0,text,6,,,text,i.redd.it,False,,,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,itiske,True,,GeorgeFree2018,,16,True,all_ads,False,[],False,,/r/tensorflow/comments/itiske/why_might_my_val_accuracy_and_loss_be_so_variable/,all_ads,False,https://i.redd.it/rjg6rh1zwdn51.png,22217,1600207560.0,0,,False,image,https://i.redd.it/rjg6rh1zwdn51.png,"{'images': [{'source': {'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?auto=webp&amp;s=28040c36a629ec84f774177d4dfae199d34d7832', 'width': 1237, 'height': 1264}, 'resolutions': [{'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b1daf88eb337331f5a3c802f0d8c5b963dd4042', 'width': 108, 'height': 110}, {'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8630d45726ee1d89efaf24b0af1565fb510d05d', 'width': 216, 'height': 220}, {'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e42a7fa49044dd1c7d5bb0bd4c3a38799137c553', 'width': 320, 'height': 326}, {'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b61b05af9552963853ac42e3385940051ac7ab3', 'width': 640, 'height': 653}, {'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=03058aa7856118f7427ba777b8a860635b62b1e8', 'width': 960, 'height': 980}, {'url': 'https://preview.redd.it/rjg6rh1zwdn51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=47ea1c88507d4f311706959f79a1b0d44dbd06cd', 'width': 1080, 'height': 1103}], 'variants': {}, 'id': 'Ey-ldZ-8mEbgoApE9JqZtJ1GFoi6qUY6TK8F3X_gqq0'}], 'enabled': True}",,,,,,
820,,tensorflow,"Hey , I am trying to do object detection with tensorflow 2 on Google Colab. I want suggestion for guide, resources or  tutorials that I can follow ! 

Thanks !",t2_71ff0dwd,False,,0,False,NEED ULTIMATE GUIDE/RESOURCES FOR TF 2.X OBJECT DETECTION ON COLAB.,[],r/tensorflow,False,6,,0,,,False,t3_it7i8l,False,dark,0.85,,public,13,0,{},,,False,[],,False,False,,{},Discussion,False,13,,False,self,False,,[],{},,True,,1600200677.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey , I am trying to do object detection with tensorflow 2 on Google Colab. I want suggestion for guide, resources or  tutorials that I can follow ! &lt;/p&gt;

&lt;p&gt;Thanks !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,it7i8l,True,,bunny1122334455,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/it7i8l/need_ultimate_guideresources_for_tf_2x_object/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/it7i8l/need_ultimate_guideresources_for_tf_2x_object/,22217,1600171877.0,0,,False,,,,,,,,,
821,,tensorflow,,t2_63ay634e,False,,0,False,Free browser extension! AI/ML Code Implementation Finder,[],r/tensorflow,False,6,,0,,,False,t3_itj92r,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,default,False,,[],{},,False,,1600237934.0,text,6,,,text,self.LatestInML,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,itj92r,True,,cv2020br,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/itj92r/free_browser_extension_aiml_code_implementation/,all_ads,False,/r/LatestInML/comments/hjokbt/mlai_code_implementation_finder_free_browser/,22217,1600209134.0,0,,False,link,/r/LatestInML/comments/hjokbt/mlai_code_implementation_finder_free_browser/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/wNOK4uFSjn0_VLV9GzzwcWxl8N-Cjs1NgKKI98QDVv8.jpg?auto=webp&amp;s=6d2c995ff6e0e752289c28367c6de1532772648d', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/wNOK4uFSjn0_VLV9GzzwcWxl8N-Cjs1NgKKI98QDVv8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d81abbb07ddce350d7a7603a6d590802e9aa0ca', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'I-n5sa7QCjcBfo5kRd7bssElIH2v7WE5U8qgV0NDZuI'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': '\\[Update\\] Just out: highly recommend this free chrome/firefox extension as a must-have! It automatically finds code implementations for machine learning papers anywhere on the web (Google, Arxiv, Twitter, Scholar, and other sites)  \n\n\n[link to chrome extension](https://chrome.google.com/webstore/detail/mlai-code-implementation/aikkeehnlfpamidigaffhfmgbkdeheil)  \nor  \n[link to firefox extension](https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/)  \n\n\nFeedback and requests are very welcome!', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'ML/AI Code Implementation Finder (free browser extension)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_hjokbt', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 55, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 55, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1593685390.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[Update] Just out: highly recommend this free chrome/firefox extension as a must-have! It automatically finds code implementations for machine learning papers anywhere on the web (Google, Arxiv, Twitter, Scholar, and other sites)  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://chrome.google.com/webstore/detail/mlai-code-implementation/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;link to chrome extension&lt;/a&gt;&lt;br/&gt;\nor&lt;br/&gt;\n&lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex/""&gt;link to firefox extension&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Feedback and requests are very welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/wNOK4uFSjn0_VLV9GzzwcWxl8N-Cjs1NgKKI98QDVv8.jpg?auto=webp&amp;s=6d2c995ff6e0e752289c28367c6de1532772648d', 'width': 128, 'height': 128}, 'resolutions': [{'url': 'https://external-preview.redd.it/wNOK4uFSjn0_VLV9GzzwcWxl8N-Cjs1NgKKI98QDVv8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d81abbb07ddce350d7a7603a6d590802e9aa0ca', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'I-n5sa7QCjcBfo5kRd7bssElIH2v7WE5U8qgV0NDZuI'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': 'moderator', 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'hjokbt', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/hjokbt/mlai_code_implementation_finder_free_browser/', 'parent_whitelist_status': 'all_ads', 'stickied': True, 'url': 'https://www.reddit.com/r/LatestInML/comments/hjokbt/mlai_code_implementation_finder_free_browser/', 'subreddit_subscribers': 6676, 'created_utc': 1593656590.0, 'num_crossposts': 35, 'media': None, 'is_video': False}]",t3_hjokbt,
822,,tensorflow,,t2_5moj37ik,False,,0,False,How do you like my Remaster? Resolution increased using neural networks to 8K,[],r/tensorflow,False,6,,0,105.0,,False,t3_itgv7c,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P4q_R73x7lM?start=13&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'BioShock 2 - Teaser (Remastered 8K)', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P4q_R73x7lM?start=13&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/P4q_R73x7lM/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P4q_R73x7lM?start=13&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/itgv7c', 'height': 338}",,False,1,,False,https://b.thumbs.redditmedia.com/uXsqt4CKwLI1hqGNz3YwZVX2AYohmgpBl_kUiru7nyU.jpg,False,,[],{},,False,,1600230162.0,text,6,,,text,youtube.com,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,itgv7c,True,,stepanmetior,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/itgv7c/how_do_you_like_my_remaster_resolution_increased/,all_ads,False,https://www.youtube.com/watch?v=P4q_R73x7lM&amp;t=13s,22217,1600201362.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'BioShock 2 - Teaser (Remastered 8K)', 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/P4q_R73x7lM?start=13&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'version': '1.0', 'author_name': '8K Games', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/P4q_R73x7lM/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/stepanmetior'}, 'type': 'youtube.com'}",False,rich:video,https://www.youtube.com/watch?v=P4q_R73x7lM&amp;t=13s,"{'images': [{'source': {'url': 'https://external-preview.redd.it/tS6WjgntFium2NPr6PFFHe9G962dxosVFBRayR_8k_8.jpg?auto=webp&amp;s=36500ad8508a5be248a7bcb4e35a582b09f0223a', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/tS6WjgntFium2NPr6PFFHe9G962dxosVFBRayR_8k_8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b7e34e4f994343890cd1196810130c681ab2ead', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/tS6WjgntFium2NPr6PFFHe9G962dxosVFBRayR_8k_8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=236704ecdd19e26d722317110e35f1b18d71bd0a', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/tS6WjgntFium2NPr6PFFHe9G962dxosVFBRayR_8k_8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf45641c4c73b1555ab3e280ec34fbd289d02b6e', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'aQxA0CDfixe05nzDcOsAD4H8DDcz1maes3p6b39-O8I'}], 'enabled': False}",,,,,,
823,,tensorflow,"I am trying to create and make predictions using a celery/huey worker. What i wanna know is that, is this a good approach? Will this work?",t2_2k0j8a7v,False,,0,False,Using celery/huey to run a tensorflow model,[],r/tensorflow,False,6,,0,,,False,t3_it66qi,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1600194778.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to create and make predictions using a celery/huey worker. What i wanna know is that, is this a good approach? Will this work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,it66qi,True,,Talhaamjad789,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/it66qi/using_celeryhuey_to_run_a_tensorflow_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/it66qi/using_celeryhuey_to_run_a_tensorflow_model/,22217,1600165978.0,0,,False,,,,,,,,,
824,,tensorflow,"Hi friends!
Could you recommend me adequate resources or bootcamps for learning tensor flow with colab?",t2_6q9kjh9j,False,,0,False,Learning tensor flow,[],r/tensorflow,False,6,,0,,,False,t3_itboqc,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1600214536.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi friends!
Could you recommend me adequate resources or bootcamps for learning tensor flow with colab?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,itboqc,True,,siibiii,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/itboqc/learning_tensor_flow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/itboqc/learning_tensor_flow/,22217,1600185736.0,0,,False,,,,,,,,,
825,,tensorflow,"I'm new to semantic segmentation and am really struggling to wrap my head around how to construct my model so that the logits and labels are the same. And then so that the loss function is the correct loss function.

I'm using Keras 

    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_6 (InputLayer)         [(None, 256, 256, 3)]     0         
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
    _________________________________________________________________
    max_pooling2d_20 (MaxPooling (None, 128, 128, 64)      0         
    ..........................................................................................................
    up_sampling2d_11 (UpSampling (None, 256, 256, 512)     0         
    _________________________________________________________________
    block7_conv1 (Conv2D)        (None, 256, 256, 123)     566907    
    _________________________________________________________________
    softmax_4 (Softmax)          (None, 256, 256, 123)     0       


That's my current setup. RGB input and then 123 classes output.

My masks are also in RGB so that could be an issue because I think they should be one-hot, but the tutorials that I've been able to follow don't mention converting the masks or its over my head what they are saying. 

I'm using 'sparse categorical crossentropy' as I haven't been able to get any custom loss function to work. I get weird errors. 

I have no idea if this is the right loss function to use, some stuff on SO suggested it could work. But I dunno.

When I try to fit I get this:

    InvalidArgumentError:  logits and labels must have the same first dimension, got logits shape [1048576,123] and labels shape [3145728]
    	 [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at &lt;ipython-input-40-8ccdd719022a&gt;:3) ]] [Op:__inference_train_function_8590]

I don't really know where these numbers come from except for the 123. Neither of the other numbers seem to relate to the 256 of the image size. 

I don't know I'm feeling a bit overwhelmed. I've been stuck on this problem for like 30 hours now and it feels like it should just be a simple fix. But I can't find the right words or resources to explain how to go from RGB frame to RGB mask. Do I need to change my mask? How come none of the tutorials explain the loss functions they use? Why do I need to download another complete repository? 

Is there a better way to feed my images into the fit method? I'm using a generator

    from keras.preprocessing.image import ImageDataGenerator
    def image_mask_generator(image_data_generator, mask_data_generator):
        train_generator = zip(image_data_generator, mask_data_generator)
        for (img, mask) in train_generator:
            yield (img, mask)
    
    SEED = 100
    
    image_data_generator = ImageDataGenerator(
        rescale = 1./255,
        width_shift_range = 0.1,
        height_shift_range = 0.1,
        rotation_range = 30,
        zoom_range = 0.1
    ).flow_from_directory('/content/drive/My Drive/Thesis Pics/train_frames', batch_size = 16, target_size = (256,256), seed = SEED)
    
    mask_data_generator = ImageDataGenerator(
        width_shift_range = 0.1,
        height_shift_range = 0.1,
        rotation_range = 30,
        zoom_range = 0.1
    ).flow_from_directory('/content/drive/My Drive/Thesis Pics/train_masks', batch_size = 16, target_size = (256,256), seed = SEED)
    
    generator = image_mask_generator(image_data_generator, mask_data_generator)

IF anyone is knowledgable about Semantic Segmentation I'd realllllllyyy appreciate being able to pick your brain for specific information. 

Thanks.",t2_5wuzf,False,,0,False,[Semantic Segmentation]How do I match up my loss function and my output/labels to agree with one another?,[],r/tensorflow,False,6,,0,,,False,t3_it61cl,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1600194059.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m new to semantic segmentation and am really struggling to wrap my head around how to construct my model so that the logits and labels are the same. And then so that the loss function is the correct loss function.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using Keras &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 128, 128, 64)      0         
..........................................................................................................
up_sampling2d_11 (UpSampling (None, 256, 256, 512)     0         
_________________________________________________________________
block7_conv1 (Conv2D)        (None, 256, 256, 123)     566907    
_________________________________________________________________
softmax_4 (Softmax)          (None, 256, 256, 123)     0       
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;#39;s my current setup. RGB input and then 123 classes output.&lt;/p&gt;

&lt;p&gt;My masks are also in RGB so that could be an issue because I think they should be one-hot, but the tutorials that I&amp;#39;ve been able to follow don&amp;#39;t mention converting the masks or its over my head what they are saying. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m using &amp;#39;sparse categorical crossentropy&amp;#39; as I haven&amp;#39;t been able to get any custom loss function to work. I get weird errors. &lt;/p&gt;

&lt;p&gt;I have no idea if this is the right loss function to use, some stuff on SO suggested it could work. But I dunno.&lt;/p&gt;

&lt;p&gt;When I try to fit I get this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;InvalidArgumentError:  logits and labels must have the same first dimension, got logits shape [1048576,123] and labels shape [3145728]
     [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at &amp;lt;ipython-input-40-8ccdd719022a&amp;gt;:3) ]] [Op:__inference_train_function_8590]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I don&amp;#39;t really know where these numbers come from except for the 123. Neither of the other numbers seem to relate to the 256 of the image size. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know I&amp;#39;m feeling a bit overwhelmed. I&amp;#39;ve been stuck on this problem for like 30 hours now and it feels like it should just be a simple fix. But I can&amp;#39;t find the right words or resources to explain how to go from RGB frame to RGB mask. Do I need to change my mask? How come none of the tutorials explain the loss functions they use? Why do I need to download another complete repository? &lt;/p&gt;

&lt;p&gt;Is there a better way to feed my images into the fit method? I&amp;#39;m using a generator&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from keras.preprocessing.image import ImageDataGenerator
def image_mask_generator(image_data_generator, mask_data_generator):
    train_generator = zip(image_data_generator, mask_data_generator)
    for (img, mask) in train_generator:
        yield (img, mask)

SEED = 100

image_data_generator = ImageDataGenerator(
    rescale = 1./255,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    rotation_range = 30,
    zoom_range = 0.1
).flow_from_directory(&amp;#39;/content/drive/My Drive/Thesis Pics/train_frames&amp;#39;, batch_size = 16, target_size = (256,256), seed = SEED)

mask_data_generator = ImageDataGenerator(
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    rotation_range = 30,
    zoom_range = 0.1
).flow_from_directory(&amp;#39;/content/drive/My Drive/Thesis Pics/train_masks&amp;#39;, batch_size = 16, target_size = (256,256), seed = SEED)

generator = image_mask_generator(image_data_generator, mask_data_generator)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IF anyone is knowledgable about Semantic Segmentation I&amp;#39;d realllllllyyy appreciate being able to pick your brain for specific information. &lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,it61cl,True,,thejeran,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/it61cl/semantic_segmentationhow_do_i_match_up_my_loss/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/it61cl/semantic_segmentationhow_do_i_match_up_my_loss/,22217,1600165259.0,0,,False,,,,,,,,,
826,,tensorflow,"I need some help help with tf.data.

I am doing a few experiments on SQUAD dataset. dataset structure given is like below:

    row-1] { conext: ""some big string"", question:""q string"", ""answer"": ""some ans"" }

I would like to make use of **tf.data for load and pre-processing**. After loading, it is loaded in foll. format:

    {   context: Tensor(""some big string""), 
        question:Tensor(q string),  
        answer"": Tensor(some ans) 
     }

Now we want to pre-process the data. Now here pre-processing is not straightforward because **values are Tensor objects.**

Tensorflow provides some apis for such kind of pre-processing but **what if I want to do my custom pre-processing or maybe I want to use spacy which just operates on raw datatypes like string and not tensors.**

Basically I want help with this snippet:

    def format_data(row): 
      # Now I can access individual data row here. But value of row is in Tensor form. 
    
      # Hence I can't use my custom function. How to use custom function or spacy 

# function which operates on string and not on tensor?

      # I can use only below tf functions return 
      tf.strings.regex_replace(row['context'],'some-regex',' ',True)   
      # I have also tried using tf.py_function, it doesn't work. 
    
    train = dataset.map(format_data).batch(2) 
    list(train.take(1))
    ",t2_5k402g9n,False,,0,False,how to do custom pre-processing on data when using tf.data?,[],r/tensorflow,False,6,,0,,,False,t3_it3ivh,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1600155634.0,,[],{},,True,,1600180972.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need some help help with tf.data.&lt;/p&gt;

&lt;p&gt;I am doing a few experiments on SQUAD dataset. dataset structure given is like below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;row-1] { conext: &amp;quot;some big string&amp;quot;, question:&amp;quot;q string&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;some ans&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I would like to make use of &lt;strong&gt;tf.data for load and pre-processing&lt;/strong&gt;. After loading, it is loaded in foll. format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{   context: Tensor(&amp;quot;some big string&amp;quot;), 
    question:Tensor(q string),  
    answer&amp;quot;: Tensor(some ans) 
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we want to pre-process the data. Now here pre-processing is not straightforward because &lt;strong&gt;values are Tensor objects.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow provides some apis for such kind of pre-processing but &lt;strong&gt;what if I want to do my custom pre-processing or maybe I want to use spacy which just operates on raw datatypes like string and not tensors.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Basically I want help with this snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def format_data(row): 
  # Now I can access individual data row here. But value of row is in Tensor form. 

  # Hence I can&amp;#39;t use my custom function. How to use custom function or spacy 
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;function which operates on string and not on tensor?&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;  # I can use only below tf functions return 
  tf.strings.regex_replace(row[&amp;#39;context&amp;#39;],&amp;#39;some-regex&amp;#39;,&amp;#39; &amp;#39;,True)   
  # I have also tried using tf.py_function, it doesn&amp;#39;t work. 

train = dataset.map(format_data).batch(2) 
list(train.take(1))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,it3ivh,True,,Striking-Net2179,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/it3ivh/how_to_do_custom_preprocessing_on_data_when_using/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/it3ivh/how_to_do_custom_preprocessing_on_data_when_using/,22217,1600152172.0,0,,False,,,,,,,,,
827,,tensorflow,"Mel spectrograms are often the feature of choice to train Deep Learning Audio algorithms. In this video, you can learn what Mel spectrograms are, how they differ from  “vanilla” spectrograms, and their applications in AI audio. To explain Mel spectrograms, I also discuss the Mel scale and Mel filter banks.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=9GHCiiDLHQ4&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=17](https://www.youtube.com/watch?v=9GHCiiDLHQ4&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=17)",t2_12ahau,False,,0,False,I published a tutorial where I explain Mel spectrograms easily,[],r/tensorflow,False,6,,0,,,False,t3_isjnc4,False,dark,1.0,,public,17,1,{},,,False,[],,False,False,,{},Discussion,False,17,,False,self,False,,[],{},,True,,1600114245.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Mel spectrograms are often the feature of choice to train Deep Learning Audio algorithms. In this video, you can learn what Mel spectrograms are, how they differ from  “vanilla” spectrograms, and their applications in AI audio. To explain Mel spectrograms, I also discuss the Mel scale and Mel filter banks.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=9GHCiiDLHQ4&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=17""&gt;https://www.youtube.com/watch?v=9GHCiiDLHQ4&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=17&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_77ba55a2-c33c-4351-ac49-807455a80148', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;s=7a2f2b927be72d2b46ebd95bab8c072c3be0fbab', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;s=6e42b7095bcc331e53202438613aa827addf70c3', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;s=c740f7ef642fd2042d62c2bcba98734d08dfae6c', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;s=74e630f1072bb2423034ae48aefa241d834d7186', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;s=0a89cd8011c8210315ee60441eefd77b973a0c82', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Prayers up for the blessed.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Bless Up', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;s=7a2f2b927be72d2b46ebd95bab8c072c3be0fbab', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;s=6e42b7095bcc331e53202438613aa827addf70c3', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;s=c740f7ef642fd2042d62c2bcba98734d08dfae6c', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;s=74e630f1072bb2423034ae48aefa241d834d7186', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;s=0a89cd8011c8210315ee60441eefd77b973a0c82', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png'}]",[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,isjnc4,True,,diabulusInMusica,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/isjnc4/i_published_a_tutorial_where_i_explain_mel/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isjnc4/i_published_a_tutorial_where_i_explain_mel/,22217,1600085445.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Y4ZK2oUNuEfTr9c9TOtQ6Ce7YYdJ0AsLzTOEptM-nS4.jpg?auto=webp&amp;s=52a8a4618595012c69e17506c5311900ce2474ea', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/Y4ZK2oUNuEfTr9c9TOtQ6Ce7YYdJ0AsLzTOEptM-nS4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7efb3d52100024f76fe71ed9da840722418e42ea', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/Y4ZK2oUNuEfTr9c9TOtQ6Ce7YYdJ0AsLzTOEptM-nS4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=65a2b00c79ba3e03e13c44dd7007104da401def0', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/Y4ZK2oUNuEfTr9c9TOtQ6Ce7YYdJ0AsLzTOEptM-nS4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e427a0f8153c61cec20797f1bf96728bc15e3e9', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'cou-D8FKJcLZ0TJLWzw9RnvPecF_Y0wFAB4-jM3BKTw'}], 'enabled': False}",,,,,,
828,,tensorflow,"I was trying to run a Unet in Keras but got

    terminate called after throwing an instance of 'std::bad_alloc'

which doesn't make sense since I'm running the same Unet as before. I did make changes to CUDA, so I'm guessing that's the cause of this

Whenever I use tensorflow (I use version 2.3.0 in Ubuntu 16 with an NVIDIA GPU) and try
 
    gpus = tf.config.experimental.list_physical_devices('GPU')

it shows `gpus` as an empty list and says

	Successfully opened dynamic library libcudart.so.10.1
	2020-09-14 16:39:11.975096: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64::/usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64::/usr/local/cuda-11.0/lib64
	2020-09-14 16:39:11.975158: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
	2020-09-14 16:39:11.975197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
	2020-09-14 16:39:11.975232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
	2020-09-14 16:39:11.975380: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64::/usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64::/usr/local/cuda-11.0/lib64
	2020-09-14 16:39:11.975436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7

even though I set

	export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}
	export PATH=/usr/local/cuda-10.0/bin:/usr/local/cuda-10.0/NsightCompute-1.0${PATH:+:${PATH}}
	export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

and `which nvcc` shows

    /usr/local/cuda-10.0/bin/nvcc

and `$LD_LIBRARY_PATH `

shows

	bash: /usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-11.0/lib64: No such file or directory

and `~/.bashrc` shows

    export PATH=""$PATH:/usr/local/cuda-10.0/bin""
    export LD_LIBRARY_PATH=""/usr/local/cuda-10.0/lib64""${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

can anyone help?",t2_tpult,False,,0,False,Tensorflow: libcublas.so.10: cannot open shared object file,[],r/tensorflow,False,6,,0,,,False,t3_isxdso,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,1600128618.0,,[],{},,True,,1600156949.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was trying to run a Unet in Keras but got&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;terminate called after throwing an instance of &amp;#39;std::bad_alloc&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which doesn&amp;#39;t make sense since I&amp;#39;m running the same Unet as before. I did make changes to CUDA, so I&amp;#39;m guessing that&amp;#39;s the cause of this&lt;/p&gt;

&lt;p&gt;Whenever I use tensorflow (I use version 2.3.0 in Ubuntu 16 with an NVIDIA GPU) and try&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gpus = tf.config.experimental.list_physical_devices(&amp;#39;GPU&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it shows &lt;code&gt;gpus&lt;/code&gt; as an empty list and says&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Successfully opened dynamic library libcudart.so.10.1
2020-09-14 16:39:11.975096: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library &amp;#39;libcublas.so.10&amp;#39;; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64::/usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64::/usr/local/cuda-11.0/lib64
2020-09-14 16:39:11.975158: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-14 16:39:11.975197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-14 16:39:11.975232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-14 16:39:11.975380: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library &amp;#39;libcusparse.so.10&amp;#39;; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64::/usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64::/usr/local/cuda-11.0/lib64
2020-09-14 16:39:11.975436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;even though I set&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}
export PATH=/usr/local/cuda-10.0/bin:/usr/local/cuda-10.0/NsightCompute-1.0${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and &lt;code&gt;which nvcc&lt;/code&gt; shows&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/usr/local/cuda-10.0/bin/nvcc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and &lt;code&gt;$LD_LIBRARY_PATH&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;shows&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash: /usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-11.0/lib64: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and &lt;code&gt;~/.bashrc&lt;/code&gt; shows&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PATH=&amp;quot;$PATH:/usr/local/cuda-10.0/bin&amp;quot;
export LD_LIBRARY_PATH=&amp;quot;/usr/local/cuda-10.0/lib64&amp;quot;${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;can anyone help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,isxdso,True,,74throwaway,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/isxdso/tensorflow_libcublasso10_cannot_open_shared/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isxdso/tensorflow_libcublasso10_cannot_open_shared/,22217,1600128149.0,0,,False,,,,,,,,,
829,,tensorflow,"I want to train a neural net that, given an image of someone, comes up with a roast (insult) about them. Originally, I figured that the amount of data and size of the network I would need to have the machine understand enough about pop culture and the human language and lots of that stuff was just too much, so I found a workaround.

I trained a variational autoencoder on human faces, then I went through /r/RoastMe and found the latent encodings of every post. Now, when I take a picture of myself, it encodes my picture through my VAE, find the closest post based on the euclidean distance of the encoding vectors, and just reads one of the roast from there.

That was a fun project that I just finished a day ago, but I'm realizing now I can achieve my original goal of just having a neural net that goes from a picture of someone straight to a new novel roast. I could just take something like GPT-2 that has a huge understanding about the world, and just make a dataset of /r/RoastMe posts -&gt; specific roasts.

I have done pretraining like this before, i.e. taking InceptionV3 (thanks to the built-in tensorflow package for it), freezing all but a few layers, replacing the output layer with my own, and retraining it very quickly.

Is this possible with something like GPT-2? I've been looking and I can't even figure out how to load the model. My guess is it's a simple solution, but the files I got from downloading one of the models just don't make sense to me. [Picture](https://imgur.com/pk24z4q).

I'm used to using .h5 files for saving and loading models, I don't know what to do with this. Any help would be appreciated.",t2_10sghc,False,,0,False,Is it possible to pretrain GPT-2 (or another NLP algorithm) for a different task?,[],r/tensorflow,False,6,,0,,,False,t3_isv70s,False,dark,0.6,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1600149591.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to train a neural net that, given an image of someone, comes up with a roast (insult) about them. Originally, I figured that the amount of data and size of the network I would need to have the machine understand enough about pop culture and the human language and lots of that stuff was just too much, so I found a workaround.&lt;/p&gt;

&lt;p&gt;I trained a variational autoencoder on human faces, then I went through &lt;a href=""/r/RoastMe""&gt;/r/RoastMe&lt;/a&gt; and found the latent encodings of every post. Now, when I take a picture of myself, it encodes my picture through my VAE, find the closest post based on the euclidean distance of the encoding vectors, and just reads one of the roast from there.&lt;/p&gt;

&lt;p&gt;That was a fun project that I just finished a day ago, but I&amp;#39;m realizing now I can achieve my original goal of just having a neural net that goes from a picture of someone straight to a new novel roast. I could just take something like GPT-2 that has a huge understanding about the world, and just make a dataset of &lt;a href=""/r/RoastMe""&gt;/r/RoastMe&lt;/a&gt; posts -&amp;gt; specific roasts.&lt;/p&gt;

&lt;p&gt;I have done pretraining like this before, i.e. taking InceptionV3 (thanks to the built-in tensorflow package for it), freezing all but a few layers, replacing the output layer with my own, and retraining it very quickly.&lt;/p&gt;

&lt;p&gt;Is this possible with something like GPT-2? I&amp;#39;ve been looking and I can&amp;#39;t even figure out how to load the model. My guess is it&amp;#39;s a simple solution, but the files I got from downloading one of the models just don&amp;#39;t make sense to me. &lt;a href=""https://imgur.com/pk24z4q""&gt;Picture&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m used to using .h5 files for saving and loading models, I don&amp;#39;t know what to do with this. Any help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,isv70s,True,,LivingPornFree,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/isv70s/is_it_possible_to_pretrain_gpt2_or_another_nlp/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isv70s/is_it_possible_to_pretrain_gpt2_or_another_nlp/,22217,1600120791.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?auto=webp&amp;s=77f98c0d46d895bbf2f5c82f3fb70ec0637dba5a', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a328475553b2740866dcb79ba5c5940a1d88c0f', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=820cc427905a95e3ed941aaf60abe02e94e4c58d', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7613786215cf066b8627ba330eeab07393e796b', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=56256734a4b4f71bbfdfe0dfcf8a63f777d03952', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fd0302d81bd888fbd7428b2827fdcbff991c285d', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/VpsxLZIualmxdOClASVbyDkS8bop7vbHfjUJmqHR8e0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=563e4604911e1b2fd2fd10510335bf87e3f10713', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'nHmB3tUVKrCUK7BucSpK1ZRAoN-XyaQHrTTqr75VHnw'}], 'enabled': False}",,,,,,
830,,tensorflow,I have a tool that is incompatible with tensorflow 2 but want to train using tensorflow 2.  How can I convert a model trained with tensorflow 2 to be a tensorflow 1 frozen graph?,t2_ihppf,False,,0,False,Converting Tensorflow 2 model to tensorflow 1,[],r/tensorflow,False,6,,0,,,False,t3_isqidm,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1600136036.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a tool that is incompatible with tensorflow 2 but want to train using tensorflow 2.  How can I convert a model trained with tensorflow 2 to be a tensorflow 1 frozen graph?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,isqidm,True,,zqq622,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/isqidm/converting_tensorflow_2_model_to_tensorflow_1/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isqidm/converting_tensorflow_2_model_to_tensorflow_1/,22217,1600107236.0,0,,False,,,,,,,,,
831,,tensorflow,"INTRODUCING TENSORFLOW LITE TASK LIBRARY

A set of powerful and easy-to-use model interfaces for popular ML tasks, it handles most of the pre and post processing and complex logic for you. Inference can now be done in just 5 lines of code!

**Summary:** [https://www.marktechpost.com/2020/09/13/tired-of-tedious-pre-processing-tasks-try-tensorflow-lite-task-library/](https://www.marktechpost.com/2020/09/13/tired-of-tedious-pre-processing-tasks-try-tensorflow-lite-task-library/)

**Resource:** [https://blog.tensorflow.org/2020/09/introducing-tensorflow-lite-task-library.html](https://blog.tensorflow.org/2020/09/introducing-tensorflow-lite-task-library.html)",t2_2wsvqwhg,False,,0,False,Tired Of Tedious Pre-Processing Tasks? Try TensorFlow Lite Task Library!,[],r/tensorflow,False,6,,0,,,False,t3_isdzj4,False,dark,0.95,,public,16,0,{},,,False,[],,False,False,,{},Discussion,False,16,,False,self,False,,[],{},,True,,1600086501.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;INTRODUCING TENSORFLOW LITE TASK LIBRARY&lt;/p&gt;

&lt;p&gt;A set of powerful and easy-to-use model interfaces for popular ML tasks, it handles most of the pre and post processing and complex logic for you. Inference can now be done in just 5 lines of code!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Summary:&lt;/strong&gt; &lt;a href=""https://www.marktechpost.com/2020/09/13/tired-of-tedious-pre-processing-tasks-try-tensorflow-lite-task-library/""&gt;https://www.marktechpost.com/2020/09/13/tired-of-tedious-pre-processing-tasks-try-tensorflow-lite-task-library/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resource:&lt;/strong&gt; &lt;a href=""https://blog.tensorflow.org/2020/09/introducing-tensorflow-lite-task-library.html""&gt;https://blog.tensorflow.org/2020/09/introducing-tensorflow-lite-task-library.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,isdzj4,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/isdzj4/tired_of_tedious_preprocessing_tasks_try/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isdzj4/tired_of_tedious_preprocessing_tasks_try/,22217,1600057701.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?auto=webp&amp;s=a2419756bd50f7d563e5fa2fbce156e591d4e704', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=951f51be45ea94a723e83f9f3c4a099deaea37ea', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdec0e2a407a7f272136255cf6b1615d8b4ec73c', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd31e1a3775d5cf4ad6a2dafc6ab7e47a625a401', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1738174856ed5ed610f796b200fe6b9c207a113', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b97a7d7c7475ceb6ff17401e0c787cf952fd7260', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/jyyWWtoDHJ6chOkshXX0Q0E1bLKGIHo5_MWUVAmurEc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aaa53b9d25048c7638fb769e04e6c1d914f9eefe', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'K6_1imWIc9Q0r6f-W44WoOGIl_ba3ZKYsT43Y9TEdZI'}], 'enabled': False}",,,,,,
832,,tensorflow,,t2_20hr56h,False,,0,False,"Building a “Motivation Bot” with TensorFlow.js, Face Detection, and Emotion Classification",[],r/tensorflow,False,6,,0,93.0,,False,t3_iskseu,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/WfHST8ortFhnRQ1hw0vTIcd-SHWcAqgJVbzpsFZThKg.jpg,False,,[],{},,False,,1600118708.0,text,6,,,text,heartbeat.fritz.ai,False,,,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iskseu,True,,taqmanplus,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iskseu/building_a_motivation_bot_with_tensorflowjs_face/,all_ads,False,https://heartbeat.fritz.ai/building-a-motivation-bot-with-tensorflow-js-face-detection-and-emotion-classification-7b80a38eb9c3,22217,1600089908.0,0,,False,link,https://heartbeat.fritz.ai/building-a-motivation-bot-with-tensorflow-js-face-detection-and-emotion-classification-7b80a38eb9c3,"{'images': [{'source': {'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?auto=webp&amp;s=ce693b662de6da8603bef8ea644ed491dff02426', 'width': 1200, 'height': 800}, 'resolutions': [{'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4165b50c128b6bc4d90f6f5b3c9e8865cb6bb6a8', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5584402cff788a807faa789d0cc3d417c37f8369', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1022bc2e342e702ed836d6b1bbddb13ed264cd5', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd84bd59d3e6830d636be2b918d78cb80cc0033b', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=98c11ace56af503a2ff194adeecfe2d857bb9034', 'width': 960, 'height': 640}, {'url': 'https://external-preview.redd.it/mlQcT804CTuUlHLxOWs9aQXEk6eCUcXLHBeAsUMHqIE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41eaa1317d2ff7397ade8606332bbdf492eb9016', 'width': 1080, 'height': 720}], 'variants': {}, 'id': 'o1SSE4F9NmKhBBWqslTQz3CNaohSvtWA0IjyEP17FbE'}], 'enabled': False}",,,,,,
833,,tensorflow,"Train GPT-2 from Scratch on your own language . 

GPT-2 Training on non-English textual  


[https://gist.github.com/miladfa7/8668eee87a17da2e7d22f1b8df5648ba](https://gist.github.com/miladfa7/8668eee87a17da2e7d22f1b8df5648ba)",t2_3upwpxft,False,,0,False,Train the GPT-2 model from scratch any langauage,[],r/tensorflow,False,6,,0,,,False,t3_isjg1v,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1600113410.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Train GPT-2 from Scratch on your own language . &lt;/p&gt;

&lt;p&gt;GPT-2 Training on non-English textual  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://gist.github.com/miladfa7/8668eee87a17da2e7d22f1b8df5648ba""&gt;https://gist.github.com/miladfa7/8668eee87a17da2e7d22f1b8df5648ba&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,isjg1v,True,,milad_farzalizadeh,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/isjg1v/train_the_gpt2_model_from_scratch_any_langauage/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isjg1v/train_the_gpt2_model_from_scratch_any_langauage/,22217,1600084610.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?auto=webp&amp;s=079a7260ec149880c73263d64811698adb22760a', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d5811c5bda5fece1040636a6af8702ba790f0fd4', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eee576fd4da7535eb53ceb88dd8b52f073048441', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=72872d880460efa723918c000adca0ed259cf775', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3545b9335d763c9da9c16bf7bf9a3f907dbd6f6', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d241ace0f1c07088fac3f8469dbad3b05d2d419', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9055f11bdc00beb0b3589e1cae5817d6070d83bc', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'OAXSl8SY6T3JK9MGQyKxkoYbqZ71HQRYXLeB8CV0NXg'}], 'enabled': False}",,,,,,
834,,tensorflow,I am able to detect the faces and draw the bounding boxes on them but now I want to crop these detected faces and then send them to another model.,t2_3cn2c07x,False,,0,False,How do I crop detected faces from Blaze Face Model in Tensorflow.js?,[],r/tensorflow,False,6,,0,,,False,t3_isdw1n,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1600086092.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am able to detect the faces and draw the bounding boxes on them but now I want to crop these detected faces and then send them to another model.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,isdw1n,True,,yudhiesh,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/isdw1n/how_do_i_crop_detected_faces_from_blaze_face/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/isdw1n/how_do_i_crop_detected_faces_from_blaze_face/,22217,1600057292.0,0,,False,,,,,,,,,
835,,tensorflow,"Which of Tensorflows distribution-strategy is most efficient for LSTMs on 2 GPUs ? ([https://www.tensorflow.org/guide/distributed\_training](https://www.tensorflow.org/guide/distributed_training))

Otherwise, how do you decide which distribution strategy to chose?

&amp;#x200B;

Float or double sequences (of around 1.000-15.000 rows &amp; around 10-100 columns), 1-2Million Samples

    [ # 1st sample
      [ 89.319787 1.329743 99.234670    ...    52.329743 0.319787 2.319787 ] 
      [ 84.319787 1.329743 49.329743    ...    52.329743 0.319    2.319787 ] 
      [ 12.319787 1.329743 33.329743    ...    52.329743 0.319787 2.319787 ] 
      [ 33.319787 1.329743 23.329743    ...    52.329743 0.319787 2.319787 ] 
    
            ...       ...       ...    ...          ...       ...     ...  
            ...       ...       ...    ...          ...       ...     ... 
    
      [ 23.319787 1.329743 45.234670    ...    52.329743 0.32721  2.319787 ] 
      [ 89.319787 1.329743 99.234670    ...    52.329743 0.319787 2.319787 ] 
      [ 84.319787 1.329743 49.329743    ...    52.329743 0.319    2.319787 ] 
      [ 12.319787 1.329743 33.329743    ...    52.329743 0.319787 2.319787 ] 
      [ 33.319787 1.329743 23.329743    ...    52.329743 0.319787 2.319787 ]   ],
    
    ...
    
    [ # n'th sample          (n = 500k or 2 million samples)
      [       ...       ...       ...    ...          ...       ...     ... ]
              ...       ...       ...    ...          ...       ...     ... 
      [       ...       ...       ...    ...          ...       ...     ... ]  ],

Batch\_sizes; 8, 16 or 32

LSTM with these layers: \[700,700,700,700,64,32\]

On 2 RTX 3080 or 1x3080+1x3090",t2_7a6vie0k,False,,0,False,most efficient distribution-strategy for LSTMs on 2 GPUs ?,[],r/tensorflow,False,6,,0,,,False,t3_iry241,False,dark,0.81,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1600031675.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Which of Tensorflows distribution-strategy is most efficient for LSTMs on 2 GPUs ? (&lt;a href=""https://www.tensorflow.org/guide/distributed_training""&gt;https://www.tensorflow.org/guide/distributed_training&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Otherwise, how do you decide which distribution strategy to chose?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Float or double sequences (of around 1.000-15.000 rows &amp;amp; around 10-100 columns), 1-2Million Samples&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ # 1st sample
  [ 89.319787 1.329743 99.234670    ...    52.329743 0.319787 2.319787 ] 
  [ 84.319787 1.329743 49.329743    ...    52.329743 0.319    2.319787 ] 
  [ 12.319787 1.329743 33.329743    ...    52.329743 0.319787 2.319787 ] 
  [ 33.319787 1.329743 23.329743    ...    52.329743 0.319787 2.319787 ] 

        ...       ...       ...    ...          ...       ...     ...  
        ...       ...       ...    ...          ...       ...     ... 

  [ 23.319787 1.329743 45.234670    ...    52.329743 0.32721  2.319787 ] 
  [ 89.319787 1.329743 99.234670    ...    52.329743 0.319787 2.319787 ] 
  [ 84.319787 1.329743 49.329743    ...    52.329743 0.319    2.319787 ] 
  [ 12.319787 1.329743 33.329743    ...    52.329743 0.319787 2.319787 ] 
  [ 33.319787 1.329743 23.329743    ...    52.329743 0.319787 2.319787 ]   ],

...

[ # n&amp;#39;th sample          (n = 500k or 2 million samples)
  [       ...       ...       ...    ...          ...       ...     ... ]
          ...       ...       ...    ...          ...       ...     ... 
  [       ...       ...       ...    ...          ...       ...     ... ]  ],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Batch_sizes; 8, 16 or 32&lt;/p&gt;

&lt;p&gt;LSTM with these layers: [700,700,700,700,64,32]&lt;/p&gt;

&lt;p&gt;On 2 RTX 3080 or 1x3080+1x3090&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iry241,True,,GerritTheBerrit,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/iry241/most_efficient_distributionstrategy_for_lstms_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iry241/most_efficient_distributionstrategy_for_lstms_on/,22217,1600002875.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?auto=webp&amp;s=cf5ddf6e0c739f87e028fa00c381776626f926ba', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c06def6745dcea7764418b35e2c5207871b951a', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69d7e9319745a6a77f09c606f82f29a53e389950', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85865bec40c26ac397932db43e979a2ff0b28', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd12d48a13c302682518f159483335a6879d67bd', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97980510a876206f40d4cdd6abeff7288d5e2f57', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/cO_bi7X7VBFjyVVBvgG3qg5zHQWGXI9JyEMIDGBJJME.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=27b5e2e4999d2ccfe1fd49a7f6784e58a5920230', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'AcUXdF9TnoVQpyFqzaP15GyAh5CohX60bP3IdtTTr7E'}], 'enabled': False}",,,,,,
836,,tensorflow," Hi guys!

I have a 1 D convolutional network that is designed to predict time series data.

It has 11 layers, as it is basically designed like an AutoEncoder, with a bottleneck in between.

My normalized input comes from \[-3, 3\] normal distribution which outputs time series data scaled from 0 to 1.

After training and achieving desired prediction performance, I tried random noise (-0.1, 0.1) as input and observed that my network had a decent prediction. Furthermore, I created an input of all zeros (shaped like my original input), and run it thought the NN model - it again predicted something reasonable even though it had all zeros as input.

My first question is: how is that possible that the network does not react much to the input data variability?",t2_4ecq42y4,False,,0,False,Conv Network predicts same output regardless of input variations,[],r/tensorflow,False,6,,0,,,False,t3_is5ua8,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1600057075.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys!&lt;/p&gt;

&lt;p&gt;I have a 1 D convolutional network that is designed to predict time series data.&lt;/p&gt;

&lt;p&gt;It has 11 layers, as it is basically designed like an AutoEncoder, with a bottleneck in between.&lt;/p&gt;

&lt;p&gt;My normalized input comes from [-3, 3] normal distribution which outputs time series data scaled from 0 to 1.&lt;/p&gt;

&lt;p&gt;After training and achieving desired prediction performance, I tried random noise (-0.1, 0.1) as input and observed that my network had a decent prediction. Furthermore, I created an input of all zeros (shaped like my original input), and run it thought the NN model - it again predicted something reasonable even though it had all zeros as input.&lt;/p&gt;

&lt;p&gt;My first question is: how is that possible that the network does not react much to the input data variability?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,is5ua8,True,,ncuxomun,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/is5ua8/conv_network_predicts_same_output_regardless_of/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/is5ua8/conv_network_predicts_same_output_regardless_of/,22217,1600028275.0,0,,False,,,,,,,,,
837,,tensorflow,"I would like to create an object recognition using the camera feed for dog breeds using tf.js.

I built an object recognition demo that works https://codesandbox.io/s/tensorflowjs-real-time-object-detection-om12e?file=/src/index.js:0-27 but it uses the cocoSsd model that doesn't have dog breeds.

So I know that mobilenet model does have dog breeds and I found a working example here https://codesandbox.io/s/o4l6pnlkzz (though it uses images upload rather than the camera feed).

When I tried to put the mobilenet model into the object detection example, I get the following error. ""tfjsconverter.loadGraphModel is not a function"".

https://codesandbox.io/s/tensorflowjs-real-time-object-detection-forked-6hxdb?file=/src/index.js:925-934

I imagine there's something wrong on line 31, but I can't figure it out.

If you know what I'm doing wrong, it would be really helpful for a few pointers.

I've also posted this question on StackOverflow, but so far, I got no response.",t2_6lb0k,False,,0,False,Tensorflow.js Error “tfjsconverter.loadGraphModel is not a function”,[],r/tensorflow,False,6,,0,,,False,t3_iru30u,False,dark,0.84,,public,4,0,{},,,False,[],,False,False,,{},Question,False,4,,False,self,False,,[],{},,True,,1600011952.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I would like to create an object recognition using the camera feed for dog breeds using tf.js.&lt;/p&gt;

&lt;p&gt;I built an object recognition demo that works &lt;a href=""https://codesandbox.io/s/tensorflowjs-real-time-object-detection-om12e?file=/src/index.js:0-27""&gt;https://codesandbox.io/s/tensorflowjs-real-time-object-detection-om12e?file=/src/index.js:0-27&lt;/a&gt; but it uses the cocoSsd model that doesn&amp;#39;t have dog breeds.&lt;/p&gt;

&lt;p&gt;So I know that mobilenet model does have dog breeds and I found a working example here &lt;a href=""https://codesandbox.io/s/o4l6pnlkzz""&gt;https://codesandbox.io/s/o4l6pnlkzz&lt;/a&gt; (though it uses images upload rather than the camera feed).&lt;/p&gt;

&lt;p&gt;When I tried to put the mobilenet model into the object detection example, I get the following error. &amp;quot;tfjsconverter.loadGraphModel is not a function&amp;quot;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://codesandbox.io/s/tensorflowjs-real-time-object-detection-forked-6hxdb?file=/src/index.js:925-934""&gt;https://codesandbox.io/s/tensorflowjs-real-time-object-detection-forked-6hxdb?file=/src/index.js:925-934&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I imagine there&amp;#39;s something wrong on line 31, but I can&amp;#39;t figure it out.&lt;/p&gt;

&lt;p&gt;If you know what I&amp;#39;m doing wrong, it would be really helpful for a few pointers.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve also posted this question on StackOverflow, but so far, I got no response.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iru30u,True,,ybinstock,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/iru30u/tensorflowjs_error_tfjsconverterloadgraphmodel_is/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iru30u/tensorflowjs_error_tfjsconverterloadgraphmodel_is/,22217,1599983152.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?auto=webp&amp;s=76a7707d4ad1e3de83d9ef41bdc26b5a6857d0b1', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=958067b3b610d5f22c6250b86f9774326615b9cb', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e59db980a1f1bc6c83bda6c8e7d219f4015222e4', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=353407f1df96dea9f0ab3f77328160bde530d872', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e0ba3a6c3d3c991fd9cc9a1e4274d29d1cb4089', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c1fc2cc7f4874fa10571b47be33086f8b29ac626', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/v32SxbpRSTMSpuRs5TF8ediXc6iTkWrHpvdksuowpJo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3e5b30ae7f9da5cae0f959f349b1ef5f44d93ca', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'Ln76EmCMTHbZ6Y1c4upRcFlbiyAXnucYLn0N08c6gCo'}], 'enabled': False}",,,,,,
838,,tensorflow,"I'm pretty new to Tensorflow and can make basic classification and detection models. 

I want to perform segmentation on satellite imagery but this isn't the same obviously as classification. I'm not quite sure how my model is supposed to output the data and how to use it.

My masks are simply RGB images, 3 channels. My question is does my output layer need to be the same dimensions as my masks? 

What's the correct workflow from going from simple RGB satellite images to RGB mask image? The models I've been looking at online are a bit hard to follow, but one of them does output to the same size as the image but with the classes for channels instead of RGB. So i'm not quite sure how it was output as an RGB image. 

Any guide for dummies on simple image to mask segmentation?",t2_5wuzf,False,,0,False,What kind of output should I be using for Semantic Segmentation?,[],r/tensorflow,False,6,,0,,,False,t3_irmxqh,False,dark,0.78,,public,5,0,{},,,False,[],,False,False,,{},Question,False,5,,False,self,False,,[],{},,True,,1599981175.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m pretty new to Tensorflow and can make basic classification and detection models. &lt;/p&gt;

&lt;p&gt;I want to perform segmentation on satellite imagery but this isn&amp;#39;t the same obviously as classification. I&amp;#39;m not quite sure how my model is supposed to output the data and how to use it.&lt;/p&gt;

&lt;p&gt;My masks are simply RGB images, 3 channels. My question is does my output layer need to be the same dimensions as my masks? &lt;/p&gt;

&lt;p&gt;What&amp;#39;s the correct workflow from going from simple RGB satellite images to RGB mask image? The models I&amp;#39;ve been looking at online are a bit hard to follow, but one of them does output to the same size as the image but with the classes for channels instead of RGB. So i&amp;#39;m not quite sure how it was output as an RGB image. &lt;/p&gt;

&lt;p&gt;Any guide for dummies on simple image to mask segmentation?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,irmxqh,True,,thejeran,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/irmxqh/what_kind_of_output_should_i_be_using_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/irmxqh/what_kind_of_output_should_i_be_using_for/,22217,1599952375.0,0,,False,,,,,,,,,
839,,tensorflow,"Rather than passing layers in the following manner

    convs=tf.keras.Sequential()
    for i in range(y):
        self.convs.add(tf.keras.Conv2D(...))
        self.convs.add(tf.keras.layers.BatchNormalization(...)

Is it possible to combine the Conv2D layer and batch layer using a function, and pass the result to Sequential()?

For example:

    def func_a():
        convs=tf.keras.Sequential()
        for i in range(y):
            self.convs.add(func_b(...))
    
    def func_b(...):
        conv=tf.keras.Conv2D(...)
        norm=tf.keras.layers.BatchNormlization(...)
        x=norm(conv)
        return(x)

Although outside of ML I would employ trial-and-error, I'm not proficient enough to realise whether the program is working as it should, or not, at this point.

If this method is a possibility, how is the input passed from func\_a() (whether initial input, or output of previous layers) to func\_b(), and how should I accommodate it?

Thanks!",t2_1cjispl7,False,,0,False,Passing stacked layers to tf.keras.Sequential() with .add(),[],r/tensorflow,False,6,,0,,,False,t3_irb1wj,False,dark,0.9,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1599939497.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Rather than passing layers in the following manner&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;convs=tf.keras.Sequential()
for i in range(y):
    self.convs.add(tf.keras.Conv2D(...))
    self.convs.add(tf.keras.layers.BatchNormalization(...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Is it possible to combine the Conv2D layer and batch layer using a function, and pass the result to Sequential()?&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def func_a():
    convs=tf.keras.Sequential()
    for i in range(y):
        self.convs.add(func_b(...))

def func_b(...):
    conv=tf.keras.Conv2D(...)
    norm=tf.keras.layers.BatchNormlization(...)
    x=norm(conv)
    return(x)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although outside of ML I would employ trial-and-error, I&amp;#39;m not proficient enough to realise whether the program is working as it should, or not, at this point.&lt;/p&gt;

&lt;p&gt;If this method is a possibility, how is the input passed from func_a() (whether initial input, or output of previous layers) to func_b(), and how should I accommodate it?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,False,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,irb1wj,True,,GeorgeFree2018,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/irb1wj/passing_stacked_layers_to_tfkerassequential_with/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/irb1wj/passing_stacked_layers_to_tfkerassequential_with/,22217,1599910697.0,0,,False,,,,,,,,,
840,,tensorflow,"I want to know **exactly** if it’s allowed to use state of the art neural network architectures to create commercial software.

This is the official source code of the Style GAN:

https://github.com/NVlabs/stylegan

On the license page it says “Attribution-NonCommercial 4.0 International“, but it refers to the idea or the source code?

Option 1 - If it refers to the idea, it means that nobody else can use a StyleGAN-based architecture to build a commercial software.

Option 2 - If it refers to the code on the page, it means that any person can use a StyleGAN-based architecture to build a commercial software, if the person implements its own code from scratch and uses its own dataset.

Now, if we navigate to this repository:

https://github.com/taki0112/StyleGAN-Tensorflow

We see that the license now says “MIT license”, which means anyone can use it commercially, but it uses the same idea from the Style GAN paper. So, it confirms the option 2, if you write your own implementation, you can use the style based architecture to build your own software. Is this correct? Or am I missing something here.",t2_6aqt5xxb,False,,0,False,Is Style GAN patented?,[],r/tensorflow,False,6,,0,,,False,t3_ir4rqs,False,dark,0.93,,public,11,0,{},,,False,[],,False,False,,{},,False,11,,False,self,False,,[],{},,True,,1599907844.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to know &lt;strong&gt;exactly&lt;/strong&gt; if it’s allowed to use state of the art neural network architectures to create commercial software.&lt;/p&gt;

&lt;p&gt;This is the official source code of the Style GAN:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/NVlabs/stylegan""&gt;https://github.com/NVlabs/stylegan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;On the license page it says “Attribution-NonCommercial 4.0 International“, but it refers to the idea or the source code?&lt;/p&gt;

&lt;p&gt;Option 1 - If it refers to the idea, it means that nobody else can use a StyleGAN-based architecture to build a commercial software.&lt;/p&gt;

&lt;p&gt;Option 2 - If it refers to the code on the page, it means that any person can use a StyleGAN-based architecture to build a commercial software, if the person implements its own code from scratch and uses its own dataset.&lt;/p&gt;

&lt;p&gt;Now, if we navigate to this repository:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/taki0112/StyleGAN-Tensorflow""&gt;https://github.com/taki0112/StyleGAN-Tensorflow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We see that the license now says “MIT license”, which means anyone can use it commercially, but it uses the same idea from the Style GAN paper. So, it confirms the option 2, if you write your own implementation, you can use the style based architecture to build your own software. Is this correct? Or am I missing something here.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ir4rqs,True,,Digital_Secrets,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/ir4rqs/is_style_gan_patented/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ir4rqs/is_style_gan_patented/,22217,1599879044.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/dKA4r5nxTtoKHmZTRQowVnk9haiGOOMEiykiBvLCi2A.jpg?auto=webp&amp;s=855875604a0ff755d4594bd2a20007503154223b', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/dKA4r5nxTtoKHmZTRQowVnk9haiGOOMEiykiBvLCi2A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1b47615f64b93f586d7e5d623fafddc2c943679', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/dKA4r5nxTtoKHmZTRQowVnk9haiGOOMEiykiBvLCi2A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e429e40be08e2f7a77853a8e54e7535f289b1623', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/dKA4r5nxTtoKHmZTRQowVnk9haiGOOMEiykiBvLCi2A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=650375ee21c1438ec032acaecacddee557040ea9', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'LQ4RDMFUhZa6L3wyMjqR3t2o9EJzHmBLIr44IhQt1MQ'}], 'enabled': False}",,,,,,
841,,tensorflow," I am looking for simple implementation of loading few sets of pictures from different folders, and then after training, identify by single image.",t2_8cpp,False,,0,False,simple exercise for school,[],r/tensorflow,False,6,,0,,,False,t3_ir801n,False,dark,0.4,,public,0,0,{},,,False,[],,False,False,,{},,False,0,,False,self,False,,[],{},,True,,1599923298.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking for simple implementation of loading few sets of pictures from different folders, and then after training, identify by single image.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ir801n,True,,rsegoly,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/ir801n/simple_exercise_for_school/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ir801n/simple_exercise_for_school/,22217,1599894498.0,0,,False,,,,,,,,,
842,,tensorflow,"I guess I could also ask how can I link a specific version of cuda to my python virtual environment? I installed cuda 11.0 but my code still uses version 10. Even when I create a new virtual env, it still uses version 10 not 11. Please help with answers related to windows. Thank you.",t2_6lquq1dr,False,,0,False,How to use different versions of cuda on same machine (Windows)?,[],r/tensorflow,False,6,,0,,,False,t3_iqxvxr,False,dark,1.0,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1599882639.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I guess I could also ask how can I link a specific version of cuda to my python virtual environment? I installed cuda 11.0 but my code still uses version 10. Even when I create a new virtual env, it still uses version 10 not 11. Please help with answers related to windows. Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iqxvxr,True,,mk1817,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/iqxvxr/how_to_use_different_versions_of_cuda_on_same/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iqxvxr/how_to_use_different_versions_of_cuda_on_same/,22217,1599853839.0,0,,False,,,,,,,,,
843,,tensorflow,I don't know how to build from source without AVX is their any up to date (ish) binary which I can install (ideally with pip)?,t2_5h5otn14,False,,0,False,Is their a pre built non AVX binary? Running on non AVX vps.,[],r/tensorflow,False,6,,0,,,False,t3_iqxz0o,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1599882913.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I don&amp;#39;t know how to build from source without AVX is their any up to date (ish) binary which I can install (ideally with pip)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iqxz0o,True,,_Well_Timed_Gimli_,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/iqxz0o/is_their_a_pre_built_non_avx_binary_running_on/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iqxz0o/is_their_a_pre_built_non_avx_binary_running_on/,22217,1599854113.0,0,,False,,,,,,,,,
844,,tensorflow,,t2_7yjfn7ok,False,,0,False,"How would one go about building a sequence to sequence model where the input sequence can have variable length, but the output sequence must always have the same length as the input sequence?",[],r/tensorflow,False,6,,0,,,False,t3_iqzfy4,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1599887623.0,text,6,,,text,self.tensorflow,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iqzfy4,True,,HotAd8181,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/iqzfy4/how_would_one_go_about_building_a_sequence_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iqzfy4/how_would_one_go_about_building_a_sequence_to/,22217,1599858823.0,0,,False,,,,,,,,,
845,,tensorflow,"## System information:
Red Hat Enterprise Linux Server release 7.7 (Maipo)
Tensorflow: tensorflow gpu 2.1
GPU: Nvidia V100
Python: 3.6.10
GCC: 7.3.0
CUDA: 10.1 (I think)
Running through slurm

## The Error log:

```
ValueError: could not broadcast input array from shape (850,550,3) into shape (850,550,3,3)
```

## model.summary()
This model is the stock xception with a custom top (global max, dense layer, and softmax) used for image classification. 
                    

        __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to
    ==================================================================================================
    input_2 (InputLayer)            [(None, 850, 550, 3) 0
    __________________________________________________________________________________________________
    block1_conv1 (Conv2D)           (None, 424, 274, 32) 864         input_2[0][0]
    __________________________________________________________________________________________________
    block1_conv1_bn (BatchNormaliza (None, 424, 274, 32) 128         block1_conv1[0][0]
    __________________________________________________________________________________________________
    block1_conv1_act (Activation)   (None, 424, 274, 32) 0           block1_conv1_bn[0][0]


## Relevant Code    
    import numpy as np
    import pandas as pd
    import tensorflow
    from tensorflow import keras
    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
    from tensorflow.keras.utils import to_categorical
    from sklearn.model_selection import train_test_split
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.models import load_model
    from tensorflow.keras.models import Model, Sequential
    from tensorflow.keras.applications import Xception
    from tensorflow.keras.preprocessing import image
    from tensorflow.keras.layers import Flatten, Dense, Input, GlobalAvgPool2D
    from tensorflow.keras import optimizers
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
    import matplotlib.pyplot as plt
    import random
    import os
    import time
    from datetime import datetime
    from IPython.display import SVG
    from PIL import ImageFile
    ImageFile.LOAD_TRUNCATED_IMAGES = True
    
    
    
    from pathlib import Path
    root_path = Path(__file__).resolve().parents[2]
    print(root_path)
    
    # verify gpus
    print(tensorflow.config.list_physical_devices('GPU'))
    
    
    FAST_RUN = False
    IMAGE_HEIGHT=850
    IMAGE_WIDTH=550
    IMAGE_CHANNELS=3
    IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)
    
    input_tensor_def = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # unused for now
    
    
    NAME = f""{datetime.today().strftime('%Y-%m-%d')}-xception_850_flowering_keras_xception""
    
    
    model_core = Xception(weights = None, include_top = False, input_shape = IMAGE_SIZE)
    
    model_head = model_core.output
    model_head = GlobalAvgPool2D()(model_head)
    model_head = Flatten()(model_head)
    model_head = Dense(512, activation = 'relu')(model_head)
    model_head = Dense(256, activation = 'relu')(model_head)
    model_head = Dense(2, activation = 'softmax')(model_head)
    
    model = Model(inputs = model_core.input, outputs = model_head)
    
    model.compile(Adam(lr=.00005), loss='categorical_crossentropy', metrics=['accuracy'])
    
    print(model.summary())
    
    earlystop = EarlyStopping(patience=20)
    
    
    filepath=f""{root_path}/Models/xception/{NAME}.hdf5""
    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
    
    callbacks = [earlystop, checkpoint]
    
    
    # hard coded for now, replace later
    nb_train_samples = 33960
    nb_validation_samples = 8482
    batch_size=16
    
    train_path = '/gpfs/loomis/home.grace/teo22/project/Herbarium/Train_Cropped_850_8_8_Flowering'
    valid_path = '/gpfs/loomis/home.grace/teo22/project/Herbarium/Valid_Cropped_850_8_8_Flowering'
    
    train_datagen = ImageDataGenerator(
        rotation_range=15,
        rescale=1./255,
        shear_range=0.1,
        zoom_range=0.2,
        horizontal_flip=True,
        width_shift_range=0.1,
        height_shift_range=0.1
    )
    train_generator = train_datagen.flow_from_directory(
        train_path, target_size=IMAGE_SIZE, class_mode='categorical', classes=['Flowering', 'Not_Flowering'], batch_size=batch_size)
    
    validation_datagen = ImageDataGenerator(rescale=1./255)
    validation_generator = validation_datagen.flow_from_directory(
        valid_path, target_size=IMAGE_SIZE, class_mode='categorical', classes=['Flowering', 'Not_Flowering'], batch_size=batch_size)
    
    print(nb_validation_samples//batch_size)
    
    epochs=3 if FAST_RUN else 500
    history = model.fit_generator(
        train_generator,
        epochs=epochs,
        validation_data=validation_generator,
        validation_steps=nb_validation_samples//batch_size,
        steps_per_epoch=nb_train_samples//batch_size,
        callbacks=callbacks
    )

## My thoughts
I feel like normally with broadcasting errors, it's generally related to the sizes of the images, or it fails to broadcast from a 3-dim input tensor to the 4-dim (batch, height ,width,channels) tensor. However, here, it just seems like the code has forgotten about the existence of the batch dimension and confused height for batches, width for height, and channels for both width and channels. I have double checked my code, but to my (admittedly very limited) knowledge, everything looks okay.",t2_fm74a,False,,0,False,xception broadcast issue with custom size,[],r/tensorflow,False,6,,0,,,False,t3_ir0y0e,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1599892784.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h2&gt;System information:&lt;/h2&gt;

&lt;p&gt;Red Hat Enterprise Linux Server release 7.7 (Maipo)
Tensorflow: tensorflow gpu 2.1
GPU: Nvidia V100
Python: 3.6.10
GCC: 7.3.0
CUDA: 10.1 (I think)
Running through slurm&lt;/p&gt;

&lt;h2&gt;The Error log:&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;
ValueError: could not broadcast input array from shape (850,550,3) into shape (850,550,3,3)
&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;model.summary()&lt;/h2&gt;

&lt;p&gt;This model is the stock xception with a custom top (global max, dense layer, and softmax) used for image classification. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    __________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_2 (InputLayer)            [(None, 850, 550, 3) 0
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 424, 274, 32) 864         input_2[0][0]
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 424, 274, 32) 128         block1_conv1[0][0]
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 424, 274, 32) 0           block1_conv1_bn[0][0]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Relevant Code&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
import pandas as pd
import tensorflow
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.applications import Xception
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Flatten, Dense, Input, GlobalAvgPool2D
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import matplotlib.pyplot as plt
import random
import os
import time
from datetime import datetime
from IPython.display import SVG
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True



from pathlib import Path
root_path = Path(__file__).resolve().parents[2]
print(root_path)

# verify gpus
print(tensorflow.config.list_physical_devices(&amp;#39;GPU&amp;#39;))


FAST_RUN = False
IMAGE_HEIGHT=850
IMAGE_WIDTH=550
IMAGE_CHANNELS=3
IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)

input_tensor_def = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # unused for now


NAME = f&amp;quot;{datetime.today().strftime(&amp;#39;%Y-%m-%d&amp;#39;)}-xception_850_flowering_keras_xception&amp;quot;


model_core = Xception(weights = None, include_top = False, input_shape = IMAGE_SIZE)

model_head = model_core.output
model_head = GlobalAvgPool2D()(model_head)
model_head = Flatten()(model_head)
model_head = Dense(512, activation = &amp;#39;relu&amp;#39;)(model_head)
model_head = Dense(256, activation = &amp;#39;relu&amp;#39;)(model_head)
model_head = Dense(2, activation = &amp;#39;softmax&amp;#39;)(model_head)

model = Model(inputs = model_core.input, outputs = model_head)

model.compile(Adam(lr=.00005), loss=&amp;#39;categorical_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])

print(model.summary())

earlystop = EarlyStopping(patience=20)


filepath=f&amp;quot;{root_path}/Models/xception/{NAME}.hdf5&amp;quot;
checkpoint = ModelCheckpoint(filepath, monitor=&amp;#39;val_accuracy&amp;#39;, verbose=1, save_best_only=True, mode=&amp;#39;max&amp;#39;)

callbacks = [earlystop, checkpoint]


# hard coded for now, replace later
nb_train_samples = 33960
nb_validation_samples = 8482
batch_size=16

train_path = &amp;#39;/gpfs/loomis/home.grace/teo22/project/Herbarium/Train_Cropped_850_8_8_Flowering&amp;#39;
valid_path = &amp;#39;/gpfs/loomis/home.grace/teo22/project/Herbarium/Valid_Cropped_850_8_8_Flowering&amp;#39;

train_datagen = ImageDataGenerator(
    rotation_range=15,
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)
train_generator = train_datagen.flow_from_directory(
    train_path, target_size=IMAGE_SIZE, class_mode=&amp;#39;categorical&amp;#39;, classes=[&amp;#39;Flowering&amp;#39;, &amp;#39;Not_Flowering&amp;#39;], batch_size=batch_size)

validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_directory(
    valid_path, target_size=IMAGE_SIZE, class_mode=&amp;#39;categorical&amp;#39;, classes=[&amp;#39;Flowering&amp;#39;, &amp;#39;Not_Flowering&amp;#39;], batch_size=batch_size)

print(nb_validation_samples//batch_size)

epochs=3 if FAST_RUN else 500
history = model.fit_generator(
    train_generator,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples//batch_size,
    steps_per_epoch=nb_train_samples//batch_size,
    callbacks=callbacks
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;My thoughts&lt;/h2&gt;

&lt;p&gt;I feel like normally with broadcasting errors, it&amp;#39;s generally related to the sizes of the images, or it fails to broadcast from a 3-dim input tensor to the 4-dim (batch, height ,width,channels) tensor. However, here, it just seems like the code has forgotten about the existence of the batch dimension and confused height for batches, width for height, and channels for both width and channels. I have double checked my code, but to my (admittedly very limited) knowledge, everything looks okay.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ir0y0e,True,,flamefoxx99,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ir0y0e/xception_broadcast_issue_with_custom_size/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ir0y0e/xception_broadcast_issue_with_custom_size/,22217,1599863984.0,0,,False,,,,,,,,,
846,,tensorflow,,t2_14fi3s,False,,0,False,Why TensorFlow Lite Has Been Running Slower On Recent Linux Kernels,[],r/tensorflow,False,6,,0,140.0,,False,t3_iqg216,False,dark,0.93,,public,11,0,{},140.0,,False,[],,False,False,,{},,False,11,,False,https://b.thumbs.redditmedia.com/4ARV3K17U3EqApx-C6KE8cMkuWZoAOKDCkbxpWaATkU.jpg,False,,[],{},,False,,1599813260.0,text,6,,,text,phoronix.com,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iqg216,True,,fsher,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iqg216/why_tensorflow_lite_has_been_running_slower_on/,all_ads,False,https://www.phoronix.com/scan.php?page=article&amp;item=tflite-kernel-regress&amp;num=1,22217,1599784460.0,0,,False,link,https://www.phoronix.com/scan.php?page=article&amp;item=tflite-kernel-regress&amp;num=1,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Hlfx8jIzRkkflb8GjHhguCFwdmWMlrqbsw_jnyJ2jjc.jpg?auto=webp&amp;s=203daf782f8240acb88dec6557ffbb3d33f356a0', 'width': 652, 'height': 658}, 'resolutions': [{'url': 'https://external-preview.redd.it/Hlfx8jIzRkkflb8GjHhguCFwdmWMlrqbsw_jnyJ2jjc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5295ffe47c97afdca9b49e0451a1adb449d56b74', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/Hlfx8jIzRkkflb8GjHhguCFwdmWMlrqbsw_jnyJ2jjc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0218f1ea4e10d71b4e144ac04262d985605b612a', 'width': 216, 'height': 217}, {'url': 'https://external-preview.redd.it/Hlfx8jIzRkkflb8GjHhguCFwdmWMlrqbsw_jnyJ2jjc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14e7d5869c30e2bf1e7809b9f6c9e425c2bd0650', 'width': 320, 'height': 322}, {'url': 'https://external-preview.redd.it/Hlfx8jIzRkkflb8GjHhguCFwdmWMlrqbsw_jnyJ2jjc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b80caab0c9ce5c21d1e83352a3d992480611bd58', 'width': 640, 'height': 645}], 'variants': {}, 'id': 'eAZnC8Favl9mVsq27c0ckRAdOs1Eyi68GMop4VgmfmA'}], 'enabled': False}",,,,,,
847,,tensorflow,"Hi

I take this course in [Udemy](https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/)

The title is Tensorflow but in Syllabus I do not see it as a topic, I passed Numpy and now learning Pandas, and I enjoy it.

But what is Tensorflow?  

#",t2_8cpp,False,,0,False,Tensorflow environment,[],r/tensorflow,False,6,,0,,,False,t3_iqky1s,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1599832653.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I take this course in &lt;a href=""https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/""&gt;Udemy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The title is Tensorflow but in Syllabus I do not see it as a topic, I passed Numpy and now learning Pandas, and I enjoy it.&lt;/p&gt;

&lt;p&gt;But what is Tensorflow?  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iqky1s,True,,rsegoly,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/iqky1s/tensorflow_environment/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iqky1s/tensorflow_environment/,22217,1599803853.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/DxGW9MqdIgN1pkGyJVoQGOGLWQcIh1D4oypV-9RSE8Q.jpg?auto=webp&amp;s=d00450919d7fdb817e4442b6661e37a603d24700', 'width': 480, 'height': 270}, 'resolutions': [{'url': 'https://external-preview.redd.it/DxGW9MqdIgN1pkGyJVoQGOGLWQcIh1D4oypV-9RSE8Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddcc9bb57a3ace510d15bc923e7a059ae0eb2f3b', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/DxGW9MqdIgN1pkGyJVoQGOGLWQcIh1D4oypV-9RSE8Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a171afbd3423839416916e15c05861bd808cf3f4', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/DxGW9MqdIgN1pkGyJVoQGOGLWQcIh1D4oypV-9RSE8Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0675b37e5e54df1332791249342390818117abb4', 'width': 320, 'height': 180}], 'variants': {}, 'id': '4DSow9fRYUux9TSJ7TJF9BWF9-lqMkDHw42E-cNVA2E'}], 'enabled': False}",,,,,,
848,,tensorflow,"Hello, I've been having this question in my mind for quite a while.

When Evaluating the model with the COCO metrics, there are a few options for max detections (1, 10, 100).

Lets consider that there are 100 object in the image and we just calculate the Precision/Recall with max detections = 1. Are the other groundthruths not being considered in the confusion matrix? 

This is what makes sense to me, that they will not be considered, and only the prediction with best score and the respective groundthuth will be when calculating the metric.

If I did not make myself clear, I would very much appreciate if someone would clarify the max detections part in the metrics!",t2_607rias5,False,,0,False,Tensorflow Object Detection API - Average Precision/Recall with max detections,[],r/tensorflow,False,6,,0,,,False,t3_iqiaap,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1599821356.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I&amp;#39;ve been having this question in my mind for quite a while.&lt;/p&gt;

&lt;p&gt;When Evaluating the model with the COCO metrics, there are a few options for max detections (1, 10, 100).&lt;/p&gt;

&lt;p&gt;Lets consider that there are 100 object in the image and we just calculate the Precision/Recall with max detections = 1. Are the other groundthruths not being considered in the confusion matrix? &lt;/p&gt;

&lt;p&gt;This is what makes sense to me, that they will not be considered, and only the prediction with best score and the respective groundthuth will be when calculating the metric.&lt;/p&gt;

&lt;p&gt;If I did not make myself clear, I would very much appreciate if someone would clarify the max detections part in the metrics!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iqiaap,True,,Akroma188,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/iqiaap/tensorflow_object_detection_api_average/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iqiaap/tensorflow_object_detection_api_average/,22217,1599792556.0,0,,False,,,,,,,,,
849,,tensorflow,,t2_ibs89,False,,0,False,Easy ML mobile development with TensorFlow Lite Task Library,[],r/tensorflow,False,6,,0,73.0,,False,t3_iq9tl5,False,dark,1.0,,public,3,0,{},140.0,,False,[],,False,False,,{},,False,3,,False,https://b.thumbs.redditmedia.com/rB8vYfkYeCN5VasnwqvAXI5mJbKW2PZIp0y8KuCg0So.jpg,False,,[],{},,False,,1599793292.0,text,6,,,text,blog.tensorflow.org,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iq9tl5,True,,nbortolotti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iq9tl5/easy_ml_mobile_development_with_tensorflow_lite/,all_ads,False,https://blog.tensorflow.org/2020/09/introducing-tensorflow-lite-task-library.html,22217,1599764492.0,0,,False,link,https://blog.tensorflow.org/2020/09/introducing-tensorflow-lite-task-library.html,"{'images': [{'source': {'url': 'https://external-preview.redd.it/968HhMk3T8JJu5ebsNUIcsS4wJhTFtK7Z2Sxr52Z8aM.jpg?auto=webp&amp;s=7a54f809822498b1eca335698194569a631e3da1', 'width': 640, 'height': 336}, 'resolutions': [{'url': 'https://external-preview.redd.it/968HhMk3T8JJu5ebsNUIcsS4wJhTFtK7Z2Sxr52Z8aM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8588a2400d9199af28660d78061cd4459eacddc', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/968HhMk3T8JJu5ebsNUIcsS4wJhTFtK7Z2Sxr52Z8aM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e3dc5d220ef7894d86f8f949b69980157835968c', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/968HhMk3T8JJu5ebsNUIcsS4wJhTFtK7Z2Sxr52Z8aM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e8220a14931d4f4c45b82e17300da3a8848bcc62', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/968HhMk3T8JJu5ebsNUIcsS4wJhTFtK7Z2Sxr52Z8aM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad8c45967cf6e9b22eb61324d14369061c60654b', 'width': 640, 'height': 336}], 'variants': {}, 'id': 'tS58_t5TwoqraAW95YMt68-JoHYrV0HOvn95GSNoCMY'}], 'enabled': False}",,,,,,
850,,tensorflow,"I'm trying to implement a generator in Keras, but my system is still running out of memory (36GB available). Each set of 64 images and masks totals \~100MB. I can't even get through one epoch without consuming &gt;30GB of memory.

Here is my generator code:

    import numpy as np
    import tensorflow as tf
    import keras
    import glob
    import math
    
    
    def getFiles(stack_dir, mask_dir):
        '''
        ** find all stack images in dir., along with matching mask image files **
        ~~~~~~~~~
        INPUTS:
                - stack_dir = directory containing all stack images
                - mask_dir = directory containing all mask images
        RETURNS:
                - 2d array of stack and mask pairs [[stack_image_loc, mask_image_loc], ...]
        '''
        stacks = []
        masks = []
        for stack_image in glob.glob(stack_dir+""/*.npy""):
            x, y, z = stack_image.split(
                stack_dir+""/stack_tile_"")[1].split("".npy"")[0].split(""_"")
            mask_image = mask_dir+""/mask_tile_{}_{}_{}.npy"".format(x, y, z)
            stacks.append(stack_image)
            masks.append(mask_image)
        return stacks, masks
    
    
    class dataset_gen(keras.utils.Sequence):
        ' See https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence'
    
        def __init__(self, stacks, masks, batch_size):
            self.stacks = stacks
            self.masks = masks
            self.batch_size = batch_size
    
        def __len__(self):
            ' number of batches per epoch '
            return math.ceil(len(self.stacks) / self.batch_size)
    
        def __getitem__(self, index):
            print(""\n\n\n{}\n\n\n"".format(index))
            indices = [index*self.batch_size, index+1*self.batch_size]
            i = indices[0]
            temp = []
            while i &lt; indices[1]:
                temp.append(i)
                i = i+1
    
            X, y = self.__data_generation(temp)
    
            return X, y
    
        def __data_generation(self, list_IDs_temp):
            X = np.empty(
                (self.batch_size, *(256, 256), 5))
            Y = np.empty(
                (self.batch_size, *(256, 256), 3))
    
            for i, ID in enumerate(list_IDs_temp):
                X[i, ] = np.load(self.stacks[ID])
                Y[i, ] = np.load(self.masks[ID])
    
            return X, Y
    

and a basic training setup:

    import tensorflow as tf
    
    import sys
    
    from tensorflow.keras.backend import pow
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add
    from tensorflow.keras.losses import binary_crossentropy
    
    
    from resunetBuild import *
    from generator import *
    
    TRAIN_LENGTH=5000
    EPOCHS=20
    BATCH_SIZE=64
    BUFFER_SIZE=100
    STEPS_PER_EPOCH=TRAIN_LENGTH // BATCH_SIZE
    
    stacks,masks=getFiles('/home/george/Documents/Github/larger-dataset-test/Data/np_tiles/stack', '/home/george/Documents/Github/larger-dataset-test/Data/np_tiles/mask')
    
    train_dataset = dataset_gen(stacks, masks, BATCH_SIZE)
    
    
    model = resuneta(256, 256, channels=5, outClasses=3)
    adam=tf.keras.optimizers.Adam(lr=0.05, epsilon=0.1)
    model.compile(optimizer=adam, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    
    history=model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH)

&amp;#x200B;

Is there a problem with my generator, or is this likely the result of the model that I'm training?",t2_1cjispl7,False,,0,False,Data Generators - TF &amp; Keras,[],r/tensorflow,False,6,,0,,,False,t3_iq4js3,False,dark,0.88,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1599777551.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to implement a generator in Keras, but my system is still running out of memory (36GB available). Each set of 64 images and masks totals ~100MB. I can&amp;#39;t even get through one epoch without consuming &amp;gt;30GB of memory.&lt;/p&gt;

&lt;p&gt;Here is my generator code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
import tensorflow as tf
import keras
import glob
import math


def getFiles(stack_dir, mask_dir):
    &amp;#39;&amp;#39;&amp;#39;
    ** find all stack images in dir., along with matching mask image files **
    ~~~~~~~~~
    INPUTS:
            - stack_dir = directory containing all stack images
            - mask_dir = directory containing all mask images
    RETURNS:
            - 2d array of stack and mask pairs [[stack_image_loc, mask_image_loc], ...]
    &amp;#39;&amp;#39;&amp;#39;
    stacks = []
    masks = []
    for stack_image in glob.glob(stack_dir+&amp;quot;/*.npy&amp;quot;):
        x, y, z = stack_image.split(
            stack_dir+&amp;quot;/stack_tile_&amp;quot;)[1].split(&amp;quot;.npy&amp;quot;)[0].split(&amp;quot;_&amp;quot;)
        mask_image = mask_dir+&amp;quot;/mask_tile_{}_{}_{}.npy&amp;quot;.format(x, y, z)
        stacks.append(stack_image)
        masks.append(mask_image)
    return stacks, masks


class dataset_gen(keras.utils.Sequence):
    &amp;#39; See https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence&amp;#39;

    def __init__(self, stacks, masks, batch_size):
        self.stacks = stacks
        self.masks = masks
        self.batch_size = batch_size

    def __len__(self):
        &amp;#39; number of batches per epoch &amp;#39;
        return math.ceil(len(self.stacks) / self.batch_size)

    def __getitem__(self, index):
        print(&amp;quot;\n\n\n{}\n\n\n&amp;quot;.format(index))
        indices = [index*self.batch_size, index+1*self.batch_size]
        i = indices[0]
        temp = []
        while i &amp;lt; indices[1]:
            temp.append(i)
            i = i+1

        X, y = self.__data_generation(temp)

        return X, y

    def __data_generation(self, list_IDs_temp):
        X = np.empty(
            (self.batch_size, *(256, 256), 5))
        Y = np.empty(
            (self.batch_size, *(256, 256), 3))

        for i, ID in enumerate(list_IDs_temp):
            X[i, ] = np.load(self.stacks[ID])
            Y[i, ] = np.load(self.masks[ID])

        return X, Y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and a basic training setup:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf

import sys

from tensorflow.keras.backend import pow
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add
from tensorflow.keras.losses import binary_crossentropy


from resunetBuild import *
from generator import *

TRAIN_LENGTH=5000
EPOCHS=20
BATCH_SIZE=64
BUFFER_SIZE=100
STEPS_PER_EPOCH=TRAIN_LENGTH // BATCH_SIZE

stacks,masks=getFiles(&amp;#39;/home/george/Documents/Github/larger-dataset-test/Data/np_tiles/stack&amp;#39;, &amp;#39;/home/george/Documents/Github/larger-dataset-test/Data/np_tiles/mask&amp;#39;)

train_dataset = dataset_gen(stacks, masks, BATCH_SIZE)


model = resuneta(256, 256, channels=5, outClasses=3)
adam=tf.keras.optimizers.Adam(lr=0.05, epsilon=0.1)
model.compile(optimizer=adam, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[&amp;#39;accuracy&amp;#39;])

history=model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is there a problem with my generator, or is this likely the result of the model that I&amp;#39;m training?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iq4js3,True,,GeorgeFree2018,,7,True,all_ads,False,[],False,,/r/tensorflow/comments/iq4js3/data_generators_tf_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iq4js3/data_generators_tf_keras/,22217,1599748751.0,0,,False,,,,,,,,,
851,,tensorflow,"I am trying to implement the learned regularisation term (5) from https://arxiv.org/pdf/1806.06438.pdf in a custom loss function in tensorflow 2.1. 

I was wondering how to recover weights of a network, w, in a custom loss function, and how to then use them in the way presented. Suppose I have array \mu in R^d and Sigma in R^dxd already. The learned reg term is given by:

(w - mu)^T Sigma^-1 (w-mu)

I can recover weights in a loss function by doing: 
``model.trainable_weights.``
However this returns a list. I feel like my problem is because my python ability is limited.

My questions are 

1. How do I use the list / convert it to be used in the term I need in the tensorflow backend? tf.convert_to_tensor(model.trainable_weights) doesn't work.

2. Will calling model.trainable_weights change dynamically in the loss function after each epoch?",t2_9b8qm,False,,0,False,Custom loss function: Using network parameters directly in a loss function.,[],r/tensorflow,False,6,,0,,,False,t3_ipjnhk,False,dark,0.92,,public,10,0,{},,,False,[],,False,False,,{},,False,10,,False,self,1599752204.0,,[],{},,True,,1599698793.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to implement the learned regularisation term (5) from &lt;a href=""https://arxiv.org/pdf/1806.06438.pdf""&gt;https://arxiv.org/pdf/1806.06438.pdf&lt;/a&gt; in a custom loss function in tensorflow 2.1. &lt;/p&gt;

&lt;p&gt;I was wondering how to recover weights of a network, w, in a custom loss function, and how to then use them in the way presented. Suppose I have array \mu in R&lt;sup&gt;d&lt;/sup&gt; and Sigma in R&lt;sup&gt;dxd&lt;/sup&gt; already. The learned reg term is given by:&lt;/p&gt;

&lt;p&gt;(w - mu)&lt;sup&gt;T&lt;/sup&gt; Sigma&lt;sup&gt;-1&lt;/sup&gt; (w-mu)&lt;/p&gt;

&lt;p&gt;I can recover weights in a loss function by doing: 
&lt;code&gt;model.trainable_weights.&lt;/code&gt;
However this returns a list. I feel like my problem is because my python ability is limited.&lt;/p&gt;

&lt;p&gt;My questions are &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;How do I use the list / convert it to be used in the term I need in the tensorflow backend? tf.convert_to_tensor(model.trainable_weights) doesn&amp;#39;t work.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Will calling model.trainable_weights change dynamically in the loss function after each epoch?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ipjnhk,True,,LiamRB,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ipjnhk/custom_loss_function_using_network_parameters/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ipjnhk/custom_loss_function_using_network_parameters/,22217,1599669993.0,0,,False,,,,,,,,,
852,,tensorflow,"So I'm running the program [https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/](https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/) on my system but facing some error although a few months ago, there was no error. Kindly help me resolve the issue.

    def train_model(weight = None, epochs = 10):
      # load dataset
      data = ld.prepare_dataset('train')
      train_features, train_descriptions = data[0]
      test_features, test_descriptions = data[1]
      print(len(train_features),len(train_descriptions))
      print(len(test_features), len(test_descriptions))
    
      # prepare tokenizer
      tokenizer = gen.create_tokenizer(train_descriptions)
      # save the tokenizer
      dump(tokenizer, open('C:\\Users\HareeM\Image_Captioning_master5\models\\tokenizer.pkl', 'wb'))
      # index_word dict
      index_word = {v: k for k, v in tokenizer.word_index.items()}
      # save dict
      dump(index_word, open('C:\\Users\HareeM\Image_Captioning_master5\models\index_word.pkl', 'wb'))
    
      vocab_size = len(tokenizer.word_index) + 1
      print('Vocabulary Size: %d' % vocab_size)
    
      # determine the maximum sequence length
      max_length = gen.max_length(train_descriptions)
      print('Description Length: %d' % max_length)
    
      # generate model
      model = gen.define_model(vocab_size, max_length)
    
      # Check if pre-trained weights to be used
      if weight != None:
        model.load_weights(weight)
    
      # define checkpoint callback
      filepath = 'C:\\Users\HareeM\Image_Captioning_master5\models\model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'
      checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1,
                    save_best_only=True, mode='min')
    
      steps = len(train_descriptions)
      val_steps = len(test_descriptions)
      # create the data generator
      train_generator = gen.data_generator(train_descriptions, train_features, tokenizer, max_length)
      val_generator = gen.data_generator(test_descriptions, test_features, tokenizer, max_length)
    
      # fit model
      model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=steps, verbose=1, callbacks=[checkpoint], validation_data=val_generator, validation_steps=val_steps)
    
      try:
          model.save('C:\\Users\HareeM\Image_Captioning_master5\models\wholeModel.h5', overwrite=True)
          model.save_weights('C:\\Users\HareeM\Image_Captioning_master5\models\weights.h5',overwrite=True)
      except:
          print(""Error in saving model."")
      print(""Training complete...\n"")
    
    if __name__ == '__main__':
        train_model(epochs=10)
    

Model is:

    def define_model(vocab_size, max_length):
      # feature extractor (encoder)
      inputs1 = Input(shape=(4096,))
      fe1 = Dropout(0.5)(inputs1)
      fe2 = Dense(256, activation='relu')(fe1)
      # sequence model
      inputs2 = Input(shape=(max_length,))
      se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
      se2 = Dropout(0.5)(se1)
      se3 = LSTM(256)(se2)
      # decoder model
      decoder1 = add([fe2, se3])
      decoder2 = Dense(256, activation='relu')(decoder1)
      outputs = Dense(vocab_size, activation='softmax')(decoder2)
      # tie it together [image, seq] [word]
      model = Model(inputs=[inputs1, inputs2], outputs=outputs)
      model.compile(loss='categorical_crossentropy', optimizer='adam')
      # summarize model
      print(model.summary())
      plot_model(model, to_file='model.png', show_shapes=True)
      return model

Error:

    Traceback (most recent call last):
      File ""D:/Hareem/Image_Captioning_master5/CapGenerator/train_model.py"", line 66, in &lt;module&gt;
        train_model(epochs=10)
      File ""D:/Hareem/Image_Captioning_master5/CapGenerator/train_model.py"", line 38, in train_model
        model = gen.define_model(vocab_size, max_length)
      File ""D:\Hareem\Image_Captioning_master5\CapGenerator\generate_model.py"", line 126, in define_model
        se3 = LSTM(256)(se2)
    
    ValueError: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=""NCHW""](add, BiasAdd/ReadVariableOp)' with input shapes: [?,1024], [1024].",t2_5lnovny1,False,,0,False,"ValueError: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=""NCHW""](add, BiasAdd/ReadVariableOp)' with input shapes: [?,1024], [1024].",[],r/tensorflow,False,6,,0,,,False,t3_ipbse4,False,dark,0.86,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1599667180.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;m running the program &lt;a href=""https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/""&gt;https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/&lt;/a&gt; on my system but facing some error although a few months ago, there was no error. Kindly help me resolve the issue.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def train_model(weight = None, epochs = 10):
  # load dataset
  data = ld.prepare_dataset(&amp;#39;train&amp;#39;)
  train_features, train_descriptions = data[0]
  test_features, test_descriptions = data[1]
  print(len(train_features),len(train_descriptions))
  print(len(test_features), len(test_descriptions))

  # prepare tokenizer
  tokenizer = gen.create_tokenizer(train_descriptions)
  # save the tokenizer
  dump(tokenizer, open(&amp;#39;C:\\Users\HareeM\Image_Captioning_master5\models\\tokenizer.pkl&amp;#39;, &amp;#39;wb&amp;#39;))
  # index_word dict
  index_word = {v: k for k, v in tokenizer.word_index.items()}
  # save dict
  dump(index_word, open(&amp;#39;C:\\Users\HareeM\Image_Captioning_master5\models\index_word.pkl&amp;#39;, &amp;#39;wb&amp;#39;))

  vocab_size = len(tokenizer.word_index) + 1
  print(&amp;#39;Vocabulary Size: %d&amp;#39; % vocab_size)

  # determine the maximum sequence length
  max_length = gen.max_length(train_descriptions)
  print(&amp;#39;Description Length: %d&amp;#39; % max_length)

  # generate model
  model = gen.define_model(vocab_size, max_length)

  # Check if pre-trained weights to be used
  if weight != None:
    model.load_weights(weight)

  # define checkpoint callback
  filepath = &amp;#39;C:\\Users\HareeM\Image_Captioning_master5\models\model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5&amp;#39;
  checkpoint = ModelCheckpoint(filepath, monitor=&amp;#39;val_loss&amp;#39;, verbose=1,
                save_best_only=True, mode=&amp;#39;min&amp;#39;)

  steps = len(train_descriptions)
  val_steps = len(test_descriptions)
  # create the data generator
  train_generator = gen.data_generator(train_descriptions, train_features, tokenizer, max_length)
  val_generator = gen.data_generator(test_descriptions, test_features, tokenizer, max_length)

  # fit model
  model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=steps, verbose=1, callbacks=[checkpoint], validation_data=val_generator, validation_steps=val_steps)

  try:
      model.save(&amp;#39;C:\\Users\HareeM\Image_Captioning_master5\models\wholeModel.h5&amp;#39;, overwrite=True)
      model.save_weights(&amp;#39;C:\\Users\HareeM\Image_Captioning_master5\models\weights.h5&amp;#39;,overwrite=True)
  except:
      print(&amp;quot;Error in saving model.&amp;quot;)
  print(&amp;quot;Training complete...\n&amp;quot;)

if __name__ == &amp;#39;__main__&amp;#39;:
    train_model(epochs=10)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Model is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def define_model(vocab_size, max_length):
  # feature extractor (encoder)
  inputs1 = Input(shape=(4096,))
  fe1 = Dropout(0.5)(inputs1)
  fe2 = Dense(256, activation=&amp;#39;relu&amp;#39;)(fe1)
  # sequence model
  inputs2 = Input(shape=(max_length,))
  se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
  se2 = Dropout(0.5)(se1)
  se3 = LSTM(256)(se2)
  # decoder model
  decoder1 = add([fe2, se3])
  decoder2 = Dense(256, activation=&amp;#39;relu&amp;#39;)(decoder1)
  outputs = Dense(vocab_size, activation=&amp;#39;softmax&amp;#39;)(decoder2)
  # tie it together [image, seq] [word]
  model = Model(inputs=[inputs1, inputs2], outputs=outputs)
  model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;, optimizer=&amp;#39;adam&amp;#39;)
  # summarize model
  print(model.summary())
  plot_model(model, to_file=&amp;#39;model.png&amp;#39;, show_shapes=True)
  return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Traceback (most recent call last):
  File &amp;quot;D:/Hareem/Image_Captioning_master5/CapGenerator/train_model.py&amp;quot;, line 66, in &amp;lt;module&amp;gt;
    train_model(epochs=10)
  File &amp;quot;D:/Hareem/Image_Captioning_master5/CapGenerator/train_model.py&amp;quot;, line 38, in train_model
    model = gen.define_model(vocab_size, max_length)
  File &amp;quot;D:\Hareem\Image_Captioning_master5\CapGenerator\generate_model.py&amp;quot;, line 126, in define_model
    se3 = LSTM(256)(se2)

ValueError: Shape must be at least rank 3 but is rank 2 for &amp;#39;{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=&amp;quot;NCHW&amp;quot;](add, BiasAdd/ReadVariableOp)&amp;#39; with input shapes: [?,1024], [1024].
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ipbse4,True,,Hareem97,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ipbse4/valueerror_shape_must_be_at_least_rank_3_but_is/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ipbse4/valueerror_shape_must_be_at_least_rank_3_but_is/,22217,1599638380.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/3C9FX7c6u9LNUsOhoLBKrIMiTz7J6tAF0M9xAIWSZjM.jpg?auto=webp&amp;s=ecfd427acb1ef03d3184edd0181daa546c070edc', 'width': 640, 'height': 512}, 'resolutions': [{'url': 'https://external-preview.redd.it/3C9FX7c6u9LNUsOhoLBKrIMiTz7J6tAF0M9xAIWSZjM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e33550aa96bbe972cc25a5dfe354c6050df63771', 'width': 108, 'height': 86}, {'url': 'https://external-preview.redd.it/3C9FX7c6u9LNUsOhoLBKrIMiTz7J6tAF0M9xAIWSZjM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=22ddaf93c9b8ed26a18292309176c7d3ab09843f', 'width': 216, 'height': 172}, {'url': 'https://external-preview.redd.it/3C9FX7c6u9LNUsOhoLBKrIMiTz7J6tAF0M9xAIWSZjM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=37477b05016528b3adf2b984b15185e81f34c17d', 'width': 320, 'height': 256}, {'url': 'https://external-preview.redd.it/3C9FX7c6u9LNUsOhoLBKrIMiTz7J6tAF0M9xAIWSZjM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6edfe60d0961ba80fadbecf04676c52cf09520ba', 'width': 640, 'height': 512}], 'variants': {}, 'id': 'aWaEpHEDp23zGEZwi_8pv0xfbQnzuMxrOWB8yCYcSpo'}], 'enabled': False}",,,,,,
853,,tensorflow,"I   understand this will be a lot to ask of someone, but I've been at this   for over a month now and can't seem to improve my TF GAN so I need  some  help.

I'm just trying to  learn the  ropes. It's been a very useful experience, and I think my  code will be  helpful to many people. I started with Colab notebooks  from TF official  and a well known PyTorch tutorial and then commented  and improved the  code along the way. The TF GAN example uses MNIST at  28x28x1 for  example, and I increased the model to cater to higher res.  It's possible  that my architecture there is bad.

Long story short, at about 60 hours of training a 128x128x3 GAN in TF, epoch 17000\~ looks like this:

&amp;#x200B;

https://preview.redd.it/9qyl1uwn4yl51.png?width=1152&amp;format=png&amp;auto=webp&amp;s=b105333e65044a3b2f6b6e42231939f8381e0e41

Whereas  at a little less time than that, my PyTorch GAN at 512x512x3 looked  like this (obviously this is a single image as opposed to a 4x4 image  grid like above):

&amp;#x200B;

https://preview.redd.it/tgxlnyoo4yl51.jpg?width=512&amp;format=pjpg&amp;auto=webp&amp;s=7961d73ac9bb9e5dec7869db71ba1e95a903f1c0

The   pyTorch GAN is clearly better. I want to transition to TF, so please  no  ""just use PyTorch"" answers, unless there is a clear superiority to  the  PT library.

Here is my TF colab: [https://colab.research.google.com/drive/1A9Z5nBT3zZ03PtPSaHc97\_Cmry3bNwpH?usp=sharing](https://colab.research.google.com/drive/1A9Z5nBT3zZ03PtPSaHc97_Cmry3bNwpH?usp=sharing)

Note that the generator has three options, I am concerned with the 128x128 architecture at the moment.

Here is my Torch code:

[https://colab.research.google.com/drive/1\_pzhQrt9NdVQxp47xFqIU7kjXmh-OUqg?usp=sharing](https://colab.research.google.com/drive/1_pzhQrt9NdVQxp47xFqIU7kjXmh-OUqg?usp=sharing)

I used the same flowers photo dataset for both: [https://drive.google.com/file/d/16YGAAJOStFmzNn5fmM\_fDVoyntW0hq1L/view?usp=sharing](https://drive.google.com/file/d/16YGAAJOStFmzNn5fmM_fDVoyntW0hq1L/view?usp=sharing)",t2_5jsg7vd6,False,,0,False,why is my TF GAN not nearly as good as my PyTorch GAN?,[],r/tensorflow,False,6,,0,,,False,t3_iow8ik,False,dark,0.95,,public,33,0,{},,,False,[],,False,False,,{},Question,False,33,,False,self,False,,[],{},,True,,1599609609.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I   understand this will be a lot to ask of someone, but I&amp;#39;ve been at this   for over a month now and can&amp;#39;t seem to improve my TF GAN so I need  some  help.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m just trying to  learn the  ropes. It&amp;#39;s been a very useful experience, and I think my  code will be  helpful to many people. I started with Colab notebooks  from TF official  and a well known PyTorch tutorial and then commented  and improved the  code along the way. The TF GAN example uses MNIST at  28x28x1 for  example, and I increased the model to cater to higher res.  It&amp;#39;s possible  that my architecture there is bad.&lt;/p&gt;

&lt;p&gt;Long story short, at about 60 hours of training a 128x128x3 GAN in TF, epoch 17000~ looks like this:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/9qyl1uwn4yl51.png?width=1152&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b105333e65044a3b2f6b6e42231939f8381e0e41""&gt;https://preview.redd.it/9qyl1uwn4yl51.png?width=1152&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b105333e65044a3b2f6b6e42231939f8381e0e41&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Whereas  at a little less time than that, my PyTorch GAN at 512x512x3 looked  like this (obviously this is a single image as opposed to a 4x4 image  grid like above):&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/tgxlnyoo4yl51.jpg?width=512&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7961d73ac9bb9e5dec7869db71ba1e95a903f1c0""&gt;https://preview.redd.it/tgxlnyoo4yl51.jpg?width=512&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7961d73ac9bb9e5dec7869db71ba1e95a903f1c0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The   pyTorch GAN is clearly better. I want to transition to TF, so please  no  &amp;quot;just use PyTorch&amp;quot; answers, unless there is a clear superiority to  the  PT library.&lt;/p&gt;

&lt;p&gt;Here is my TF colab: &lt;a href=""https://colab.research.google.com/drive/1A9Z5nBT3zZ03PtPSaHc97_Cmry3bNwpH?usp=sharing""&gt;https://colab.research.google.com/drive/1A9Z5nBT3zZ03PtPSaHc97_Cmry3bNwpH?usp=sharing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Note that the generator has three options, I am concerned with the 128x128 architecture at the moment.&lt;/p&gt;

&lt;p&gt;Here is my Torch code:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://colab.research.google.com/drive/1_pzhQrt9NdVQxp47xFqIU7kjXmh-OUqg?usp=sharing""&gt;https://colab.research.google.com/drive/1_pzhQrt9NdVQxp47xFqIU7kjXmh-OUqg?usp=sharing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I used the same flowers photo dataset for both: &lt;a href=""https://drive.google.com/file/d/16YGAAJOStFmzNn5fmM_fDVoyntW0hq1L/view?usp=sharing""&gt;https://drive.google.com/file/d/16YGAAJOStFmzNn5fmM_fDVoyntW0hq1L/view?usp=sharing&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iow8ik,True,,diditforthevideocard,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/iow8ik/why_is_my_tf_gan_not_nearly_as_good_as_my_pytorch/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iow8ik/why_is_my_tf_gan_not_nearly_as_good_as_my_pytorch/,22217,1599580809.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?auto=webp&amp;s=ffc13b63083ce9180bdf2cf28705ee407b659975', 'width': 256, 'height': 256}, 'resolutions': [{'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f53340195fae0f84ec3871625087bf02fd428ab', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/kfDh9FNsuWs5VThFyc16bdwBtJ99FmMWgOZYUyq7LPg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6722a649351a89204dede7d65ad009eea43566c', 'width': 216, 'height': 216}], 'variants': {}, 'id': 'mAwt5FN14h93icEvsjkWqFiukRT9FqTVVq54ZHDgaos'}], 'enabled': False}",,"{'9qyl1uwn4yl51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbac3e05f7a6cb7b26a6fc72053d43a44c8a5586'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1ec8c45dee9811326eb373b7119e67218346e3d'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=983b1316b82c8add50025d69eb8d638fa4ebfe03'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c4d006c17e2044e8db3b5176b7226156fbd3333'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a050d34658d62a99236e03772fc9b331093c1c9'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5cba5b6b1adb98248ae2609bd540d9ba79bcf36'}], 's': {'y': 1152, 'x': 1152, 'u': 'https://preview.redd.it/9qyl1uwn4yl51.png?width=1152&amp;format=png&amp;auto=webp&amp;s=b105333e65044a3b2f6b6e42231939f8381e0e41'}, 'id': '9qyl1uwn4yl51'}, 'tgxlnyoo4yl51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/tgxlnyoo4yl51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=03ace05c8dca9fe1f1b3e9258cf4050220e8524a'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/tgxlnyoo4yl51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1bf5db0f41e7bbab860334c70d2d36db301fcae4'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/tgxlnyoo4yl51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf1b406710247efae610c4bd4a459c0f04da463b'}], 's': {'y': 512, 'x': 512, 'u': 'https://preview.redd.it/tgxlnyoo4yl51.jpg?width=512&amp;format=pjpg&amp;auto=webp&amp;s=7961d73ac9bb9e5dec7869db71ba1e95a903f1c0'}, 'id': 'tgxlnyoo4yl51'}}",,,,
854,,tensorflow,"Can someone help me with this question?

I have two tensors, A and B:

A = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(1, 64, 4, 1, 1)))
B = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(32, 1, 4, 256, 256)))

I'm trying to perform this operation:

tf.einsum('abcde,abcde-&gt;abde', A, B) # in other words, ""K.sum(A * B, axis=2)""

But when I run the code, I get a error:

Expected dimension 1 at axis 0 of the input shaped [32,1,4,256,256] but got dimension 32 [Op:Einsum]

I don't understand what is happening, because the same code works using numpy:

A = np.ones((1, 64, 4, 1, 1))
B = np.ones((32, 1, 4, 256, 256))

np.einsum('abcde,abcde-&gt;abde', A, B) # works great

Why do the tensors need to have the same shape on tensorflow? I don't want them to have the same shape because it will consume a LOT of memory, the same code on numpy works perfectly.",t2_6aqt5xxb,False,,0,False,Why tf.einsum is different than np.einsum?,[],r/tensorflow,False,6,,0,,,False,t3_iow3gd,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,1599580557.0,,[],{},,True,,1599609162.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone help me with this question?&lt;/p&gt;

&lt;p&gt;I have two tensors, A and B:&lt;/p&gt;

&lt;p&gt;A = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(1, 64, 4, 1, 1)))
B = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(32, 1, 4, 256, 256)))&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to perform this operation:&lt;/p&gt;

&lt;p&gt;tf.einsum(&amp;#39;abcde,abcde-&amp;gt;abde&amp;#39;, A, B) # in other words, &amp;quot;K.sum(A * B, axis=2)&amp;quot;&lt;/p&gt;

&lt;p&gt;But when I run the code, I get a error:&lt;/p&gt;

&lt;p&gt;Expected dimension 1 at axis 0 of the input shaped [32,1,4,256,256] but got dimension 32 [Op:Einsum]&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t understand what is happening, because the same code works using numpy:&lt;/p&gt;

&lt;p&gt;A = np.ones((1, 64, 4, 1, 1))
B = np.ones((32, 1, 4, 256, 256))&lt;/p&gt;

&lt;p&gt;np.einsum(&amp;#39;abcde,abcde-&amp;gt;abde&amp;#39;, A, B) # works great&lt;/p&gt;

&lt;p&gt;Why do the tensors need to have the same shape on tensorflow? I don&amp;#39;t want them to have the same shape because it will consume a LOT of memory, the same code on numpy works perfectly.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iow3gd,True,,Digital_Secrets,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/iow3gd/why_tfeinsum_is_different_than_npeinsum/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iow3gd/why_tfeinsum_is_different_than_npeinsum/,22217,1599580362.0,0,,False,,,,,,,,,
855,,tensorflow,"Hey People,

I'm trying to insert some custom layer that shifts the tensors output by a layer in a certain way before it is input to the next layer into a pre-trained model. For example when I load a VGG16 with: 

from tensorflow.keras.applications.vgg16 import VGG16

base\_model = VGG16(weights='imagenet', include\_top=False)

Does anyone know how to insert a custom layer between block1 and block 2 for example? The only solution I currently see is that I extract the weights of each layer from the pre-trained model, design a new model with the same layers but my custom layer in between the blocks, and then load the extracted weights of the pre-trained model into the according layers of my new model.

Has anyone an easier approach?",t2_7vgy07ra,False,,0,False,Insert Layers in pre-trained Model,[],r/tensorflow,False,6,,0,,,False,t3_ioveog,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1599606985.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey People,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to insert some custom layer that shifts the tensors output by a layer in a certain way before it is input to the next layer into a pre-trained model. For example when I load a VGG16 with: &lt;/p&gt;

&lt;p&gt;from tensorflow.keras.applications.vgg16 import VGG16&lt;/p&gt;

&lt;p&gt;base_model = VGG16(weights=&amp;#39;imagenet&amp;#39;, include_top=False)&lt;/p&gt;

&lt;p&gt;Does anyone know how to insert a custom layer between block1 and block 2 for example? The only solution I currently see is that I extract the weights of each layer from the pre-trained model, design a new model with the same layers but my custom layer in between the blocks, and then load the extracted weights of the pre-trained model into the according layers of my new model.&lt;/p&gt;

&lt;p&gt;Has anyone an easier approach?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ioveog,True,,TheBigJones93,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ioveog/insert_layers_in_pretrained_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ioveog/insert_layers_in_pretrained_model/,22217,1599578185.0,0,,False,,,,,,,,,
856,,tensorflow,"So I have been looking up on some advice as to how to implement research papers. There are numerous guides out there for pytorch but I wanted to go with Tensorflow2 cz I'm familiar with the syntax. Can someone recommend some resources for getting started with implementing research papers as it looks like a mammoth task to me rn.
I tried implementing a GAN based style transfer paper and even though I feel like I've done things right im not getting the desired results. So I would like to learn this art of implementing papers properly before I go ahead with anything else. 
Would be really grateful if someone could link some really cool resources in the thread.

Thanks in advance❤️

(PS I have looked into paperswithcode.com but would like to implement papers that don't have any existing implementation)",t2_7ufkir8z,False,,0,False,Implementing Research Papers - for beginners,[],r/tensorflow,False,6,,0,,,False,t3_ionajb,False,dark,0.9,,public,8,0,{},,,False,[],,False,False,,{},Question,False,8,,False,self,False,,[],{},,True,,1599568845.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have been looking up on some advice as to how to implement research papers. There are numerous guides out there for pytorch but I wanted to go with Tensorflow2 cz I&amp;#39;m familiar with the syntax. Can someone recommend some resources for getting started with implementing research papers as it looks like a mammoth task to me rn.
I tried implementing a GAN based style transfer paper and even though I feel like I&amp;#39;ve done things right im not getting the desired results. So I would like to learn this art of implementing papers properly before I go ahead with anything else. 
Would be really grateful if someone could link some really cool resources in the thread.&lt;/p&gt;

&lt;p&gt;Thanks in advance❤️&lt;/p&gt;

&lt;p&gt;(PS I have looked into paperswithcode.com but would like to implement papers that don&amp;#39;t have any existing implementation)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ionajb,True,,theMLguynextDoor,,10,True,all_ads,False,[],False,,/r/tensorflow/comments/ionajb/implementing_research_papers_for_beginners/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ionajb/implementing_research_papers_for_beginners/,22217,1599540045.0,0,,False,,,,,,,,,
857,,tensorflow,"[https://medium.com/@cawin.chan/installing-tensorflow-2-3-0-for-raspberry-pi3-4-debian-buster-11447cb31fc4](https://medium.com/@cawin.chan/installing-tensorflow-2-3-0-for-raspberry-pi3-4-debian-buster-11447cb31fc4)

It works surprisingly well! But you should aim for your model to be as small as possible to be around 1MB, you can look at Tensorflow post-quantization techniques which can reduce up to around x4 the size of your model with almost negligible accuracy loss (from my experience).

I achieved a prediction speed of around 1-2s for a 6MB h5 model, but this same h5 model converted to tf lite model now at 1MB would have a prediction speed of around 90ms.

Which really took me by surprise on how great of a performance improvement tf lite was able to churn and how much a rpi could handle a TF model.",t2_5z1hrtz2,False,,0,False,Guide to install Tensorflow 2.3.0 on Raspberry Pi 3/4 (Debian Buster),[],r/tensorflow,False,6,,0,,,False,t3_io50vp,False,dark,0.96,,public,24,0,{},,,False,[],,False,False,,{},Walkthrough 📝,False,24,,False,self,False,,[],{},,True,,1599503014.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://medium.com/@cawin.chan/installing-tensorflow-2-3-0-for-raspberry-pi3-4-debian-buster-11447cb31fc4""&gt;https://medium.com/@cawin.chan/installing-tensorflow-2-3-0-for-raspberry-pi3-4-debian-buster-11447cb31fc4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It works surprisingly well! But you should aim for your model to be as small as possible to be around 1MB, you can look at Tensorflow post-quantization techniques which can reduce up to around x4 the size of your model with almost negligible accuracy loss (from my experience).&lt;/p&gt;

&lt;p&gt;I achieved a prediction speed of around 1-2s for a 6MB h5 model, but this same h5 model converted to tf lite model now at 1MB would have a prediction speed of around 90ms.&lt;/p&gt;

&lt;p&gt;Which really took me by surprise on how great of a performance improvement tf lite was able to churn and how much a rpi could handle a TF model.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,io50vp,True,,beta_lasagna,,8,True,all_ads,False,[],False,,/r/tensorflow/comments/io50vp/guide_to_install_tensorflow_230_on_raspberry_pi/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/io50vp/guide_to_install_tensorflow_230_on_raspberry_pi/,22217,1599474214.0,2,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?auto=webp&amp;s=b0b46b3a708360735363664baa04fd8b2f18bc7a', 'width': 1200, 'height': 1061}, 'resolutions': [{'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92f7b0988ff22d100beec6aec37d8f074cdf50c0', 'width': 108, 'height': 95}, {'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b137f65d1318ce0f8a963b6a06c81737d2eef31f', 'width': 216, 'height': 190}, {'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca2a1a267f6bb85d793f8c92fa0fb1483c8d8faf', 'width': 320, 'height': 282}, {'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=123d11205bf0b7e7dbd93dfbde4e497c8c4398f3', 'width': 640, 'height': 565}, {'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9eaba30ac9f223798d62322578d38a5682773b42', 'width': 960, 'height': 848}, {'url': 'https://external-preview.redd.it/sIHMeEfT0Hk_GihgngUy0HR4rOzKmBHOZMHWsYpyQLs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb116e3587113b716d7d12686136dd0fd8524d2b', 'width': 1080, 'height': 954}], 'variants': {}, 'id': '6Nf5F4wMjp7AQZV4o96MoO2E7k_pNLSUZxB_yAR76fk'}], 'enabled': False}",,,,,,
858,,tensorflow,,t2_44mbtmjy,False,,0,False,Latest in drones! Efficient trajectory generation for chasing a dynamic target,[],r/tensorflow,False,6,,0,85.0,,False,t3_iom24j,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/tROLJ9N7eOTlBcyVJJ3x7uI-m7ZFodwh0LNGtRf7bvw.jpg,False,,[],{},,False,,1599563536.0,text,6,,,text,self.LatestInML,False,,,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iom24j,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iom24j/latest_in_drones_efficient_trajectory_generation/,all_ads,False,/r/LatestInML/comments/iol6q3/latest_in_drones_efficient_trajectory_generation/,22217,1599534736.0,0,,False,link,/r/LatestInML/comments/iol6q3/latest_in_drones_efficient_trajectory_generation/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://catalyzex.com/paper/arxiv:2009.01565)\n\nhttps://preview.redd.it/4dau8cx12ul51.png?width=2008&amp;format=png&amp;auto=webp&amp;s=cc160a683876e4a8b582507c35634a595b9331f4', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest in drones! Efficient trajectory generation for chasing a dynamic target', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 85, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'4dau8cx12ul51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=651029670a86f5067e548220d78c93805582100b'}, {'y': 132, 'x': 216, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9a50dfb377ce035c018dbde7d936a96b44a93d8'}, {'y': 196, 'x': 320, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2b0c7fa7bb34c8e02e0ea50dd74864509c27a03'}, {'y': 392, 'x': 640, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c92821d4373b43d98772f6d54df3529ae3e44133'}, {'y': 589, 'x': 960, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=725a817be61f688645cdfb671c30f94c1c102a87'}, {'y': 662, 'x': 1080, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cc1d65efee9239a35e553cae4b4084cc2587654d'}], 's': {'y': 1232, 'x': 2008, 'u': 'https://preview.redd.it/4dau8cx12ul51.png?width=2008&amp;format=png&amp;auto=webp&amp;s=cc160a683876e4a8b582507c35634a595b9331f4'}, 'id': '4dau8cx12ul51'}}, 'name': 't3_iol6q3', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 26, 'total_awards_received': 1, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 26, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/tROLJ9N7eOTlBcyVJJ3x7uI-m7ZFodwh0LNGtRf7bvw.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1599560034.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://catalyzex.com/paper/arxiv:2009.01565""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/4dau8cx12ul51.png?width=2008&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc160a683876e4a8b582507c35634a595b9331f4""&gt;https://preview.redd.it/4dau8cx12ul51.png?width=2008&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc160a683876e4a8b582507c35634a595b9331f4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iol6q3', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/iol6q3/latest_in_drones_efficient_trajectory_generation/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/iol6q3/latest_in_drones_efficient_trajectory_generation/', 'subreddit_subscribers': 6676, 'created_utc': 1599531234.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_iol6q3,
859,,tensorflow,"Our mission is to Train and Certify the next generation of software developers and engineers worldwide in artificial intelligence and machine learning. Niches: Artificial Intelligence, Machine Learning, Data Science, Python, TensorFlow, PyTorch, Convolutional Neural Networks.. Top Partners: Google, Microsoft, IBM, DeepLearning.ai, MIT, Johns Hopkins, Stanford University, University of Michigan, UC Berkeley, Coursera, Pearson IT, EDx and Edureka.

Visit us today at:  https://aimlacademy.blogspot.com/    
  
Lawrence E. Wilson",t2_36ixj,False,,0,False,Artificial Intelligence Academy (AIA),[],r/tensorflow,False,6,,0,,,False,t3_ioihwe,False,dark,0.75,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1599549750.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Our mission is to Train and Certify the next generation of software developers and engineers worldwide in artificial intelligence and machine learning. Niches: Artificial Intelligence, Machine Learning, Data Science, Python, TensorFlow, PyTorch, Convolutional Neural Networks.. Top Partners: Google, Microsoft, IBM, DeepLearning.ai, MIT, Johns Hopkins, Stanford University, University of Michigan, UC Berkeley, Coursera, Pearson IT, EDx and Edureka.&lt;/p&gt;

&lt;p&gt;Visit us today at:  &lt;a href=""https://aimlacademy.blogspot.com/""&gt;https://aimlacademy.blogspot.com/&lt;/a&gt;    &lt;/p&gt;

&lt;p&gt;Lawrence E. Wilson&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,ioihwe,True,,lwilson747,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ioihwe/artificial_intelligence_academy_aia/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ioihwe/artificial_intelligence_academy_aia/,22217,1599520950.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/gu3RgbQ9C4RKsWpD43qphcY6Aw2dLxGPAyKidiwDa9Q.jpg?auto=webp&amp;s=86118294fb2ce656e426ec909eeb27f56af2273f', 'width': 301, 'height': 251}, 'resolutions': [{'url': 'https://external-preview.redd.it/gu3RgbQ9C4RKsWpD43qphcY6Aw2dLxGPAyKidiwDa9Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=22ab7058217595e71b54a38063282af1bd999360', 'width': 108, 'height': 90}, {'url': 'https://external-preview.redd.it/gu3RgbQ9C4RKsWpD43qphcY6Aw2dLxGPAyKidiwDa9Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=67b7a5785a15094c63f7099b83a7f34cda7f4766', 'width': 216, 'height': 180}], 'variants': {}, 'id': '4KHTPaT1hyBeoLaZsgGwRcTPzUAfK8HqUIo8ez481jE'}], 'enabled': False}",,,,,,
860,,tensorflow,"Can you all lead me in the right direction. I need to use tensor flow for facial characteristic recognition. So I will be id’ing specific facial traits. 

Any help would be amazing and much appreciated. 

You are all amazing!",t2_3yo0vhwl,False,,0,False,Need some help,[],r/tensorflow,False,6,,0,,,False,t3_iok3k2,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Discussion,False,1,,False,self,False,,[],{},,True,,1599555890.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can you all lead me in the right direction. I need to use tensor flow for facial characteristic recognition. So I will be id’ing specific facial traits. &lt;/p&gt;

&lt;p&gt;Any help would be amazing and much appreciated. &lt;/p&gt;

&lt;p&gt;You are all amazing!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iok3k2,True,,Joerogan69,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iok3k2/need_some_help/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iok3k2/need_some_help/,22217,1599527090.0,0,,False,,,,,,,,,
861,,tensorflow,"The Short-Time Fourier Transform 🎧 🎧 is one of the most important tools an AI audio / music engineer has. It enables them to extract spectrograms, the main feature we feed to DL audio models. In my new video, I explain the theory behind the Short-Time Fourier Transform in a simple way.

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=-Yxj3yfvY-4&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=15](https://www.youtube.com/watch?v=-Yxj3yfvY-4&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=15)",t2_12ahau,False,,0,False,I published a tutorial where I explain how the Short-Time Fourier Transform works,[],r/tensorflow,False,6,,0,,,False,t3_io9ivn,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Discussion,False,2,,False,self,False,,[],{},,True,,1599521465.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The Short-Time Fourier Transform 🎧 🎧 is one of the most important tools an AI audio / music engineer has. It enables them to extract spectrograms, the main feature we feed to DL audio models. In my new video, I explain the theory behind the Short-Time Fourier Transform in a simple way.&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=-Yxj3yfvY-4&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=15""&gt;https://www.youtube.com/watch?v=-Yxj3yfvY-4&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=15&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,io9ivn,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/io9ivn/i_published_a_tutorial_where_i_explain_how_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/io9ivn/i_published_a_tutorial_where_i_explain_how_the/,22217,1599492665.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/vA_cp850i0SQER3VGOosBK6iRt649VNMfxKOUwvAxgQ.jpg?auto=webp&amp;s=42affb14ad43c5316f2b08e759dfcf9bc8f142d1', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/vA_cp850i0SQER3VGOosBK6iRt649VNMfxKOUwvAxgQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb4c8110ea3dfa9eded198a3462da6c1811ea1d9', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/vA_cp850i0SQER3VGOosBK6iRt649VNMfxKOUwvAxgQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c02311ef1520181d68f834529e1eed6fce34e2c8', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/vA_cp850i0SQER3VGOosBK6iRt649VNMfxKOUwvAxgQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ee002dc4a44d64faeccc48452a00dd739c0404e', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'fWwK8fTuxcgmn21RMp9CGKdqVfETWG_slTimu2Yqawg'}], 'enabled': False}",,,,,,
862,,tensorflow,,t2_2e4fra5g,False,,0,False,Trading environment for TF-Agent,[],r/tensorflow,False,6,,0,105.0,,False,t3_ioccd4,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/RyKvndUwPmI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Part VII. Reinforcement Learning. Trading Environment.', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/RyKvndUwPmI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'CloseToAlgoTrading', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/RyKvndUwPmI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC02enwSCkf5S5GXV3jBwSzg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/RyKvndUwPmI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ioccd4', 'height': 338}",,False,1,,False,https://b.thumbs.redditmedia.com/PbeX5xBH-9XHKJ28wPMxw4IZLAOrMA4grMs8Uqzip6E.jpg,False,,[],{},,False,,1599530033.0,text,6,,,text,youtu.be,False,,,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ioccd4,True,,Denis_Vo,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ioccd4/trading_environment_for_tfagent/,all_ads,False,https://youtu.be/RyKvndUwPmI,22217,1599501233.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Part VII. Reinforcement Learning. Trading Environment.', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/RyKvndUwPmI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'CloseToAlgoTrading', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/RyKvndUwPmI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC02enwSCkf5S5GXV3jBwSzg'}}",False,rich:video,https://youtu.be/RyKvndUwPmI,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VsRGM2yfJYVyzixwrIQI-USfTe7CngDW1spsICmBwIU.jpg?auto=webp&amp;s=0f5bb3f564671563da835aa09a180a3443a02b75', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/VsRGM2yfJYVyzixwrIQI-USfTe7CngDW1spsICmBwIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=340f2195c151444d5318a4bce3ab21e5f7179a14', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/VsRGM2yfJYVyzixwrIQI-USfTe7CngDW1spsICmBwIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d03eebc3b6ffe29c59ce69547498aab4fa2a3b5', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/VsRGM2yfJYVyzixwrIQI-USfTe7CngDW1spsICmBwIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=10888abe5301bfe20e8dd3e68ab761894089c3da', 'width': 320, 'height': 240}], 'variants': {}, 'id': '0hUVo9CzAO-0ttP79JDu1yvO7oUNy_DHZn57-2D1V7g'}], 'enabled': False}",,,,,,
863,,tensorflow,"Basically I want to start making the change from sklearn to TensorFlow to do some more interesting stuff, but as far as I can tell I can't get a basic k means implementation in keras or TensorFlow in much the same way you can in sklearn.  I ended up on [this webpage](https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/experimental/KMeans), which does k means, but I found it rather not user friendly.  When I ran the algorithm on a smallish dataset (\~130 instances of 121 attributes each), I got a lot of outputs like ""cluster center"", which I understand as just where the clusters are located, but then I also got outputs ""score"" (gave me a large integer value), ""delta"" (output a vector and occasionally the zero vector), and ""point"" (told me what points were in what cluster), which I don't understand.  

I was wondering if someone could explain what these outputs mean and how to interpret them.  My project that I'm using this for is to try to sort Shakespearian sonnets into similar categories.  I already did all the work like reading the text files, transforming each poem from text to numeric data and making all the input tensors into constant length of 121.  I'm more concerned about learning how to manage messy data than get groundbreaking results, but at the very least I would like to try to have something I can be proud to put on my GitHub.  Or if someone knows a better ML model to use than k means I would be glad to hear about that as well.  

As a side note I am also wondering if there is any way to create an embedding (I think this is the correct term) of a large input dataset (in my case 121 dimensional vectors), into much more manageable sizes (say 20 dimensions).  I know you can do it in keras sequential layers, but I was wondering how I could create this dimension squishing in an unsupervised network.",t2_5jo16juy,False,,0,False,I used tf.compat.v1.estimator.experimental.KMeans to implement KMeans on a dataset. How do I interpret the outputs?,[],r/tensorflow,False,6,,0,,,False,t3_ioaknb,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1599524660.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Basically I want to start making the change from sklearn to TensorFlow to do some more interesting stuff, but as far as I can tell I can&amp;#39;t get a basic k means implementation in keras or TensorFlow in much the same way you can in sklearn.  I ended up on &lt;a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/experimental/KMeans""&gt;this webpage&lt;/a&gt;, which does k means, but I found it rather not user friendly.  When I ran the algorithm on a smallish dataset (~130 instances of 121 attributes each), I got a lot of outputs like &amp;quot;cluster center&amp;quot;, which I understand as just where the clusters are located, but then I also got outputs &amp;quot;score&amp;quot; (gave me a large integer value), &amp;quot;delta&amp;quot; (output a vector and occasionally the zero vector), and &amp;quot;point&amp;quot; (told me what points were in what cluster), which I don&amp;#39;t understand.  &lt;/p&gt;

&lt;p&gt;I was wondering if someone could explain what these outputs mean and how to interpret them.  My project that I&amp;#39;m using this for is to try to sort Shakespearian sonnets into similar categories.  I already did all the work like reading the text files, transforming each poem from text to numeric data and making all the input tensors into constant length of 121.  I&amp;#39;m more concerned about learning how to manage messy data than get groundbreaking results, but at the very least I would like to try to have something I can be proud to put on my GitHub.  Or if someone knows a better ML model to use than k means I would be glad to hear about that as well.  &lt;/p&gt;

&lt;p&gt;As a side note I am also wondering if there is any way to create an embedding (I think this is the correct term) of a large input dataset (in my case 121 dimensional vectors), into much more manageable sizes (say 20 dimensions).  I know you can do it in keras sequential layers, but I was wondering how I could create this dimension squishing in an unsupervised network.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ioaknb,True,,CauchySchwartzDaddy,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ioaknb/i_used_tfcompatv1estimatorexperimentalkmeans_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ioaknb/i_used_tfcompatv1estimatorexperimentalkmeans_to/,22217,1599495860.0,0,,False,,,,,,,,,
864,,tensorflow,I am a self-taught machine learning person and I have a few personal projects that I have made like Image Captioning and CycleGAN but is there anyway to learn about these advanced TF functions.(I'm 14 btw so math isn't going to be my strong point),t2_5m5rpe85,False,,0,False,How does a Self-taught machine learner learn advanced custom training and loss functions?,[],r/tensorflow,False,6,,0,,,False,t3_io16oc,False,dark,0.83,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1599483137.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a self-taught machine learning person and I have a few personal projects that I have made like Image Captioning and CycleGAN but is there anyway to learn about these advanced TF functions.(I&amp;#39;m 14 btw so math isn&amp;#39;t going to be my strong point)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,io16oc,True,,boiboi3333,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/io16oc/how_does_a_selftaught_machine_learner_learn/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/io16oc/how_does_a_selftaught_machine_learner_learn/,22217,1599454337.0,0,,False,,,,,,,,,
865,,tensorflow,,t2_1ree,False,,0,False,TensorFlow Datasets: The Bad Parts,[],r/tensorflow,False,6,,0,,,False,t3_inoq0t,False,dark,0.92,,public,18,0,{},,,False,[],,False,False,,{},,False,18,,False,default,False,,[],{},,False,,1599437694.0,text,6,,,text,determined.ai,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,inoq0t,True,,neilc,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/inoq0t/tensorflow_datasets_the_bad_parts/,all_ads,False,https://determined.ai/blog/tf-dataset-the-bad-parts/,22217,1599408894.0,0,,False,,https://determined.ai/blog/tf-dataset-the-bad-parts/,,,,,,,
867,,tensorflow,,t2_5w4i5kd1,False,,0,False,First model ever went horrible. Any suggestions?,[],r/tensorflow,False,6,,0,140.0,,False,t3_inug0e,False,dark,0.59,,public,3,0,{},140.0,,False,[],,True,False,,{},,False,3,,False,https://b.thumbs.redditmedia.com/_t4muNuVzyDxolQ_Xy4JDiYM-BQVpGgOvJgRpzb3bSA.jpg,False,,[],{},,False,,1599456726.0,text,6,,,text,i.redd.it,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,inug0e,True,,veeeerain,,20,True,all_ads,False,[],False,,/r/tensorflow/comments/inug0e/first_model_ever_went_horrible_any_suggestions/,all_ads,False,https://i.redd.it/x3tmf2cvill51.jpg,22217,1599427926.0,0,,False,image,https://i.redd.it/x3tmf2cvill51.jpg,"{'images': [{'source': {'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?auto=webp&amp;s=956e11f37d7e7cca7e763043936f2cf4b7c34663', 'width': 3024, 'height': 4032}, 'resolutions': [{'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8965e192182b38585b6d7a1cd3467e22ca7dd931', 'width': 108, 'height': 144}, {'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=00585ec155197b39ac6f322d9d559ad400e7d288', 'width': 216, 'height': 288}, {'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d158b9836db699c87289c8118711edce8d51c76', 'width': 320, 'height': 426}, {'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e6b13ad28acf39b20e4b08e3f212edd00ff4f125', 'width': 640, 'height': 853}, {'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e24059c8b5dc628cb30764710fe3e6f63862a700', 'width': 960, 'height': 1280}, {'url': 'https://preview.redd.it/x3tmf2cvill51.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14fbc863efe3e847c3ad9bf43a00719a85d000d6', 'width': 1080, 'height': 1440}], 'variants': {}, 'id': '5i1rcweFxnGXI2z3FbhvLgCxf-VdvSPikWMNwMH2v0I'}], 'enabled': True}",,,,,,
868,,tensorflow,,t2_3e708,False,,0,False,Binary and Categorical classification in TensorFlow,[],r/tensorflow,False,6,,0,,,False,t3_inko2r,False,dark,0.73,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,True,default,False,,[],{},,False,,1599421410.0,text,6,,,text,self.learnmachinelearning,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,inko2r,True,,iamflimflam1,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/inko2r/binary_and_categorical_classification_in/,all_ads,False,/r/learnmachinelearning/comments/inknq1/binary_and_categorical_classification_in/,22217,1599392610.0,0,,False,link,/r/learnmachinelearning/comments/inknq1/binary_and_categorical_classification_in/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?auto=webp&amp;s=b0fe6b5cdb11574766b6ae302ad077950806d170', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65d0bb8b391ce0d44a62df28c0b85dc16e03d955', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4eebba35988f8233a582b07b6a8c501e75be00a8', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=135e9cd964bfbde75a50b215863119fe3ef9fe6b', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'jHFpoLHRVPznfz1Bf8HVZNMpRXjb51BbgJb9a01tsj0'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': ""I've been learning TensorFlow for a couple of projects and wanted to capture some of what I've learned in some basic end to end tutorials.\n\nBinary Classification using BinaryCrossentropy loss function - [https://youtu.be/olkRurD-\\_t4](https://youtu.be/olkRurD-_t4)\n\nAnd Categorical Classification using CategoricalCrossentropy loss function - [https://youtu.be/LPPTi38Zfqc](https://youtu.be/LPPTi38Zfqc)\n\nI used  Categorical Classification in my augmented reality Sudoku solver ([https://youtu.be/cOC-ad0BsY0](https://youtu.be/cOC-ad0BsY0)) and wanted to produce a cut-down version to show the basics.\n\nHope it's useful to someone!"", 'author_fullname': 't2_3e708', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Binary and Categorical classification in TensorFlow', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_inknq1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1599421361.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been learning TensorFlow for a couple of projects and wanted to capture some of what I&amp;#39;ve learned in some basic end to end tutorials.&lt;/p&gt;\n\n&lt;p&gt;Binary Classification using BinaryCrossentropy loss function - &lt;a href=""https://youtu.be/olkRurD-_t4""&gt;https://youtu.be/olkRurD-_t4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And Categorical Classification using CategoricalCrossentropy loss function - &lt;a href=""https://youtu.be/LPPTi38Zfqc""&gt;https://youtu.be/LPPTi38Zfqc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I used  Categorical Classification in my augmented reality Sudoku solver (&lt;a href=""https://youtu.be/cOC-ad0BsY0""&gt;https://youtu.be/cOC-ad0BsY0&lt;/a&gt;) and wanted to produce a cut-down version to show the basics.&lt;/p&gt;\n\n&lt;p&gt;Hope it&amp;#39;s useful to someone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?auto=webp&amp;s=b0fe6b5cdb11574766b6ae302ad077950806d170', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65d0bb8b391ce0d44a62df28c0b85dc16e03d955', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4eebba35988f8233a582b07b6a8c501e75be00a8', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/-PtgGy0S46tbhQDrY7X4-jFa8JzXYBPs1THMi20hojk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=135e9cd964bfbde75a50b215863119fe3ef9fe6b', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'jHFpoLHRVPznfz1Bf8HVZNMpRXjb51BbgJb9a01tsj0'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '8aeee882-d289-11ea-b4f0-0ed750cbd99b', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'inknq1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'iamflimflam1', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/inknq1/binary_and_categorical_classification_in/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/inknq1/binary_and_categorical_classification_in/', 'subreddit_subscribers': 217922, 'created_utc': 1599392561.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_inknq1,
869,,tensorflow,"I’m trying to create a network which can continue a sentence when given with a starting word. My dataset consists of ~21,000 samples with an average length of 70 characters each. I’ve seen great I’ve neural networks done with both keras GRU layers or LSTM layers.

I’ve seen that these layers are quite similar and was wondering which layer would be best to use for this application.

Thank you for any answers!",t2_4gc23p0w,False,,0,False,Generating text with GRU or LSTM,[],r/tensorflow,False,6,,0,,,False,t3_inrwdb,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1599448082.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m trying to create a network which can continue a sentence when given with a starting word. My dataset consists of ~21,000 samples with an average length of 70 characters each. I’ve seen great I’ve neural networks done with both keras GRU layers or LSTM layers.&lt;/p&gt;

&lt;p&gt;I’ve seen that these layers are quite similar and was wondering which layer would be best to use for this application.&lt;/p&gt;

&lt;p&gt;Thank you for any answers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,inrwdb,True,,F1nn1711,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/inrwdb/generating_text_with_gru_or_lstm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/inrwdb/generating_text_with_gru_or_lstm/,22217,1599419282.0,0,,False,,,,,,,,,
870,,tensorflow,"This is the error message that I get when I try to install tensorflow using Anaconda. I am getting the same error when I tried installing tensorflow-gpu, how should I go about this issue?

(base) C:\\Users\\adwit&gt;conda install tensorflow

Collecting package metadata (current\_repodata.json): done

Solving environment: failed with initial frozen solve. Retrying with flexible solve.

Solving environment: failed with repodata from current\_repodata.json, will retry with next repodata source.

Collecting package metadata (repodata.json): done

Solving environment: failed with initial frozen solve. Retrying with flexible solve.

Solving environment: -

Found conflicts! Looking for incompatible packages.

This can take several minutes.  Press CTRL-C to abort.

failed

&amp;#x200B;

UnsatisfiableError: The following specifications were found

to be incompatible with the existing python installation in your environment:

&amp;#x200B;

Specifications:

&amp;#x200B;

  \- tensorflow -&gt; python\[version='3.5.\*|3.6.\*|3.7.\*'\]

&amp;#x200B;

Your python: python=3.8

&amp;#x200B;

If python is on the left-most side of the chain, that's the version you've asked for.

When python appears to the right, that indicates that the thing on the left is somehow

not available for the python version you are constrained to. Note that conda will not

change your python version to a different minor version unless you explicitly specify

that.

&amp;#x200B;

The following specifications were found to be incompatible with your system:

&amp;#x200B;

  \- feature:/win-64::\_\_cuda==11.0=0

  \- feature:|@/win-64::\_\_cuda==11.0=0

&amp;#x200B;

Your installed version is: 11.0",t2_7qni1mdu,False,,0,False,Issue with Tensorflow installation,[],r/tensorflow,False,6,,0,,,False,t3_inh4ho,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1599401865.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is the error message that I get when I try to install tensorflow using Anaconda. I am getting the same error when I tried installing tensorflow-gpu, how should I go about this issue?&lt;/p&gt;

&lt;p&gt;(base) C:\Users\adwit&amp;gt;conda install tensorflow&lt;/p&gt;

&lt;p&gt;Collecting package metadata (current_repodata.json): done&lt;/p&gt;

&lt;p&gt;Solving environment: failed with initial frozen solve. Retrying with flexible solve.&lt;/p&gt;

&lt;p&gt;Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.&lt;/p&gt;

&lt;p&gt;Collecting package metadata (repodata.json): done&lt;/p&gt;

&lt;p&gt;Solving environment: failed with initial frozen solve. Retrying with flexible solve.&lt;/p&gt;

&lt;p&gt;Solving environment: -&lt;/p&gt;

&lt;p&gt;Found conflicts! Looking for incompatible packages.&lt;/p&gt;

&lt;p&gt;This can take several minutes.  Press CTRL-C to abort.&lt;/p&gt;

&lt;p&gt;failed&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;UnsatisfiableError: The following specifications were found&lt;/p&gt;

&lt;p&gt;to be incompatible with the existing python installation in your environment:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Specifications:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;- tensorflow -&amp;gt; python[version=&amp;#39;3.5.*|3.6.*|3.7.*&amp;#39;]&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Your python: python=3.8&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;If python is on the left-most side of the chain, that&amp;#39;s the version you&amp;#39;ve asked for.&lt;/p&gt;

&lt;p&gt;When python appears to the right, that indicates that the thing on the left is somehow&lt;/p&gt;

&lt;p&gt;not available for the python version you are constrained to. Note that conda will not&lt;/p&gt;

&lt;p&gt;change your python version to a different minor version unless you explicitly specify&lt;/p&gt;

&lt;p&gt;that.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The following specifications were found to be incompatible with your system:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;- feature:/win-64::__cuda==11.0=0&lt;/p&gt;

&lt;p&gt;- feature:|@/win-64::__cuda==11.0=0&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Your installed version is: 11.0&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,inh4ho,True,,Meteor-Sama,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/inh4ho/issue_with_tensorflow_installation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/inh4ho/issue_with_tensorflow_installation/,22217,1599373065.0,0,,False,,,,,,,,,
871,,tensorflow,,t2_6wt510of,False,,0,False,StyleGAN2 generates Ricardo Milos,[],r/tensorflow,False,6,,0,105.0,,False,t3_imyvet,False,dark,0.89,,public,25,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nx9iJoh0Euk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Ricardo Milos' Enourmous Brain | (StyleGAN2)"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nx9iJoh0Euk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/nx9iJoh0Euk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nx9iJoh0Euk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/imyvet', 'height': 338}",,False,25,,False,https://b.thumbs.redditmedia.com/G_u35kQCtuqxxZ9tDyd-XQ8GJu9atVG-v1_O6HBFQ6I.jpg,False,,[],{},,False,,1599330289.0,text,6,,,text,youtu.be,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,imyvet,True,,Snoo_72253,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/imyvet/stylegan2_generates_ricardo_milos/,all_ads,False,https://youtu.be/nx9iJoh0Euk,22217,1599301489.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Ricardo Milos' Enourmous Brain | (StyleGAN2)"", 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/nx9iJoh0Euk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/nx9iJoh0Euk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,rich:video,https://youtu.be/nx9iJoh0Euk,"{'images': [{'source': {'url': 'https://external-preview.redd.it/E3ZhZmMw34E55IgRwrsgBylPwT_qH3fOF_PiM_VWb5M.jpg?auto=webp&amp;s=24d462b5bead0aff2a07c5895ac98c01bb7b17b1', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/E3ZhZmMw34E55IgRwrsgBylPwT_qH3fOF_PiM_VWb5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=215b4d1a1c924245366e9c8a7f633bc997b0c8d0', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/E3ZhZmMw34E55IgRwrsgBylPwT_qH3fOF_PiM_VWb5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=767b4b3dd824ee9011fce05956fd52808ba9df2c', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/E3ZhZmMw34E55IgRwrsgBylPwT_qH3fOF_PiM_VWb5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65bc63293cb7571ced3e80559726ec2a399d4e87', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'V5kObsxWrIp1QqVd1M5S1jg5xwWpnaR0IETPs5wzY74'}], 'enabled': False}",,,,,,
872,,tensorflow,"Hello,

I was thinking of writing something that identified if a vessel was for bulk, containers, or cars but then it dawned on me that I would have to pull all these images from the web. Does anyone know of any good websites/sources that already do this? I would really hate to pull 500 images manually just for a fun weekend project.

I",t2_201jqw46,False,,0,False,Best way to get lots of images for image classification,[],r/tensorflow,False,6,,0,,,False,t3_in0w5y,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1599340394.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I was thinking of writing something that identified if a vessel was for bulk, containers, or cars but then it dawned on me that I would have to pull all these images from the web. Does anyone know of any good websites/sources that already do this? I would really hate to pull 500 images manually just for a fun weekend project.&lt;/p&gt;

&lt;p&gt;I&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,in0w5y,True,,OmegaZomma,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/in0w5y/best_way_to_get_lots_of_images_for_image/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/in0w5y/best_way_to_get_lots_of_images_for_image/,22217,1599311594.0,0,,False,,,,,,,,,
873,,tensorflow,"Hi I have a ResCNN Keras model that works with fbanks as inputs. I would like to include a preprocessing layer so the conversion from wav to fbank will be done inside the net. Righit now I'm trying like this:

    original_model = Model(inputs, x, name='ResCNN')  
    input = Input(shape=(SAMPLE_RATE,None))  
    preproc_layer = PreprocessingLayer(wav_tofb)(input)  
    output = original_model(preproc_layer)  
    model = Model(input, output) 

The proprocessing function is:

    def wav_tofb(input_filename): 
        audio = Audio.read(input_filename, SAMPLE_RATE) 
        energy = np.abs(audio)
        silence_threshold = np.percentile(energy, 95) 
        offsets = np.where(energy &gt; silence_threshold)[0] 
        audio_voice_only = audio[offsets[0]:offsets[-1]] 
        fb = fbank(audio_voice_only, SAMPLE_RATE) 
    return fb 

The problem is that when I try to do:

    model.predict('audio.wav') 

it doesn't work. How I can fix it? I think the problem is the input I give to the net. The original model have the following inputs:

    input (InputLayer)              [(None, 160, 64, 1)] 0",t2_tilym,False,,0,False,Add preprocessing layer to Model,[],r/tensorflow,False,6,,0,,,False,t3_imzjj9,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1599333967.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi I have a ResCNN Keras model that works with fbanks as inputs. I would like to include a preprocessing layer so the conversion from wav to fbank will be done inside the net. Righit now I&amp;#39;m trying like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;original_model = Model(inputs, x, name=&amp;#39;ResCNN&amp;#39;)  
input = Input(shape=(SAMPLE_RATE,None))  
preproc_layer = PreprocessingLayer(wav_tofb)(input)  
output = original_model(preproc_layer)  
model = Model(input, output) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The proprocessing function is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def wav_tofb(input_filename): 
    audio = Audio.read(input_filename, SAMPLE_RATE) 
    energy = np.abs(audio)
    silence_threshold = np.percentile(energy, 95) 
    offsets = np.where(energy &amp;gt; silence_threshold)[0] 
    audio_voice_only = audio[offsets[0]:offsets[-1]] 
    fb = fbank(audio_voice_only, SAMPLE_RATE) 
return fb 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem is that when I try to do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;model.predict(&amp;#39;audio.wav&amp;#39;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it doesn&amp;#39;t work. How I can fix it? I think the problem is the input I give to the net. The original model have the following inputs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;input (InputLayer)              [(None, 160, 64, 1)] 0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,imzjj9,True,,matdtr,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/imzjj9/add_preprocessing_layer_to_model/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/imzjj9/add_preprocessing_layer_to_model/,22217,1599305167.0,0,,False,,,,,,,,,
874,,tensorflow,"I have a Window 10 machine with Cuda v11 and I have pip-installed tensorflow 2.3. 
But tensorflow is trying to load cudart64_101.dll, also some other dll from older versions.
What am I doing wrong ?",t2_773b68ac,False,,0,False,tensorflow looking for old version of cuda,[],r/tensorflow,False,6,,0,,,False,t3_imwn8j,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1599317537.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a Window 10 machine with Cuda v11 and I have pip-installed tensorflow 2.3. 
But tensorflow is trying to load cudart64_101.dll, also some other dll from older versions.
What am I doing wrong ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,imwn8j,True,,Software_Janitor,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/imwn8j/tensorflow_looking_for_old_version_of_cuda/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/imwn8j/tensorflow_looking_for_old_version_of_cuda/,22217,1599288737.0,0,,False,,,,,,,,,
875,,tensorflow,"I have some variables I would like to save in a Keras model so that when the model is saved to disk and later loaded, the variables are accessible from the model. However, the model itself doesn't use these variables: they are intended as hints to the user about what the model does and how to use it.

With the Keras functional API, I don't see an obvious way to do this. I could add a layer whose only function is to store these variables, but I think I would still need to connect it to the rest of the graph somehow so that it becomes part of the model. Is there a simple way to do this that I am missing?",t2_olv50,False,,0,False,Saving unused variable in model created with the Keras functional API (TensorFlow 2.0),[],r/tensorflow,False,6,,0,,,False,t3_imss1q,False,dark,0.8,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1599299203.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have some variables I would like to save in a Keras model so that when the model is saved to disk and later loaded, the variables are accessible from the model. However, the model itself doesn&amp;#39;t use these variables: they are intended as hints to the user about what the model does and how to use it.&lt;/p&gt;

&lt;p&gt;With the Keras functional API, I don&amp;#39;t see an obvious way to do this. I could add a layer whose only function is to store these variables, but I think I would still need to connect it to the rest of the graph somehow so that it becomes part of the model. Is there a simple way to do this that I am missing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,imss1q,True,,Pukkeh,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/imss1q/saving_unused_variable_in_model_created_with_the/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/imss1q/saving_unused_variable_in_model_created_with_the/,22217,1599270403.0,0,,False,,,,,,,,,
876,,tensorflow,"How does TF-Coder synthesize the answers to TensorFlow questions in  StackOverflow at the ‘superhuman’ level? What are the technologies  behind it?

Check out my new blog post. 

[https://us.github.io/how-tf-coder-works](https://us.github.io/how-tf-coder-works)",t2_32ysdpj0,False,,0,False,How TF-Coder Works? (Explained),[],r/tensorflow,False,6,,0,,,False,t3_imjjoq,False,dark,1.0,,public,9,0,{},,,False,[],,False,False,,{},,False,9,,False,self,False,,[],{},,True,,1599266988.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How does TF-Coder synthesize the answers to TensorFlow questions in  StackOverflow at the ‘superhuman’ level? What are the technologies  behind it?&lt;/p&gt;

&lt;p&gt;Check out my new blog post. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://us.github.io/how-tf-coder-works""&gt;https://us.github.io/how-tf-coder-works&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,imjjoq,True,,saritekin,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/imjjoq/how_tfcoder_works_explained/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/imjjoq/how_tfcoder_works_explained/,22217,1599238188.0,0,,False,,,,,,,,,
877,,tensorflow,"I created a preprocessing layer that just applies Sobel filter to the input and concatenates it as follows:  
class SobelPreprocessor(tf.keras.layers.Layer):

    class SobelPreprocessor(tf.keras.layers.Layer):
        def __init__( self, **kwargs):
            super(SobelPreprocessor, self).__init__(**kwargs)
    
        def call(self, inputs):
            sobel = tf.image.sobel_edges(inputs)
            sobel_y = sobel[...,0]
            sobel_x = sobel[...,1]
            return tf.concat([inputs, sobel_y, sobel_x], axis=-1)

I want to use those tensors (sobel\_y and sobel\_x) in a custom loss, but how can I retrieve them inside this function?  

    @tf.function
    def custom_mean_squared_error(y_true, y_pred):
        y_pred = tf.python.framework.ops.convert_to_tensor_v2(y_pred)
        y_true = tf.python.math_ops.cast(y_true, y_pred.dtype)
    
        #sobel_x and sobel_y needed here !!!
    
        return K.mean(tf.python.math_ops.squared_difference(y_pred, y_true), axis=-1)

There is something like ""sobel\_x = self.model.get\_layer('sobel\_layer')\[0\] "" ?",t2_4s2g77fy,False,,0,False,Using intermediate preprocessing layers in custom loss,[],r/tensorflow,False,6,,0,,,False,t3_imn425,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,False,,[],{},,True,,1599278327.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I created a preprocessing layer that just applies Sobel filter to the input and concatenates it as follows:&lt;br/&gt;
class SobelPreprocessor(tf.keras.layers.Layer):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class SobelPreprocessor(tf.keras.layers.Layer):
    def __init__( self, **kwargs):
        super(SobelPreprocessor, self).__init__(**kwargs)

    def call(self, inputs):
        sobel = tf.image.sobel_edges(inputs)
        sobel_y = sobel[...,0]
        sobel_x = sobel[...,1]
        return tf.concat([inputs, sobel_y, sobel_x], axis=-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I want to use those tensors (sobel_y and sobel_x) in a custom loss, but how can I retrieve them inside this function?  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@tf.function
def custom_mean_squared_error(y_true, y_pred):
    y_pred = tf.python.framework.ops.convert_to_tensor_v2(y_pred)
    y_true = tf.python.math_ops.cast(y_true, y_pred.dtype)

    #sobel_x and sobel_y needed here !!!

    return K.mean(tf.python.math_ops.squared_difference(y_pred, y_true), axis=-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is something like &amp;quot;sobel_x = self.model.get_layer(&amp;#39;sobel_layer&amp;#39;)[0] &amp;quot; ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,imn425,True,,mitherdil,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/imn425/using_intermediate_preprocessing_layers_in_custom/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/imn425/using_intermediate_preprocessing_layers_in_custom/,22217,1599249527.0,0,,False,,,,,,,,,
878,,tensorflow,"I’m building a neural network that will predict the outcome between two sides based on statistics from previous fights. However I have a few questions on how I should format the data in the CSV file:

1. Should I put the name of the fighter / team of allocate each of them a number which would be the winning / losing end result given to us.

2. How should I format the data in the CSV file?

3. How should I separate the training data from the CSV file from the testing data in the CSV

Any suggested answers to these would be great!",t2_3mzxrea7,False,,0,False,Confused about CSV formatting in data inputting?!,[],r/tensorflow,False,6,,0,,,False,t3_imoi8d,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1599282985.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m building a neural network that will predict the outcome between two sides based on statistics from previous fights. However I have a few questions on how I should format the data in the CSV file:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Should I put the name of the fighter / team of allocate each of them a number which would be the winning / losing end result given to us.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How should I format the data in the CSV file?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How should I separate the training data from the CSV file from the testing data in the CSV&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Any suggested answers to these would be great!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,imoi8d,True,,hamiltonusername,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/imoi8d/confused_about_csv_formatting_in_data_inputting/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/imoi8d/confused_about_csv_formatting_in_data_inputting/,22217,1599254185.0,0,,False,,,,,,,,,
879,,tensorflow,,t2_dpzgk,False,,0,False,Lean how to Install TensorFlow Using Anaconda Navigator &amp; Prompt In 18 Minutes,[],r/tensorflow,False,6,,0,78.0,,False,t3_imfvuv,False,dark,0.5,,public,0,0,{},140.0,,False,[],,False,False,,{},,False,0,,False,https://b.thumbs.redditmedia.com/2seB0qyCpevoMLNslchSdZ9TAT3qmLwZzP4M_DPojBs.jpg,False,,[],{},,False,,1599254765.0,text,6,,,text,youtu.be,False,,,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,imfvuv,True,,Reginald_Martin,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/imfvuv/lean_how_to_install_tensorflow_using_anaconda/,all_ads,False,https://youtu.be/G5oVrTTbLqM,22217,1599225965.0,0,,False,link,https://youtu.be/G5oVrTTbLqM,"{'images': [{'source': {'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?auto=webp&amp;s=4d67d146b3bc282b9b344394f551e8d8e9ea3dc0', 'width': 1280, 'height': 720}, 'resolutions': [{'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=737d9ec9602b5355072bb220f6b9bb8b747fee57', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e9933eb447f16ca024209c9c054c92d1a73ef28', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=52fe936fa84d72b2ec011a836db4612e3a3755f7', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d3a0aaee3307d2b4153a741e6013064a4fa284ac', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=51955085496f72d2a663c924371275c6e4dd2fb8', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/RvnnFR4cOa1gaZDuEWX0LBXcjg6fZZboFWm1mzrpGvI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ab01b4b33c43a50e48acb80fe96441b9a844536', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'wRkOIu8vsCCr6USTJR90AqAUXdAqqWIjdr9AOgUx7XE'}], 'enabled': False}",,,,,,
880,,tensorflow,"Hi All,

When i was running quickstart MNIST model.fit() was showing an ETA of hours per epoch. Passing in verbosity=2 sped things up immensely (hours to seconds). 

Hopefully this helps someone who doesn't have time to dive down a rabbit hole of troubleshooting. I was using tf-nightly-gpu for cuda 11 and fully expected the troubleshooting. 

Tldr ""why isn't tensorflow using my GPU"" turned out to be caused by model fit default verbosity instead of GPU related",t2_4wvtk,False,,0,False,Solution for long epochs,[],r/tensorflow,False,6,,0,,,False,t3_im5ev8,False,dark,0.82,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1599206940.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;When i was running quickstart MNIST model.fit() was showing an ETA of hours per epoch. Passing in verbosity=2 sped things up immensely (hours to seconds). &lt;/p&gt;

&lt;p&gt;Hopefully this helps someone who doesn&amp;#39;t have time to dive down a rabbit hole of troubleshooting. I was using tf-nightly-gpu for cuda 11 and fully expected the troubleshooting. &lt;/p&gt;

&lt;p&gt;Tldr &amp;quot;why isn&amp;#39;t tensorflow using my GPU&amp;quot; turned out to be caused by model fit default verbosity instead of GPU related&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,im5ev8,True,,hooferboof,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/im5ev8/solution_for_long_epochs/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/im5ev8/solution_for_long_epochs/,22217,1599178140.0,0,,False,,,,,,,,,
881,,tensorflow,"I'd like to find out how to use Keras tuning api together with HParams Dashboard for tensorboard.

I've found a nice example of using HParams Dashboard for tensorboard here:

[https://www.tensorflow.org/tensorboard/hyperparameter\_tuning\_with\_hparams](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)

Unforunately the example doesn't use the keras tuner.

There are nice examples of using the Keras tuner here:

[https://github.com/keras-team/keras-tuner/blob/master/examples/helloworld.py](https://github.com/keras-team/keras-tuner/blob/master/examples/helloworld.py)

However there aren't any examples of it being used with tensorboard

Thanks in advance",t2_1zeejow0,False,,0,False,Hyperparameter tuning with Keras and logging for Tensorboard,[],r/tensorflow,False,6,,0,,,False,t3_ilucmt,False,dark,1.0,,public,6,0,{},,,False,[],,False,False,,{},,False,6,,False,self,False,,[],{},,True,,1599171835.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;d like to find out how to use Keras tuning api together with HParams Dashboard for tensorboard.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve found a nice example of using HParams Dashboard for tensorboard here:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams""&gt;https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Unforunately the example doesn&amp;#39;t use the keras tuner.&lt;/p&gt;

&lt;p&gt;There are nice examples of using the Keras tuner here:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/keras-team/keras-tuner/blob/master/examples/helloworld.py""&gt;https://github.com/keras-team/keras-tuner/blob/master/examples/helloworld.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However there aren&amp;#39;t any examples of it being used with tensorboard&lt;/p&gt;

&lt;p&gt;Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ilucmt,True,,srm1355,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ilucmt/hyperparameter_tuning_with_keras_and_logging_for/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ilucmt/hyperparameter_tuning_with_keras_and_logging_for/,22217,1599143035.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?auto=webp&amp;s=7d4c3575585ca91ff066914d1e9d42598e7c4188', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc56121fede7a8078a72a3627ea489a116970d30', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42fe78d6c25e73b3edd524cb720195bdc6355066', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ddcb8cbd29efd800a55bef4a34bb7446dc16e64', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cc185d66a3da2d09af2c800d6d6867519d992c32', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=572e2d1dee8d27c5a38581322ac3113a7f5e7b47', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/Dfh2qDKLz16LP6xUFIcxUv-FGLWC9t884Qch1nwFDiE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bd62fc41bd72dcab777b92677d5e199835168bc3', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'ZGM5dIwVGnMldjBmsY4vCszmiXsUpyoP3bh0LrRGS58'}], 'enabled': False}",,,,,,
882,,tensorflow,,t2_v7nu2,False,,0,False,"John Snow Labs Spark-NLP 2.6.0: New multi-label classifier, BERT sentence embeddings, unsupervised keyword extractions, over 110 pretrained pipelines, models, Transformers, and more!",[],r/tensorflow,False,6,,0,70.0,,False,t3_ilpu89,False,dark,1.0,,public,16,0,{},140.0,,False,[],,False,False,,{},,False,16,,False,https://b.thumbs.redditmedia.com/mcSIn49_o2H_1T3Lr_nLbD8oB2-_PQjUpMC0MQ5xuSo.jpg,False,,[],{},,False,,1599151905.0,text,6,,,text,github.com,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ilpu89,True,,dark-night-rises,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ilpu89/john_snow_labs_sparknlp_260_new_multilabel/,all_ads,False,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.0,22217,1599123105.0,0,,False,link,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.0,"{'images': [{'source': {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?auto=webp&amp;s=26d4e2ccac57601a99f4cf45d17f0e00f92fead8', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d55caafe011d4551ac15197e82b07dc37606c085', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e16ade26c248b8f9dfe83d12e5a437af7764697', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6301bc373904ebf9e06640d72df79738f466d080', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c3eadd9c1d9a2e41e1b423431c1666469d533309', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d59956f28b0a75b5571510adebb6a47c3dff02e2', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/T1Gvrk-6ikOXB2FJ2UxTc8ZJaATvVLXy5wa88Y3OMQU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2cd7fba8bfcb78eb50ebaa2190e9d66a954f7bf8', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'jMsd8PwIcNruRH9ONi-X0NcTUSJ4CHYE0cb1s8qw_TI'}], 'enabled': False}",,,,,,
883,,tensorflow,"I have a fairly complicated custom training loop (using TF2) and my loss function depends on the gradients of the output wrt the input. So in my loss function I use a gradient tape to get the gradients of the output of the network wrt the input passed in. However, in the overall training loop, I use a different gradient tape to get the gradients of the loss function with respect to the network weights so I can update the network. TF is telling me that the gradients of the loss wrt the network weights don't exist, although it is able to compute the gradients of the network output wrt the input within the loss function. How do I achieve/fix this?

&amp;#x200B;

here is the loss function, where I am able to get numerical gradient values of the output wrt the input

&amp;#x200B;

https://preview.redd.it/te0unjk3vyk51.png?width=720&amp;format=png&amp;auto=webp&amp;s=e9ea99aa512c790f075a9c3411b224d964249759

and here is where I update the network with the training loop

&amp;#x200B;

https://preview.redd.it/wq1kq6afvyk51.png?width=1256&amp;format=png&amp;auto=webp&amp;s=4b8e7c37651bf9d3beabb6aa3423847fb4eede20

I get warnings from the training loop saying that the gradients don't exist",t2_7yjfn7ok,False,,0,False,help getting gradients of a gradient computation,[],r/tensorflow,False,6,,0,94.0,,False,t3_ilxeoz,False,dark,0.67,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/q57MmrKQOvK-_Cps1IG199SoZtJuSJSva6uTGR1Kxmc.jpg,1599153825.0,,[],{},,True,,1599181220.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a fairly complicated custom training loop (using TF2) and my loss function depends on the gradients of the output wrt the input. So in my loss function I use a gradient tape to get the gradients of the output of the network wrt the input passed in. However, in the overall training loop, I use a different gradient tape to get the gradients of the loss function with respect to the network weights so I can update the network. TF is telling me that the gradients of the loss wrt the network weights don&amp;#39;t exist, although it is able to compute the gradients of the network output wrt the input within the loss function. How do I achieve/fix this?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;here is the loss function, where I am able to get numerical gradient values of the output wrt the input&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/te0unjk3vyk51.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e9ea99aa512c790f075a9c3411b224d964249759""&gt;https://preview.redd.it/te0unjk3vyk51.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e9ea99aa512c790f075a9c3411b224d964249759&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and here is where I update the network with the training loop&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/wq1kq6afvyk51.png?width=1256&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4b8e7c37651bf9d3beabb6aa3423847fb4eede20""&gt;https://preview.redd.it/wq1kq6afvyk51.png?width=1256&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4b8e7c37651bf9d3beabb6aa3423847fb4eede20&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I get warnings from the training loop saying that the gradients don&amp;#39;t exist&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ilxeoz,True,,HotAd8181,,3,True,all_ads,False,[],False,,/r/tensorflow/comments/ilxeoz/help_getting_gradients_of_a_gradient_computation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ilxeoz/help_getting_gradients_of_a_gradient_computation/,22217,1599152420.0,0,,False,,,,,"{'wq1kq6afvyk51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 20, 'x': 108, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f32ad533f7c09a029135b25101503521eb5746a4'}, {'y': 40, 'x': 216, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=73196e34af7c2d4e29eb927f1044fc6fefacad08'}, {'y': 60, 'x': 320, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f8fc7d1f208860b978a24e134b1f03b65882d7ff'}, {'y': 120, 'x': 640, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fefbcdb634943fefc50a7998848c28b15192902f'}, {'y': 180, 'x': 960, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=17841df59693ce6d3ecdfa7cce8c8a37da8bbcf9'}, {'y': 202, 'x': 1080, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=67f2386c665a88e2798755c14126039009d4fe7e'}], 's': {'y': 236, 'x': 1256, 'u': 'https://preview.redd.it/wq1kq6afvyk51.png?width=1256&amp;format=png&amp;auto=webp&amp;s=4b8e7c37651bf9d3beabb6aa3423847fb4eede20'}, 'id': 'wq1kq6afvyk51'}, 'te0unjk3vyk51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/te0unjk3vyk51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=96a241d864fb0abdf8d2413a8689d9223a4e1e02'}, {'y': 145, 'x': 216, 'u': 'https://preview.redd.it/te0unjk3vyk51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f8ef8810a593360ff46ca593d0a113c2cf3c084'}, {'y': 215, 'x': 320, 'u': 'https://preview.redd.it/te0unjk3vyk51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=51eca074571a0c58e0ee6c3757baf49509b8d1c0'}, {'y': 430, 'x': 640, 'u': 'https://preview.redd.it/te0unjk3vyk51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e456e13ac90559a69ca53ce68949e57628256b0b'}], 's': {'y': 484, 'x': 720, 'u': 'https://preview.redd.it/te0unjk3vyk51.png?width=720&amp;format=png&amp;auto=webp&amp;s=e9ea99aa512c790f075a9c3411b224d964249759'}, 'id': 'te0unjk3vyk51'}}",,,,
884,,tensorflow,"I’m using the tensor flow module in python to aid in my project set by my professor to create a program to predict soccer matches, the only problem is that I’m confused about how the data should be presented. 
Data types e.g. possession, av shots, av goals etc.
Any suggestions on how to layout this data?",t2_3mzxrea7,False,,0,False,Sports betting data using AI to predict results.,[],r/tensorflow,False,6,,0,,,False,t3_ilvfep,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1599175257.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m using the tensor flow module in python to aid in my project set by my professor to create a program to predict soccer matches, the only problem is that I’m confused about how the data should be presented. 
Data types e.g. possession, av shots, av goals etc.
Any suggestions on how to layout this data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ilvfep,True,,hamiltonusername,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/ilvfep/sports_betting_data_using_ai_to_predict_results/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ilvfep/sports_betting_data_using_ai_to_predict_results/,22217,1599146457.0,0,,False,,,,,,,,,
885,,tensorflow,"It may be obvious for most of the people, but it wasn't for me, so I'm going to share what I have found.

When a model is saved through `model.save` it is possible to restore it in two ways: both recreating the model through `model = tf.keras.models.load_model(..)` or by creating the model manually and then loading the weights through `model.load_weights(..)`.

What I have found is that if you load a model through `load`, you will get a model identical to the one you have saved **included the optimizer state**, while if you load the model through `load_weights` the state of the optimizer will be discarded. Which means that if you are going to continue training a model which you have checkpointed through the model save callback, you will want to recreate the model using `model = tf.keras.models.load_model(..)`, or else your model will get worse during the first training epoch since your optimizer will have lost its internal state. On the other hand, if you plan to use a trained model in inference mode only, or you want to use it for transfer learning, `load_weights` is perfectly fine, since you won't need the state of the optimizer. 

While we are at it, I have found that the `experimental_steps_per_execution` option in compile, which is extremely useful while training models on TPU, is not being saved by model.save, so when you load the model using `model = tf.keras.models.load_model(..)` you need to set this property manually, which can easily done in this way:
```python
with strategy.scope():
    model = tf.keras.models.load_model('path/to/checkpoint.h5')
    model._configure_steps_per_execution(nsteps)
```

Where nsteps is the number of steps per execution. Ideally, you will want nsteps to be big enough so that the time required for on_batch_end operations is much smaller than the time required to train for that number of batches. This number can easily be found by looking at the timings included in the warning `Callbacks method on_train_batch_end is slow compared to the batch time` which is what tells you that you should use the `experimental_steps_per_execution` option. 

Have a nice day!",t2_26t6gid3,False,,0,False,Difference between load and load_weights in keras,[],r/tensorflow,False,6,,0,,,False,t3_iloxjl,False,dark,1.0,,public,4,0,{},,,False,[],,False,False,,{},,False,4,,False,self,False,,[],{},,True,,1599146721.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It may be obvious for most of the people, but it wasn&amp;#39;t for me, so I&amp;#39;m going to share what I have found.&lt;/p&gt;

&lt;p&gt;When a model is saved through &lt;code&gt;model.save&lt;/code&gt; it is possible to restore it in two ways: both recreating the model through &lt;code&gt;model = tf.keras.models.load_model(..)&lt;/code&gt; or by creating the model manually and then loading the weights through &lt;code&gt;model.load_weights(..)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;What I have found is that if you load a model through &lt;code&gt;load&lt;/code&gt;, you will get a model identical to the one you have saved &lt;strong&gt;included the optimizer state&lt;/strong&gt;, while if you load the model through &lt;code&gt;load_weights&lt;/code&gt; the state of the optimizer will be discarded. Which means that if you are going to continue training a model which you have checkpointed through the model save callback, you will want to recreate the model using &lt;code&gt;model = tf.keras.models.load_model(..)&lt;/code&gt;, or else your model will get worse during the first training epoch since your optimizer will have lost its internal state. On the other hand, if you plan to use a trained model in inference mode only, or you want to use it for transfer learning, &lt;code&gt;load_weights&lt;/code&gt; is perfectly fine, since you won&amp;#39;t need the state of the optimizer. &lt;/p&gt;

&lt;p&gt;While we are at it, I have found that the &lt;code&gt;experimental_steps_per_execution&lt;/code&gt; option in compile, which is extremely useful while training models on TPU, is not being saved by model.save, so when you load the model using &lt;code&gt;model = tf.keras.models.load_model(..)&lt;/code&gt; you need to set this property manually, which can easily done in this way:
&lt;code&gt;python
with strategy.scope():
    model = tf.keras.models.load_model(&amp;#39;path/to/checkpoint.h5&amp;#39;)
    model._configure_steps_per_execution(nsteps)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where nsteps is the number of steps per execution. Ideally, you will want nsteps to be big enough so that the time required for on_batch_end operations is much smaller than the time required to train for that number of batches. This number can easily be found by looking at the timings included in the warning &lt;code&gt;Callbacks method on_train_batch_end is slow compared to the batch time&lt;/code&gt; which is what tells you that you should use the &lt;code&gt;experimental_steps_per_execution&lt;/code&gt; option. &lt;/p&gt;

&lt;p&gt;Have a nice day!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iloxjl,True,,TrPhantom8,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iloxjl/difference_between_load_and_load_weights_in_keras/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iloxjl/difference_between_load_and_load_weights_in_keras/,22217,1599117921.0,0,,False,,,,,,,,,
886,,tensorflow,,t2_44mbtmjy,False,,0,False,Recovering multi-person 3D poses from a single RGB image!,[],r/tensorflow,False,6,,0,98.0,,False,t3_ilijal,False,dark,0.94,,public,13,0,{},140.0,,False,[],,False,False,,{},,False,13,,False,https://b.thumbs.redditmedia.com/zFxwXbd6YY8WegimANUDJbjrsBxkedVIlRQQxva15lU.jpg,False,,[],{},,False,,1599119524.0,text,6,,,text,self.LatestInML,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ilijal,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ilijal/recovering_multiperson_3d_poses_from_a_single_rgb/,all_ads,False,/r/LatestInML/comments/iliic2/recovering_multiperson_3d_poses_from_a_single_rgb/,22217,1599090724.0,0,,False,link,/r/LatestInML/comments/iliic2/recovering_multiperson_3d_poses_from_a_single_rgb/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?auto=webp&amp;s=6e6e992c74881ffc84a4b2ede231484edf71b3a7', 'width': 698, 'height': 490}, 'resolutions': [{'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85a4f502dfaa793649e14f243bccbb0106fe5102', 'width': 108, 'height': 75}, {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6c0a4af9a99e488f304b49ebdde5e5c10743d00', 'width': 216, 'height': 151}, {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63c06c2a49a148678340e352d46139fba4bad690', 'width': 320, 'height': 224}, {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=73cd98997f4c01a39df12f1941950dfb7c4934c9', 'width': 640, 'height': 449}], 'variants': {}, 'id': '1n1slrsssSZeiTqXvfWZ0IA-TrY-Xy0GI9D6EEzt8Ck'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2008.11469)\n\n&amp;#x200B;\n\nhttps://reddit.com/link/iliic2/video/3h3wr7pvntk51/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Recovering multi-person 3D poses from a single RGB image!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 98, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'3h3wr7pvntk51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/iliic2/asset/3h3wr7pvntk51/DASHPlaylist.mpd?a=1618044866%2CYmRjNThjZDlhY2YzODg1OTIwNGFiMmU0MDY3NTA2Y2Y3MjNlMWZjNWE4ZDY4OTM1MGY4NGQxMzY4MmU4MTQ5Yw%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/iliic2/asset/3h3wr7pvntk51/HLSPlaylist.m3u8?a=1618044866%2CZDlkMGUyMDk1MzUyMzg2MjRjMmNjNmNmNTJkOGM0MTg3YmQzOTZiNjRmODhkMDJjOThiMGM2Zjk3M2YyYjUxZQ%3D%3D&amp;v=1&amp;f=sd', 'id': '3h3wr7pvntk51', 'isGif': False}}, 'name': 't3_iliic2', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.96, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 71, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 71, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/zFxwXbd6YY8WegimANUDJbjrsBxkedVIlRQQxva15lU.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1599119428.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2008.11469""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/iliic2/video/3h3wr7pvntk51/player""&gt;https://reddit.com/link/iliic2/video/3h3wr7pvntk51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?auto=webp&amp;s=6e6e992c74881ffc84a4b2ede231484edf71b3a7', 'width': 698, 'height': 490}, 'resolutions': [{'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85a4f502dfaa793649e14f243bccbb0106fe5102', 'width': 108, 'height': 75}, {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6c0a4af9a99e488f304b49ebdde5e5c10743d00', 'width': 216, 'height': 151}, {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63c06c2a49a148678340e352d46139fba4bad690', 'width': 320, 'height': 224}, {'url': 'https://external-preview.redd.it/P5dHnpgNoMYypzJAKOWBwvVO5ZEvMYbf__UAfaIKDFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=73cd98997f4c01a39df12f1941950dfb7c4934c9', 'width': 640, 'height': 449}], 'variants': {}, 'id': '1n1slrsssSZeiTqXvfWZ0IA-TrY-Xy0GI9D6EEzt8Ck'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'iliic2', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/iliic2/recovering_multiperson_3d_poses_from_a_single_rgb/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/iliic2/recovering_multiperson_3d_poses_from_a_single_rgb/', 'subreddit_subscribers': 6676, 'created_utc': 1599090628.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_iliic2,
887,,tensorflow,,t2_7f71agho,False,,0,False,Is GradientDescentOptimizer's minimize function meant to be used in loop?,[],r/tensorflow,False,6,,0,,,False,t3_ilptk5,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1599151797.0,text,6,,,text,self.tensorflow,False,,,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ilptk5,True,,DrAsgardian,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ilptk5/is_gradientdescentoptimizers_minimize_function/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ilptk5/is_gradientdescentoptimizers_minimize_function/,22217,1599122997.0,0,,False,,,,,,,,,
888,,tensorflow," Tensorflow says they support python 3.5-3.8 . Anybody know if it supports 3.8.5 ?

Just not sure if they mean strictly 3.8.0 or 3.8.x.",t2_15srr1,False,,0,False,Tensorflow supports python 3.8.5?,[],r/tensorflow,False,6,,0,,,False,t3_ildm1t,False,dark,0.89,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1599103581.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Tensorflow says they support python 3.5-3.8 . Anybody know if it supports 3.8.5 ?&lt;/p&gt;

&lt;p&gt;Just not sure if they mean strictly 3.8.0 or 3.8.x.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ildm1t,True,,IgorTtk,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/ildm1t/tensorflow_supports_python_385/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ildm1t/tensorflow_supports_python_385/,22217,1599074781.0,0,,False,,,,,,,,,
889,,tensorflow,"I'm working on drowsiness detection using [this dataset. ](https://sites.google.com/view/utarldd/home)

The dataset has 3 classes of different awareness levels with 60 videos for each class and each video is about 10 mins long. 

Steps for preprocessing videos:

Converted to frames(a frame every 5 seconds).
Rotated them to ensure all the faces are vertical.
Extracted the faces from the frames. 
Combined all the frames in each class to a new folder. (example all frames of class 10 are combined together and each class is nearly perfectly balanced except 1 class which had 1% less frames than the others).
Split them into train(95%), validation(5%) and test(5%).

Now I am using transfer learning with MobilenetV2 for the spatial features then a LSTM layer for temporal features.

I resized the frames into (224,224,3) as MobilenetV2 requires them in this size and I load them in using tf.keras.preprocessing.image_dataset_from_directory in batches of size 32.

MobilenetV2 function:

```
def build_mobilenet(shape=INPUT_SHAPE, nbout=CLASSES):

    # INPUT_SHAPE = (224,224,3)

    # CLASSES = 3

    model = MobileNetV2(

        include_top=False,

        input_shape=shape,

        weights='imagenet')

    base_model.trainable = True

    output = GlobalMaxPool2D()

    return Sequential([model, output])

```

LSTM function:

```
def action_model(shape=INSHAPE, nbout=3):

    # INSHAPE = (5, 224, 224, 3)

    convnet = build_mobilenet(shape[1:])
    
    model = Sequential()

    model.add(TimeDistributed(convnet, input_shape=shape))

    model.add(LSTM(64))

    model.add(Dense(1024, activation='relu'))

    model.add(Dropout(.5))

    model.add(Dense(512, activation='relu'))

    model.add(Dropout(.5))

    model.add(Dense(128, activation='relu'))

    model.add(Dropout(.5))

    model.add(Dense(64, activation='relu'))

    model.add(Dense(nbout, activation='softmax'))

    return model
```

When I train the model I get the following error which I think means I'm trying to feed something like (32, 224, 224, 3) but my model needs (32, 5, 224, 224, 3). 

```
ValueError: Input 0 of layer sequential_16 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: [None, 224, 224, 3]
```

I am not sure what to do to fix this.",t2_3cn2c07x,False,,0,False,Confused about input shape for MobileNetV2 + LSTM,[],r/tensorflow,False,6,,0,,,False,t3_il0yru,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,1599025725.0,,[],{},,True,,1599053426.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on drowsiness detection using &lt;a href=""https://sites.google.com/view/utarldd/home""&gt;this dataset. &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The dataset has 3 classes of different awareness levels with 60 videos for each class and each video is about 10 mins long. &lt;/p&gt;

&lt;p&gt;Steps for preprocessing videos:&lt;/p&gt;

&lt;p&gt;Converted to frames(a frame every 5 seconds).
Rotated them to ensure all the faces are vertical.
Extracted the faces from the frames. 
Combined all the frames in each class to a new folder. (example all frames of class 10 are combined together and each class is nearly perfectly balanced except 1 class which had 1% less frames than the others).
Split them into train(95%), validation(5%) and test(5%).&lt;/p&gt;

&lt;p&gt;Now I am using transfer learning with MobilenetV2 for the spatial features then a LSTM layer for temporal features.&lt;/p&gt;

&lt;p&gt;I resized the frames into (224,224,3) as MobilenetV2 requires them in this size and I load them in using tf.keras.preprocessing.image_dataset_from_directory in batches of size 32.&lt;/p&gt;

&lt;p&gt;MobilenetV2 function:&lt;/p&gt;

&lt;p&gt;```
def build_mobilenet(shape=INPUT_SHAPE, nbout=CLASSES):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# INPUT_SHAPE = (224,224,3)

# CLASSES = 3

model = MobileNetV2(

    include_top=False,

    input_shape=shape,

    weights=&amp;#39;imagenet&amp;#39;)

base_model.trainable = True

output = GlobalMaxPool2D()

return Sequential([model, output])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;LSTM function:&lt;/p&gt;

&lt;p&gt;```
def action_model(shape=INSHAPE, nbout=3):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# INSHAPE = (5, 224, 224, 3)

convnet = build_mobilenet(shape[1:])

model = Sequential()

model.add(TimeDistributed(convnet, input_shape=shape))

model.add(LSTM(64))

model.add(Dense(1024, activation=&amp;#39;relu&amp;#39;))

model.add(Dropout(.5))

model.add(Dense(512, activation=&amp;#39;relu&amp;#39;))

model.add(Dropout(.5))

model.add(Dense(128, activation=&amp;#39;relu&amp;#39;))

model.add(Dropout(.5))

model.add(Dense(64, activation=&amp;#39;relu&amp;#39;))

model.add(Dense(nbout, activation=&amp;#39;softmax&amp;#39;))

return model
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;When I train the model I get the following error which I think means I&amp;#39;m trying to feed something like (32, 224, 224, 3) but my model needs (32, 5, 224, 224, 3). &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
ValueError: Input 0 of layer sequential_16 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: [None, 224, 224, 3]
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;I am not sure what to do to fix this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,il0yru,True,,yudhiesh,,9,True,all_ads,False,[],False,,/r/tensorflow/comments/il0yru/confused_about_input_shape_for_mobilenetv2_lstm/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/il0yru/confused_about_input_shape_for_mobilenetv2_lstm/,22217,1599024626.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?auto=webp&amp;s=57cbfdd9680462ba7b97dcaf73a684da50a756f1', 'width': 1686, 'height': 1491}, 'resolutions': [{'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=08132a15403c911ee9937a946605fe4efb788a16', 'width': 108, 'height': 95}, {'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=81d5739d31758cf295483476271afe6d88aac7cb', 'width': 216, 'height': 191}, {'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3715982c0c89a33b7cf52481cd96a8675cf01bf6', 'width': 320, 'height': 282}, {'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=256d54d82933216108667ddb6dfa65e5a4174d3c', 'width': 640, 'height': 565}, {'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9cf728242f8dc43a068fc35db21e39a4e6dfde19', 'width': 960, 'height': 848}, {'url': 'https://external-preview.redd.it/hzYaFMTKLiAVeQHVjbp9AKlrfeUhK0FndDUturLr2ho.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=242f46798f83c4f645d288223f64cb34ddc2afe3', 'width': 1080, 'height': 955}], 'variants': {}, 'id': 'weIwcphjW5KzSlP3Ng4tMju06KR8C_u8ic_CjXXktpg'}], 'enabled': False}",,,,,,
890,,tensorflow,"I have several records that all follow the same pattern. All of them change their behaviour from a variable point in time. This point is known in advance. What is the best way to pass on this fixed point next to the Time Series?

Thanks to everyone who helps me.",t2_6oi9ephi,False,,0,False,Time Series Forecasting with change at certain point,[],r/tensorflow,False,6,,0,,,False,t3_ikq115,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1599014215.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have several records that all follow the same pattern. All of them change their behaviour from a variable point in time. This point is known in advance. What is the best way to pass on this fixed point next to the Time Series?&lt;/p&gt;

&lt;p&gt;Thanks to everyone who helps me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ikq115,True,,inner_chaos_,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ikq115/time_series_forecasting_with_change_at_certain/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ikq115/time_series_forecasting_with_change_at_certain/,22217,1598985415.0,0,,False,,,,,,,,,
891,,tensorflow,,t2_44mbtmjy,False,,0,False,Generating photo-realistic face images from hand-drawn sketches!,[],r/tensorflow,False,6,,0,140.0,,False,t3_ikeqn9,False,dark,1.0,,public,7,0,{},140.0,,False,[],,False,False,,{},,False,7,,False,https://b.thumbs.redditmedia.com/vI_WpCO3-3hbMwyAwVM0VnrQD1DnPKjhSFfCOE1t89M.jpg,False,,[],{},,False,,1598967862.0,text,6,,,text,self.LatestInML,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ikeqn9,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ikeqn9/generating_photorealistic_face_images_from/,all_ads,False,/r/LatestInML/comments/ikeh82/generating_photorealistic_face_images_from/,22217,1598939062.0,0,,False,link,/r/LatestInML/comments/ikeh82/generating_photorealistic_face_images_from/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2008.13343)\n\nhttps://preview.redd.it/4jkb6j580hk51.jpg?width=666&amp;format=pjpg&amp;auto=webp&amp;s=71fc07b1a247535c616db82d8430ebdc073b02f7', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Generating photo-realistic face images from hand-drawn sketches!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'4jkb6j580hk51': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 174, 'x': 108, 'u': 'https://preview.redd.it/4jkb6j580hk51.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=337702e56d3d991d3d01a85cf5fb2c927a83332b'}, {'y': 348, 'x': 216, 'u': 'https://preview.redd.it/4jkb6j580hk51.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0703a9c8da655fb51ed9a49377a3d28a4f690050'}, {'y': 516, 'x': 320, 'u': 'https://preview.redd.it/4jkb6j580hk51.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eefa17d3f07b92d10c706ffa21ee1c0efc1df15b'}, {'y': 1032, 'x': 640, 'u': 'https://preview.redd.it/4jkb6j580hk51.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84d3c93dfc08fb5ca81f623a144bf6f97cdf1b56'}], 's': {'y': 1074, 'x': 666, 'u': 'https://preview.redd.it/4jkb6j580hk51.jpg?width=666&amp;format=pjpg&amp;auto=webp&amp;s=71fc07b1a247535c616db82d8430ebdc073b02f7'}, 'id': '4jkb6j580hk51'}}, 'name': 't3_ikeh82', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 28, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 28, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/vI_WpCO3-3hbMwyAwVM0VnrQD1DnPKjhSFfCOE1t89M.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1598966581.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2008.13343""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/4jkb6j580hk51.jpg?width=666&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71fc07b1a247535c616db82d8430ebdc073b02f7""&gt;https://preview.redd.it/4jkb6j580hk51.jpg?width=666&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71fc07b1a247535c616db82d8430ebdc073b02f7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ikeh82', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/ikeh82/generating_photorealistic_face_images_from/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/ikeh82/generating_photorealistic_face_images_from/', 'subreddit_subscribers': 6676, 'created_utc': 1598937781.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_ikeh82,
892,,tensorflow,"Just a quick question - is the certificate network dead as of early July?
Seems like the TF network hasn’t been updated for well over 2 months now and I want my name to be displayed!!! :D",t2_34vxg1em,False,,0,False,Tensorflow Certificate Network dead?,[],r/tensorflow,False,6,,0,,,False,t3_ikdsrw,False,dark,0.72,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1598963518.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just a quick question - is the certificate network dead as of early July?
Seems like the TF network hasn’t been updated for well over 2 months now and I want my name to be displayed!!! :D&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ikdsrw,True,,djkim3190,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ikdsrw/tensorflow_certificate_network_dead/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ikdsrw/tensorflow_certificate_network_dead/,22217,1598934718.0,0,,False,,,,,,,,,
893,,tensorflow,"Hello community , as the title spoke of itself
I can see the distribution of the weights using tensor board but that is not what I’m looking for ,  , I want to extract weights  of every layer of my model and be able to see the tensor values of it .
Any solution ??
Thank you",t2_7l9ti89m,False,,0,False,Extract weights of every hidden layers,[],r/tensorflow,False,6,,0,,,False,t3_ikiuc7,False,dark,0.67,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1598989973.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community , as the title spoke of itself
I can see the distribution of the weights using tensor board but that is not what I’m looking for ,  , I want to extract weights  of every layer of my model and be able to see the tensor values of it .
Any solution ??
Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ikiuc7,True,,rayanaay,,15,True,all_ads,False,[],False,,/r/tensorflow/comments/ikiuc7/extract_weights_of_every_hidden_layers/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ikiuc7/extract_weights_of_every_hidden_layers/,22217,1598961173.0,0,,False,,,,,,,,,
894,,tensorflow,"In my new video, I explain how to extract the Fourier Transform from an audio file with Python and Numpy. I also visualise and compare the magnitude spectra of the same note played on different musical instruments. 

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=R-5uxKTRjzM&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=14](https://www.youtube.com/watch?v=R-5uxKTRjzM&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=14)",t2_12ahau,False,,0,False,I published a tutorial where I explain how to extract the Fourier Transform from audio with Python,[],r/tensorflow,False,6,,0,,,False,t3_ijzgct,False,dark,1.0,,public,28,0,{},,,False,[],,False,False,,{},Discussion,False,28,,False,self,False,,[],{},,True,,1598914499.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my new video, I explain how to extract the Fourier Transform from an audio file with Python and Numpy. I also visualise and compare the magnitude spectra of the same note played on different musical instruments. &lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=R-5uxKTRjzM&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=14""&gt;https://www.youtube.com/watch?v=R-5uxKTRjzM&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=14&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,ijzgct,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ijzgct/i_published_a_tutorial_where_i_explain_how_to/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijzgct/i_published_a_tutorial_where_i_explain_how_to/,22217,1598885699.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/ANYLZAEGtXuSL9gljXP-zv-__fwaUaCxK6I97xS_Gmw.jpg?auto=webp&amp;s=a6f038ce28f140e214d43621a2ea83d08e5368e5', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/ANYLZAEGtXuSL9gljXP-zv-__fwaUaCxK6I97xS_Gmw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1108e6f9172e28b2caf9bfd3ee75b08f574facc', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/ANYLZAEGtXuSL9gljXP-zv-__fwaUaCxK6I97xS_Gmw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8482b72f136bc44c2d3fcb86eabfb9f529089044', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/ANYLZAEGtXuSL9gljXP-zv-__fwaUaCxK6I97xS_Gmw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44c501da408caf7d88d51b5cdc32bc90b1b4fa12', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'TU9AwnlC0gDluFnYnTu-1vQQSh8Q9LSv7v_dUANOqu8'}], 'enabled': False}",,,,,,
895,,tensorflow,"I have a model that predicts the age and gender of the input image of size 160X160. I am creating a byte buffer to input the image to the model and everything works just fine when using a model with only one output.

But when I am using the tflite.runForMultipleInputsOutputs(), I am getting garbage values which are of the form -&gt; \[\[F@e233 etc.

I have followed the documentation and the sample apps to the detail and have been stuck at this for almost 2 days. Please help. 

I am posting my code below for reference.

The model has 2 outputs: 

* age -&gt; float32 \[1, 2\]
* gender -&gt; float32 \[1,101\]

P.S - I am not doing anything with the output as of now. I just want to see the result of the model.

    String classifyImage(Bitmap bitmap){
            try{
                ByteBuffer byteBuffer = convertBitmaptoByteBuffer(bitmap);
    
                float[][] out_gender = new float[1][2];
                float[][] out_age = new float[1][101];
                Object[] input = {byteBuffer};
    
                Map&lt;Integer, Object&gt; outputs = new HashMap();
                outputs.put(0, out_age);
                outputs.put(1, out_gender);
    
                interpreter.runForMultipleInputsOutputs(input, outputs);
                
            }catch (Exception e){
                e.printStackTrace();
            }
            return """";
        }",t2_39eh7mnm,False,,0,False,TfLite Android: Garbage values when running inference for multiple output model,[],r/tensorflow,False,6,,0,,,False,t3_ikeavb,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},NEED HELP,False,1,,False,self,False,,[],{},,True,,1598965751.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a model that predicts the age and gender of the input image of size 160X160. I am creating a byte buffer to input the image to the model and everything works just fine when using a model with only one output.&lt;/p&gt;

&lt;p&gt;But when I am using the tflite.runForMultipleInputsOutputs(), I am getting garbage values which are of the form -&amp;gt; [[F@e233 etc.&lt;/p&gt;

&lt;p&gt;I have followed the documentation and the sample apps to the detail and have been stuck at this for almost 2 days. Please help. &lt;/p&gt;

&lt;p&gt;I am posting my code below for reference.&lt;/p&gt;

&lt;p&gt;The model has 2 outputs: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;age -&amp;gt; float32 [1, 2]&lt;/li&gt;
&lt;li&gt;gender -&amp;gt; float32 [1,101]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;P.S - I am not doing anything with the output as of now. I just want to see the result of the model.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;String classifyImage(Bitmap bitmap){
        try{
            ByteBuffer byteBuffer = convertBitmaptoByteBuffer(bitmap);

            float[][] out_gender = new float[1][2];
            float[][] out_age = new float[1][101];
            Object[] input = {byteBuffer};

            Map&amp;lt;Integer, Object&amp;gt; outputs = new HashMap();
            outputs.put(0, out_age);
            outputs.put(1, out_gender);

            interpreter.runForMultipleInputsOutputs(input, outputs);

        }catch (Exception e){
            e.printStackTrace();
        }
        return &amp;quot;&amp;quot;;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ikeavb,True,,abhishekti,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ikeavb/tflite_android_garbage_values_when_running/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ikeavb/tflite_android_garbage_values_when_running/,22217,1598936951.0,0,,False,,,,,,,,,
896,,tensorflow,"I'm an occupational therapy student and am wondering if anyone has tried to develop this demo into a real program:
https://github.com/shekit/alexa-sign-language-translator

It doesn't look like anything has happened for 2 years.

According to a person on deaf reddit, the current programs have a very limited vocab and require precise signing, but I thought you may have a handle on making the program work better and maybe we could collab with ASL signers to develop the machine learning further.

Also is there translation from Spanish to English in tensor flow?

Update: I've been talking to the creator and he confirmed that he trained and tested in the same environment.",t2_aak6i,False,,0,False,ASL to English,[],r/tensorflow,False,6,,0,,,False,t3_ik8pxk,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},Question,False,3,,False,self,1598932799.0,,[],{},,True,,1598943787.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m an occupational therapy student and am wondering if anyone has tried to develop this demo into a real program:
&lt;a href=""https://github.com/shekit/alexa-sign-language-translator""&gt;https://github.com/shekit/alexa-sign-language-translator&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It doesn&amp;#39;t look like anything has happened for 2 years.&lt;/p&gt;

&lt;p&gt;According to a person on deaf reddit, the current programs have a very limited vocab and require precise signing, but I thought you may have a handle on making the program work better and maybe we could collab with ASL signers to develop the machine learning further.&lt;/p&gt;

&lt;p&gt;Also is there translation from Spanish to English in tensor flow?&lt;/p&gt;

&lt;p&gt;Update: I&amp;#39;ve been talking to the creator and he confirmed that he trained and tested in the same environment.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ik8pxk,True,,ZuriBella,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ik8pxk/asl_to_english/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ik8pxk/asl_to_english/,22217,1598914987.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/wrjZiJBw94Bw8briJ3C6qwoI6lSUK2GkC5_53o26Gm4.jpg?auto=webp&amp;s=c92fc0e320df4f4bdbb378002a0204dd027efe9b', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/wrjZiJBw94Bw8briJ3C6qwoI6lSUK2GkC5_53o26Gm4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=375ff62237e356136d222094d126e570c265fa57', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/wrjZiJBw94Bw8briJ3C6qwoI6lSUK2GkC5_53o26Gm4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b13bcd3294515cac0bbb00f3a70cad116b196be9', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/wrjZiJBw94Bw8briJ3C6qwoI6lSUK2GkC5_53o26Gm4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e31795272e0df13ed2d8cb7a499c546fae50918f', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'Kfdo1y0vRsv7DQp78Q0xWE6H1pdNT1mqRd9h62V2IZ0'}], 'enabled': False}",,,,,,
897,,tensorflow,"I'm trying to update some code from tensorflow 1 to tensorflow 2.

Could someone help me with an error I have with the following line of code?

    layer_activations = [end_points_collection[l] for l in loss_layers] 

I got it from:

[https://github.com/google-research/google-research/blob/master/demogen/margin\_utils.py](https://github.com/google-research/google-research/blob/master/demogen/margin_utils.py)

However, I'm getting the following traceback. In another post, I learned that the error comes from end\_point\_collection being empty. This was called from `model_config.get_modelfn()` which also calls `contrib_training.HParams()` from `tensorflow.contrib`. Alternatively, if anybody knows how to calculate layer margins with a keras or tensorflow 2, that would be greatly appreciated.

    Traceback (most recent call last):
    File ""C:\Users\user\.conda\envs\tf2\lib\site-packages\IPython\core\interactiveshell.py"", line 3417, in run_code
            exec(code_obj, self.user_global_ns, self.user_ns)
    File ""&lt;ipython-input-49-ccf9839481e1&gt;"", line 1, in &lt;module&gt;
            layer_activations = [end_points_collection[l] for l in loss_layers]
    File ""&lt;ipython-input-49-ccf9839481e1&gt;"", line 1, in &lt;listcomp&gt;
            layer_activations = [end_points_collection[l] for l in loss_layers]
    KeyError: 'inputs'",t2_7x60aoy8,False,,0,False,Calculating margins in tensorflow 2,[],r/tensorflow,False,6,,0,,,False,t3_ik7gti,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1598939530.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to update some code from tensorflow 1 to tensorflow 2.&lt;/p&gt;

&lt;p&gt;Could someone help me with an error I have with the following line of code?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;layer_activations = [end_points_collection[l] for l in loss_layers] 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I got it from:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/google-research/google-research/blob/master/demogen/margin_utils.py""&gt;https://github.com/google-research/google-research/blob/master/demogen/margin_utils.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, I&amp;#39;m getting the following traceback. In another post, I learned that the error comes from end_point_collection being empty. This was called from &lt;code&gt;model_config.get_modelfn()&lt;/code&gt; which also calls &lt;code&gt;contrib_training.HParams()&lt;/code&gt; from &lt;code&gt;tensorflow.contrib&lt;/code&gt;. Alternatively, if anybody knows how to calculate layer margins with a keras or tensorflow 2, that would be greatly appreciated.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Traceback (most recent call last):
File &amp;quot;C:\Users\user\.conda\envs\tf2\lib\site-packages\IPython\core\interactiveshell.py&amp;quot;, line 3417, in run_code
        exec(code_obj, self.user_global_ns, self.user_ns)
File &amp;quot;&amp;lt;ipython-input-49-ccf9839481e1&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
        layer_activations = [end_points_collection[l] for l in loss_layers]
File &amp;quot;&amp;lt;ipython-input-49-ccf9839481e1&amp;gt;&amp;quot;, line 1, in &amp;lt;listcomp&amp;gt;
        layer_activations = [end_points_collection[l] for l in loss_layers]
KeyError: &amp;#39;inputs&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ik7gti,True,,Significant-Cup6220,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ik7gti/calculating_margins_in_tensorflow_2/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ik7gti/calculating_margins_in_tensorflow_2/,22217,1598910730.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/x_JXtaVgDCsNm1Ewo_Vr1BSkwRWAxe52vRTol6O-BHM.jpg?auto=webp&amp;s=08435cfa9675d6dc077faf5d82ce66418853a018', 'width': 400, 'height': 400}, 'resolutions': [{'url': 'https://external-preview.redd.it/x_JXtaVgDCsNm1Ewo_Vr1BSkwRWAxe52vRTol6O-BHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3803e728f229ac349b426204400c2715a61d6533', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/x_JXtaVgDCsNm1Ewo_Vr1BSkwRWAxe52vRTol6O-BHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9721699f4c4ae84df4565518a932a302457613d7', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/x_JXtaVgDCsNm1Ewo_Vr1BSkwRWAxe52vRTol6O-BHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26becca3e7d0f5b931a174ba43a48167c3010f31', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'lLjMPiIvWrDN7TYg5RayUylJK4F7TDqwbW4LKvWWlVQ'}], 'enabled': False}",,,,,,
898,,tensorflow,"TensorFlow callbacks have become a basic and essential part of training deep learning models. For instance, the EarlyStopping callback is commonly used to prevent overfitting; ModelCheckpoint is critical to prevent losing progress from interrupted training, or being able to return to a previous point in time; and TensorBoard is commonly used to visualize the progression of your model training.

This article covers the 10 main callback functions in TensorFlow, with runnable Python code included.

Tutorial link:  [https://blog.paperspace.com/tensorflow-callbacks/](https://blog.paperspace.com/tensorflow-callbacks/) 

Run the code for free: [https://ml-showcase.paperspace.com/projects/tensorflow-callback-functions](https://ml-showcase.paperspace.com/projects/tensorflow-callback-functions)",t2_15en0l,False,,0,False,[Tutorial] A Guide to TensorFlow Callback Functions,[],r/tensorflow,False,6,,0,,,False,t3_ijyi3d,False,dark,1.0,,public,3,0,{},,,False,[],,False,False,,{},,False,3,,False,self,False,,[],{},,True,,1598911268.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TensorFlow callbacks have become a basic and essential part of training deep learning models. For instance, the EarlyStopping callback is commonly used to prevent overfitting; ModelCheckpoint is critical to prevent losing progress from interrupted training, or being able to return to a previous point in time; and TensorBoard is commonly used to visualize the progression of your model training.&lt;/p&gt;

&lt;p&gt;This article covers the 10 main callback functions in TensorFlow, with runnable Python code included.&lt;/p&gt;

&lt;p&gt;Tutorial link:  &lt;a href=""https://blog.paperspace.com/tensorflow-callbacks/""&gt;https://blog.paperspace.com/tensorflow-callbacks/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Run the code for free: &lt;a href=""https://ml-showcase.paperspace.com/projects/tensorflow-callback-functions""&gt;https://ml-showcase.paperspace.com/projects/tensorflow-callback-functions&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ijyi3d,True,,hellopaperspace,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/ijyi3d/tutorial_a_guide_to_tensorflow_callback_functions/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijyi3d/tutorial_a_guide_to_tensorflow_callback_functions/,22217,1598882468.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?auto=webp&amp;s=f54b438b8ebe4178fd200caf12b2f1bc9d7edb5f', 'width': 2000, 'height': 1333}, 'resolutions': [{'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4552e6686e7faf5cf313bbb6a65f24a7841609ca', 'width': 108, 'height': 71}, {'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d008c97b601412cebca18fbca865d6d540fac939', 'width': 216, 'height': 143}, {'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a88cfbedb9dac6931b37f09e8412e9c7c4c1e9d', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5198e08781847a1ca1c049352af17406741ce9b1', 'width': 640, 'height': 426}, {'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9a464f73db3c4b50c3ee9abe79c70f023e3dfb36', 'width': 960, 'height': 639}, {'url': 'https://external-preview.redd.it/bovsLVt7mrVXEnyA-NXBW-3-Lc75chqJ-GCcOIlhOSw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3dca0dc3f7d5da3fd72774858a7554b96e723ce7', 'width': 1080, 'height': 719}], 'variants': {}, 'id': 'NdUMev1k86WE1Y4dzjpB2d7VYw-vNLkmlAAlXtdgAxo'}], 'enabled': False}",,,,,,
899,,tensorflow,"AI and Deep Learning in TensorFlow with Python Certification Training master the concepts of SoftMax function, Autoencoder Neural Networks, Restricted Boltzmann Machine (RBM) and work with libraries like Keras &amp; TFLearn. Gain high-demand skills in Deep Learning and TensorFlow Concepts, Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Keras, TFlearn, Autoencoders, Restricted Boltz-mann Machine (RBM), Neural Networks &amp; Natural Language Processing (NLP), Python with TensorFlow Libraries, Text Analytics and Processing. 
Training modules include: 1) Introduction to Deep Learning, 2) Neural Networks with TensorFlow, 3) Deep Networks, 4) Convolutional Neural Networks (CNN), 5 )Recurrent Neural Networks (RNN), 6) Restricted Boltzmann Machine (RBM) and Autoencoders, 7) Keras API, 8) TFLearn API, and 9) In-Class Project.

Register today at: https://fxo.co/9PYj  

Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)",t2_36ixj,False,,0,False,AI and Deep Learning with TensorFlow,[],r/tensorflow,False,6,,0,,,False,t3_ik4nom,False,dark,0.5,,public,0,0,{},,,False,[],,False,False,,{},Discussion,False,0,,False,self,False,,[],{},,True,,1598930658.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;AI and Deep Learning in TensorFlow with Python Certification Training master the concepts of SoftMax function, Autoencoder Neural Networks, Restricted Boltzmann Machine (RBM) and work with libraries like Keras &amp;amp; TFLearn. Gain high-demand skills in Deep Learning and TensorFlow Concepts, Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Keras, TFlearn, Autoencoders, Restricted Boltz-mann Machine (RBM), Neural Networks &amp;amp; Natural Language Processing (NLP), Python with TensorFlow Libraries, Text Analytics and Processing. 
Training modules include: 1) Introduction to Deep Learning, 2) Neural Networks with TensorFlow, 3) Deep Networks, 4) Convolutional Neural Networks (CNN), 5 )Recurrent Neural Networks (RNN), 6) Restricted Boltzmann Machine (RBM) and Autoencoders, 7) Keras API, 8) TFLearn API, and 9) In-Class Project.&lt;/p&gt;

&lt;p&gt;Register today at: &lt;a href=""https://fxo.co/9PYj""&gt;https://fxo.co/9PYj&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,ik4nom,True,,lwilson747,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ik4nom/ai_and_deep_learning_with_tensorflow/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ik4nom/ai_and_deep_learning_with_tensorflow/,22217,1598901858.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VMRFvkQHVdXfgNonNgQqyZ0OahUKPWNk2i8WCc1GvWQ.jpg?auto=webp&amp;s=cc797a16a4903a07ea59e911f5da734772198413', 'width': 133, 'height': 133}, 'resolutions': [{'url': 'https://external-preview.redd.it/VMRFvkQHVdXfgNonNgQqyZ0OahUKPWNk2i8WCc1GvWQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75332b3d984e26528e25c2059a0dc95b0cb1af33', 'width': 108, 'height': 108}], 'variants': {}, 'id': 'yPhkz8WPAAg_BC_Es2wblaXjyHMFhVUxxDxzL5mxSuA'}], 'enabled': False}",,,,,,
900,,tensorflow," Hello! I started a company (Naptic) about a year ago built around gun detection for ip cameras and recently received a 18m valuation. I need to hire an engineer to help deploy and develop our AI to act as head of AI development as well as a co-founder. This position would include a generous salary and a couple million dollars in company shares. If you or anyone you know would be a good fit for this position and are interested, please contact me at [jeffschulze@yahoo.com](mailto:jeffschulze@yahoo.com). Thanks for your help!",t2_6d8yg4fu,False,,0,False,Seeking Tensorflow/Keras lead developer that specializes in object detection,[],r/tensorflow,False,6,,0,,,False,t3_iju7co,False,dark,0.77,,public,7,0,{},,,False,[],,False,False,,{},,False,7,,False,self,False,,[],{},,True,,1598890915.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I started a company (Naptic) about a year ago built around gun detection for ip cameras and recently received a 18m valuation. I need to hire an engineer to help deploy and develop our AI to act as head of AI development as well as a co-founder. This position would include a generous salary and a couple million dollars in company shares. If you or anyone you know would be a good fit for this position and are interested, please contact me at [&lt;a href=""mailto:jeffschulze@yahoo.com""&gt;jeffschulze@yahoo.com&lt;/a&gt;](mailto:&lt;a href=""mailto:jeffschulze@yahoo.com""&gt;jeffschulze@yahoo.com&lt;/a&gt;). Thanks for your help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iju7co,True,,hot_pants_1,,12,True,all_ads,False,[],False,,/r/tensorflow/comments/iju7co/seeking_tensorflowkeras_lead_developer_that/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iju7co/seeking_tensorflowkeras_lead_developer_that/,22217,1598862115.0,0,,False,,,,,,,,,
901,,tensorflow,"Hey, guys. SparkNLP has the option of using Embeddings, but only in English and Multi-language. I tried to train a NER model using multi_cased BERT, but when used in a pipeline, the resulting labels were all the same: ""in"". 
I was wondering if there's a way of downloading a tensorflow checkpoint (from neuralmind/portuguese-bert) and using it as an input for the training algorithm. Or even transform it to the format that works with SparkNLP. I don't know a lot about tensorflow and I'm struggling with that. 

Thanks!!",t2_51f9ur4y,False,,0,False,Using Portuguese BERT with SparkNLP,[],r/tensorflow,False,6,,0,,,False,t3_ijy87z,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1598910241.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, guys. SparkNLP has the option of using Embeddings, but only in English and Multi-language. I tried to train a NER model using multi_cased BERT, but when used in a pipeline, the resulting labels were all the same: &amp;quot;in&amp;quot;. 
I was wondering if there&amp;#39;s a way of downloading a tensorflow checkpoint (from neuralmind/portuguese-bert) and using it as an input for the training algorithm. Or even transform it to the format that works with SparkNLP. I don&amp;#39;t know a lot about tensorflow and I&amp;#39;m struggling with that. &lt;/p&gt;

&lt;p&gt;Thanks!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ijy87z,True,,heymiloca,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ijy87z/using_portuguese_bert_with_sparknlp/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijy87z/using_portuguese_bert_with_sparknlp/,22217,1598881441.0,0,,False,,,,,,,,,
902,,tensorflow,"Hi, I’m new to TensorFlow and machine learning, so please forgive my ignorance. I have a model that I’m trying to train to play a game by making moves based on the board state. The training data has examples of games lost and games won. It’s easy to find the loss for games won, because I know what the optimal move should’ve been. For games lost however, I only know what I shouldn’t have done. I also have a metric for how completely I won or lost that should probably factor in there somehow.

My question is: should I,
1) Only train on the winning data
2) Create a model that predicts the winning move and a model that predicts the losing move and compare them
3) Somehow find a way to feed all of it into the single network, a problem I’ve been struggling to figure out for a while

Any help would be greatly appreciated!",t2_sw3pq8l,False,,0,False,Calculating loss from both good and bad examples,[],r/tensorflow,False,6,,0,,,False,t3_ik0100,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},Question,False,1,,False,self,False,,[],{},,True,,1598916385.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I’m new to TensorFlow and machine learning, so please forgive my ignorance. I have a model that I’m trying to train to play a game by making moves based on the board state. The training data has examples of games lost and games won. It’s easy to find the loss for games won, because I know what the optimal move should’ve been. For games lost however, I only know what I shouldn’t have done. I also have a metric for how completely I won or lost that should probably factor in there somehow.&lt;/p&gt;

&lt;p&gt;My question is: should I,
1) Only train on the winning data
2) Create a model that predicts the winning move and a model that predicts the losing move and compare them
3) Somehow find a way to feed all of it into the single network, a problem I’ve been struggling to figure out for a while&lt;/p&gt;

&lt;p&gt;Any help would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ik0100,True,,animation-addict,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ik0100/calculating_loss_from_both_good_and_bad_examples/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ik0100/calculating_loss_from_both_good_and_bad_examples/,22217,1598887585.0,0,,False,,,,,,,,,
903,,tensorflow,"Assuming a small dataset, in general machine learning problems, one should do cross validation.

But in the case of Object Detection I've been looking for some explanation on this topic but seem to find no concrete answer, and some say we should not do it.

Can someone elaborate on the matter? Should we do it or not?",t2_607rias5,False,,0,False,Cross Validation in Object Detection,[],r/tensorflow,False,6,,0,,,False,t3_ijqahx,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},,False,5,,False,self,False,,[],{},,True,,1598871787.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Assuming a small dataset, in general machine learning problems, one should do cross validation.&lt;/p&gt;

&lt;p&gt;But in the case of Object Detection I&amp;#39;ve been looking for some explanation on this topic but seem to find no concrete answer, and some say we should not do it.&lt;/p&gt;

&lt;p&gt;Can someone elaborate on the matter? Should we do it or not?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ijqahx,True,,Akroma188,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ijqahx/cross_validation_in_object_detection/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijqahx/cross_validation_in_object_detection/,22217,1598842987.0,0,,False,,,,,,,,,
904,,tensorflow,"I have some experience in Python and Python packages in general but I'm always amazed by the difficulties in installing Tensorflow. I couldn't find any explanations about the great number of encountered errors compared to other libraries.

PS: this is not a rage post, I'm genuinely curious.",t2_npixkyh,False,,0,False,[ELI5] Why is Tensorflow so difficult to install?,[],r/tensorflow,False,6,,0,,,False,t3_ijblh0,False,dark,0.91,,public,17,0,{},,,False,[],,False,False,,{},,False,17,,False,self,False,,[],{},,True,,1598817722.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have some experience in Python and Python packages in general but I&amp;#39;m always amazed by the difficulties in installing Tensorflow. I couldn&amp;#39;t find any explanations about the great number of encountered errors compared to other libraries.&lt;/p&gt;

&lt;p&gt;PS: this is not a rage post, I&amp;#39;m genuinely curious.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ijblh0,True,,Arthurion9,,18,True,all_ads,False,[],False,,/r/tensorflow/comments/ijblh0/eli5_why_is_tensorflow_so_difficult_to_install/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijblh0/eli5_why_is_tensorflow_so_difficult_to_install/,22217,1598788922.0,0,,False,,,,,,,,,
905,,tensorflow,,t2_1144nh,False,,0,False,Alfred Workflow to quickly jump to the TensorFlow official API docs https://github.com/lsgrep/mldocs,[],r/tensorflow,False,6,,0,119.0,,False,t3_ij7b8j,False,dark,1.0,,public,44,0,{},140.0,,False,[],,True,False,,{},,False,44,,False,https://b.thumbs.redditmedia.com/gKc7KD0a9006qg10WiGVEBbQqfD00ktQ5uhAw84AeFI.jpg,False,,[],{},,False,,1598792907.0,text,6,,,text,i.redd.it,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ij7b8j,True,,staged_blue,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/ij7b8j/alfred_workflow_to_quickly_jump_to_the_tensorflow/,all_ads,False,https://i.redd.it/cobp7sqvo2k51.gif,22217,1598764107.0,0,,False,image,https://i.redd.it/cobp7sqvo2k51.gif,"{'images': [{'source': {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?format=png8&amp;s=ce8ee4ef697842fcb20951676755990296207031', 'width': 320, 'height': 273}, 'resolutions': [{'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=81907a176353917eb12b92a67de4b779ca0670d3', 'width': 108, 'height': 92}, {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=fe88c93b85c571fc194d044ab78aba92984f0154', 'width': 216, 'height': 184}, {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=9dc711d74304cfce74549bcbcde766e8a74dffb1', 'width': 320, 'height': 273}], 'variants': {'gif': {'source': {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?s=1414432e10fb072d91d461e6857c954fe89140b6', 'width': 320, 'height': 273}, 'resolutions': [{'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=108&amp;crop=smart&amp;s=8e147ddec1b7536a35a14554510aeffdc38fe052', 'width': 108, 'height': 92}, {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=216&amp;crop=smart&amp;s=9c6268afc5140a15f3939ca06800d482c088e807', 'width': 216, 'height': 184}, {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=320&amp;crop=smart&amp;s=1f688aa3da4d57643d8be2ded29008589b77aed9', 'width': 320, 'height': 273}]}, 'mp4': {'source': {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?format=mp4&amp;s=96d02ab86224b804d6190ea643f2dcdec7b08e83', 'width': 320, 'height': 273}, 'resolutions': [{'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=108&amp;format=mp4&amp;s=59ad1b7a0401e30c2dda3f484fd53fce72b8f96b', 'width': 108, 'height': 92}, {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=216&amp;format=mp4&amp;s=688c80c79e296c8062857288283994af38e5b68b', 'width': 216, 'height': 184}, {'url': 'https://preview.redd.it/cobp7sqvo2k51.gif?width=320&amp;format=mp4&amp;s=ab0b1f8c2daf9197e2ca223f564eb000fa3206bc', 'width': 320, 'height': 273}]}}, 'id': 'HfXaPmSH18oOynDFCI4Hlnay_73REWIiMw7e7Dcn00k'}], 'enabled': True}",,,,,,
906,,tensorflow,,t2_d7n70k0,False,,0,False,My Tensorflow Tutorial Predicting Numbers,[],r/tensorflow,False,6,,0,105.0,,False,t3_ijczpa,False,dark,0.73,,public,5,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/g4P-An6k_mU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Python Tensor Flow Tutorial - Predicting Numbers', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/g4P-An6k_mU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Consulting Joe', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/g4P-An6k_mU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/zerocool60544'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/g4P-An6k_mU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ijczpa', 'height': 338}",,False,5,,False,https://b.thumbs.redditmedia.com/DDoxQ-O69hyJUxOt0XFPe5kP1pXf1kjtEZBOHgVM69I.jpg,False,,[],{},,False,,1598824399.0,text,6,,,text,youtu.be,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ijczpa,True,,ConsultingJoe,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ijczpa/my_tensorflow_tutorial_predicting_numbers/,all_ads,False,https://youtu.be/g4P-An6k_mU,22217,1598795599.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Python Tensor Flow Tutorial - Predicting Numbers', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/g4P-An6k_mU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Consulting Joe', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/g4P-An6k_mU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/zerocool60544'}}",False,rich:video,https://youtu.be/g4P-An6k_mU,"{'images': [{'source': {'url': 'https://external-preview.redd.it/WWRuvLKtTrJdKJ8qdygPWPPvL8O_u0nkP24IRLy9vrk.jpg?auto=webp&amp;s=3e98db7639b912617eec67899529736423dafb72', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/WWRuvLKtTrJdKJ8qdygPWPPvL8O_u0nkP24IRLy9vrk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7afcdf79507c978f9a0ef15038dfeeda4d4dcf4b', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/WWRuvLKtTrJdKJ8qdygPWPPvL8O_u0nkP24IRLy9vrk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d3da6886253822cb8fd3c7e3d809f8d2f838de2', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/WWRuvLKtTrJdKJ8qdygPWPPvL8O_u0nkP24IRLy9vrk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ced0c5c570d54b72c4bf877ae58fb5421ade127', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'Q2gPNZkdN-1p8zoTkmJCOuyya3axs3VUS8adAG1BeKM'}], 'enabled': False}",,,,,,
907,,tensorflow,"Hi, I'm a beginner in python and Tensorflow. I'm interested in AI and machine learning. I have done some introductory courses online on ML. I want to participate in GSoC 2021. I know the basics of python and github, but I'm unable to decide what to do next to get into open source development or how to contribute to the community. Can anyone guide me how to get started? Can you guide me to resources/tips to get better chances at cracking GSoC?

PS: I'm completely lost. I don't know what to do with python by knowing just the basics like if/else statements, loops etc. and also I'm not able to do much in ML other than basic classification, regression tasks. Any help is highly appreciated. Thanks in advance.",t2_5o7kd0ho,False,,0,False,Help for GSoC preparation.,[],r/tensorflow,False,6,,0,,,False,t3_ijgcoe,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},,False,2,,False,self,False,,[],{},,True,,1598836449.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m a beginner in python and Tensorflow. I&amp;#39;m interested in AI and machine learning. I have done some introductory courses online on ML. I want to participate in GSoC 2021. I know the basics of python and github, but I&amp;#39;m unable to decide what to do next to get into open source development or how to contribute to the community. Can anyone guide me how to get started? Can you guide me to resources/tips to get better chances at cracking GSoC?&lt;/p&gt;

&lt;p&gt;PS: I&amp;#39;m completely lost. I don&amp;#39;t know what to do with python by knowing just the basics like if/else statements, loops etc. and also I&amp;#39;m not able to do much in ML other than basic classification, regression tasks. Any help is highly appreciated. Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ijgcoe,True,,slayerfx132,,2,True,all_ads,False,[],False,,/r/tensorflow/comments/ijgcoe/help_for_gsoc_preparation/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijgcoe/help_for_gsoc_preparation/,22217,1598807649.0,0,,False,,,,,,,,,
908,,tensorflow,"Hi I just tried to install TensorFlow for the first time in my laptop but what I got was

https://preview.redd.it/zagtuz91z4k51.png?width=1470&amp;format=png&amp;auto=webp&amp;s=9b32848ce9406ff1f22efaaf58f6c411132c4df9

I am having **AMD Radeon (TM) R5 M330.** if I have an Nvidia GPU I could install CUDA but What could I do now for AMD GPU?",t2_7esabl9k,False,,0,False,Installing TensorFlow for AMD GPU in Windows,[],r/tensorflow,False,6,,0,22.0,,False,t3_ijc7wr,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},Question,False,1,,False,https://b.thumbs.redditmedia.com/bBtm7K-JjKkSqfikUgaVSUhbXmQITtFUZFgOyEF9A_U.jpg,False,,[],{},,True,,1598820801.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi I just tried to install TensorFlow for the first time in my laptop but what I got was&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/zagtuz91z4k51.png?width=1470&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9b32848ce9406ff1f22efaaf58f6c411132c4df9""&gt;https://preview.redd.it/zagtuz91z4k51.png?width=1470&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9b32848ce9406ff1f22efaaf58f6c411132c4df9&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am having &lt;strong&gt;AMD Radeon (TM) R5 M330.&lt;/strong&gt; if I have an Nvidia GPU I could install CUDA but What could I do now for AMD GPU?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ijc7wr,True,,Adithya-Kannan,,5,True,all_ads,False,[],False,,/r/tensorflow/comments/ijc7wr/installing_tensorflow_for_amd_gpu_in_windows/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ijc7wr/installing_tensorflow_for_amd_gpu_in_windows/,22217,1598792001.0,0,,False,,,,,"{'zagtuz91z4k51': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 17, 'x': 108, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0d3b40048ad5df2d4b2e7159068ce251c34c0b6'}, {'y': 34, 'x': 216, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1a17f31ed56c3e1fdb2a00173b75f82bdc8d193'}, {'y': 50, 'x': 320, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc98b8e75b8b14ed426261df47ee4cdce033835f'}, {'y': 101, 'x': 640, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=320ccee379cfe1c073a5f7f4e4c26c625aae4baa'}, {'y': 152, 'x': 960, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b78d9e9f97df5a43d03ba840e169835b71d47747'}, {'y': 171, 'x': 1080, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87999922b7128880236aeedb100b26ff6c67e196'}], 's': {'y': 233, 'x': 1470, 'u': 'https://preview.redd.it/zagtuz91z4k51.png?width=1470&amp;format=png&amp;auto=webp&amp;s=9b32848ce9406ff1f22efaaf58f6c411132c4df9'}, 'id': 'zagtuz91z4k51'}}",,,,
909,,tensorflow,,t2_44mbtmjy,False,,0,False,State of the art in lip-syncing a talking face video!,[],r/tensorflow,False,6,,0,28.0,,False,t3_ij3du8,False,dark,1.0,,public,2,0,{},140.0,,False,[],,False,False,,{},,False,2,,False,https://b.thumbs.redditmedia.com/aLb3-5LwoSLdq-2Pd8FKOyE_ngSTDHuvHbxHMQKkcIg.jpg,False,,[],{},,False,,1598775786.0,text,6,,,text,self.LatestInML,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ij3du8,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ij3du8/state_of_the_art_in_lipsyncing_a_talking_face/,all_ads,False,/r/LatestInML/comments/ij326w/state_of_the_art_in_lipsyncing_a_talking_face/,22217,1598746986.0,0,,False,link,/r/LatestInML/comments/ij326w/state_of_the_art_in_lipsyncing_a_talking_face/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?auto=webp&amp;s=c6b4a4952b0d5958a1ee23175775b0888e3af850', 'width': 1256, 'height': 260}, 'resolutions': [{'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc28199f96944b105964ffecc941ba55ce38f972', 'width': 108, 'height': 22}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac387b5dbaf09f556d46fc4afbf15b0ce142cbee', 'width': 216, 'height': 44}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1cb92ece5baa3477f096cf0055a5253ff377a53', 'width': 320, 'height': 66}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=658d52f410e5cc3f615977ffb7ddcfcbcfc49dfe', 'width': 640, 'height': 132}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=029a760dfc6d27886ea0adf438eba7d16359f726', 'width': 960, 'height': 198}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae2ae5aa30793d03cf4a0d6c899aaa64a2b8c386', 'width': 1080, 'height': 223}], 'variants': {}, 'id': 'bgsfrs0KWgDkNbiz2DPur83aArfRHoebv1dokgiVsL4'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2008.10010)\n\n&amp;#x200B;\n\nhttps://reddit.com/link/ij326w/video/kyuixqdl51k51/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in lip-syncing a talking face video!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 28, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'kyuixqdl51k51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/ij326w/asset/kyuixqdl51k51/DASHPlaylist.mpd?a=1618044872%2CYzNkODIzY2FjNGIzNWIzOWYxNzE0OWVhMWRmMTliNzlmMzVkNzlhNjI0MTA4MjZkNWQ4Njc2NzM5ZjQzZmE1Yg%3D%3D&amp;v=1&amp;f=sd', 'x': 421, 'y': 240, 'hlsUrl': 'https://v.redd.it/link/ij326w/asset/kyuixqdl51k51/HLSPlaylist.m3u8?a=1618044872%2CNGViNWJjMjFhM2JlNmM3ZmFhYjlkZGI0YjEwZjg0NjllMmQ4ZGZlMjNkMmMyMzdjNWZlYmM3YWM0ZDVlZDVlNw%3D%3D&amp;v=1&amp;f=sd', 'id': 'kyuixqdl51k51', 'isGif': False}}, 'name': 't3_ij326w', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.77, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 7, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/aLb3-5LwoSLdq-2Pd8FKOyE_ngSTDHuvHbxHMQKkcIg.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1598774509.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2008.10010""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/ij326w/video/kyuixqdl51k51/player""&gt;https://reddit.com/link/ij326w/video/kyuixqdl51k51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?auto=webp&amp;s=c6b4a4952b0d5958a1ee23175775b0888e3af850', 'width': 1256, 'height': 260}, 'resolutions': [{'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc28199f96944b105964ffecc941ba55ce38f972', 'width': 108, 'height': 22}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac387b5dbaf09f556d46fc4afbf15b0ce142cbee', 'width': 216, 'height': 44}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1cb92ece5baa3477f096cf0055a5253ff377a53', 'width': 320, 'height': 66}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=658d52f410e5cc3f615977ffb7ddcfcbcfc49dfe', 'width': 640, 'height': 132}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=029a760dfc6d27886ea0adf438eba7d16359f726', 'width': 960, 'height': 198}, {'url': 'https://external-preview.redd.it/xtFs7g9kkWqXgZZ72wPdiJYKMUPMJ5AkAj4qm-gQUa0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae2ae5aa30793d03cf4a0d6c899aaa64a2b8c386', 'width': 1080, 'height': 223}], 'variants': {}, 'id': 'bgsfrs0KWgDkNbiz2DPur83aArfRHoebv1dokgiVsL4'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ij326w', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/ij326w/state_of_the_art_in_lipsyncing_a_talking_face/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/ij326w/state_of_the_art_in_lipsyncing_a_talking_face/', 'subreddit_subscribers': 6676, 'created_utc': 1598745709.0, 'num_crossposts': 14, 'media': None, 'is_video': False}]",t3_ij326w,
910,,tensorflow,"Hi, I have a list of tensorflow tensors(some of them constants, and some tf.Variables), of different shapes. How to I store a list of these lists, to easily feed them back to SGD.minimize type calculations, while using multiprocessing(this last bit is a problem I haven't been able to solve yet)",t2_2nvdpdl,False,,0,False,Storing a list of tensors(each of different shape),[],r/tensorflow,False,6,,0,,,False,t3_iix5cp,False,dark,1.0,,public,7,0,{},,,False,[],,False,False,,{},Question,False,7,,False,self,False,,[],{},,True,,1598753322.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I have a list of tensorflow tensors(some of them constants, and some tf.Variables), of different shapes. How to I store a list of these lists, to easily feed them back to SGD.minimize type calculations, while using multiprocessing(this last bit is a problem I haven&amp;#39;t been able to solve yet)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,iix5cp,True,,curtlytalks,,6,True,all_ads,False,[],False,,/r/tensorflow/comments/iix5cp/storing_a_list_of_tensorseach_of_different_shape/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iix5cp/storing_a_list_of_tensorseach_of_different_shape/,22217,1598724522.0,0,,False,,,,,,,,,
911,,tensorflow,,t2_2wsvqwhg,False,,0,False,"Google AI introduces TF-Coder, a program synthesis tool that helps you write TensorFlow code",[],r/tensorflow,False,6,,0,72.0,,False,t3_iih9z6,False,dark,1.0,,public,52,0,{},140.0,,False,[],,False,False,,{},Discussion,False,52,,False,https://a.thumbs.redditmedia.com/cmd9eW_GVXadpa4YOiBAosYQjCuZN7nW6wPOEjG0qF4.jpg,False,,[],{},,False,,1598683423.0,text,6,,,text,marktechpost.com,False,,,,,,True,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,iih9z6,True,,ai-lover,,1,True,all_ads,False,[],False,,/r/tensorflow/comments/iih9z6/google_ai_introduces_tfcoder_a_program_synthesis/,all_ads,False,https://www.marktechpost.com/2020/08/28/google-ai-introduces-tf-coder-a-program-synthesis-tool-that-helps-you-write-tensorflow-code/,22217,1598654623.0,0,,False,link,https://www.marktechpost.com/2020/08/28/google-ai-introduces-tf-coder-a-program-synthesis-tool-that-helps-you-write-tensorflow-code/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/R-cApTujUgbBHUiwDVNJ5Zxo44aL5SiqbQq_9IA-F0c.jpg?auto=webp&amp;s=9f49837cc16c7873698d6397e827a3b6b772adb8', 'width': 882, 'height': 457}, 'resolutions': [{'url': 'https://external-preview.redd.it/R-cApTujUgbBHUiwDVNJ5Zxo44aL5SiqbQq_9IA-F0c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e1e613c60cbbb3439aa9395fa271d28045aae57b', 'width': 108, 'height': 55}, {'url': 'https://external-preview.redd.it/R-cApTujUgbBHUiwDVNJ5Zxo44aL5SiqbQq_9IA-F0c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61b424964d9566567f154bd5a54e0a4ec84128b4', 'width': 216, 'height': 111}, {'url': 'https://external-preview.redd.it/R-cApTujUgbBHUiwDVNJ5Zxo44aL5SiqbQq_9IA-F0c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6169fe2c60cf6605e7f611eb553639a39d0b157f', 'width': 320, 'height': 165}, {'url': 'https://external-preview.redd.it/R-cApTujUgbBHUiwDVNJ5Zxo44aL5SiqbQq_9IA-F0c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e54588e21a5809760124373392b332a47ab0734', 'width': 640, 'height': 331}], 'variants': {}, 'id': 'i2Sx4yKw2-vmnWqzFWTf397xQYOHDBvam9wTcp1So4M'}], 'enabled': False}",,,,,,
912,,tensorflow,"Hi,

I'm quite fresh to machine learning and tensorflow but would love some idea of which direction to go on this one.

I have rough drawings and lidar scans of indoor maps, but I want to make basically ""nice"" looking maps from these scans and drawings.

My original idea was to use a CycleGAN and hand draw some of the maps myself as the truth. Then let it train itself on those.

What I don't know is if it would translate well to later use with brand new scans and drawings.

&amp;#x200B;

Any ideas or recommendations would be great. Thanks",t2_7to94,False,,0,False,Creating nice indoor maps from drawings,[],r/tensorflow,False,6,,0,,,False,t3_iirym9,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1598734730.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m quite fresh to machine learning and tensorflow but would love some idea of which direction to go on this one.&lt;/p&gt;

&lt;p&gt;I have rough drawings and lidar scans of indoor maps, but I want to make basically &amp;quot;nice&amp;quot; looking maps from these scans and drawings.&lt;/p&gt;

&lt;p&gt;My original idea was to use a CycleGAN and hand draw some of the maps myself as the truth. Then let it train itself on those.&lt;/p&gt;

&lt;p&gt;What I don&amp;#39;t know is if it would translate well to later use with brand new scans and drawings.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any ideas or recommendations would be great. Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iirym9,True,,mamoen,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/iirym9/creating_nice_indoor_maps_from_drawings/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/iirym9/creating_nice_indoor_maps_from_drawings/,22217,1598705930.0,0,,False,,,,,,,,,
913,,tensorflow,,t2_6wt510of,False,,0,False,StyleGAN2 generates Shrek,[],r/tensorflow,False,6,,0,105.0,,False,t3_iibrcd,False,dark,0.94,,public,29,0,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/LOHhT94tClM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",140.0,,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates Shrek Face (StyleGAN2)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/LOHhT94tClM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/LOHhT94tClM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/LOHhT94tClM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/iibrcd', 'height': 338}",,False,29,,False,https://a.thumbs.redditmedia.com/cr1qjLrDe0pGbGQGhhAETzRmlPoHVtyTtttVZgYVLr0.jpg,False,,[],{},,False,,1598665587.0,text,6,,,text,youtu.be,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,iibrcd,True,,Snoo_72253,,4,True,all_ads,False,[],False,,/r/tensorflow/comments/iibrcd/stylegan2_generates_shrek/,all_ads,False,https://youtu.be/LOHhT94tClM,22217,1598636787.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates Shrek Face (StyleGAN2)', 'type': 'video', 'thumbnail_width': 480, 'height': 338, 'width': 600, 'html': '&lt;iframe width=""600"" height=""338"" src=""https://www.youtube.com/embed/LOHhT94tClM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/LOHhT94tClM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,rich:video,https://youtu.be/LOHhT94tClM,"{'images': [{'source': {'url': 'https://external-preview.redd.it/EoG7kMa-MFsVCMko8tNq-k2uaA3izEkZugOS_bLqhU4.jpg?auto=webp&amp;s=61a4b613c61d7a3ea142b5a90189902b83fdc6fa', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/EoG7kMa-MFsVCMko8tNq-k2uaA3izEkZugOS_bLqhU4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b250e9b9bb08f7ccfc5698fe95bfd66fac830ccb', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/EoG7kMa-MFsVCMko8tNq-k2uaA3izEkZugOS_bLqhU4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1659baf0f82cfe24f26612ac7407fad0d29a9781', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/EoG7kMa-MFsVCMko8tNq-k2uaA3izEkZugOS_bLqhU4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c210e8b16d79323de501d5154484796a4ae88ef', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'KBGqTw-dUVS3GxcMspkUjiVnlzb_j5zkY2oPD4Yoy-M'}], 'enabled': False}",,,,,,
914,,tensorflow,,t2_hwubl,False,,0,False,TensorFlow for .NET Release Candidate,[],r/tensorflow,False,6,,0,,,False,t3_ii1ja3,False,dark,0.86,,public,10,0,{},,,False,[],,False,False,,{},,False,10,,False,default,False,,[],{},,False,,1598622400.0,text,6,,,text,self.csharp,False,,,,,,True,False,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ii1ja3,True,,lostmsu,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ii1ja3/tensorflow_for_net_release_candidate/,all_ads,False,/r/csharp/comments/ii1g5d/tensorflow_for_net_release_candidate/,22217,1598593600.0,0,,False,link,/r/csharp/comments/ii1g5d/tensorflow_for_net_release_candidate/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?auto=webp&amp;s=61daee0c3362c9c7ef987e9eac10f19c7cd5572a', 'width': 746, 'height': 605}, 'resolutions': [{'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fcbca77026a67cc02416a46e68683eb107d77f63', 'width': 108, 'height': 87}, {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b43d11e71c5dc67e782b47dec2e7ba79a92cda90', 'width': 216, 'height': 175}, {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16e2763a277691cc19c50e19642e2eb5f6edcbfd', 'width': 320, 'height': 259}, {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f27252630263cfdf6627258ca3d0010fc20d5c1a', 'width': 640, 'height': 519}], 'variants': {}, 'id': 'OrUuk05NWqr3BVWZfexrWuca6j8pxG16CfL1LGZaVeM'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'csharp', 'selftext': 'I am proud to announce the first Go-Live release candidate of our full [TensorFlow binding for .NET](https://ml.blogs.losttech.software/TF-1.15-Release-Candidate/).\n\nThe previous [preview announcement here](https://www.reddit.com/r/csharp/comments/bbiop5/gradient_full_tensorflow_binding_for_c/) was well-received, and has more background on the idea behind the project.\n\nTL;DR; you can now make and train your own deep learning models like GPT-2, BERT, YOLOv3+, or do reinforcement learning for robotics without leaving C# and the comfort of Visual Studio ( or Rider, whichever is your poison :) ). And yes, we are more powerful and faster, than TensorFlow.NET', 'author_fullname': 't2_hwubl', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'TensorFlow for .NET Release Candidate', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/csharp', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'news', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_ii1g5d', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.98, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 108, 'total_awards_received': 2, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'News', 'can_mod_post': False, 'score': 108, 'approved_by': None, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 1}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1598621966.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.csharp', 'allow_live_comments': True, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am proud to announce the first Go-Live release candidate of our full &lt;a href=""https://ml.blogs.losttech.software/TF-1.15-Release-Candidate/""&gt;TensorFlow binding for .NET&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The previous &lt;a href=""https://www.reddit.com/r/csharp/comments/bbiop5/gradient_full_tensorflow_binding_for_c/""&gt;preview announcement here&lt;/a&gt; was well-received, and has more background on the idea behind the project.&lt;/p&gt;\n\n&lt;p&gt;TL;DR; you can now make and train your own deep learning models like GPT-2, BERT, YOLOv3+, or do reinforcement learning for robotics without leaving C# and the comfort of Visual Studio ( or Rider, whichever is your poison :) ). And yes, we are more powerful and faster, than TensorFlow.NET&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?auto=webp&amp;s=61daee0c3362c9c7ef987e9eac10f19c7cd5572a', 'width': 746, 'height': 605}, 'resolutions': [{'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fcbca77026a67cc02416a46e68683eb107d77f63', 'width': 108, 'height': 87}, {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b43d11e71c5dc67e782b47dec2e7ba79a92cda90', 'width': 216, 'height': 175}, {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16e2763a277691cc19c50e19642e2eb5f6edcbfd', 'width': 320, 'height': 259}, {'url': 'https://external-preview.redd.it/bzoxsnp6UxmcO-OGH8MD0mfnrFLZCccilR2sxKTHPr4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f27252630263cfdf6627258ca3d0010fc20d5c1a', 'width': 640, 'height': 519}], 'variants': {}, 'id': 'OrUuk05NWqr3BVWZfexrWuca6j8pxG16CfL1LGZaVeM'}], 'enabled': False}, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'award_74fe5152-7906-4991-9016-bc2d8e261200', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': False, 'awardings_required_to_grant_benefits': None, 'description': ""I don't know what to do with my hands!"", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Excited', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=16&amp;height=16&amp;auto=webp&amp;s=094da86916604f4fc9f7f63c827e31c976f00928', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=32&amp;height=32&amp;auto=webp&amp;s=52886a42b9871ec69a4465609472a864dbab27b1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=48&amp;height=48&amp;auto=webp&amp;s=63a8f5eff627778a221c58daffbfbbb87b7fe350', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=64&amp;height=64&amp;auto=webp&amp;s=da0d9de08517646db45b766dbb0e7b94d2e97312', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png?width=128&amp;height=128&amp;auto=webp&amp;s=58d3501a4314be9d47349a1f7925e18f30a832e5', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/x069ow7ewnf51_Excited.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'e74ee3a2-e356-11e4-878f-22000b6f0317', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qhdf', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ii1g5d', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'lostmsu', 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/csharp/comments/ii1g5d/tensorflow_for_net_release_candidate/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/csharp/comments/ii1g5d/tensorflow_for_net_release_candidate/', 'subreddit_subscribers': 166999, 'created_utc': 1598593166.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_ii1g5d,
915,,tensorflow,"Hey, I have to implement a linear learning rate warmup which linearly increases the learning rate from 0 to 0.1 over k iterations for a neural network using TensorFLow 2 and Python 3.8. For example, k = 10000 training iterations/steps. Also, I am training a neural network model using tf.GradientTape. Any help for a tutorial or code demo is appreciated!

&amp;#x200B;

Thanks",t2_2mmql89p,False,,0,False,Linear learning rate warmup,[],r/tensorflow,False,6,,0,,,False,t3_ii5gux,False,dark,1.0,,public,1,0,{},,,False,[],,False,False,,{},,False,1,,False,self,False,,[],{},,True,,1598643472.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, I have to implement a linear learning rate warmup which linearly increases the learning rate from 0 to 0.1 over k iterations for a neural network using TensorFLow 2 and Python 3.8. For example, k = 10000 training iterations/steps. Also, I am training a neural network model using tf.GradientTape. Any help for a tutorial or code demo is appreciated!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ii5gux,True,,grid_world,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ii5gux/linear_learning_rate_warmup/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ii5gux/linear_learning_rate_warmup/,22217,1598614672.0,0,,False,,,,,,,,,
916,,tensorflow,"If anyone has (or you know someone who has) the developer certificate , I've got a few questions :

1. How hard is the exam and what kinda questions are asked ? because the syllabus is from the specialization course on coursera which seems pretty basic 
2. Was 5 hours enough to solve 5 questions ?
3. How long were you preparing for it ? 
4. Has it impacted your career ?",t2_16kcfa,False,,0,False,Has anyone attempted the tensorflow developer certificate exam ?,[],r/tensorflow,False,6,,0,,,False,t3_ihpyvy,False,dark,0.93,,public,12,0,{},,,False,[],,False,False,,{},Question,False,12,,False,self,False,,[],{},,True,,1598580041.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If anyone has (or you know someone who has) the developer certificate , I&amp;#39;ve got a few questions :&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How hard is the exam and what kinda questions are asked ? because the syllabus is from the specialization course on coursera which seems pretty basic &lt;/li&gt;
&lt;li&gt;Was 5 hours enough to solve 5 questions ?&lt;/li&gt;
&lt;li&gt;How long were you preparing for it ? &lt;/li&gt;
&lt;li&gt;Has it impacted your career ?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ihpyvy,True,,emphee12,,9,False,all_ads,False,[],False,,/r/tensorflow/comments/ihpyvy/has_anyone_attempted_the_tensorflow_developer/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ihpyvy/has_anyone_attempted_the_tensorflow_developer/,22217,1598551241.0,0,,False,,,,,,,,,
917,,tensorflow,,t2_44mbtmjy,False,,0,False,Create 3d photos from old photos as well!,[],r/tensorflow,False,6,,0,140.0,,False,t3_ihzlww,False,dark,1.0,,public,1,0,{},140.0,,False,[],,False,False,,{},,False,1,,False,https://b.thumbs.redditmedia.com/wtJARMzeY72J7XbDPic0qhiLfqKmF7p_s5wEmpowBZc.jpg,False,,[],{},,False,,1598613631.0,text,6,,,text,self.LatestInML,False,,,,,,True,True,False,False,False,[],[],False,,False,False,False,,[],False,,,,t5_3alkk,,,,ihzlww,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ihzlww/create_3d_photos_from_old_photos_as_well/,all_ads,False,/r/LatestInML/comments/ihzd7p/create_3d_photos_from_old_photos_as_well/,22217,1598584831.0,0,,False,link,/r/LatestInML/comments/ihzd7p/create_3d_photos_from_old_photos_as_well/,"{'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}",,,,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': 'For project and code/API/expert requests: [click here](https://www.catalyzex.com/paper/arxiv:2008.12298)\n\nhttps://reddit.com/link/ihzd7p/video/nzmopyhxsnj51/player', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Create 3d photos from old photos as well!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'nzmopyhxsnj51': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/ihzd7p/asset/nzmopyhxsnj51/DASHPlaylist.mpd?a=1618044872%2CY2RjZjM3ZmNlYWRhMDYyMDBhMjhjMmFiZjhiN2RjNGIyNTc2MGUzMDg3MWM1ZmUyYjEwNWNiNTUxYjdmMzFlYg%3D%3D&amp;v=1&amp;f=sd', 'x': 426, 'y': 239, 'hlsUrl': 'https://v.redd.it/link/ihzd7p/asset/nzmopyhxsnj51/HLSPlaylist.m3u8?a=1618044872%2CMjQ1MWE1M2Q4YjVmZTA2YzNkYTYzZWU5ZDU5MDIxOWM3MTVkNmNiOWNkY2U0NTliMWQzMGVlMjA1NTk0ZWU4YQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'nzmopyhxsnj51', 'isGif': False}}, 'name': 't3_ihzd7p', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.96, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 21, 'approved_by': None, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/wtJARMzeY72J7XbDPic0qhiLfqKmF7p_s5wEmpowBZc.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1598612631.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For project and code/API/expert requests: &lt;a href=""https://www.catalyzex.com/paper/arxiv:2008.12298""&gt;click here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/ihzd7p/video/nzmopyhxsnj51/player""&gt;https://reddit.com/link/ihzd7p/video/nzmopyhxsnj51/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?auto=webp&amp;s=4433271552041dbb48641eeab7fc92329936ded0', 'width': 466, 'height': 466}, 'resolutions': [{'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9b7cabdef09304877213eb836fa68de9ba16b40', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38a6011d4229584591143498e125f4d4ca61d27d', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/VrDWnS5ZDDoFvQICvZOWZ881K5C96wjYsp-cQ33a-jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=624b9fd4d910a83d7d2cc43056a728e8ee1a0969', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'X4W47ha8bZrbpA5MgJZUopc3rjrPepNW7LlZStVXlZc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ihzd7p', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/ihzd7p/create_3d_photos_from_old_photos_as_well/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/ihzd7p/create_3d_photos_from_old_photos_as_well/', 'subreddit_subscribers': 6676, 'created_utc': 1598583831.0, 'num_crossposts': 12, 'media': None, 'is_video': False}]",t3_ihzd7p,
918,,tensorflow," I'm building a LSTM ANN and I'm not sure of using generator in my case. The net should have several hyperparameters it should iterate, e.g. epochs, activation functions..., however, if the generator is used in this case, each iteration is trained on different set, right? So more correct is using list or array instead? Thank you 

I mean, it shoul iterate like this:

 

    for epoch in EPOCHS do:
        for activation in ACTIVATION do:
            trainLSTM(epoch, activation)
            save best model",t2_6deupbic,False,,0,False,When to use generator TensorFlow in time series,[],r/tensorflow,False,6,,0,,,False,t3_ihu5gd,False,dark,1.0,,public,2,0,{},,,False,[],,False,False,,{},Question,False,2,,False,self,False,,[],{},,True,,1598593038.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building a LSTM ANN and I&amp;#39;m not sure of using generator in my case. The net should have several hyperparameters it should iterate, e.g. epochs, activation functions..., however, if the generator is used in this case, each iteration is trained on different set, right? So more correct is using list or array instead? Thank you &lt;/p&gt;

&lt;p&gt;I mean, it shoul iterate like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for epoch in EPOCHS do:
    for activation in ACTIVATION do:
        trainLSTM(epoch, activation)
        save best model
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,187eeff2-afc0-11e7-822b-0e48d05df30a,False,False,False,,[],False,,,,t5_3alkk,,,,ihu5gd,True,,Fuzzy-Pen7805,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ihu5gd/when_to_use_generator_tensorflow_in_time_series/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ihu5gd/when_to_use_generator_tensorflow_in_time_series/,22217,1598564238.0,0,,False,,,,,,,,,
919,,tensorflow,"We live in a world engulfed with digital (audio) signals 🎧 🎧. To make sense of these signals, we can’t use the (Continuous) Fourier Transform. We should adapt this powerful tool to the digital domain. Hence, the Digital Fourier Transform (DFT). Discover the secrets of DFT in my new video!

This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.

Here’s the video:

[https://www.youtube.com/watch?v=ZUi\_jdOyxIQ&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=13](https://www.youtube.com/watch?v=ZUi_jdOyxIQ&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=13)",t2_12ahau,False,,0,False,I published a video where I explain the Discrete Fourier Transform in the context of audio data,[],r/tensorflow,False,6,,0,,,False,t3_ihies9,False,dark,1.0,,public,5,0,{},,,False,[],,False,False,,{},Discussion,False,5,,False,self,False,,[],{},,True,,1598551886.0,text,6,,,text,self.tensorflow,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We live in a world engulfed with digital (audio) signals 🎧 🎧. To make sense of these signals, we can’t use the (Continuous) Fourier Transform. We should adapt this powerful tool to the digital domain. Hence, the Digital Fourier Transform (DFT). Discover the secrets of DFT in my new video!&lt;/p&gt;

&lt;p&gt;This video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data 🎧 and extract relevant audio features for your machine learning applications 🤖🤖.&lt;/p&gt;

&lt;p&gt;Here’s the video:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=ZUi_jdOyxIQ&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=13""&gt;https://www.youtube.com/watch?v=ZUi_jdOyxIQ&amp;amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;amp;index=13&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,True,False,False,False,False,[],[],False,1db20040-afc0-11e7-b8c9-0e6c50199bd0,False,False,False,,[],False,,,,t5_3alkk,,,,ihies9,True,,diabulusInMusica,,0,True,all_ads,False,[],False,,/r/tensorflow/comments/ihies9/i_published_a_video_where_i_explain_the_discrete/,all_ads,False,https://www.reddit.com/r/tensorflow/comments/ihies9/i_published_a_video_where_i_explain_the_discrete/,22217,1598523086.0,0,,False,self,,"{'images': [{'source': {'url': 'https://external-preview.redd.it/xBKi9ujnEUw7rY-rV_hOOqFDtzPXfh7yVw0CaeaUfes.jpg?auto=webp&amp;s=761535abb96ee95555ec5dd733fbfd44a8f6fa9a', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/xBKi9ujnEUw7rY-rV_hOOqFDtzPXfh7yVw0CaeaUfes.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d8ea290cd014901238a2a2becc4412ebad51857', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/xBKi9ujnEUw7rY-rV_hOOqFDtzPXfh7yVw0CaeaUfes.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=104d76e8a87771994548144bc4da610124c3aad3', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/xBKi9ujnEUw7rY-rV_hOOqFDtzPXfh7yVw0CaeaUfes.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e27cbafc5ef560d0117e43f74b7efc9eb7d578f9', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'eikKt4vaoaqYrgFl5lVJWHJSbFvqt9-SsFtmG4K6JNQ'}], 'enabled': False}",,,,,,
